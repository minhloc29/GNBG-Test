2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:04:56 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 198, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_prompt_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLM.sample_solution() got an unexpected keyword argument 'role_prompt_index'
.
2025-06-15 08:05:02 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:02 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:02 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:02 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:03 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:03 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:04 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:04 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:04 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:04 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:04 ERROR Can not run the algorithm
2025-06-15 08:05:05 INFO Run function 8 complete. FEHistory len: 600, AOCC: 0.0000
2025-06-15 08:05:05 INFO FeHistory: [112642.36481177 217564.12811651 181525.4321116  256639.09735532
 189497.44833966 224544.54551098 184946.88348389 192725.88787207
  95627.8338268  111385.22842231 152241.90545226 153477.34424733
 193894.24179835 198472.48879683 195383.26838451 205647.61421738
 170178.71001505 165351.35172345 227807.10281839 199832.08774644
 180469.48864117 168932.45892109 153118.02704398 166042.19602802
 124017.90687718 275423.07584198 157481.22683879 148867.35710504
 166167.95759315 186272.05157214 142649.83405901 176885.50483622
 240425.11277154 237705.78894126 166739.18817332 211138.78485157
 149536.87116849 179611.90873197  98881.75775914 133686.55083896
 115102.29975804 190218.31659292 194197.72492813 216251.9647628
  59684.56977516 214756.04927024 139395.45418066 208526.51281996
 263981.48840856 265467.7596608  211402.23525919 171463.81280113
  86495.87137836 210117.96153573 195825.8987221  135096.40311146
 205380.76808525 150827.07798017 186700.31754034 150713.10722859
 150027.54814134 180564.81452382 313375.20643902 204956.38671746
 263409.72719333 139256.87295739 213006.63817405 160506.70207854
 228824.17381604 194102.41575376 203743.02904243 158251.43823352
 130458.70581818 281864.60349712 153287.85696133 106253.4418383
 152906.5063385  194555.54474236 173039.40522519 119247.71721812
 248357.32197457 177027.41408126 170252.13416779 270973.89326472
 192603.52269176 169286.46957883 227139.67834058 151519.39380324
 308566.19779369 170997.70221897 165040.30963666 267651.53558234
 174120.23503639 304228.93279427 269577.51663008 113322.96193898
 196964.61951453 136482.14674683 201104.32960029 305878.94272148
 230047.71451332 230744.05415958 172194.58928109 214574.43481455
 231022.60361534 201632.64933637 162914.30559076 199568.47276051
 127970.54280278 203696.35637373 216738.05079165 134196.88503889
 151838.04606779 177109.88966416 198859.53734913 314543.11955728
 187291.95945876 172044.82532502 151039.92025933 151106.47891102
 174173.56786139 174714.86528738 222035.84659374 229313.69485669
 140210.99661378 142635.55734217 246570.71673464 222545.25473213
  91533.21631797 290742.74531903 127982.51640025 249217.53381804
 226270.85540468 210564.89431599 176300.85544963 166674.17326576
 190248.23191464 206398.4344205  166790.14464074 241787.70918854
 189211.9572984  299658.27718246 178055.81301617 180971.16800188
 157806.62185905 266272.98619218 124461.75563284 230932.28507683
 235496.93892117 132396.9389282  152777.52846143 199670.6485801
 248075.65734606 199591.05669224 257732.91041715 157207.11022094
 193730.87572797 163274.05362506 208123.48587911 203803.54794102
 134546.07500708 272831.5789183  157413.9642966  268280.09090428
 176488.26960328 137224.13635368 206850.56519686 175319.58417058
 139152.52590385 279538.01813375 271438.84484403 175747.35743169
 205371.78464579 229286.67925831 214896.94990203 220610.36738843
 150955.40343568 224965.69755711 128493.35207403 171129.19398953
 284932.04991051 311443.60653356 137202.37016711 212433.0903102
 206119.0945369  138426.59025207 205613.84994142 210903.23181741
 189653.43863472 173597.75619789 232030.22939436 184867.36738093
 303400.1004352  162359.81050863 134728.36393812 222327.04519638
 186386.80175969 167606.07135802  87374.77069758 160083.03957626
 202769.58957355 286207.64163903 130410.29556182 178443.61871868
 266692.46282388 309596.57467049 125897.93723054 116747.51179841
 127720.58095262  89788.65065776 205330.01615314 203376.71634244
 163393.5165962  172460.74045592 103430.42741769 223680.1378445
 115960.36840736 183628.23536504  75521.02101285 171581.50702739
 213104.43452572 155406.95403634 252386.38534771 137944.57638306
 223101.32381696 197865.4594808  162275.14907559 202548.27898493
 144685.71598749 153228.70447725 187798.54443531 156178.56216519
 229729.4467402  131754.35037214 125822.42102134 207347.80275436
 269571.18834019 214325.6776625  239726.12045062 178618.32050796
  98936.09107761 200831.66126292 182315.45241753 239220.10175949
 221751.06046643 146824.70144182 222257.46114649 252855.40523372
 156783.12674286 200563.95337272 216123.41006703 178848.41929085
 204868.50349765 203071.80531081 189972.64974387 243471.07477487
 216207.38921432 255821.16715778 120447.24416236 216697.77594874
 154128.97829348 194288.57616084 290496.28033186 248088.20843477
 216611.59274818 208449.63307726 246567.56631102 220515.96090839
 205690.64347304 123865.09399785 240943.10333452 179378.89671485
 306006.83488993 226421.99717661 147033.68743883 202701.95169078
 221703.44370047 248399.33048762 244819.71886803 124149.29700352
 260563.9992781  217765.91074599 167175.46656976 251839.80649065
 267050.81811198 252621.83647243 127634.97708151 111571.76244269
 210361.20431701 182225.79443361 305746.8105726  139036.50355618
 246116.36425548 169825.56265905 275060.39472519 170201.32871811
 131941.64008538 162498.25788815 216062.58867517 127317.81289896
 155149.2840504  224643.86759194 213082.59286677 258858.19475064
 210306.56960486 379576.75763337 257553.76750975 212954.68740404
 249255.16461226 107337.30687895 157063.65400412 110920.67670461
 266226.8061547  169138.55793904 167510.04126427 285110.86854051
 200884.64133951 189165.64758704 224801.51117259 201005.49545767
 229326.57946002 203346.96214878 181908.64730647 249817.96945417
 216822.81235571 246136.14776307 218604.33972011 226765.16614407
 210553.3475899  126965.52572683 228273.3268342  205717.02718167
 317299.98579648 212804.11151338 179985.56779101 284100.08169773
 232042.60759548 170996.98442033 153884.79468178 192301.35261787
 191254.05534707 213258.04294918 256790.04009875 245726.04896842
 118472.01162044 247452.45195215 171809.14958063 329596.12775084
 281107.31809307 332291.78954234 370659.06557749 323853.58446949
 154798.73159873 294984.71320283 299643.16801594 186916.281928
 134102.33555568 246775.37876492 166981.55090028 284943.99568703
 166290.99497183 173692.41892387 255245.22467754 179901.09743443
 219181.99147891 170388.36292254 295694.25003279 231082.72490803
 251823.00522222 241831.14941511 155191.72958275 277237.81078617
 153232.80024313 282202.77903994 214901.54253094 180876.3392037
 182457.04037819 136376.8337019  202491.23262064 179660.80603983
 293898.69519533 262255.48057208 197385.55571277 311217.17066643
 159285.22933066 252776.80271317 157766.5653193  219383.40847095
 273753.37171387 150676.98429061 245302.14205669 252829.30090575
 196968.16042304 266082.20487369 269766.25531193 135386.3487289
 153927.1883977  122608.7198969  266329.49680394 340590.57440397
 137481.75145754 176133.04886946 162878.89243498 198107.90272136
 183001.04578494 168317.2243325  250544.36600632 207465.25299534
 204270.35057692 308548.44040153 219566.18255023 181312.91052017
 279616.95709317 215669.57208495 194416.50520831 362566.27511541
 189904.51357191 182955.48101079 207844.78800199 202537.3657196
 211642.53539246 230768.182261   187832.26940411 223257.80166924
 174471.00627606 152614.65821864 445629.21501753 222338.34527712
 152749.19961366 169570.66502108 156276.08598511 343366.9198883
 136024.58915175 118129.00081854 145942.25578588 315039.46572488
 114041.44653589 222575.78543981 261504.98320633 279493.92885465
 217438.78239144 276255.86060483 163358.58954772 172527.35475658
 220908.5158175  196665.63454546 104289.28787269 307995.08570453
 250864.50355033 110041.19663359 256726.99932735 178408.18835263
 243991.13850354 297504.73252794 244311.83243007 200706.14167165
 263124.8525589  146668.75186907 165277.9239415  332084.23813405
 249554.82804363 193927.20722398 286397.63584174 169103.98297247
 165265.8066637  180161.14903231 231304.77362508 185683.18638949
 148681.26621124 255793.21636026 232030.86605316 224335.2354182
 140790.21752161 210847.62305988 263442.28095342 233097.04791621
 142883.5227341  189884.7570967   97103.94332199 211365.29870747
 256955.22666041 386727.66497993 163615.38907751 249664.93617189
 203963.15772208 201854.12928188 196391.28919466 222685.34084943
 224277.07468661 257008.21801758 313004.88879042 276288.75717882
 242169.87111394 153770.01757961 199903.89407104 283903.36507365
 187408.26044016 165315.20062645 185692.96603871 222092.71745412
 262541.9862947  321370.26584279 169574.85948278 184927.05214269
 208948.87374367 254148.6624851  153940.71401559 179821.6823674
 208504.58340043 173891.5852291  131243.50557067 218042.83566748
 193566.45042228 273844.73670801 186589.81951957 181327.42490738
 229924.0876628  273686.1928846  207351.19853918 157463.05653014
 212180.86720189 246530.81236503 163128.80073557 128253.58149055
 304686.74386691 286276.28353468 157189.13459551 206654.74152638
 212910.23980532 252626.72560338 211145.63711697 200820.34595296
 229890.44162438 195600.33492961 257541.91852073 218612.58019208
 233875.8624179  231895.3076641  134229.98153128 128707.87934461
 124407.25249923 158160.96064916 204627.69197903 198118.20561187
 286770.7104763  172982.89124566 261466.40822379 250940.16923072
 180800.83920823 180807.43596224 162953.82719824 148539.34476555
 168292.39737901 216415.57262394 196379.44170796 315268.15909224
 247676.39333967 283740.53268826 350901.15857302 284290.69431812
 188203.03563731 254447.02588387 313147.57756132 361813.83267151
 195356.15939412 203428.06759028 180959.98616702 180805.51660075
 212404.88909164 192663.06327378 264052.24165116 176924.76078265
 344632.35996258 303440.1548247  217135.97562768 243676.5116437
 231546.77559919 224528.19593432 259024.68727783 247630.34079449
 217804.43598231 277469.18491404 195977.72669298 273252.15026037
 225529.24472162 362781.9658288  221057.72445356 160732.42617139
 174410.33542932 158432.38309275 372894.34784331 175793.97441616
 210185.39496134 143722.09943339 320614.20310692 179462.39445316
 172750.02421588 132733.89583841 253295.38560031 145683.6412672 ]
2025-06-15 08:05:05 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:05 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:05 INFO AOCC mean: 0.0000
2025-06-15 08:05:08 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:08 INFO FeHistory: [309334.48326154 312764.95788035 293443.482309   ... 403600.69581818
 429983.65258347 393862.52431983]
2025-06-15 08:05:08 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:08 INFO AOCC mean: 0.0000
2025-06-15 08:05:08 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:08 INFO FeHistory: [173308.45751188 145681.84170677 253672.88157816 ...  69727.23717474
  69727.23717474  69727.23717474]
2025-06-15 08:05:08 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:08 INFO AOCC mean: 0.0000
2025-06-15 08:05:08 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:08 INFO FeHistory: [205618.72256793 314801.18631847 299255.28061045 ...  88042.52322343
 104824.04932736  74704.88778214]
2025-06-15 08:05:08 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:08 INFO AOCC mean: 0.0000
2025-06-15 08:05:08 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:08 INFO FeHistory: [180773.93835865 179950.61198822 177433.37159427 ...  68236.7386762
  71104.02152598  70969.68718011]
2025-06-15 08:05:08 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:08 INFO AOCC mean: 0.0000
2025-06-15 08:05:09 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:09 INFO FeHistory: [193945.05693598 174190.26466268 138201.39348065 ... 235845.96119774
  54391.67858743 196131.52762477]
2025-06-15 08:05:09 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:09 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:09 INFO AOCC mean: 0.0000
2025-06-15 08:05:09 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:09 INFO FeHistory: [178953.84619178 162710.31521862 131842.64574984 ... 467315.0322026
 320248.63243368 377572.16319818]
2025-06-15 08:05:09 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:09 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:09 INFO AOCC mean: 0.0000
2025-06-15 08:05:10 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:10 INFO FeHistory: [194423.60575812 138482.01186132 252726.12418973 ...   8799.57475598
   8799.57475598   8799.57475598]
2025-06-15 08:05:10 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:10 INFO AOCC mean: 0.0000
2025-06-15 08:05:10 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:10 INFO FeHistory: [227105.37819936 196228.41451154 169506.4258942  ... 181601.1627791
 215850.62199503 202953.91190255]
2025-06-15 08:05:10 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:10 INFO AOCC mean: 0.0000
2025-06-15 08:05:10 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:10 INFO FeHistory: [166992.49006365 102200.5946233  213111.99699446 ...  48557.61504903
  42139.65343971  38393.39379227]
2025-06-15 08:05:10 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:10 INFO AOCC mean: 0.0000
2025-06-15 08:05:11 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 48
}
]
.
2025-06-15 08:05:11 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 48
}
]
.
2025-06-15 08:05:11 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 48
}
]
.
2025-06-15 08:05:11 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 48
}
]
.
2025-06-15 08:05:15 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:15 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:05:20 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:20 INFO FeHistory: [172803.93343891 133268.71802983 275330.497058   ... 119555.58062594
 190799.91070956 326304.89983722]
2025-06-15 08:05:20 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:20 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:20 INFO AOCC mean: 0.0000
2025-06-15 08:05:20 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:20 INFO FeHistory: [171364.86022918 167411.03506489 175696.7912184  ... 308200.27240637
 408450.0449952  423994.79331275]
2025-06-15 08:05:20 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:20 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:20 INFO AOCC mean: 0.0000
2025-06-15 08:05:20 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:20 INFO FeHistory: [129701.95839887 131262.54491353 139235.23870935 ...  71759.03621295
  71759.03621295  71759.03621295]
2025-06-15 08:05:20 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:20 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:20 INFO AOCC mean: 0.0000
2025-06-15 08:05:20 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:20 INFO FeHistory: [212849.86281214 203671.82623918 204568.09363377 ...  75482.32383411
  75482.32383411  75482.32383411]
2025-06-15 08:05:20 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:20 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:20 INFO AOCC mean: 0.0000
2025-06-15 08:05:21 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:21 INFO FeHistory: [224249.13881528 207885.75748179 227469.09805288 ... 281506.72265659
 420910.28429646 356972.28369513]
2025-06-15 08:05:21 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:21 INFO AOCC mean: 0.0000
2025-06-15 08:05:21 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:05:21 INFO FeHistory: [156052.02550062 154292.71947782 161831.52335166 ... 124025.58197215
  90571.88600633 103875.81695872]
2025-06-15 08:05:21 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:05:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:05:21 INFO AOCC mean: 0.0000
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
2025-06-15 08:05:21 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 367, in evolve_solution
    evolved_individual = self.llm.sample_solution(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 277, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 38
}
]
.
