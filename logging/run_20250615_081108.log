2025-06-15 08:11:15 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:15 ERROR Can not run the algorithm
2025-06-15 08:11:15 INFO Run function 8 complete. FEHistory len: 5, AOCC: 0.0000
2025-06-15 08:11:15 INFO FeHistory: [204021.58461695 240908.31727189 165209.71631638 184260.53808587
 130121.09487125]
2025-06-15 08:11:15 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:15 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:15 INFO AOCC mean: 0.0000
2025-06-15 08:11:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:17 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:17 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:17 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:17 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:19 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:19 ERROR Can not run the algorithm
2025-06-15 08:11:19 INFO Run function 8 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-15 08:11:19 INFO FeHistory: [230426.08819301 158754.00594438 134582.6486842  191833.26895777
 163747.94812913 237963.44314671 232573.88116201 139553.67846805
 221206.28371776 146151.56009749 285160.56985195 123935.36456815
 172154.17757176 192200.35870519 164054.1161748  210615.58362382
 151749.74982506 147892.96440755 100388.53097248 199163.13833592
 122374.30832098 125490.06438429 145063.25220273 102402.73396602
 244972.58530112 164580.53381584 149536.77727765 294556.87952926
 110679.10817084 252482.13301797 209785.65623467 202573.35018639
 131173.53940076 219709.58424494 184357.32249364 218291.02025578
 193120.60749565 283216.90151937 129374.50358189 167745.17701784
 144961.46592237 142781.56505223 244494.6877539  199226.21831668
 187266.03711784 202927.89264536 165770.67486972 134760.74690421
 214176.69479754 154969.0395444  287796.11567539 213064.39475714
 180647.18584706 119827.29507141 189557.46517988 181091.94251458
 217625.35351233 139757.09692396 216075.31289532 325791.67173829
 185718.16190312 213236.03731091 147920.06024411 178111.05582862
 205722.2037563  213898.0911539  177928.19418734 121354.72813279
 187431.38022971 197011.29690211 150852.18800951 166673.49452481
 216377.97670061 157055.14296444 214750.94034465 105401.10868701
 170796.99278696 211765.79470122 228668.42231696 201420.85068161
 163434.39012661 153741.20728593 137455.48242644 204251.21652128
 296921.95194671 176423.82971228 190576.03757605 121947.88830368
 242103.69082221 212236.83238504 234332.72291722 215655.95540018
 170252.27068034 233470.29135395 133167.41800544 256543.59889558
 150801.76008102 185216.46437134 159371.0495591  252137.1530815
 173832.25816244 146891.05347681 200610.65503682 197719.8426294
 115357.07414625 269754.21182294 171321.6671833  103206.9752232
 219425.81723419 163847.94008749 188606.42725191 223619.32330697
 226727.91489323 253506.69610515 253158.87419792 207952.63455129
 229060.90854573 125192.63174274 136199.83574129 216699.03758752
 243184.90077069 230100.08854072 189306.16162145 149089.77290557
 190355.06952187 234431.93497447 249923.35103352 324412.71227793
 120536.35522502 223951.8643395  269337.95610067 201187.6492519
 181859.10101526 161024.80031521 176519.47998095 158718.95116505
 260691.41876313 190734.7034164  187578.66099621 229482.49408329
 258937.29453803 125115.83233702 229286.0045309  183510.97406077
 228082.69216094 121124.65575892 268515.36861432 261159.23956678
 132304.08747763 199536.61869789 140346.77661635 167874.70262951
 181329.49879436 134163.0771129  219866.70122158 176037.57015865
 184388.58466421 210185.79955331 193688.60512824 182008.43638326
 268195.36486576  93980.15656259 179190.32739031 206585.29176407
 212447.74113492 198815.80215466 237300.98842123 140348.96764175
 157307.8003437  148357.85092773  80063.73024317 166246.31374763
 266328.90404861 291189.27788736 154160.03960219 276487.86721962
 223233.35906939 223311.58972135 178679.65530053 103106.32757938
 330968.80992693 200994.58759603 148313.5174217  130693.38844162
 241946.95637202 124649.20017084 212239.30313192 129513.69257462
 163748.8936666  235386.88494561 259490.63486371 145878.9032445
 159758.55307187 265990.34970808 232665.61237344 155981.73702584
 169419.50156595 144575.36280774 191138.3348069  296186.72651813
 231512.16627508 204729.51438371 210331.90565395 200294.78176041
 189732.07871948 186871.49826262 105465.22198092 185248.967878
 170468.42839321 210194.41803174 178729.70803261 131453.8940674
 164068.87327306 224115.80912681 192469.72816741 179628.00071137
 206973.7739218  147891.19478758 166300.62570599 196835.20290422
 172814.00190551 203184.69586792 221679.5154231  171991.92756242
 130865.74991287 183737.50635737 169605.50233066 123972.5878765
 257927.30628867 168921.57940037 221499.78004646 272121.83561387
 157890.66019309 137368.80288501 174749.94947151 186884.74398785
 204332.43704969 161515.91515413 240446.09270591 274050.26967169
 108105.9714593  211623.66317277 197014.49330002 235946.74154597
 250287.19769106 185781.31841774 244511.94481737 136844.15220616
 140309.48216264 228702.64788459 183217.83946191 206767.30164923
 189036.80556037 243461.634579   251477.5359539  224448.33565169
 225739.69699356 124977.81758788 147208.16578659 409289.149162
 192640.49771828 223390.99159687 220388.77679101 238435.30591706
 235491.86195394 180090.43696964 267130.26357923 131476.07350907
 186371.98185644 133495.33495789 110716.3930012  274130.00174644
 196921.28417155 221978.71340223 171688.78862391 173892.02027012
 297503.22332583 215655.83532021 244247.90360675 159985.38540114
 220572.58626307 170164.75985057 245973.49535546 288822.74104765
 206968.76884276 144773.3708374  257675.17678203 166075.94720956
 166350.32864164 161911.59777265 254886.81219291 135253.76779164
 177793.97004798 216453.64518351 282979.8511636  176471.11281156
 227143.54348093 242785.14269755 255897.37196213 191809.68904509]
2025-06-15 08:11:19 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:19 INFO AOCC mean: 0.0000
2025-06-15 08:11:19 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:19 ERROR Can not run the algorithm
2025-06-15 08:11:20 INFO Run function 8 complete. FEHistory len: 20, AOCC: 0.0000
2025-06-15 08:11:20 INFO FeHistory: [239225.48433743 267164.29855016 227863.8858624  156880.40296216
 155583.85873745 187617.38680058 131802.40640243 141209.92593884
 121322.83677249 224483.27699945 254450.43402074 217546.10690927
 274281.42939872 235078.48623189 135802.96445539 203646.44937379
 205332.14311524 144624.23429128 125681.97325471 224022.63517345]
2025-06-15 08:11:20 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:20 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:20 INFO AOCC mean: 0.0000
2025-06-15 08:11:20 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:11:20 INFO FeHistory: [ 74594.18631272 248369.12110215 172123.84300152 ... 267843.3894636
 323304.01245511 277858.64331655]
2025-06-15 08:11:20 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:20 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:20 INFO AOCC mean: 0.0000
2025-06-15 08:11:23 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:11:23 INFO FeHistory: [199568.75244678 152461.30376314 269970.31446941 ...  64167.48986393
  43365.63860113  37393.89395914]
2025-06-15 08:11:23 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:23 INFO AOCC mean: 0.0000
2025-06-15 08:11:23 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:11:23 INFO FeHistory: [195025.41162375 219405.87523527 111588.63815971 ... 183382.02018288
  81850.11960475  43981.88540545]
2025-06-15 08:11:23 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:23 INFO AOCC mean: 0.0000
2025-06-15 08:11:23 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.2613
2025-06-15 08:11:23 INFO FeHistory: [138665.0101347  123739.44658494 216431.30257827 ...   -656.7889712
   -656.78895934   -656.78897096]
2025-06-15 08:11:23 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:23 INFO Multimodal (single component) AOCC mean: 0.2613
2025-06-15 08:11:23 INFO AOCC mean: 0.2613
2025-06-15 08:11:23 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:24 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 35
}
]
.
2025-06-15 08:11:24 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 35
}
]
.
2025-06-15 08:11:25 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 34
}
]
.
2025-06-15 08:11:26 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 34
}
]
.
2025-06-15 08:11:26 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:26 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 33
}
]
.
2025-06-15 08:11:27 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 32
}
]
.
2025-06-15 08:11:27 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 32
}
]
.
2025-06-15 08:11:28 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:11:28 INFO FeHistory: [200525.54147267 245895.0059186  148104.44741855 ...  49121.92037468
  48771.52299653  49151.96234941]
2025-06-15 08:11:28 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:28 INFO AOCC mean: 0.0000
2025-06-15 08:11:28 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 31
}
]
.
2025-06-15 08:11:28 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:28 INFO Run function 8 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-15 08:11:28 INFO FeHistory: [383857.07838992]
2025-06-15 08:11:28 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:28 INFO AOCC mean: 0.0000
2025-06-15 08:11:28 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 31
}
]
.
2025-06-15 08:11:28 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 31
}
]
.
2025-06-15 08:11:28 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 31
}
]
.
2025-06-15 08:11:28 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:11:28 INFO FeHistory: [228632.96129525 145828.77074403 254193.43244665 ...  71311.18089433
  61810.83701341  65555.33358584]
2025-06-15 08:11:28 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:28 INFO AOCC mean: 0.0000
2025-06-15 08:11:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:11:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:11:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:11:30 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:11:30 INFO FeHistory: [299971.82675479 172123.73010697 344698.8793104  ...  12402.3028245
  12392.80400474  12446.57292074]
2025-06-15 08:11:30 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:30 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:30 INFO AOCC mean: 0.0000
2025-06-15 08:11:30 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:30 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:30 ERROR Can not run the algorithm
2025-06-15 08:11:31 INFO Run function 8 complete. FEHistory len: 1170, AOCC: 0.0000
2025-06-15 08:11:31 INFO FeHistory: [132756.64810367 133938.57397386 257549.27067608 ... 142227.89303106
 142227.89303106 142227.89303106]
2025-06-15 08:11:31 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:31 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:31 INFO AOCC mean: 0.0000
2025-06-15 08:11:32 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:11:32 ERROR Can not run the algorithm
2025-06-15 08:11:32 INFO Run function 8 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-15 08:11:32 INFO FeHistory: [150081.14605351 166635.33972372 184937.82710856 144292.80855248
 153154.35786198 226550.23596047 163635.29487998 301784.26873777
 181736.55045493 170081.60685128 194408.80649859 139369.44639015
 158411.39438788 158244.46293458 149854.50380264 198547.25768409
 196979.21565171 221322.49660369 164550.80072604 163508.06715693
 192195.88215698 197350.69046386 138567.81890154 181572.56913677
 123519.79675175 173773.61020115 188157.45097977 148783.96052871
 148294.50058069 173569.69599841 136778.68604384 303599.64461235
 169951.86020913  89250.0476902  212846.22842798 132462.98404409
 263219.41946714 153655.72256668 217065.53744499 253390.07283337
 240949.2655374  202948.59865057 191437.92781159 132566.31326109
 149962.592116   135748.83256489 127196.52346929 245099.70925831
 204067.71471105 191537.23130333 136467.59898598 237425.80137984
 191290.37883116 176855.10184014 140599.27073549 182171.39525738
 202993.61154237 214853.80394481 170838.41475528 157180.06670247
 196031.95718645 195595.68275422 204188.75034213 166464.0813404
 200855.90626316 211035.62543347 206397.26768236 272482.48668438
 153521.55691836 177180.80533504 233024.35570194 241450.54447228
 125793.98931247 210058.12133978 216058.33801167 178838.29530917
 124434.55781641 184594.96800212 118894.01581074 214321.63314096
 228376.30049955 307277.42293197 126211.40367644 168718.77751469
 153204.29023144 161471.43137667 176606.78995946 302519.62313509
 163603.2763839  139269.8937395  227275.01988193 269757.36558261
 165644.34506526 159525.173748   274443.18021082 177595.00634949
 203054.57119919 145465.64115129  72531.69555853 187255.47079386
 173942.036605   292807.95146217 241092.93832138 188573.26285997
 183495.7931397  178620.5487469  171988.32308107 164187.32630335
 220469.22565786 220054.52466075 221487.46371044 229621.54920806
 207455.5735685  171325.59214668 194765.52745785 135921.33381405
 202413.66359532 265644.99891848 135619.84209532 145728.64657157
 233669.2061524  135768.18572763 186165.55435325 207867.53376714
 208864.74078233 199767.25659667 166297.92702541 309685.82831993
 158822.72478426 133227.22870529 150180.17445048 153554.51632939
 212395.90466599 296766.20682924 219526.86537467 190965.79688658
 168944.74202534 199928.41665537 111585.45486187 105284.2443877
 145912.97876128 111771.42960761  87776.36229489 195734.23050182
 154532.72151668 176897.87276796 194892.72384785 144558.5783094
 139130.05116167 221736.54910571 162192.28385415 142297.99733225
 204062.11169369 291916.85564033 228813.8497837  114455.1780899
 177612.3180411  182311.08344562 240816.73816694 201523.28365065
 170902.4515992  147250.36318751 119881.70660785  99407.11048661
 152356.90297841 120171.67726201 145528.71561673 204528.71935135
 294541.82172821 169541.09544115 267549.08194648 238558.66106219
 132260.14995444 207684.25150021 148016.41222824 100261.02462412
 248405.84731155 191103.41751145 239948.73982621 131009.21304454
 204738.74125525 229004.50166363 223739.24105842  99429.34587156
 170921.81030344 242230.65496327 182284.48228054 222303.14499996
 127760.36200374 145672.50638992 204285.50764783 214061.16525581
 227366.13802235 212757.11112495 186150.61958241 176414.5925157
 155097.25992847 186442.17577352 260209.44171159 235189.89363723
 234268.53895029 235280.34892347 157008.00971284 173740.12319008
 216921.5616516  286971.44088939 162016.95685032 203789.32777124
 259000.21787905 141222.59554722 115433.86766759 188132.75970372
 149391.63516342 114700.08130314 184323.31260117 250493.00829405
 158178.4812     249906.00674939 195864.09379949 212942.47650923
 141398.70603439 135321.91345675 192856.58518135 137484.09339218
 170623.69145618 189270.9623192  225108.97982721  97333.44644766
 123194.44607947 121189.42061161 246777.38638111 218379.43923835
 156403.94612522 145744.16029671 162535.44269623 219750.37128898
 164111.71631218 260319.28642486 331495.80869394 179254.25439738
 198077.57098731 181505.32832003 266071.30236514 265278.84799813
 116274.25185893 118434.66097262 119108.73944893 224605.27154234
 250739.10096877 229249.82081793 133498.0153465  215734.99920063
 124403.45758024 191292.28149516 160281.85143724 186559.57683678
 227674.43388995 153363.21466687 203266.22857293 241257.03816307
 234035.79844629 180785.93004854 204837.76020355 269094.73570881
 267412.53039257 170957.14893236 173949.9708314  190640.9843996
  99058.43067313 169936.29107559 200587.16094114 218287.97468998
  88108.95626525 148871.04017879 162333.30971594 214394.41360408
 226473.17626915 198956.55230583 207290.94929713 129182.24565013
 237249.43066546 179797.977649   230305.80559986 170426.114911
 245418.53399338 141872.95110912 177659.2426126  207757.86669001
 209105.83681426 187533.86366377 195162.10762352 205623.05317713
 235323.15587307 145490.5229279  199339.57423564 198213.0993804
 216259.93370712 250643.40686029 189083.4441121  169296.39799622]
2025-06-15 08:11:32 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:32 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:32 INFO AOCC mean: 0.0000
2025-06-15 08:11:35 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:11:35 INFO FeHistory: [163568.84621939 147926.88479983 161779.17812774 ...  94873.31049498
 112416.88096535 142073.49092688]
2025-06-15 08:11:35 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:11:35 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:11:35 INFO AOCC mean: 0.0000
