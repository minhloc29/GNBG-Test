2025-06-23 15:59:09 INFO Initializing first population
2025-06-23 15:59:09 INFO Initializing population from 8 seed files...
2025-06-23 16:06:01 INFO Started evolutionary loop, best so far: 0.10988657163916095
2025-06-23 16:06:01 INFO Population length is: 20
2025-06-23 16:06:01 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-23 16:06:01 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 1.0989e-01# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 5.3904e-02# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 3 (Overall AOCC Score on function 24: 5.1458e-02# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 4 (Overall AOCC Score on function 24: 4.4665e-02# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 5 (Overall AOCC Score on function 24: 4.0365e-02# Name: AdaptiveMultimodalEvolutionaryStrategy
# Description: An evolutionary strategy that adapts mutation strength based on population diversity and fitness improvements, enhancing exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.population = self.initialize_population()
        self.sigma = 10.0 # Initial mutation strength
        self.sigma_decay = 0.99 #Decay rate for sigma

    def initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def evaluate_population(self, objective_function):
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness_values

    def select_parents(self, fitness_values):
        # Tournament selection
        parents = []
        for _ in range(self.population_size // 2):
            tournament = random.sample(range(self.population_size), 5)
            winner1_index = min(tournament, key=lambda i: fitness_values[i])
            tournament = random.sample(range(self.population_size), 5)
            winner2_index = min(tournament, key=lambda i: fitness_values[i])
            parents.extend([winner1_index, winner2_index])
        return parents

    def recombine_and_mutate(self, parents):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(0, self.population_size, 2):
            parent1_index = parents[i]
            parent2_index = parents[i+1]
            
            #Intermediate Recombination
            offspring[i] = 0.5 * (self.population[parent1_index] + self.population[parent2_index])
            offspring[i+1] = 0.5 * (self.population[parent1_index] + self.population[parent2_index])
            
            #Mutation with adaptive sigma
            offspring[i] += np.random.normal(0, self.sigma, self.dim)
            offspring[i+1] += np.random.normal(0, self.sigma, self.dim)
            
            #Clamp to bounds
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
            offspring[i+1] = np.clip(offspring[i+1], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_sigma(self, fitness_values, prev_best_fitness):
        #Adaptively adjust sigma based on fitness improvement and diversity
        improvement = prev_best_fitness - np.min(fitness_values)
        diversity = np.std(self.population)

        if improvement > 0 and diversity > 10: #Increase exploration
            self.sigma *= 1.05
        elif improvement <= 0: #Reduce exploration
            self.sigma *= self.sigma_decay
        
        self.sigma = np.clip(self.sigma, 0.1, 20.0) #Clamp Sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self.initialize_population()
        fitness_values = self.evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self.get_best(fitness_values)

        prev_best_fitness = self.best_fitness_overall


        while self.eval_count < self.budget:
            parents = self.select_parents(fitness_values)
            offspring = self.recombine_and_mutate(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size //2

            #Elitist replacement
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness_values = combined_fitness[indices[:self.population_size]]

            self.update_sigma(fitness_values, prev_best_fitness)
            
            best_solution, best_fitness = self.get_best(fitness_values)

            if best_fitness < self.best_fitness_overall:
              self.best_fitness_overall = best_fitness
              self.best_solution_overall = best_solution
            
            prev_best_fitness = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def get_best(self, fitness_values):
      best_index = np.argmin(fitness_values)
      return self.population[best_index], fitness_values[best_index]
```

### Rank 6 (Overall AOCC Score on function 24: 3.3587e-02# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 7 (Overall AOCC Score on function 24: 2.5122e-02# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 10 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A differential evolution algorithm with adaptive mutation and crossover strategies for efficiently exploring and exploiting multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 10 * self.dim #Larger population for higher dimensionality
        self.population = None
        self.fitness_values = None

        self.F = 0.8 #Differential weight
        self.CR = 0.9 #Crossover rate
        self.adaptation_rate = 0.1 #Rate of adaptation for F and CR

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)

        while self.eval_count < self.budget:
            new_population = np.empty_like(self.population)
            new_fitness_values = np.empty_like(self.fitness_values)
            for i in range(self.population_size):
                # Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                
                #Boundary Constraint Handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count +=1
                new_population[i] = trial if trial_fitness < self.fitness_values[i] else self.population[i]
                new_fitness_values[i] = min(trial_fitness, self.fitness_values[i])

                #Adaptive parameter adjustment
                if trial_fitness < self.fitness_values[i]:
                    self.F = self.F + self.adaptation_rate * (np.random.rand() -0.5)
                    self.CR = self.CR + self.adaptation_rate * (np.random.rand() - 0.5)

                self.F = np.clip(self.F, 0.1, 1.0) #Keep F within bounds
                self.CR = np.clip(self.CR, 0.1, 1.0) #Keep CR within bounds

            self.population = new_population
            self.fitness_values = new_fitness_values
            if np.min(new_fitness_values) < self.best_fitness_overall:
                self.best_fitness_overall = np.min(new_fitness_values)
                self.best_solution_overall = self.population[np.argmin(new_fitness_values)]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 11 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) enhanced with adaptive population size and restarts to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import norm

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.lambda_ = 4 + int(3 * np.log(self.dim))  # Initial population size
        self.mu = self.lambda_ // 2  # Number of parents
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds).mean() # initial step size

        self.C = np.eye(self.dim)  # Covariance matrix
        self.p_sigma = np.zeros(self.dim)  # Evolution path for sigma
        self.p_c = np.zeros(self.dim)  # Evolution path for covariance matrix
        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))
        self.weights /= np.sum(self.weights)
        self.mu_eff = 1 / np.sum(self.weights ** 2)
        self.c_sigma = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)
        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma
        self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + self.mu_eff / self.dim)


        self.restart_threshold = 1000 # Number of evaluations without improvement before restart

        self.last_improvement = 0


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        while self.eval_count < self.budget:
            # Generate population
            X = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.lambda_)
            X = self.sigma * X + np.mean((self.upper_bounds + self.lower_bounds)/2)
            X = np.clip(X, self.lower_bounds, self.upper_bounds)

            # Evaluate fitness
            fitness = objective_function(X)
            self.eval_count += self.lambda_

            # Sort by fitness
            sorted_indices = np.argsort(fitness)
            X = X[sorted_indices]
            fitness = fitness[sorted_indices]

            # Update best solution
            if fitness[0] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[0]
                self.best_solution_overall = X[0]
                self.last_improvement = self.eval_count

            # Update CMA-ES parameters
            x_mean = np.average(X[:self.mu], axis=0, weights=self.weights)
            z = (x_mean - np.mean((self.upper_bounds + self.lower_bounds)/2))/ self.sigma
            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mu_eff) * z
            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))

            self.p_c = (1 - self.c_c) * self.p_c + np.sqrt(self.c_c * (2 - self.c_c) * self.mu_eff) * z
            self.C = (1 - self.c_c) * self.C + self.c_c * (np.outer(self.p_c, self.p_c) + (1-self.c_c)*(self.mu_eff-1)/self.mu_eff * self.C)
            
            # Adaptive population size and restarts
            if self.eval_count - self.last_improvement > self.restart_threshold:
                #print("Restarting CMA-ES...")
                self.lambda_ = max(4, int(0.5*self.lambda_))
                self.mu = self.lambda_ // 2
                self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds).mean()
                self.C = np.eye(self.dim)
                self.p_sigma = np.zeros(self.dim)
                self.p_c = np.zeros(self.dim)
                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))
                self.weights /= np.sum(self.weights)
                self.mu_eff = 1 / np.sum(self.weights ** 2)
                self.c_sigma = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)
                self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma
                self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + self.mu_eff / self.dim)
                self.last_improvement = self.eval_count

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'restarts': (self.eval_count - self.last_improvement) // self.restart_threshold if self.eval_count > 0 else 0
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 12 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: A CMA-ES variant with adaptive mutation strength and population diversification for multimodal landscapes.
# Code:
```python
# Name: AdaptiveMultimodalCMAES
# Description: A CMA-ES variant with adaptive mutation strength and population diversification for multimodal landscapes.
# Code:
import numpy as np
from cma import CMA

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 + int(3 * np.log(self.dim)) #increase initial population size
        self.cma_instances = []
        self.diversity_threshold = 0.1  # Parameter to control population diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count +=1
        
        self.cma_instances.append(CMA(mean=self.best_solution_overall, sigma=20.0, population_size = self.population_size,bounds=[self.lower_bounds,self.upper_bounds]))

        while self.eval_count < self.budget:
            for i, cma in enumerate(self.cma_instances):
                solutions = cma.ask(self.population_size)
                fitnesses = objective_function(solutions)
                self.eval_count += self.population_size

                for sol, fit in zip(solutions, fitnesses):
                    if fit < self.best_fitness_overall:
                        self.best_fitness_overall = fit
                        self.best_solution_overall = sol

                cma.tell(solutions, fitnesses)

            # Adaptive Population Diversification
            if len(self.cma_instances) > 1:
              # Calculate population diversity (e.g., using standard deviation of population mean)
              population_mean = np.mean([cma.mean for cma in self.cma_instances], axis=0)
              population_std = np.std([cma.mean for cma in self.cma_instances], axis=0)

              diversity = np.mean(population_std)

              if diversity < self.diversity_threshold:
                  #Add a new CMA instance if diversity is low.
                  new_mean = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                  new_sigma = 20.0
                  self.cma_instances.append(CMA(mean=new_mean, sigma=new_sigma, population_size = self.population_size, bounds=[self.lower_bounds,self.upper_bounds]))
                
        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'number_of_cma_instances': len(self.cma_instances)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 13 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalEvolutionaryStrategy
# Description: An evolutionary strategy that adapts mutation strength based on exploration/exploitation needs and uses a diverse initial population to efficiently tackle multimodal landscapes.
# Code:
```python
# Name: AdaptiveMultimodalEvolutionaryStrategy
# Description: An evolutionary strategy that adapts mutation strength based on exploration/exploitation needs and uses a diverse initial population to efficiently tackle multimodal landscapes.
# Code:

import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 100  # Adjust as needed
        self.mutation_rate = 0.1  # Initial mutation rate
        self.mutation_strength = 5.0 # Initial mutation strength
        self.elite_size = 10 #Size of the elite set

        self.population = self.generate_diverse_population(self.population_size)
        self.elite = []

    def generate_diverse_population(self, pop_size):
        """Generates a diverse initial population using Latin Hypercube Sampling"""
        population = np.zeros((pop_size, self.dim))
        for i in range(self.dim):
            indices = np.random.permutation(pop_size)
            values = np.linspace(self.lower_bounds[i], self.upper_bounds[i], pop_size)
            population[:, i] = values[indices]
        return population


    def mutate(self, individual):
        """Applies mutation to an individual."""
        return individual + np.random.normal(0, self.mutation_strength * self.mutation_rate, self.dim)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.elite = []

        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        #Initial elite selection
        sorted_indices = np.argsort(fitness_values)
        self.elite = self.population[sorted_indices[:self.elite_size]]

        while self.eval_count < self.budget:
            offspring = []
            for _ in range(self.population_size):
                parent1_index = random.randint(0, self.elite_size -1)
                parent1 = self.elite[parent1_index]
                offspring.append(self.mutate(parent1))

            offspring = np.array(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_population = np.vstack((self.elite, offspring))
            combined_fitness = np.concatenate((fitness_values[sorted_indices[:self.elite_size]], offspring_fitness))

            sorted_indices = np.argsort(combined_fitness)
            self.elite = combined_population[sorted_indices[:self.elite_size]]
            fitness_values = combined_fitness[sorted_indices[:self.elite_size]]


            best_solution_index = np.argmin(fitness_values)
            best_fitness = fitness_values[best_solution_index]
            best_solution = self.elite[best_solution_index]

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Adaptive Mutation
            if self.eval_count > self.budget * 0.2 : # Start adapting after 20% of budget
                if best_fitness < acceptance_threshold:
                    self.mutation_strength *= 0.8 # Reduce if close to optimum
                else:
                    self.mutation_strength *= 1.2 # Increase if far from optimum


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 14 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) enhanced with adaptive population size and restarts to efficiently explore multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(4 + np.floor(3 * np.log(self.dim))) # Initial population size
        self.restart_threshold = 0.1  # Fraction of budget before restarting
        self.restart_multiplier = 1.2 # Factor to increase population after restart
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.mean = 0.5 * (self.upper_bounds + self.lower_bounds)
        self.C = np.eye(self.dim)
        self.pc = np.zeros(self.dim)
        self.ps = np.zeros(self.dim)

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        while self.eval_count < self.budget:
            # Generate population
            population = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, self.population_size)
            population = np.clip(population, self.lower_bounds, self.upper_bounds) #Handle bounds

            # Evaluate population
            fitness = objective_function(population)
            self.eval_count += self.population_size

            # Update best solution
            best_index = np.argmin(fitness)
            best_solution = population[best_index]
            best_fitness = fitness[best_index]
            
            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # CMA-ES update
            sorted_indices = np.argsort(fitness)
            weights = np.log(self.population_size + 0.5) - np.log(np.arange(1, self.population_size + 1))
            weights /= np.sum(weights)
            
            mean_shifted = np.average(population[sorted_indices[:int(self.population_size/2)],:], axis=0, weights=weights[:int(self.population_size/2)])
            self.pc = (1 - 1 / (self.population_size +1 )) * self.pc + np.sqrt(self.population_size/(self.population_size +1 )) * (mean_shifted - self.mean) / self.sigma
            self.ps = (1 - 1/(self.population_size +1)) * self.ps + (self.pc/np.linalg.norm(self.pc))* np.sqrt(self.population_size/(self.population_size +1)) * np.sqrt(1 - (np.linalg.norm(self.pc)**2)/(self.population_size +1))
            self.C = (1 - 1/ (self.population_size+1)) * self.C + (1/(self.population_size+1)) * np.outer(self.pc,self.pc)
            self.sigma = self.sigma * np.exp((np.linalg.norm(self.ps) - np.sqrt(self.dim))/(self.dim * np.sqrt(2)))
            self.mean = mean_shifted

            if self.eval_count/ self.budget > self.restart_threshold and self.best_fitness_overall > -99:  #Restart Condition
                self.population_size = int(self.population_size * self.restart_multiplier)
                self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
                self.mean = 0.5 * (self.upper_bounds + self.lower_bounds)
                self.C = np.eye(self.dim)
                self.pc = np.zeros(self.dim)
                self.ps = np.zeros(self.dim)

        if self.best_solution_overall is None:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 15 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) enhanced with adaptive population size and restarts to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import norm

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.lambda_ = 4 + int(3 * np.log(self.dim)) # Initial population size
        self.mu = self.lambda_ // 2 # Number of parents
        self.sigma = 0.5 # Initial step size

        self.C = np.eye(self.dim) # Covariance matrix
        self.pc = np.zeros(self.dim) # Evolution path
        self.ps = np.zeros(self.dim) # Evolution path for sigma
        self.c_c = 2 / (self.dim + 1.3)**2
        self.c_s = 0.4 + 0.4 * (self.dim -1) / (self.dim +1)
        self.d_s = 1 + 2 * max(0, np.sqrt((self.mu -1) / (self.dim +1)) -1) + self.c_s

        self.restart_threshold = 1000 # Number of evaluations before restart


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        xmean = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        while self.eval_count < self.budget:
            # Generate population
            population = np.random.multivariate_normal(xmean, self.sigma**2 * self.C, size=self.lambda_)
            population = np.clip(population, self.lower_bounds, self.upper_bounds)


            #Evaluate population
            fitness_values = objective_function(population)
            self.eval_count += self.lambda_

            # Sort by fitness (ascending)
            indices = np.argsort(fitness_values)
            sorted_population = population[indices]
            sorted_fitness = fitness_values[indices]

            # Update best solution
            if sorted_fitness[0] < self.best_fitness_overall:
                self.best_fitness_overall = sorted_fitness[0]
                self.best_solution_overall = sorted_population[0]

            # Update mean
            xmean = np.mean(sorted_population[:self.mu], axis=0)

            # Update covariance matrix and step size

            z = (sorted_population[:self.mu] - xmean) / self.sigma
            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * np.mean(z, axis=0)
            self.ps = (1 - self.c_s) * self.ps + np.sqrt(self.c_s * (2 - self.c_s)) * np.mean(z, axis=0)
            self.C = (1 - self.c_c) * self.C + self.c_c * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :] + (2-self.c_c) * np.cov(z, rowvar=False))
            self.sigma *= np.exp(self.c_s / self.d_s * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))


            # Adaptive population size and restart (every self.restart_threshold evaluations)
            if self.eval_count % self.restart_threshold == 0 :
                if self.lambda_ < 100:  # Limit population size growth
                   self.lambda_ = int(self.lambda_ * 1.2) # Increase population size if not enough exploration
                self.mu = self.lambda_ // 2
                self.c_c = 2 / (self.dim + 1.3)**2
                self.c_s = 0.4 + 0.4 * (self.dim -1) / (self.dim +1)
                self.d_s = 1 + 2 * max(0, np.sqrt((self.mu -1) / (self.dim +1)) -1) + self.c_s
                xmean = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim) # Restart from a random point
                self.C = np.eye(self.dim)
                self.pc = np.zeros(self.dim)
                self.ps = np.zeros(self.dim)
                self.sigma = 0.5



        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size_history': [self.lambda_] #Add history of population size, can be further improved.
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 16 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDifferentialEvolutionGNBG
# Description: An adaptive differential evolution algorithm employing a multi-population strategy and local search to escape local optima in high-dimensional, multimodal landscapes.
# Code:
```python
# Name: AdaptiveDifferentialEvolutionGNBG
# Description: An adaptive differential evolution algorithm employing a multi-population strategy and local search to escape local optima in high-dimensional, multimodal landscapes.
# Code:

import numpy as np
from scipy.spatial.distance import cdist

class AdaptiveDifferentialEvolutionGNBG:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim  # Adaptive population size
        self.num_populations = 5       # Multiple populations for exploration
        self.F = 0.8                   # Differential evolution scaling factor (adaptive)
        self.CR = 0.9                  # Crossover rate (adaptive)
        self.populations = [np.random.uniform(self.lower_bounds, self.upper_bounds, (self.pop_size // self.num_populations, self.dim)) for _ in range(self.num_populations)]


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        while self.eval_count < self.budget:
            for i in range(self.num_populations):
                fitness_values = objective_function(self.populations[i])
                self.eval_count += len(fitness_values)

                best_index = np.argmin(fitness_values)
                best_solution = self.populations[i][best_index]
                best_fitness = fitness_values[best_index]

                if best_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = best_fitness
                    self.best_solution_overall = best_solution

                # Adaptive F and CR based on population diversity
                diversity = np.mean(cdist(self.populations[i], self.populations[i], 'euclidean'))
                self.F = 0.5 + 0.3 * (1 - diversity / np.max(self.upper_bounds - self.lower_bounds))
                self.CR = 0.5 + 0.4 * diversity / np.max(self.upper_bounds - self.lower_bounds)


                # Differential Evolution Mutation and Crossover
                new_population = np.zeros_like(self.populations[i])
                for j in range(self.pop_size // self.num_populations):
                    r1, r2, r3 = np.random.choice(np.arange(self.pop_size // self.num_populations), 3, replace=False)
                    while r1 == j:
                        r1 = np.random.choice(np.arange(self.pop_size // self.num_populations))
                    mutant = self.populations[i][r1] + self.F * (self.populations[i][r2] - self.populations[i][r3])
                    mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) # Bounds handling

                    cross_points = np.random.rand(self.dim) < self.CR
                    trial = np.where(cross_points, mutant, self.populations[i][j])

                    trial_fitness = objective_function(trial.reshape(1, -1))
                    self.eval_count += 1
                    if trial_fitness[0] < fitness_values[j]:
                        new_population[j] = trial

                self.populations[i] = new_population


                # Local Search (Optional - to avoid local optima)
                if self.eval_count < self.budget * 0.9 : # Limit local search iterations
                    local_search_steps = int(np.sqrt(self.dim))
                    for k in range(local_search_steps):
                        perturbation = np.random.normal(0, 1, self.dim) * 0.1  #small perturbation
                        neighbor = best_solution + perturbation
                        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                        neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                        self.eval_count +=1
                        if neighbor_fitness < best_fitness:
                            best_solution = neighbor
                            best_fitness = neighbor_fitness


                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 17 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) enhanced with adaptive population size and niching to efficiently explore multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import norm

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.lambda_ = 4 + int(3 * np.log(self.dim)) #Initial population size, adaptive
        self.mu = int(self.lambda_ / 2) #Parent selection
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds).mean() #Initial step size
        self.mean = 0.5 * (self.upper_bounds + self.lower_bounds) #Initial mean
        self.C = np.eye(self.dim) #Covariance matrix
        self.pc = np.zeros(self.dim) #Evolution path
        self.ps = np.zeros(self.dim) #Evolution path
        self.cc = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)
        self.cs = (self.mu / (self.dim**2 + self.mu))**0.5
        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mu)
        self.cmu = min(1 - self.c1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))
        self.d_sigma = 1 + self.cs * (norm.ppf(1 - (1 + self.mu)**-1) - 1)

        self.niche_radius = 0.1 * (self.upper_bounds - self.lower_bounds).mean()  #Initialize niche radius
        self.niches = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        while self.eval_count < self.budget:
            # Generate population
            X = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.lambda_)
            X = np.clip(X, self.lower_bounds, self.upper_bounds)

            # Evaluate fitness
            fitnesses = objective_function(X)
            self.eval_count += self.lambda_

            #Update best solution
            for i, fitness in enumerate(fitnesses):
                if fitness < self.best_fitness_overall:
                    self.best_fitness_overall = fitness
                    self.best_solution_overall = X[i]

            # Sort and select parents
            sorted_indices = np.argsort(fitnesses)
            parents = X[sorted_indices[:self.mu]]

            # Update mean
            self.mean = np.mean(parents, axis=0)

            # Update covariance matrix and step-size (CMA-ES core)
            y = (parents - self.mean) / self.sigma
            self.pc = (1 - self.cc) * self.pc + (self.cc * (self.cc + 2)**0.5) * np.mean(y, axis=0)
            self.ps = (1 - self.cs) * self.ps + self.cs * (self.cs * (self.cs + 2)**0.5) * np.mean(y, axis=0)
            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * np.outer(self.pc, self.pc) + self.cmu * np.cov(y, rowvar=False)
            self.sigma *= np.exp(self.d_sigma / 2 * (np.linalg.norm(self.ps) / self.dim**0.5 -1))


            #Adaptive population size and niching (multimodal enhancement)
            if self.eval_count > self.budget / 4 and self.best_fitness_overall < -90: # Adjust conditions if needed
                self.lambda_ = max(4, int(self.lambda_ * 0.9))  # Gradually reduce population
                self.mu = int(self.lambda_ / 2)
                self.niche_radius *= 0.95  #Shrink niche radius for finer exploration
                
                #Check for niches
                add_niche = True
                for niche in self.niches:
                    if np.linalg.norm(self.best_solution_overall - niche) < self.niche_radius:
                        add_niche = False
                        break
                if add_niche:
                    self.niches.append(self.best_solution_overall)

                if len(self.niches) > 5: # Limit the number of niches for efficiency
                    self.niches.sort(key=lambda x: objective_function(np.array([x])))
                    self.niches = self.niches[:5]
                    self.mean = np.mean(np.array(self.niches), axis=0) #Maintain exploratin of current niches
                
        return self.best_solution_overall, self.best_fitness_overall, {'function_evaluations_used': self.eval_count, 'final_best_fitness': self.best_fitness_overall}

```

### Rank 18 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: An adaptive CMA-ES variant employing multiple populations and dynamic mutation for multimodal landscapes.
# Code:
```python
# Name: AdaptiveMultimodalCMAES
# Description: An adaptive CMA-ES variant employing multiple populations and dynamic mutation for multimodal landscapes.
# Code:

import numpy as np
from scipy.stats import norm

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 4 + int(3 * np.log(self.dim)) # standard CMA-ES population size
        self.num_populations = 5  # Number of CMA-ES instances, each exploring different regions
        self.populations = []
        for i in range(self.num_populations):
            x0 = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
            sigma0 = 0.5 * np.ptp(np.array([self.lower_bounds, self.upper_bounds])) # initial sigma based on bounds
            self.populations.append({'mean': x0, 'sigma': sigma0, 'C': np.eye(self.dim), 'p_sigma': np.zeros(self.dim), 'pc': np.zeros(self.dim)})


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        while self.eval_count < self.budget:
            for i in range(self.num_populations):
                pop_data = self.populations[i]
                mean = pop_data['mean']
                sigma = pop_data['sigma']
                C = pop_data['C']
                p_sigma = pop_data['p_sigma']
                pc = pop_data['pc']

                # Generate offspring using CMA-ES
                z = np.random.normal(size=(self.population_size, self.dim))
                D = np.linalg.cholesky(C)
                x = mean + sigma * (z @ D)
                x = np.clip(x, self.lower_bounds, self.upper_bounds) # Ensure bounds are respected

                # Evaluate fitness
                fitness = objective_function(x)
                self.eval_count += self.population_size

                # Update CMA-ES parameters (simplified for brevity, full implementation is more complex)
                best_index = np.argmin(fitness)
                best_solution = x[best_index]
                best_fitness = fitness[best_index]

                if best_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = best_fitness
                    self.best_solution_overall = best_solution


                # Adapt sigma and covariance matrix (simplified for demonstration)
                if best_fitness < pop_data['sigma'] * 0.1: # adaptive step size reduction
                    pop_data['sigma'] *= 0.8
                elif best_fitness > pop_data['sigma'] * 10:
                    pop_data['sigma'] *= 1.2
                
                # Adapt the exploration rate of each population
                pop_data['C'] = 0.9 * pop_data['C'] + 0.1*np.cov(x,rowvar=False) #Cov update
                
                pop_data['mean'] = best_solution
                

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'num_populations': self.num_populations
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 19 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A differential evolution algorithm with adaptive mutation and crossover rates for escaping local optima in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 10 * self.dim  # Adjust as needed
        self.population = None
        self.F = 0.8  # Initial mutation factor
        self.CR = 0.9 # Initial crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall, self.best_fitness_overall = self.find_best(self.population, fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Mutation
                a, b, c = self.select_mutants(i)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.copy(self.population[i])
                j_rand = random.randint(0, self.dim - 1)
                for j in range(self.dim):
                    if random.random() < self.CR or j == j_rand:
                        trial[j] = mutant[j]
                
                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial
                        self.best_fitness_overall = trial_fitness

                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)

            #Adaptive Parameter Adjustment (crucial for multimodal)
            self.adapt_parameters(fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_F': self.F,
            'final_CR': self.CR
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def select_mutants(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i or a == b or b == c or a == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def adapt_parameters(self, fitness_values):
        # Simple adaptive strategy:  Reduce F and CR if convergence slows down.
        # More sophisticated strategies could be implemented here.
        std_fitness = np.std(fitness_values)
        if std_fitness < 0.1: #example threshold - adjust as needed
            self.F *= 0.9
            self.CR *= 0.9
        elif self.F < 1.0:
          self.F *= 1.1
          self.CR *= 1.1

        self.F = np.clip(self.F, 0.1, 1.0) #keep F and CR in range
        self.CR = np.clip(self.CR, 0.1, 1.0)

```

### Rank 20 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A differential evolution algorithm with adaptive mutation and population diversification to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8 # Mutation factor
        self.CR = 0.9 # Crossover rate
        self.adaptation_rate = 0.1 # Rate of adaptation for F and CR

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                #Clamp values to bounds
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.zeros(self.dim)
                j_rand = random.randint(0, self.dim - 1)
                for j in range(self.dim):
                    if random.random() < self.CR or j == j_rand:
                        trial[j] = mutant[j]
                    else:
                        trial[j] = self.population[i][j]

                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness[0]
                    if trial_fitness[0] < self.best_fitness_overall:
                        self.best_solution_overall = trial.copy()
                        self.best_fitness_overall = trial_fitness[0]
                else:
                    new_population.append(self.population[i])

                # Adaptive parameter adjustment (simple example)
                if trial_fitness[0] < fitness_values[i]:
                    self.F = self.F + self.adaptation_rate * random.uniform(-0.1, 0.1)
                    self.CR = self.CR + self.adaptation_rate * random.uniform(-0.1, 0.1)
                    self.F = np.clip(self.F, 0.1, 1) # keep F and CR within reasonable bounds
                    self.CR = np.clip(self.CR, 0.1, 1)

            self.population = np.array(new_population)
            if abs(self.best_fitness_overall - (-100.0)) < acceptance_threshold:
                break  #converged


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 16:06:09 INFO Full response text: **Analysis:**

Comparing (best) EnhancedArchiveGuidedDE vs (worst) AdaptiveMultimodalDifferentialEvolution, we see that EnhancedArchiveGuidedDE uses an archive to maintain diversity and guide the search, while AdaptiveMultimodalDifferentialEvolution lacks such a mechanism, leading to potential premature convergence.  EnhancedArchiveGuidedDE also incorporates adaptive scaling factors for more robust exploration.

(second best) AdaptiveGaussianArchiveEA vs (second worst) AdaptiveMultimodalOptimizerImproved: AdaptiveGaussianArchiveEA employs adaptive Gaussian sampling and tournament selection, combining exploration and exploitation effectively. AdaptiveMultimodalOptimizerImproved uses a simpler, less efficient local search, and its adaptive perturbation strength lacks a clear strategy.

Comparing (1st) EnhancedArchiveGuidedDE vs (2nd) AdaptiveGaussianArchiveEA, we see that EnhancedArchiveGuidedDE uses Differential Evolution, a more powerful search operator compared to AdaptiveGaussianArchiveEA's basic Gaussian recombination and mutation.  EnhancedArchiveGuidedDE's archive management also contributes to superior performance.

(3rd) AdaptiveGaussianMutationDE vs (4th) AdaptiveGaussianSamplingEAwithArchive: Both use Gaussian mutation but AdaptiveGaussianMutationDE incorporates Differential Evolution, creating more diverse offspring and preventing stagnation. AdaptiveGaussianSamplingEAwithArchives simpler adaptive mutation strategy and tournament selection are less effective.

Comparing (second worst) AdaptiveMultimodalOptimizerImproved vs (worst) AdaptiveMultimodalCMAES, we see that AdaptiveMultimodalOptimizerImproved's local search, though basic, is better than AdaptiveMultimodalCMAES, which struggles with efficient exploration and exploitation in the high-dimensional space. AdaptiveMultimodalCMAES doesn't effectively adapt its population size or mutation strength.

Overall: The best-performing algorithms consistently use sophisticated search operators (DE), archive mechanisms to maintain diversity, and adaptive parameter adjustments.  Simpler strategies, lacking these features, struggle with the complex, high-dimensional search space of f24.


**Experience:**

Effective heuristics for high-dimensional multimodal problems require sophisticated search operators, diversity maintenance (archives), and adaptive parameter control.  Simpler methods often struggle with premature convergence and inefficient exploration.  Integrating local search can significantly improve performance.

2025-06-23 16:06:10 INFO Full response text: * **Keywords:**  High-dimensional, multimodal, search operators, diversity, adaptation, local search, premature convergence.

* **Advice:** Focus on designing robust search operators that handle high dimensionality and multimodality effectively.  Incorporate mechanisms for maintaining diversity (e.g., niching, crowding) and adapting parameters (e.g., learning rates, step sizes) based on search progress. Integrate local search methods to refine solutions found by global search.  Thoroughly analyze failure modes to understand premature convergence.

* **Avoid:**  Overly simplistic methods lacking diversity mechanisms or adaptive control. Ignoring the impact of high dimensionality. Neglecting local search refinement.  Relying solely on single metrics for performance evaluation.

* **Explanation:**  Effective heuristics require a multi-faceted approach addressing the challenges of high dimensionality and multimodality.  A balance of exploration (global search) and exploitation (local search) is crucial.  Adaptive parameter control and diversity mechanisms help avoid getting stuck in local optima.  Rigorous evaluation is essential.

2025-06-23 16:06:10 INFO Generating offspring via Crossover...
2025-06-23 16:16:26 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
AdaptiveMultimodalDifferentialEvolution
import numpy as np
import random

class AdaptiveMultimodalDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 10 * self.dim #Larger population for higher dimensionality
        self.population = None
        self.fitness_values = None

        self.F = 0.8 #Differential weight
        self.CR = 0.9 #Crossover rate
        self.adaptation_rate = 0.1 #Rate of adaptation for F and CR

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)

        while self.eval_count < self.budget:
            new_population = np.empty_like(self.population)
            new_fitness_values = np.empty_like(self.fitness_values)
            for i in range(self.population_size):
                # Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                
                #Boundary Constraint Handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count +=1
                new_population[i] = trial if trial_fitness < self.fitness_values[i] else self.population[i]
                new_fitness_values[i] = min(trial_fitness, self.fitness_values[i])

                #Adaptive parameter adjustment
                if trial_fitness < self.fitness_values[i]:
                    self.F = self.F + self.adaptation_rate * (np.random.rand() -0.5)
                    self.CR = self.CR + self.adaptation_rate * (np.random.rand() - 0.5)

                self.F = np.clip(self.F, 0.1, 1.0) #Keep F within bounds
                self.CR = np.clip(self.CR, 0.1, 1.0) #Keep CR within bounds

            self.population = new_population
            self.fitness_values = new_fitness_values
            if np.min(new_fitness_values) < self.best_fitness_overall:
                self.best_fitness_overall = np.min(new_fitness_values)
                self.best_solution_overall = self.population[np.argmin(new_fitness_values)]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


### Worse code
AdaptiveMultimodalEvolutionaryStrategy
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.population = self.initialize_population()
        self.sigma = 10.0 # Initial mutation strength
        self.sigma_decay = 0.99 #Decay rate for sigma

    def initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def evaluate_population(self, objective_function):
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness_values

    def select_parents(self, fitness_values):
        # Tournament selection
        parents = []
        for _ in range(self.population_size // 2):
            tournament = random.sample(range(self.population_size), 5)
            winner1_index = min(tournament, key=lambda i: fitness_values[i])
            tournament = random.sample(range(self.population_size), 5)
            winner2_index = min(tournament, key=lambda i: fitness_values[i])
            parents.extend([winner1_index, winner2_index])
        return parents

    def recombine_and_mutate(self, parents):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(0, self.population_size, 2):
            parent1_index = parents[i]
            parent2_index = parents[i+1]
            
            #Intermediate Recombination
            offspring[i] = 0.5 * (self.population[parent1_index] + self.population[parent2_index])
            offspring[i+1] = 0.5 * (self.population[parent1_index] + self.population[parent2_index])
            
            #Mutation with adaptive sigma
            offspring[i] += np.random.normal(0, self.sigma, self.dim)
            offspring[i+1] += np.random.normal(0, self.sigma, self.dim)
            
            #Clamp to bounds
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
            offspring[i+1] = np.clip(offspring[i+1], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_sigma(self, fitness_values, prev_best_fitness):
        #Adaptively adjust sigma based on fitness improvement and diversity
        improvement = prev_best_fitness - np.min(fitness_values)
        diversity = np.std(self.population)

        if improvement > 0 and diversity > 10: #Increase exploration
            self.sigma *= 1.05
        elif improvement <= 0: #Reduce exploration
            self.sigma *= self.sigma_decay
        
        self.sigma = np.clip(self.sigma, 0.1, 20.0) #Clamp Sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self.initialize_population()
        fitness_values = self.evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self.get_best(fitness_values)

        prev_best_fitness = self.best_fitness_overall


        while self.eval_count < self.budget:
            parents = self.select_parents(fitness_values)
            offspring = self.recombine_and_mutate(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size //2

            #Elitist replacement
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness_values = combined_fitness[indices[:self.population_size]]

            self.update_sigma(fitness_values, prev_best_fitness)
            
            best_solution, best_fitness = self.get_best(fitness_values)

            if best_fitness < self.best_fitness_overall:
              self.best_fitness_overall = best_fitness
              self.best_solution_overall = best_solution
            
            prev_best_fitness = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def get_best(self, fitness_values):
      best_index = np.argmin(fitness_values)
      return self.population[best_index], fitness_values[best_index]

### Analyze & experience
- Comparing (best) EnhancedArchiveGuidedDE vs (worst) AdaptiveMultimodalDifferentialEvolution, we see that EnhancedArchiveGuidedDE uses an archive to maintain diversity and guide the search, while AdaptiveMultimodalDifferentialEvolution lacks such a mechanism, leading to potential premature convergence.  EnhancedArchiveGuidedDE also incorporates adaptive scaling factors for more robust exploration.

(second best) AdaptiveGaussianArchiveEA vs (second worst) AdaptiveMultimodalOptimizerImproved: AdaptiveGaussianArchiveEA employs adaptive Gaussian sampling and tournament selection, combining exploration and exploitation effectively. AdaptiveMultimodalOptimizerImproved uses a simpler, less efficient local search, and its adaptive perturbation strength lacks a clear strategy.

Comparing (1st) EnhancedArchiveGuidedDE vs (2nd) AdaptiveGaussianArchiveEA, we see that EnhancedArchiveGuidedDE uses Differential Evolution, a more powerful search operator compared to AdaptiveGaussianArchiveEA's basic Gaussian recombination and mutation.  EnhancedArchiveGuidedDE's archive management also contributes to superior performance.

(3rd) AdaptiveGaussianMutationDE vs (4th) AdaptiveGaussianSamplingEAwithArchive: Both use Gaussian mutation but AdaptiveGaussianMutationDE incorporates Differential Evolution, creating more diverse offspring and preventing stagnation. AdaptiveGaussianSamplingEAwithArchives simpler adaptive mutation strategy and tournament selection are less effective.

Comparing (second worst) AdaptiveMultimodalOptimizerImproved vs (worst) AdaptiveMultimodalCMAES, we see that AdaptiveMultimodalOptimizerImproved's local search, though basic, is better than AdaptiveMultimodalCMAES, which struggles with efficient exploration and exploitation in the high-dimensional space. AdaptiveMultimodalCMAES doesn't effectively adapt its population size or mutation strength.

Overall: The best-performing algorithms consistently use sophisticated search operators (DE), archive mechanisms to maintain diversity, and adaptive parameter adjustments.  Simpler strategies, lacking these features, struggle with the complex, high-dimensional search space of f24.
- * **Keywords:**  High-dimensional, multimodal, search operators, diversity, adaptation, local search, premature convergence.

* **Advice:** Focus on designing robust search operators that handle high dimensionality and multimodality effectively.  Incorporate mechanisms for maintaining diversity (e.g., niching, crowding) and adapting parameters (e.g., learning rates, step sizes) based on search progress. Integrate local search methods to refine solutions found by global search.  Thoroughly analyze failure modes to understand premature convergence.

* **Avoid:**  Overly simplistic methods lacking diversity mechanisms or adaptive control. Ignoring the impact of high dimensionality. Neglecting local search refinement.  Relying solely on single metrics for performance evaluation.

* **Explanation:**  Effective heuristics require a multi-faceted approach addressing the challenges of high dimensionality and multimodality.  A balance of exploration (global search) and exploitation (local search) is crucial.  Adaptive parameter control and diversity mechanisms help avoid getting stuck in local optima.  Rigorous evaluation is essential.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 16:16:26 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  High-dimensional, multimodal, search operators, diversity, adaptation, local search, premature convergence.

* **Advice:** Focus on designing robust search operators that handle high dimensionality and multimodality effectively.  Incorporate mechanisms for maintaining diversity (e.g., niching, crowding) and adapting parameters (e.g., learning rates, step sizes) based on search progress. Integrate local search methods to refine solutions found by global search.  Thoroughly analyze failure modes to understand premature convergence.

* **Avoid:**  Overly simplistic methods lacking diversity mechanisms or adaptive control. Ignoring the impact of high dimensionality. Neglecting local search refinement.  Relying solely on single metrics for performance evaluation.

* **Explanation:**  Effective heuristics require a multi-faceted approach addressing the challenges of high dimensionality and multimodality.  A balance of exploration (global search) and exploitation (local search) is crucial.  Adaptive parameter control and diversity mechanisms help avoid getting stuck in local optima.  Rigorous evaluation is essential.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 16:19:22 INFO Perform Harmony Search...
2025-06-23 16:19:32 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:20:18 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0361
2025-06-23 16:20:18 INFO FeHistory: [227.53641178 197.03472206 147.39607879 ... -78.12918519 -80.17615615
 -78.59340178]
2025-06-23 16:20:18 INFO Expected Optimum FE: -100
2025-06-23 16:20:18 INFO Unimodal AOCC mean: nan
2025-06-23 16:20:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:20:18 INFO Multimodal (multiple components) AOCC mean: 0.0361
2025-06-23 16:20:18 INFO AOCC mean: 0.0361
2025-06-23 16:20:18 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:21:06 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0009
2025-06-23 16:21:06 INFO FeHistory: [166.21962084 210.82947046 237.39342185 ...  29.92029068  29.30776253
  14.8431451 ]
2025-06-23 16:21:06 INFO Expected Optimum FE: -100
2025-06-23 16:21:06 INFO Unimodal AOCC mean: nan
2025-06-23 16:21:06 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:21:06 INFO Multimodal (multiple components) AOCC mean: 0.0009
2025-06-23 16:21:06 INFO AOCC mean: 0.0009
2025-06-23 16:21:06 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:21:51 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0175
2025-06-23 16:21:51 INFO FeHistory: [199.5250853  190.78070147 210.65934789 ... -50.01960163 -46.19486413
 -48.67963973]
2025-06-23 16:21:51 INFO Expected Optimum FE: -100
2025-06-23 16:21:51 INFO Unimodal AOCC mean: nan
2025-06-23 16:21:51 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:21:51 INFO Multimodal (multiple components) AOCC mean: 0.0175
2025-06-23 16:21:51 INFO AOCC mean: 0.0175
2025-06-23 16:21:51 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:22:37 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0312
2025-06-23 16:22:37 INFO FeHistory: [160.92741757 202.78487774 179.66263721 ... -64.40917626 -61.6853922
 -62.52989563]
2025-06-23 16:22:37 INFO Expected Optimum FE: -100
2025-06-23 16:22:37 INFO Unimodal AOCC mean: nan
2025-06-23 16:22:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:22:37 INFO Multimodal (multiple components) AOCC mean: 0.0312
2025-06-23 16:22:37 INFO AOCC mean: 0.0312
2025-06-23 16:22:37 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:23:23 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0087
2025-06-23 16:23:23 INFO FeHistory: [183.41474671 199.36775957 171.60988758 ... -29.65127695 -22.83564375
 -27.91614311]
2025-06-23 16:23:23 INFO Expected Optimum FE: -100
2025-06-23 16:23:23 INFO Unimodal AOCC mean: nan
2025-06-23 16:23:23 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:23:23 INFO Multimodal (multiple components) AOCC mean: 0.0087
2025-06-23 16:23:23 INFO AOCC mean: 0.0087
2025-06-23 16:23:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:24:10 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0733
2025-06-23 16:24:10 INFO FeHistory: [147.63609028 191.4772263  228.05863075 ... -96.98992473 -97.14354918
 -97.16433177]
2025-06-23 16:24:10 INFO Expected Optimum FE: -100
2025-06-23 16:24:10 INFO Unimodal AOCC mean: nan
2025-06-23 16:24:10 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:24:10 INFO Multimodal (multiple components) AOCC mean: 0.0733
2025-06-23 16:24:10 INFO AOCC mean: 0.0733
2025-06-23 16:24:10 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:24:55 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0311
2025-06-23 16:24:55 INFO FeHistory: [198.14782681 218.93927306 194.57803156 ... -65.62752922 -70.51025773
 -72.6588296 ]
2025-06-23 16:24:55 INFO Expected Optimum FE: -100
2025-06-23 16:24:55 INFO Unimodal AOCC mean: nan
2025-06-23 16:24:55 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:24:55 INFO Multimodal (multiple components) AOCC mean: 0.0311
2025-06-23 16:24:55 INFO AOCC mean: 0.0311
2025-06-23 16:24:55 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:25:45 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0072
2025-06-23 16:25:45 INFO FeHistory: [166.3613243  187.79436735 166.84577809 ... -20.25634738 -15.55366591
 -21.84771216]
2025-06-23 16:25:45 INFO Expected Optimum FE: -100
2025-06-23 16:25:45 INFO Unimodal AOCC mean: nan
2025-06-23 16:25:45 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:25:45 INFO Multimodal (multiple components) AOCC mean: 0.0072
2025-06-23 16:25:45 INFO AOCC mean: 0.0072
2025-06-23 16:25:45 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:26:30 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0168
2025-06-23 16:26:30 INFO FeHistory: [171.70358239 173.3374855  165.73948571 ... -30.17272983 -31.4920518
 -27.7804117 ]
2025-06-23 16:26:30 INFO Expected Optimum FE: -100
2025-06-23 16:26:30 INFO Unimodal AOCC mean: nan
2025-06-23 16:26:30 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:26:30 INFO Multimodal (multiple components) AOCC mean: 0.0168
2025-06-23 16:26:30 INFO AOCC mean: 0.0168
2025-06-23 16:26:30 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:27:17 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0333
2025-06-23 16:27:17 INFO FeHistory: [190.39045545 201.40098274 175.41631098 ... -73.05081855 -71.10634911
 -72.96117335]
2025-06-23 16:27:17 INFO Expected Optimum FE: -100
2025-06-23 16:27:17 INFO Unimodal AOCC mean: nan
2025-06-23 16:27:17 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:27:17 INFO Multimodal (multiple components) AOCC mean: 0.0333
2025-06-23 16:27:17 INFO AOCC mean: 0.0333
2025-06-23 16:27:17 INFO Generation 1, best so far: 0.10988657163916095
2025-06-23 16:27:17 INFO Population length is: 12
2025-06-23 16:27:17 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-23 16:27:17 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 7.3292e-02# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 8.70277547234484, archive_size: int = 606.0233589740867, initial_F_scale: float = 0.23868493959566067):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 1.4293e-02# Name: ArchiveGuidedDifferentialEvolution
# Description: Combines Differential Evolution with an archive for enhanced exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedDifferentialEvolution:
    """
    Combines Differential Evolution with an archive for enhanced exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 10 * self.dim  #Larger population for higher dimensionality
        self.archive_size = 100 #Size of the archive to maintain diversity
        self.archive = None
        self.archive_fitness = None

        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.adaptation_rate = 0.1 #Rate of adaptation for F and CR


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, self.population)
        self.eval_count += self.population_size
        self.archive = self.population.copy()
        self.archive_fitness = self.fitness_values.copy()

        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)

        while self.eval_count < self.budget:
            new_population = np.empty_like(self.population)
            new_fitness_values = np.empty_like(self.fitness_values)
            for i in range(self.population_size):
                # Mutation using archive and population
                a, b, c = random.sample(range(self.population_size + len(self.archive)), 3)
                
                #Select from archive or population randomly
                if a < self.population_size:
                   x_a = self.population[a]
                else:
                   x_a = self.archive[a - self.population_size]
                if b < self.population_size:
                   x_b = self.population[b]
                else:
                   x_b = self.archive[b - self.population_size]
                if c < self.population_size:
                   x_c = self.population[c]
                else:
                   x_c = self.archive[c - self.population_size]

                mutant = x_a + self.F * (x_b - x_c)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Boundary handling

                #Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count += 1
                new_population[i] = trial if trial_fitness < self.fitness_values[i] else self.population[i]
                new_fitness_values[i] = min(trial_fitness, self.fitness_values[i])

                #Adaptive parameter adjustment
                if trial_fitness < self.fitness_values[i]:
                    self.F = self.F + self.adaptation_rate * (np.random.rand() - 0.5)
                    self.CR = self.CR + self.adaptation_rate * (np.random.rand() - 0.5)

                self.F = np.clip(self.F, 0.1, 1.0)
                self.CR = np.clip(self.CR, 0.1, 1.0)


            self.population = new_population
            self.fitness_values = new_fitness_values

            #Update Archive - keep only best solutions
            combined_archive = np.vstack((self.archive, self.population))
            combined_fitness = np.concatenate((self.archive_fitness, self.fitness_values))
            indices = np.argsort(combined_fitness)
            self.archive = combined_archive[indices[:self.archive_size]]
            self.archive_fitness = combined_fitness[indices[:self.archive_size]]
            
            if np.min(self.fitness_values) < self.best_fitness_overall:
                self.best_fitness_overall = np.min(self.fitness_values)
                self.best_solution_overall = self.population[np.argmin(self.fitness_values)]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 3 (Overall AOCC Score on function 24: 1.0027e-02# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.F_scale_variation = 0.3 #variation range for F


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive with enhanced diversity management
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor with controlled variation
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()  #scale factor with slight variation,bounded to [0.5, 0.8]
        self.F_scale = np.clip(self.F_scale, 0.5, 0.8)

        for i in range(self.population_size):
            # Select pbest from archive (if available) with a bias toward better solutions
            if self.archive:
                #Weighted random choice to favour better solutions
                weights = np.exp(-np.array([f for _,f in self.archive]))
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive using a combined metric
                worst_index = np.argmax([f for _, f in self.archive])
                
                #Combine fitness and diversity in the update decision
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 4 (Overall AOCC Score on function 24: 3.2540e-05# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an archive for maintaining diversity and adaptive Gaussian mutation for multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an archive to maintain diversity and adaptive Gaussian mutation for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Initial Gaussian mutation strength
        self.sigma_decay = 0.98
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._adaptive_gaussian_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Select three distinct individuals other than the current one
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)

            a, b, c = population[indices]
            mutant = a + self.F * (b - c)

            # Binomial crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _adaptive_gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an archive for diversity and adaptive scaling factor.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an archive for diversity and adaptive scaling factor.
# Code:

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an archive for diversity maintenance and an adaptive scaling factor for robust exploration in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # Common heuristic
        self.archive_size = 200 # Increased archive size for higher dimensionality
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive with elitism and diversity consideration.
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor with more aggressive exploration early on
        self.F_scale = 0.5 + 0.5 * np.exp(-self.eval_count / (self.budget / 2)) #decaying exploration

        for i in range(self.population_size):
            # Select pbest from archive (if available), prioritizing diversity
            if self.archive:
                distances = np.linalg.norm(np.array([ind[0] for ind in self.archive]) - population[i], axis=1)
                pbest_index = np.argmax(distances)  #Select farthest individual from current to promote diversity
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize better fitness and diversity in the archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveGuidedDE
# Description: Combines Differential Evolution with an archive for diversity and adaptive mutation for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveArchiveGuidedDE:
    """
    Combines Differential Evolution with an archive for diversity and adaptive mutation for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive = []  # Archive to maintain diversity
        self.archive_size = 100  # Maximum size of the archive
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor (adaptive)
        self.CR = 0.9  # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._get_best(fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(objective_function)
            offspring_fitness = self._evaluate_population(objective_function)
            
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness_values = combined_fitness[indices[:self.population_size]]

            self._update_archive(self.population, fitness_values)
            self._adapt_F() #Adaptive F based on diversity

            best_solution, best_fitness = self._get_best(fitness_values)
            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_F': self.F
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness_values

    def _generate_offspring(self, objective_function):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            r1, r2, r3 = self._select_individuals(i)
            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])
            offspring[i] = self._crossover(self.population[i], v)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring


    def _select_individuals(self, i):
        candidates = list(range(self.population_size))
        candidates.remove(i)
        r1, r2, r3 = random.sample(candidates, 3)
        return r1, r2, r3

    def _crossover(self, x, v):
        u = np.zeros_like(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
            else:
                u[j] = x[j]
        return u

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            self._add_to_archive(population[i], fitness_values[i])

    def _add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_solution, worst_fitness = max(self.archive, key=lambda item: item[1])
            if fitness < worst_fitness:
                self.archive.remove((worst_solution, worst_fitness))
                self.archive.append((solution, fitness))

    def _adapt_F(self):
      archive_diversity = np.std(np.array([item[0] for item in self.archive]), axis=0).mean() if len(self.archive)>0 else 0
      if archive_diversity > 10: #Increase exploration
          self.F = min(1.2, self.F * 1.05)
      else:
          self.F = max(0.5, self.F * 0.95)

    def _get_best(self, fitness_values):
        best_index = np.argmin(fitness_values)
        return self.population[best_index], fitness_values[best_index]
```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an archive for diversity and adaptive mutation for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an archive for diversity and adaptive mutation for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Initial population size
        self.archive_size = 20 * self.dim #Archive size
        self.archive = []
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.tau = 0.1 # Adaptation parameter for F

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        # Initialize population
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += self.population_size

        #Update best solution
        best_index = np.argmin(fitness)
        self.best_solution_overall = population[best_index]
        self.best_fitness_overall = fitness[best_index]
        
        # Main optimization loop
        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                # Select three random individuals from population and archive
                indices = np.random.choice(np.concatenate((np.arange(self.population_size), np.arange(len(self.archive)))), size=3, replace=False)
                a, b, c = [population[j] if j < self.population_size else self.archive[j - self.population_size] for j in indices]

                #Differential evolution mutation
                mutant = a + self.F * (b - c)
                
                # Adaptive Mutation using Cauchy Distribution
                mutant += cauchy.rvs(loc=0, scale=self.tau * np.abs(mutant), size=self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])

                offspring.append(trial)

            offspring = np.array(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection
            combined_population = np.vstack((population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = population[best_index]
                self.best_fitness_overall = fitness[best_index]

            # Update archive
            self.archive.extend(combined_population[indices[self.population_size:]])
            if len(self.archive) > self.archive_size:
                 self.archive = sorted(self.archive, key=lambda x: np.linalg.norm(x))[:self.archive_size]

            #Adapt F
            self.F = max(0.1, min(1.0, self.F + self.tau * (fitness[best_index] - self.best_fitness_overall)))

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A Differential Evolution variant with adaptive mutation and niching for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A Differential Evolution variant with adaptive mutation and niching for multimodal optimization.
# Code:
class AdaptiveMultimodalDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 20 * self.dim  # Increased population size for higher dimensionality
        self.population = None
        self.F = 0.5  # Initial scaling factor
        self.CR = 0.9  # Crossover rate
        self.niche_radius = 0.1  # Parameter controlling niche size; adjust as needed
        self.niches = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self.update_niches(offspring, offspring_fitness)
            self.update_population(offspring, offspring_fitness)
            
            self.adapt_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'number_of_niches': len(self.niches)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])

        return offspring

    def update_niches(self, offspring, offspring_fitness):
        for i in range(self.population_size):
            added_to_niche = False
            for j in range(len(self.niches)):
                if np.linalg.norm(offspring[i] - self.niches[j][0]) < self.niche_radius:
                    self.niches[j][1].append((offspring[i], offspring_fitness[i]))
                    added_to_niche = True
                    break
            if not added_to_niche:
                self.niches.append([(offspring[i]), [(offspring[i], offspring_fitness[i])]])


    def update_population(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        
        new_population = []
        new_fitness = []

        #Select best from each niche
        for niche in self.niches:
            best_solution = min(niche[1],key=lambda item:item[1])[0]
            best_fitness = min(niche[1],key=lambda item:item[1])[1]
            new_population.append(best_solution)
            new_fitness.append(best_fitness)

        self.population = np.array(new_population)
        fitness = np.array(new_fitness)
        
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        self.niches = [] #clear niches for the next iteration

    def adapt_parameters(self):
        # Simple adaptive strategy: Reduce F and CR if progress is slow
        if self.eval_count > self.budget * 0.2 and self.best_fitness_overall > -90: # Adjust threshold as needed
            self.F *= 0.9
            self.CR *= 0.9
            self.niche_radius *= 0.9

```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A differential evolution variant with adaptive mutation and niching to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A differential evolution variant with adaptive mutation and niching to escape local optima in multimodal landscapes.
# Code:

class AdaptiveMultimodalDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 20 * self.dim  # Increased population size for higher dimensionality
        self.population = None
        self.F = 0.5  # Initial scaling factor
        self.CR = 0.9  # Crossover rate
        self.niche_radius = 0.1  # Initial niche radius

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self.update_population(offspring, offspring_fitness)

            #Adaptive Niche Radius and Mutation
            if self.eval_count % (self.budget//10) == 0: # Adjust every 10% of budget
                self.adapt_parameters(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            r0, r1, r2, r3 = random.sample(range(self.population_size), 4)
            while r0 == i:
                r0 = random.randint(0, self.population_size - 1)

            v = self.population[r0] + self.F * (self.population[r1] - self.population[r2] + self.population[r3] - self.population[i])
            v = np.clip(v, self.lower_bounds, self.upper_bounds)

            jrand = random.randint(0, self.dim - 1)
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i, j] = v[j]
                else:
                    offspring[i, j] = self.population[i, j]
        return offspring

    def update_population(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((self.get_fitness(), offspring_fitness))

        # Niching selection: Prioritize diversity.
        new_population = []
        for i in range(self.population_size):
            best_candidate = None
            best_candidate_fitness = float('inf')
            for j in range(len(combined_population)):
                is_niche_occupied = False
                for k in range(len(new_population)):
                  if np.linalg.norm(combined_population[j]-np.array(new_population[k][0])) < self.niche_radius:
                      is_niche_occupied = True
                      break
                if combined_fitness[j] < best_candidate_fitness and not is_niche_occupied:
                  best_candidate = combined_population[j]
                  best_candidate_fitness = combined_fitness[j]
            new_population.append([best_candidate, best_candidate_fitness])

        self.population = np.array([sol for sol, _ in new_population])
        self.best_solution_overall = self.population[np.argmin(self.get_fitness())]
        self.best_fitness_overall = np.min(self.get_fitness())

    def get_fitness(self):
        return np.array([self.best_fitness_overall if np.isnan(x).any() else x for x in self.best_fitness_overall])


    def adapt_parameters(self, fitness):
        # Adapt F and CR based on convergence
        std_dev = np.std(fitness)
        if std_dev < 0.1:  # Adjust thresholds as needed
            self.F = max(0.1, self.F - 0.1) #Reduce exploration
            self.CR = max(0.1, self.CR - 0.1)
        else:
            self.F = min(1, self.F + 0.1) #Increase exploration
            self.CR = min(1, self.CR + 0.1)

        # Adapt niche radius to balance exploration and exploitation.
        self.niche_radius = 0.1 + 0.05* (np.mean(fitness) / abs(self.best_fitness_overall))
        self.niche_radius = min(5, max(0.1, self.niche_radius))



```

### Rank 10 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A Differential Evolution variant with adaptive mutation and population diversification strategies for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDifferentialEvolution
# Description: A Differential Evolution variant with adaptive mutation and population diversification strategies for multimodal optimization.
# Code:
class AdaptiveMultimodalDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 20 * self.dim  # Increased population size for higher dimensionality
        self.population = None
        self.F = 0.5  # Initial scaling factor
        self.CR = 0.9  # Crossover rate
        self.niche_radius = 0.1 * (self.upper_bounds - self.lower_bounds).mean() #Adaptive niche radius
        self.best_solutions = [] #Maintain a diverse set of best solutions from different niches

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self.update_population(offspring, offspring_fitness)
            self.diversify_population() #Add diversity mechanism
            self.update_best()

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'best_solutions_found': len(self.best_solutions)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            #Adaptive Mutation Strategy
            self.F = max(0.1, min(1.0, self.F + 0.1 * np.random.randn())) #Adaptive scaling factor

            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])

        return offspring

    def update_population(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((np.array([self.best_fitness_overall]), offspring_fitness)) #Prioritize the current best

        indices = np.argsort(combined_fitness)
        self.population = combined_population[indices[:self.population_size]]

    def diversify_population(self):
        #Replace a fraction of the worst solutions with randomly generated solutions
        num_to_replace = int(0.1 * self.population_size)
        worst_indices = np.argsort(self.population)[-num_to_replace:]
        self.population[worst_indices] = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_to_replace, self.dim))

    def update_best(self):
        current_best_solution = self.population[np.argmin(objective_function(self.population))]
        current_best_fitness = np.min(objective_function(self.population))

        if current_best_fitness < self.best_fitness_overall:
          self.best_fitness_overall = current_best_fitness
          self.best_solution_overall = current_best_solution
          #add to best solutions if it's sufficiently different from existing ones
          is_new_niche = True
          for best_sol in self.best_solutions:
            if np.linalg.norm(current_best_solution - best_sol) < self.niche_radius:
              is_new_niche = False
              break
          if is_new_niche:
            self.best_solutions.append(current_best_solution.copy())

```

### Rank 11 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive mutation and niching for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive mutation and niching for multimodal optimization.
# Code:
class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 20 * self.dim  # Increased population size
        self.niche_radius = 0.2  # Initial niche radius
        self.F_scale = 0.8 #Initial scaling factor
        self.CR = 0.9 # Crossover rate

        self.population = None
        self.fitness = None
        self.niches = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness)]
        self.best_fitness_overall = np.min(self.fitness)
        self.niches = [ (self.best_solution_overall, self.best_fitness_overall)]

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_population(offspring, offspring_fitness)
            
            #Adaptive Niche Radius
            self.niche_radius *= 0.99 #slowly decrease niche radius

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'niches_found': len(self.niches)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            #Adaptive scaling factor and CR
            self.F_scale = 0.5 + 0.5*np.random.rand()
            self.CR = 0.5 + 0.5*np.random.rand()

            #Select a target vector
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            #Differential mutation
            mutant = self.population[a] + self.F_scale * (self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)


            #Crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])
            
        return offspring

    def update_population(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((self.fitness, offspring_fitness))

        #Niching Selection
        new_population = []
        new_fitness = []
        for i in range(len(combined_population)):
            added = False
            for j, (niche_center, _) in enumerate(self.niches):
                if np.linalg.norm(combined_population[i] - niche_center) < self.niche_radius:
                    if len(self.niches[j]) < 10 :
                       new_population.append(combined_population[i])
                       new_fitness.append(combined_fitness[i])
                       added = True
                       break
            if not added:
                new_population.append(combined_population[i])
                new_fitness.append(combined_fitness[i])

        self.population = np.array(new_population[:self.population_size])
        self.fitness = np.array(new_fitness[:self.population_size])
        
        #Update best solution and niches
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = self.fitness[best_index]
            self.niches = [(self.best_solution_overall, self.best_fitness_overall)]
        else:
            self.niches.append((self.population[best_index], self.fitness[best_index]))

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 16:27:21 INFO Full response text: **Analysis:**

Comparing (best) EnhancedArchiveGuidedDE vs (worst) AdaptiveMultimodalDE, we see that the best uses an archive to guide the search, adapting the scaling factor (F) for a balance between exploration and exploitation. The worst uses simpler adaptive mutation and niching, lacking the sophisticated archive management and adaptive F scaling of the best.  (second best) ArchiveGuidedDifferentialEvolution vs (second worst) ArchiveGuidedAdaptiveDE show that using a larger population size with adaptive parameter adjustment for F and CR is better than a fixed F and CR, even with a larger archive. Comparing (1st) vs (2nd), we see that incorporating pbest selection from the archive with a more refined archive update strategy (prioritizing diversity and fitness) in EnhancedArchiveGuidedDE leads to significantly better results than a random selection from the population and archive in ArchiveGuidedDifferentialEvolution. (3rd) ArchiveGuidedAdaptiveDE vs (4th) ArchiveGuidedAdaptiveDE highlights the importance of adaptive scaling factors for exploration and archive update strategies that consider both fitness and diversity for improved performance. Comparing (second worst) ArchiveGuidedAdaptiveDE vs (worst) AdaptiveMultimodalDE reveals that while both use archives, the second worst employs better adaptive mechanisms for mutation and archive management, resulting in superior performance. Overall:  The top-performing algorithms consistently leverage archives to guide the search, use adaptive strategies for mutation and scaling factors, and employ sophisticated archive update mechanisms that balance exploration and exploitation.  Simple adaptive mutation and niching alone are insufficient to tackle the complexities of f24.


**Experience:**

Effective high-dimensional optimization requires sophisticated population management, adaptive parameter tuning, and mechanisms to balance exploration and exploitation. Archives are crucial for maintaining diversity and guiding the search towards promising regions.  Adaptive scaling factors and selective archive updates are key components of high-performing algorithms.

2025-06-23 16:27:23 INFO Full response text: * **Keywords:**  Adaptive scaling, selective archiving, exploration-exploitation balance, high-dimensional optimization, population management.

* **Advice:** Focus on designing adaptive mechanisms that dynamically adjust based on the search landscape.  Prioritize efficient archive management strategies that favor diversity and promising solutions.  Develop robust exploration strategies to avoid premature convergence. Quantify the exploration/exploitation balance.

* **Avoid:**  Generic statements about "sophisticated" methods or vague terms like "diversity maintenance." Avoid simply integrating local search without a clear strategy for its application and integration with global search. Avoid relying on pre-defined parameter settings.

* **Explanation:** The current self-reflection lacks concrete actionable steps. The ineffective reflection highlights common pitfalls.  The improved approach emphasizes specific design choices for adaptive heuristics, moving beyond abstract descriptions to concrete implementation details.  This focus leads to better-defined and more testable heuristics.

2025-06-23 16:27:23 INFO Generating offspring via Crossover...
2025-06-23 16:37:31 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
ArchiveGuidedAdaptiveDE
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an archive to maintain diversity and adaptive Gaussian mutation for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Initial Gaussian mutation strength
        self.sigma_decay = 0.98
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._adaptive_gaussian_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Select three distinct individuals other than the current one
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)

            a, b, c = population[indices]
            mutant = a + self.F * (b - c)

            # Binomial crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _adaptive_gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])


### Worse code
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 8.70277547234484, archive_size: int = 606.0233589740867, initial_F_scale: float = 0.23868493959566067):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

### Analyze & experience
- Comparing (best) EnhancedArchiveGuidedDE vs (worst) AdaptiveMultimodalDE, we see that the best uses an archive to guide the search, adapting the scaling factor (F) for a balance between exploration and exploitation. The worst uses simpler adaptive mutation and niching, lacking the sophisticated archive management and adaptive F scaling of the best.  (second best) ArchiveGuidedDifferentialEvolution vs (second worst) ArchiveGuidedAdaptiveDE show that using a larger population size with adaptive parameter adjustment for F and CR is better than a fixed F and CR, even with a larger archive. Comparing (1st) vs (2nd), we see that incorporating pbest selection from the archive with a more refined archive update strategy (prioritizing diversity and fitness) in EnhancedArchiveGuidedDE leads to significantly better results than a random selection from the population and archive in ArchiveGuidedDifferentialEvolution. (3rd) ArchiveGuidedAdaptiveDE vs (4th) ArchiveGuidedAdaptiveDE highlights the importance of adaptive scaling factors for exploration and archive update strategies that consider both fitness and diversity for improved performance. Comparing (second worst) ArchiveGuidedAdaptiveDE vs (worst) AdaptiveMultimodalDE reveals that while both use archives, the second worst employs better adaptive mechanisms for mutation and archive management, resulting in superior performance. Overall:  The top-performing algorithms consistently leverage archives to guide the search, use adaptive strategies for mutation and scaling factors, and employ sophisticated archive update mechanisms that balance exploration and exploitation.  Simple adaptive mutation and niching alone are insufficient to tackle the complexities of f24.
- * **Keywords:**  Adaptive scaling, selective archiving, exploration-exploitation balance, high-dimensional optimization, population management.

* **Advice:** Focus on designing adaptive mechanisms that dynamically adjust based on the search landscape.  Prioritize efficient archive management strategies that favor diversity and promising solutions.  Develop robust exploration strategies to avoid premature convergence. Quantify the exploration/exploitation balance.

* **Avoid:**  Generic statements about "sophisticated" methods or vague terms like "diversity maintenance." Avoid simply integrating local search without a clear strategy for its application and integration with global search. Avoid relying on pre-defined parameter settings.

* **Explanation:** The current self-reflection lacks concrete actionable steps. The ineffective reflection highlights common pitfalls.  The improved approach emphasizes specific design choices for adaptive heuristics, moving beyond abstract descriptions to concrete implementation details.  This focus leads to better-defined and more testable heuristics.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 16:37:31 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Adaptive scaling, selective archiving, exploration-exploitation balance, high-dimensional optimization, population management.

* **Advice:** Focus on designing adaptive mechanisms that dynamically adjust based on the search landscape.  Prioritize efficient archive management strategies that favor diversity and promising solutions.  Develop robust exploration strategies to avoid premature convergence. Quantify the exploration/exploitation balance.

* **Avoid:**  Generic statements about "sophisticated" methods or vague terms like "diversity maintenance." Avoid simply integrating local search without a clear strategy for its application and integration with global search. Avoid relying on pre-defined parameter settings.

* **Explanation:** The current self-reflection lacks concrete actionable steps. The ineffective reflection highlights common pitfalls.  The improved approach emphasizes specific design choices for adaptive heuristics, moving beyond abstract descriptions to concrete implementation details.  This focus leads to better-defined and more testable heuristics.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 16:39:55 INFO Perform Harmony Search...
2025-06-23 16:40:04 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:40:48 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0097
2025-06-23 16:40:48 INFO FeHistory: [210.61403613 193.38360766 142.62866535 ...   3.32491771  -4.10440858
 -10.32771776]
2025-06-23 16:40:48 INFO Expected Optimum FE: -100
2025-06-23 16:40:48 INFO Unimodal AOCC mean: nan
2025-06-23 16:40:48 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:40:48 INFO Multimodal (multiple components) AOCC mean: 0.0097
2025-06-23 16:40:48 INFO AOCC mean: 0.0097
2025-06-23 16:40:48 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:41:34 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0026
2025-06-23 16:41:34 INFO FeHistory: [155.32484123 210.57983077 157.52305244 ...  19.05147913  19.89013227
   5.53660025]
2025-06-23 16:41:34 INFO Expected Optimum FE: -100
2025-06-23 16:41:34 INFO Unimodal AOCC mean: nan
2025-06-23 16:41:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:41:34 INFO Multimodal (multiple components) AOCC mean: 0.0026
2025-06-23 16:41:34 INFO AOCC mean: 0.0026
2025-06-23 16:41:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:42:20 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0206
2025-06-23 16:42:20 INFO FeHistory: [180.50541347 186.23517178 187.98530619 ... -52.8345292  -62.32536338
 -56.58233883]
2025-06-23 16:42:20 INFO Expected Optimum FE: -100
2025-06-23 16:42:20 INFO Unimodal AOCC mean: nan
2025-06-23 16:42:20 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:42:20 INFO Multimodal (multiple components) AOCC mean: 0.0206
2025-06-23 16:42:20 INFO AOCC mean: 0.0206
2025-06-23 16:42:20 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:43:05 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0183
2025-06-23 16:43:05 INFO FeHistory: [229.20585543 167.08718565 203.9859828  ... -36.82752539 -40.69649301
 -43.63376819]
2025-06-23 16:43:05 INFO Expected Optimum FE: -100
2025-06-23 16:43:05 INFO Unimodal AOCC mean: nan
2025-06-23 16:43:05 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:43:05 INFO Multimodal (multiple components) AOCC mean: 0.0183
2025-06-23 16:43:05 INFO AOCC mean: 0.0183
2025-06-23 16:43:05 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:43:49 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0643
2025-06-23 16:43:49 INFO FeHistory: [200.39360368 174.34748335 191.33565767 ... -94.52847177 -94.86691567
 -94.61022826]
2025-06-23 16:43:49 INFO Expected Optimum FE: -100
2025-06-23 16:43:49 INFO Unimodal AOCC mean: nan
2025-06-23 16:43:49 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:43:49 INFO Multimodal (multiple components) AOCC mean: 0.0643
2025-06-23 16:43:49 INFO AOCC mean: 0.0643
2025-06-23 16:43:49 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:44:34 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0003
2025-06-23 16:44:34 INFO FeHistory: [170.5691518  186.37481022 189.25367502 ...  43.66386225  26.34373325
  38.33258156]
2025-06-23 16:44:34 INFO Expected Optimum FE: -100
2025-06-23 16:44:34 INFO Unimodal AOCC mean: nan
2025-06-23 16:44:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:44:34 INFO Multimodal (multiple components) AOCC mean: 0.0003
2025-06-23 16:44:34 INFO AOCC mean: 0.0003
2025-06-23 16:44:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:45:18 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0188
2025-06-23 16:45:18 INFO FeHistory: [208.24245557 191.75758415 192.69053421 ... -55.75396693 -44.83476024
 -53.45058366]
2025-06-23 16:45:18 INFO Expected Optimum FE: -100
2025-06-23 16:45:18 INFO Unimodal AOCC mean: nan
2025-06-23 16:45:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:45:18 INFO Multimodal (multiple components) AOCC mean: 0.0188
2025-06-23 16:45:18 INFO AOCC mean: 0.0188
2025-06-23 16:45:18 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:46:01 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0007
2025-06-23 16:46:01 INFO FeHistory: [194.27228129 211.83679113 161.79778627 ...   2.66223639   9.9808505
  21.9102269 ]
2025-06-23 16:46:01 INFO Expected Optimum FE: -100
2025-06-23 16:46:01 INFO Unimodal AOCC mean: nan
2025-06-23 16:46:01 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:46:01 INFO Multimodal (multiple components) AOCC mean: 0.0007
2025-06-23 16:46:01 INFO AOCC mean: 0.0007
2025-06-23 16:46:01 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:46:47 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0069
2025-06-23 16:46:47 INFO FeHistory: [202.15867752 199.5697013  182.97573924 ... -15.14270815 -20.94958942
 -27.04291474]
2025-06-23 16:46:47 INFO Expected Optimum FE: -100
2025-06-23 16:46:47 INFO Unimodal AOCC mean: nan
2025-06-23 16:46:47 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:46:47 INFO Multimodal (multiple components) AOCC mean: 0.0069
2025-06-23 16:46:47 INFO AOCC mean: 0.0069
2025-06-23 16:46:47 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:47:31 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0268
2025-06-23 16:47:31 INFO FeHistory: [162.21507488 185.89120646 186.95799065 ... -36.0568772  -40.04115779
 -29.09369092]
2025-06-23 16:47:31 INFO Expected Optimum FE: -100
2025-06-23 16:47:31 INFO Unimodal AOCC mean: nan
2025-06-23 16:47:31 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:47:31 INFO Multimodal (multiple components) AOCC mean: 0.0268
2025-06-23 16:47:31 INFO AOCC mean: 0.0268
2025-06-23 16:47:31 INFO Generation 2, best so far: 0.10988657163916095
2025-06-23 16:47:31 INFO Population length is: 12
2025-06-23 16:47:31 INFO --- Performing Long-Term Reflection at Generation 3 ---
2025-06-23 16:47:31 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 6.4319e-02# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 8.174802229725055, archive_size: int = 270.06092544891357,
                 initial_F_scale: float = 0.20479542288074049, F_scale_variation: float = 0.5761099516092845,
                 archive_update_threshold: float = 0.06764885795066156):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.F_scale_variation = F_scale_variation
        self.archive_update_threshold = archive_update_threshold


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 1.6112e-03# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided pbest and scaling factor for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided pbest and scaling factor for multimodal optimization.

class AdaptiveArchiveDE:
    """
    Combines Differential Evolution with an archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 500  # Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.F_scale_variation = 0.3 #variation range for F


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive with enhanced diversity management
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Early stopping condition
            if self.best_fitness_overall < acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor with controlled variation
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()  #scale factor with slight variation,bounded to [0.5, 0.8]
        self.F_scale = np.clip(self.F_scale, 0.1, 1.0) #adjust the range as needed

        for i in range(self.population_size):
            # Select pbest from archive (if available) with a bias toward better solutions
            if self.archive:
                #Weighted random choice to favour better solutions
                weights = np.exp(-np.array([f for _,f in self.archive]))
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive using a combined metric
                worst_index = np.argmax([f for _, f in self.archive])
                
                #Combine fitness and diversity in the update decision.  Prioritize better fitness.
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 3 (Overall AOCC Score on function 24: 2.2067e-04# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided pbest and scaling factor for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided pbest and scaling factor for multimodal optimization.

class AdaptiveArchiveDE:
    """
    Combines Differential Evolution with an archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.F_scale_variation = 0.3 #variation range for F


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive with enhanced diversity management
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


            if self.best_fitness_overall <= acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor with controlled variation
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()  #scale factor with slight variation,bounded to [0.5, 0.8]
        self.F_scale = np.clip(self.F_scale, 0.5, 0.8)

        for i in range(self.population_size):
            # Select pbest from archive (if available) with a bias toward better solutions
            if self.archive:
                #Weighted random choice to favour better solutions
                weights = np.exp(-np.array([f for _,f in self.archive]))
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive using a combined metric
                worst_index = np.argmax([f for _, f in self.archive])
                
                #Combine fitness and diversity in the update decision
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 4 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveGuidedDE
# Description: Combines Differential Evolution with an adaptive archive and scaling factor for efficient multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveArchiveGuidedDE:
    """
    Combines Differential Evolution with an adaptive archive and scaling factor for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 2.0, archive_size: int = 100, initial_F_scale: float = 0.5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = int(population_size_multiplier * self.dim)
        self.archive_size = archive_size
        self.archive = []
        self.F_scale = initial_F_scale
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            #Adapt F_scale based on progress.  Increase exploration if stuck.
            if self.eval_count > self.budget * 0.2 and self.best_fitness_overall > self.best_fitness_overall * 0.99:
                self.F_scale = min(1.0, self.F_scale + 0.1) # Gradually increase exploration.

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided pbest and scaling factor for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided pbest and scaling factor for multimodal optimization.
class AdaptiveArchiveDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for higher dimensionality
        self.archive = []
        self.F_scale = 0.5  # Initial scaling factor
        self.F_scale_variation = 0.3 # Variation in F


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            if np.min(fitness) < self.best_fitness_overall:
                self.best_fitness_overall = np.min(fitness)
                self.best_solution_overall = self.population[np.argmin(fitness)]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = np.clip(self.F_scale + 0.1 * (random.random() - 0.5), 0.1, 1.0) #Adaptive F scale


        for i in range(self.population_size):
            # pbest selection from archive (if available), otherwise use global best
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = self.population[np.argmin(objective_function(self.population))] # Use global best if no archive

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveGuidedDEwithPbest
# Description: Differential Evolution with adaptive F, archive for diversity, and pbest selection from archive.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveGuidedDEwithPbest
# Description: Differential Evolution with adaptive F, archive for diversity, and pbest selection from archive.
class AdaptiveArchiveGuidedDEwithPbest:
    """
    Combines Differential Evolution with an archive for diversity and adaptive mutation for multimodal optimization.
    Includes pbest selection from the archive.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive = []  # Archive to maintain diversity
        self.archive_size = int(8.70277547234484 * self.dim) # Heuristic from EnhancedArchiveGuidedDE
        self.population_size = int(8.70277547234484 * self.dim) # Heuristic from EnhancedArchiveGuidedDE
        self.F = 0.8  # Differential evolution scaling factor (adaptive)
        self.CR = 0.9  # Crossover rate
        self.F_scale_variation = 0.3 # Variation for F


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._get_best(fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(objective_function)
            offspring_fitness = self._evaluate_population(objective_function)
            
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness_values = combined_fitness[indices[:self.population_size]]

            self._update_archive(self.population, fitness_values)
            self._adapt_F() #Adaptive F based on diversity

            best_solution, best_fitness = self._get_best(fitness_values)
            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_F': self.F
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness_values

    def _generate_offspring(self, objective_function):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            #Pbest selection from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = self.population[np.argmin(self._evaluate_population(objective_function))]

            r1, r2, r3 = self._select_individuals(i)
            v = pbest + self.F * (self.population[r1] - self.population[r2] + self.population[r3]) #Modified DE/best/1/bin
            offspring[i] = self._crossover(self.population[i], v)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring


    def _select_individuals(self, i):
        candidates = list(range(self.population_size))
        candidates.remove(i)
        r1, r2, r3 = random.sample(candidates, 3)
        return r1, r2, r3

    def _crossover(self, x, v):
        u = np.zeros_like(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
            else:
                u[j] = x[j]
        return u

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            self._add_to_archive(population[i], fitness_values[i])

    def _add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_solution, worst_fitness = max(self.archive, key=lambda item: item[1])
            if fitness < worst_fitness:
                self.archive.remove((worst_solution, worst_fitness))
                self.archive.append((solution, fitness))

    def _adapt_F(self):
      archive_diversity = np.std(np.array([item[0] for item in self.archive]), axis=0).mean() if len(self.archive)>0 else 0
      self.F = 0.5 + self.F_scale_variation * np.random.rand() #Adaptive F with variation


    def _get_best(self, fitness_values):
        best_index = np.argmin(fitness_values)
        return self.population[best_index], fitness_values[best_index]
```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedAdaptiveDE_Enhanced
# Description: Adaptive Differential Evolution with archive guidance and pbest selection for multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDE_Enhanced:
    """
    Combines Differential Evolution with an archive to maintain diversity and adaptive Gaussian mutation for multimodal optimization.  Uses pbest from archive.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.archive_size = 200  # Adjust as needed
        self.F_scale = 0.5 # Initial scaling factor
        self.F_scale_variation = 0.3 # Variation in scaling factor
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Initial Gaussian mutation strength
        self.sigma_decay = 0.98
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._adaptive_gaussian_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay
            self.F_scale = 0.5 + self.F_scale_variation * np.random.rand() #Adaptive scaling factor

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive.size > 0:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness_values)]

            # Select three distinct individuals other than the current one
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)

            a, b, c = population[indices]
            mutant = pbest + self.F_scale * (a + b - 2 * c) # Modified DE strategy with pbest

            # Binomial crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _adaptive_gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive)[:self.archive_size]

```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: A Differential Evolution variant with adaptive scaling and a diversity-preserving archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: A Differential Evolution variant with adaptive scaling and a diversity-preserving archive for multimodal optimization.
class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt F and CR based on success rate.  This is a simplified example; more advanced strategies exist.
            success_rate = np.mean(offspring_fitness < fitness)
            self.F_scale = max(0.1, min(1.0, self.F_scale + 0.1 * (success_rate - 0.2) )) #Adjust F 
            self.CR = max(0.1,min(1.0, self.CR + 0.1*(success_rate - 0.2))) # Adjust CR

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            #Select pbest from archive, prioritizing diversity
            if self.archive:
                distances = np.sum((np.array([x[0] for x in self.archive]) - population[i])**2, axis=1)
                pbest_index = np.argmax(distances) # choose furthest point from current solution.
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]


            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover (Binomial)
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Remove worst solution from archive, favouring diversity
                distances = np.sum((np.array([x[0] for x in self.archive]) - offspring[i])**2, axis=1)
                worst_index = np.argmin(distances)  #Remove the closest solution

                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling and niching for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling and niching for multimodal optimization.
# Code:
class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.niche_radius = 0.1  # Parameter controlling niche radius (adaptable)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            
            # Niche-based selection: prioritize diverse solutions
            selected_indices = self.niche_selection(combined_population, combined_fitness)
            self.population = combined_population[selected_indices]
            fitness = combined_fitness[selected_indices]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adaptive Niche Radius
            self.niche_radius = max(0.01, self.niche_radius * 0.995 + 0.005 * (1 - np.mean(fitness)/abs(np.min(fitness))))

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.5 * np.random.rand() # Increased variation

        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def niche_selection(self, population, fitness):
        selected_indices = []
        while len(selected_indices) < self.population_size:
            best_index = np.argmin(fitness)
            selected_indices.append(best_index)
            fitness[best_index] = float('inf')  # Mark as selected

            # Remove solutions within the niche radius
            for i in range(len(fitness)):
                if fitness[i] != float('inf'):
                    distance = np.linalg.norm(population[best_index] - population[i])
                    if distance < self.niche_radius:
                        fitness[i] = float('inf')
        return np.array(selected_indices)

```

### Rank 10 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling, selective archiving, and a diversity-promoting mechanism for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling, selective archiving, and a diversity-promoting mechanism for multimodal optimization.
# Code:

class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            
            # Selection based on Pareto dominance for multimodal scenarios
            pareto_front = self.pareto_selection(combined_population, combined_fitness)
            self.population = pareto_front[:self.population_size]
            fitness = combined_fitness[np.where(np.isin(combined_population,pareto_front))[0][:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adapt F based on success rate (more sophisticated adaptation)
            self.adapt_F(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            #Adaptive scaling factor with CR (Crossover rate)
            self.F_scale = 0.3 + 0.7 * np.random.rand() #scale factor with slight variation

            # Select pbest from archive (if available), prioritizes diversity
            if self.archive:
                distances = np.linalg.norm(self.archive[:, 0] - population[i], axis=1)
                pbest_index = np.argmax(distances) #select furthest point from current solution
                pbest = self.archive[pbest_index, 0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            jrand = random.randint(0, self.dim - 1)
            offspring[i] = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            offspring[i, jrand] = mutant[jrand] #Ensure at least one parameter is changed


        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax(self.archive[:, 1]) #replace worst solution
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
        self.archive = np.array(self.archive) #convert to numpy array for efficient calculation



    def adapt_F(self, fitness):
        success_rate = np.mean(fitness < np.median(fitness))  #Simple success rate calculation
        if success_rate > 0.9:
            self.F_scale *= 0.9 #decrease F for better exploitation
        elif success_rate < 0.1:
            self.F_scale *= 1.1 #increase F for better exploration


    def pareto_selection(self, population, fitness):
        pareto_front = []
        is_dominated = np.zeros(len(population), dtype=bool)

        for i in range(len(population)):
            for j in range(len(population)):
                if i != j and fitness[j] <= fitness[i]:  # Condition for dominance
                    is_dominated[i] = True
                    break
        pareto_front = population[~is_dominated]
        return pareto_front

```

### Rank 11 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling, selective archiving, and a dynamic exploration-exploitation balance for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling, selective archiving, and a dynamic exploration-exploitation balance for multimodal optimization.
# Code:
class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9  # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adapt F and CR based on progress
            self.adapt_parameters(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            #Adaptive pbest selection (weighted towards diverse solutions)

            if self.archive:
                weights = np.exp(-np.array([f for _, f in self.archive])) #Weight by fitness (lower is better)
                weights /= np.sum(weights) #Normalize to probabilities
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            #Differential mutation with crossover
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            crosspoints = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crosspoints, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_parameters(self, fitness):
        #Simple adaptation: Increase F for exploration if progress is slow, decrease otherwise.
        
        # Measure progress: Standard deviation of fitness values
        fitness_std = np.std(fitness)
        
        #Adjust F_scale
        if fitness_std > 0.1 * (np.max(fitness) - np.min(fitness)): #Significant spread; encourage exploration
            self.F_scale = min(1.0, self.F_scale + 0.1) #Cap at 1.0
        else:
            self.F_scale = max(0.1, self.F_scale - 0.05) #Cap at 0.1


```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 16:47:37 INFO Full response text: **Analysis:**

Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveMultimodalDE` (last example), we see that the best-performing algorithm uses a more sophisticated archive update strategy, prioritizing both fitness improvement and a threshold for archive update based on a percentage of the archive size.  The worst algorithm uses a simpler replacement strategy for the archive, and its adaptive F_scale lacks a clear strategy.  `EnhancedArchiveGuidedDE` also employs a more robust mechanism for choosing the pbest from the archive (random sampling). The worst algorithm uses a simplified method that doesn't prioritize the best solutions from the archive.

`(second best)` `AdaptiveArchiveDE` vs `(second worst)` `AdaptiveMultimodalDE` (second to last example): The second-best algorithm uses weighted random choice for pbest selection, favoring better solutions. The second-worst also updates the archive but does not account for diversity in its update strategy. It lacks advanced archive and pbest selection heuristics used in the top-ranked method.

Comparing (1st) `EnhancedArchiveGuidedDE` vs (2nd) `AdaptiveArchiveDE`, we see that the top performer leverages a more carefully tuned population size multiplier (8.17) and archive size (270), resulting in a more efficient balance between exploration and exploitation.  The second-best uses simpler, more commonly used heuristics (10*dim population size, 500 archive size).  `EnhancedArchiveGuidedDE` also has a more sophisticated archive update threshold.

(3rd) `AdaptiveArchiveDE` (second example) vs (4th) `AdaptiveArchiveGuidedDE`: Both use archives, but the third-ranked one has more refined parameter tuning and utilizes weighted pbest selection from the archive to improve convergence speed.  The 4th-ranked one lacks this strategic weighting, which leads to inferior performance.  The third-ranked uses a dynamic F_scale. The 4th's F_scale adaptation is less precise.

Comparing (second worst) `AdaptiveMultimodalDE` (second to last example) vs (worst) `AdaptiveMultimodalDE` (last example): Both algorithms use adaptive scaling and an archive, but the second-worst includes a more sophisticated approach to pbest selection and a more intuitive archive update mechanism, while the worst one uses a simpler archive update with no consideration for diversity.


Overall: The top-performing algorithms consistently utilize more sophisticated archive management techniques, including weighted pbest selection and adaptive archive update thresholds.  They also employ more carefully tuned hyperparameters and adaptive scaling factor strategies for robust exploration and exploitation.  The lower-ranked algorithms often employ simpler heuristics, leading to less effective search in the complex landscape.


**Experience:**

Effective archive management, including intelligent pbest selection and adaptive archive update mechanisms, combined with carefully tuned hyperparameters and robust adaptive scaling factors are crucial for efficiently exploring and exploiting complex, high-dimensional multimodal landscapes.  Strategic parameter tuning improves convergence speed.

2025-06-23 16:47:39 INFO Full response text: **Keywords:**  Adaptive parameter control, intelligent pbest selection, archive management, multimodal optimization, high-dimensional search.

**Advice:** Focus on developing novel mechanisms for intelligent pbest selection (e.g., incorporating fitness landscape information) and adaptive archive updates (e.g.,  dynamic archive sizing based on search progress).  Explore advanced scaling factor adaptation strategies that dynamically adjust based on local search landscape characteristics. Design experiments to rigorously test the impact of each component.

**Avoid:**  Generic statements about "sophisticated" methods or the need for diversity.  Avoid rehashing known techniques without offering novel improvements. Don't fall into the trap of simply combining existing methods without a clear rationale and experimental validation.

**Explanation:** The current self-reflection lacks specific, actionable steps.  The ineffective self-reflection is too general.  To design better heuristics, we need to move beyond broad claims and concentrate on concrete, measurable improvements to existing components.  The focus should be on *how* to make existing techniques more intelligent and adaptive, not just *that* they are needed.

2025-06-23 16:47:39 INFO Generating offspring via Crossover...
2025-06-23 16:50:07 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
AdaptiveArchiveDE
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided pbest and scaling factor for multimodal optimization.

class AdaptiveArchiveDE:
    """
    Combines Differential Evolution with an archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.F_scale_variation = 0.3 #variation range for F


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive with enhanced diversity management
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


            if self.best_fitness_overall <= acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor with controlled variation
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()  #scale factor with slight variation,bounded to [0.5, 0.8]
        self.F_scale = np.clip(self.F_scale, 0.5, 0.8)

        for i in range(self.population_size):
            # Select pbest from archive (if available) with a bias toward better solutions
            if self.archive:
                #Weighted random choice to favour better solutions
                weights = np.exp(-np.array([f for _,f in self.archive]))
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive using a combined metric
                worst_index = np.argmax([f for _, f in self.archive])
                
                #Combine fitness and diversity in the update decision
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

### Worse code
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 8.174802229725055, archive_size: int = 270.06092544891357,
                 initial_F_scale: float = 0.20479542288074049, F_scale_variation: float = 0.5761099516092845,
                 archive_update_threshold: float = 0.06764885795066156):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.F_scale_variation = F_scale_variation
        self.archive_update_threshold = archive_update_threshold


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

### Analyze & experience
- Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveMultimodalDE` (last example), we see that the best-performing algorithm uses a more sophisticated archive update strategy, prioritizing both fitness improvement and a threshold for archive update based on a percentage of the archive size.  The worst algorithm uses a simpler replacement strategy for the archive, and its adaptive F_scale lacks a clear strategy.  `EnhancedArchiveGuidedDE` also employs a more robust mechanism for choosing the pbest from the archive (random sampling). The worst algorithm uses a simplified method that doesn't prioritize the best solutions from the archive.

`(second best)` `AdaptiveArchiveDE` vs `(second worst)` `AdaptiveMultimodalDE` (second to last example): The second-best algorithm uses weighted random choice for pbest selection, favoring better solutions. The second-worst also updates the archive but does not account for diversity in its update strategy. It lacks advanced archive and pbest selection heuristics used in the top-ranked method.

Comparing (1st) `EnhancedArchiveGuidedDE` vs (2nd) `AdaptiveArchiveDE`, we see that the top performer leverages a more carefully tuned population size multiplier (8.17) and archive size (270), resulting in a more efficient balance between exploration and exploitation.  The second-best uses simpler, more commonly used heuristics (10*dim population size, 500 archive size).  `EnhancedArchiveGuidedDE` also has a more sophisticated archive update threshold.

(3rd) `AdaptiveArchiveDE` (second example) vs (4th) `AdaptiveArchiveGuidedDE`: Both use archives, but the third-ranked one has more refined parameter tuning and utilizes weighted pbest selection from the archive to improve convergence speed.  The 4th-ranked one lacks this strategic weighting, which leads to inferior performance.  The third-ranked uses a dynamic F_scale. The 4th's F_scale adaptation is less precise.

Comparing (second worst) `AdaptiveMultimodalDE` (second to last example) vs (worst) `AdaptiveMultimodalDE` (last example): Both algorithms use adaptive scaling and an archive, but the second-worst includes a more sophisticated approach to pbest selection and a more intuitive archive update mechanism, while the worst one uses a simpler archive update with no consideration for diversity.


Overall: The top-performing algorithms consistently utilize more sophisticated archive management techniques, including weighted pbest selection and adaptive archive update thresholds.  They also employ more carefully tuned hyperparameters and adaptive scaling factor strategies for robust exploration and exploitation.  The lower-ranked algorithms often employ simpler heuristics, leading to less effective search in the complex landscape.
- **Keywords:**  Adaptive parameter control, intelligent pbest selection, archive management, multimodal optimization, high-dimensional search.

**Advice:** Focus on developing novel mechanisms for intelligent pbest selection (e.g., incorporating fitness landscape information) and adaptive archive updates (e.g.,  dynamic archive sizing based on search progress).  Explore advanced scaling factor adaptation strategies that dynamically adjust based on local search landscape characteristics. Design experiments to rigorously test the impact of each component.

**Avoid:**  Generic statements about "sophisticated" methods or the need for diversity.  Avoid rehashing known techniques without offering novel improvements. Don't fall into the trap of simply combining existing methods without a clear rationale and experimental validation.

**Explanation:** The current self-reflection lacks specific, actionable steps.  The ineffective self-reflection is too general.  To design better heuristics, we need to move beyond broad claims and concentrate on concrete, measurable improvements to existing components.  The focus should be on *how* to make existing techniques more intelligent and adaptive, not just *that* they are needed.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 16:50:07 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Adaptive parameter control, intelligent pbest selection, archive management, multimodal optimization, high-dimensional search.

**Advice:** Focus on developing novel mechanisms for intelligent pbest selection (e.g., incorporating fitness landscape information) and adaptive archive updates (e.g.,  dynamic archive sizing based on search progress).  Explore advanced scaling factor adaptation strategies that dynamically adjust based on local search landscape characteristics. Design experiments to rigorously test the impact of each component.

**Avoid:**  Generic statements about "sophisticated" methods or the need for diversity.  Avoid rehashing known techniques without offering novel improvements. Don't fall into the trap of simply combining existing methods without a clear rationale and experimental validation.

**Explanation:** The current self-reflection lacks specific, actionable steps.  The ineffective self-reflection is too general.  To design better heuristics, we need to move beyond broad claims and concentrate on concrete, measurable improvements to existing components.  The focus should be on *how* to make existing techniques more intelligent and adaptive, not just *that* they are needed.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 16:51:42 INFO Perform Harmony Search...
2025-06-23 16:51:51 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:52:37 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0043
2025-06-23 16:52:37 INFO FeHistory: [225.10001144 182.68938946 182.44986002 ...  10.8097835   -7.8599491
  -1.88571568]
2025-06-23 16:52:37 INFO Expected Optimum FE: -100
2025-06-23 16:52:37 INFO Unimodal AOCC mean: nan
2025-06-23 16:52:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:52:37 INFO Multimodal (multiple components) AOCC mean: 0.0043
2025-06-23 16:52:37 INFO AOCC mean: 0.0043
2025-06-23 16:52:37 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:53:25 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0119
2025-06-23 16:53:25 INFO FeHistory: [211.25834627 164.07183465 193.99295353 ... -35.8143638  -36.26673954
 -44.55500329]
2025-06-23 16:53:25 INFO Expected Optimum FE: -100
2025-06-23 16:53:25 INFO Unimodal AOCC mean: nan
2025-06-23 16:53:25 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:53:25 INFO Multimodal (multiple components) AOCC mean: 0.0119
2025-06-23 16:53:25 INFO AOCC mean: 0.0119
2025-06-23 16:53:25 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:54:09 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0170
2025-06-23 16:54:09 INFO FeHistory: [172.84066207 156.75352869 162.66648732 ... -46.63847518 -37.64758375
 -42.68268637]
2025-06-23 16:54:09 INFO Expected Optimum FE: -100
2025-06-23 16:54:09 INFO Unimodal AOCC mean: nan
2025-06-23 16:54:09 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:54:09 INFO Multimodal (multiple components) AOCC mean: 0.0170
2025-06-23 16:54:09 INFO AOCC mean: 0.0170
2025-06-23 16:54:09 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:54:58 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0089
2025-06-23 16:54:58 INFO FeHistory: [144.51172531 178.24391075 160.88796381 ... -23.11641126 -22.44742292
 -31.86406005]
2025-06-23 16:54:58 INFO Expected Optimum FE: -100
2025-06-23 16:54:58 INFO Unimodal AOCC mean: nan
2025-06-23 16:54:58 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:54:58 INFO Multimodal (multiple components) AOCC mean: 0.0089
2025-06-23 16:54:58 INFO AOCC mean: 0.0089
2025-06-23 16:54:58 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:55:47 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0051
2025-06-23 16:55:47 INFO FeHistory: [180.75675214 165.26840679 178.55679669 ... -11.27805473  -3.94350368
  -9.19053576]
2025-06-23 16:55:47 INFO Expected Optimum FE: -100
2025-06-23 16:55:47 INFO Unimodal AOCC mean: nan
2025-06-23 16:55:47 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:55:47 INFO Multimodal (multiple components) AOCC mean: 0.0051
2025-06-23 16:55:47 INFO AOCC mean: 0.0051
2025-06-23 16:55:47 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:56:37 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0006
2025-06-23 16:56:37 INFO FeHistory: [172.6675576  192.63688165 199.56715126 ...  27.99079292  25.55926449
  33.46788768]
2025-06-23 16:56:37 INFO Expected Optimum FE: -100
2025-06-23 16:56:37 INFO Unimodal AOCC mean: nan
2025-06-23 16:56:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:56:37 INFO Multimodal (multiple components) AOCC mean: 0.0006
2025-06-23 16:56:37 INFO AOCC mean: 0.0006
2025-06-23 16:56:37 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:57:26 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0182
2025-06-23 16:57:26 INFO FeHistory: [174.79596918 171.73564216 189.41086836 ... -46.95244663 -47.5524148
 -48.22186297]
2025-06-23 16:57:26 INFO Expected Optimum FE: -100
2025-06-23 16:57:26 INFO Unimodal AOCC mean: nan
2025-06-23 16:57:26 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:57:26 INFO Multimodal (multiple components) AOCC mean: 0.0182
2025-06-23 16:57:26 INFO AOCC mean: 0.0182
2025-06-23 16:57:26 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:58:13 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0110
2025-06-23 16:58:13 INFO FeHistory: [170.68733178 198.35821541 165.80787167 ... -34.82715049 -38.09558371
 -35.12192563]
2025-06-23 16:58:13 INFO Expected Optimum FE: -100
2025-06-23 16:58:13 INFO Unimodal AOCC mean: nan
2025-06-23 16:58:13 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:58:13 INFO Multimodal (multiple components) AOCC mean: 0.0110
2025-06-23 16:58:13 INFO AOCC mean: 0.0110
2025-06-23 16:58:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:58:58 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0714
2025-06-23 16:58:58 INFO FeHistory: [178.95225251 194.91947133 209.60593313 ... -96.62116211 -96.78507421
 -96.67244947]
2025-06-23 16:58:58 INFO Expected Optimum FE: -100
2025-06-23 16:58:58 INFO Unimodal AOCC mean: nan
2025-06-23 16:58:58 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:58:58 INFO Multimodal (multiple components) AOCC mean: 0.0714
2025-06-23 16:58:58 INFO AOCC mean: 0.0714
2025-06-23 16:58:58 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 16:59:47 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0602
2025-06-23 16:59:47 INFO FeHistory: [220.45704303 203.26531513 196.79074126 ... -94.11942935 -93.24932792
 -93.6710431 ]
2025-06-23 16:59:47 INFO Expected Optimum FE: -100
2025-06-23 16:59:47 INFO Unimodal AOCC mean: nan
2025-06-23 16:59:47 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 16:59:47 INFO Multimodal (multiple components) AOCC mean: 0.0602
2025-06-23 16:59:47 INFO AOCC mean: 0.0602
2025-06-23 16:59:47 INFO Generation 3, best so far: 0.10988657163916095
2025-06-23 16:59:47 INFO Population length is: 12
2025-06-23 16:59:47 INFO --- Performing Long-Term Reflection at Generation 4 ---
2025-06-23 16:59:47 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 7.1437e-02# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 15.224936165062283, archive_size: int = 117.75908896730343, initial_F_scale: float = 0.3844953961449251):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 5.4641e-04# Name: AdaptiveWeightedArchiveDE
# Description: Adaptive Differential Evolution with weighted archive and pbest selection for multimodal optimization.
# Code:
```python
# Name: AdaptiveWeightedArchiveDE
# Description: Adaptive Differential Evolution with weighted archive and pbest selection for multimodal optimization.

import numpy as np
import random

class AdaptiveWeightedArchiveDE:
    """
    Combines Differential Evolution with an archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.  Employs weighted pbest selection and archive update based on fitness and diversity.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(8.1748 * self.dim)  # Optimized population size multiplier
        self.archive_size = 270  # Optimized archive size
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.F_scale_variation = 0.3  # variation range for F
        self.archive_update_threshold = 0.06764885795066156 # Threshold for archive update


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            if self.best_fitness_overall <= acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()
        self.F_scale = np.clip(self.F_scale, 0.5, 0.8) # Ensure F_scale stays within a reasonable range

        for i in range(self.population_size):
            if self.archive:
                weights = np.exp(-np.array([f for _, f in self.archive])) # Weighting favours better solutions
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 3 (Overall AOCC Score on function 24: 9.0670e-05# Name: AdaptiveArchiveDE_Enhanced
# Description: Adaptive Differential Evolution with enhanced archive management for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE_Enhanced
# Description: Adaptive Differential Evolution with enhanced archive management for multimodal optimization.

class AdaptiveArchiveDE_Enhanced:
    """
    Combines Differential Evolution with an archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.  Improves upon AdaptiveArchiveDE by incorporating a more sophisticated archive update strategy and weighted pbest selection.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(8.17 * self.dim)  # Optimized population size multiplier
        self.archive_size = int(270.06 * (self.dim/30)) # Scaled archive size
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor
        self.F_scale_variation = 0.3 #variation range for F
        self.archive_update_threshold = 0.0676  #Threshold for archive update

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive with enhanced diversity management
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Early stopping condition
            if self.best_fitness_overall < acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor with controlled variation
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()  #scale factor with slight variation
        self.F_scale = np.clip(self.F_scale, 0.1, 1.0) #adjust the range as needed

        for i in range(self.population_size):
            # Select pbest from archive (if available) with a bias toward better solutions
            if self.archive:
                weights = np.exp(-np.array([f for _,f in self.archive])) #Weighting by fitness
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive using a combined metric
                worst_index = np.argmax([f for _, f in self.archive])
                
                #Combine fitness and diversity in the update decision.  Prioritize better fitness.
                if offspring_fitness[i] < self.archive[worst_index][1] or random.random() < self.archive_update_threshold :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 4 (Overall AOCC Score on function 24: 3.9253e-05# Name: AdaptiveWeightedArchiveDE
# Description: Adaptive Differential Evolution with weighted archive and pbest selection for multimodal optimization.
# Code:
```python
# Name: AdaptiveWeightedArchiveDE
# Description: Adaptive Differential Evolution with weighted archive and pbest selection for multimodal optimization.

import numpy as np
import random

class AdaptiveWeightedArchiveDE:
    """
    Combines Differential Evolution with a weighted archive for diversity and adaptive scaling factor for robust exploration in multimodal landscapes.  
    Improves upon previous versions by using weighted archive selection for pbest and a more robust archive update strategy.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(8.17 * self.dim) # Optimized population size multiplier
        self.archive_size = int(270) # Optimized archive size
        self.archive = []
        self.population = None
        self.F_scale = 0.5 # initial scaling factor
        self.F_scale_variation = 0.3 # variation range for F
        self.archive_update_threshold = 0.8 # Threshold for archive update


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            if self.best_fitness_overall <= acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()
        self.F_scale = np.clip(self.F_scale, 0.2, 0.8) #clipped to prevent extreme values

        for i in range(self.population_size):
            if self.archive:
                weights = np.exp(-np.array([f for _, f in self.archive])) #Weighted probability based on inverse fitness
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: EnhancedArchiveGuidedDE
# Description: Differential Evolution with adaptive archive and weighted pbest selection for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: EnhancedArchiveGuidedDE
# Description: Differential Evolution with adaptive archive and weighted pbest selection for multimodal optimization.
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(8.17 * self.dim) #tuned multiplier
        self.archive_size = 270 # tuned size
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9
        self.archive_update_threshold = 0.1 #fraction of archive to replace

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            if self.best_fitness_overall < acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        
        #Adapt F based on success rate.
        success_rate = np.mean(offspring_fitness < fitness) if len(offspring_fitness)>0 else 0
        self.F_scale = max(0.1, min(1.0, self.F_scale + 0.1 * (success_rate - 0.2)))

        for i in range(self.population_size):
            if self.archive:
                weights = np.exp(-np.array([f for _, f in self.archive])) #Weighted by fitness
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        num_to_replace = int(self.archive_update_threshold * self.archive_size)
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Replace worst solutions based on fitness, favoring diversity implicitly through random selection
                indices_to_replace = np.random.choice(len(self.archive), size=num_to_replace, replace=False)
                if offspring_fitness[i] < np.max([f for _,f in self.archive]):
                    self.archive[random.choice(indices_to_replace)] = (offspring[i], offspring_fitness[i])

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveDE
# Description: Differential Evolution with adaptive scaling and an archive prioritizing diverse, high-quality solutions.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Differential Evolution with adaptive scaling and an archive prioritizing diverse, high-quality solutions.
# Code:
class AdaptiveArchiveDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 8 * self.dim  # refined population size
        self.archive_size = 270  # refined archive size
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adapt_parameters(fitness) # Adapt parameters before combining populations

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            # Weighted pbest selection from archive
            if self.archive:
                weights = np.exp(-np.array([f for _, f in self.archive]))
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            crosspoints = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crosspoints, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_parameters(self, fitness):
        # Adapt F_scale based on fitness spread
        fitness_std = np.std(fitness)
        if fitness_std > 0.1 * (np.max(fitness) - np.min(fitness)):
            self.F_scale = min(1.0, self.F_scale + 0.1)
        else:
            self.F_scale = max(0.1, self.F_scale - 0.05)

```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling factor and niching to tackle multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling factor and niching to tackle multimodal landscapes.
# Code:
class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.niche_radius = 0.2  # Initial niche radius
        self.population = None
        self.F_scale = 0.5
        self.niche_centers = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        self.niche_centers = [self.best_solution_overall]

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_population(offspring, offspring_fitness)
            self.update_niches()
            self.adapt_niche_radius()
            self.adapt_F_scale()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_niche_radius': self.niche_radius,
            'num_niches': len(self.niche_centers)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            #Intelligent pbest selection:  Weighted probability based on proximity to niches
            weights = np.array([np.linalg.norm(self.population[i] - center) for center in self.niche_centers])
            weights = 1.0 / (weights + 1e-9) # Avoid division by zero. Invert to get higher weight for closer centers
            weights /= np.sum(weights) # Normalize into probability distribution

            pbest_index = np.random.choice(len(self.niche_centers), p=weights)
            pbest = self.niche_centers[pbest_index]


            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_population(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        self.population = combined_population[indices[:self.population_size]]
        self.best_solution_overall = self.population[np.argmin(combined_fitness)]
        self.best_fitness_overall = np.min(combined_fitness)

    def update_niches(self):
        # Maintain niches, remove redundant ones:
        new_centers = []
        for sol in self.population:
            is_close = False
            for center in self.niche_centers:
                if np.linalg.norm(sol - center) < self.niche_radius:
                    is_close = True
                    break
            if not is_close:
                new_centers.append(sol)
        self.niche_centers.extend(new_centers)
        #Remove redundant niches
        self.niche_centers = [center for i, center in enumerate(self.niche_centers) if all(np.linalg.norm(center - other_center) > self.niche_radius for j, other_center in enumerate(self.niche_centers) if i != j)]



    def adapt_niche_radius(self):
        # Reduce niche radius as optimization progresses
        self.niche_radius *= 0.99 #Slow decay
        self.niche_radius = max(self.niche_radius, 0.01) # Minimum radius


    def adapt_F_scale(self):
        #Adapt F based on exploration/exploitation
        self.F_scale = 0.5 + 0.3 * random.random()  # Some variation
        #In future iterations, a more sophisticated adaptation could be implemented to better respond to the local landscape
        #For instance, this could depend on the convergence rate of the algorithm.


def objective_function(X):
    # Placeholder for your actual f24 objective function.  Replace this.
    return np.sum(X**2, axis=1) #Sphere function for testing

```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive parameter control and intelligent archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive parameter control and intelligent archive for multimodal optimization.

class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Dynamically adjusted
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adapt_parameters(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Dynamic archive size adjustment
            self.adjust_archive_size(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self.select_pbest(population, fitness)
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            # Binomial Crossover
            crosspoints = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crosspoints, mutant, population[i])

        return offspring

    def select_pbest(self, population, fitness):
        if self.archive:
            # Weighted probability based on fitness and distance from current solution
            archive_fitness = np.array([f for _, f in self.archive])
            archive_solutions = np.array([x for x, _ in self.archive])
            distances = np.linalg.norm(archive_solutions - population[np.argmin(fitness)], axis=1)
            probabilities = np.exp(-archive_fitness / np.mean(archive_fitness)) / distances
            probabilities /= np.sum(probabilities) # Normalize
            pbest_index = np.random.choice(len(self.archive), p=probabilities)
            return self.archive[pbest_index][0]
        else:
            return population[np.argmin(fitness)]

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_parameters(self, offspring, offspring_fitness):
        # Adapt F based on success rate
        success_rate = np.sum(offspring_fitness < np.min(self.population)) / len(offspring_fitness)
        if success_rate > 0.9:
            self.F_scale *= 1.1 #increase if successful
        elif success_rate < 0.1:
            self.F_scale *= 0.9 # Decrease if unsuccessful
        self.F_scale = np.clip(self.F_scale, 0.1, 1.0) #keep F scale within bounds


    def adjust_archive_size(self, fitness):
        # Increase archive size if diversity is low
        if len(self.archive) > 0:
            diversity = np.std(np.array([f for _, f in self.archive]))
            if diversity < 0.1 * np.std(fitness) and len(self.archive) < 400:
                self.archive_size += 50

```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution variant with adaptive parameter control and niching for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution variant with adaptive parameter control and niching for multimodal optimization.
# Code:

class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Dynamically adjusted
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9  # Crossover rate

        self.niche_radius = 50  # Initial niche radius
        self.niche_reduction_factor = 0.95

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adaptive archive size and niche radius
            self.adapt_parameters(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        
        for i in range(self.population_size):
            # Intelligent pbest selection (closest in fitness and distance)
            pbest = self.select_pbest(population[i], fitness, population)

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            diff = self.F_scale * (pbest - population[i] + population[a] - population[b])
            jrand = random.randint(0, self.dim -1)
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i, j] = population[i, j] + diff[j]
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def select_pbest(self, individual, fitness, population):
        best_pbest = None
        min_dist = float('inf')

        for j in range(len(population)):
            dist = np.linalg.norm(individual - population[j])
            if best_pbest is None or (fitness[j] < fitness[np.argmin(fitness) if best_pbest is None else np.argmin([fitness[k] for k in range(len(population)) if population[k] == best_pbest])] and dist < min_dist):
                best_pbest = population[j]
                min_dist = dist
        return best_pbest


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            is_new_niche = True
            for j in range(len(self.archive)):
                if np.linalg.norm(offspring[i] - self.archive[j][0]) < self.niche_radius:
                    is_new_niche = False
                    break
            if is_new_niche and offspring_fitness[i] < self.best_fitness_overall * 1.5:
                if len(self.archive) < self.archive_size:
                    self.archive.append((offspring[i], offspring_fitness[i]))
                else:
                    worst_index = np.argmax([f for _, f in self.archive])
                    if offspring_fitness[i] < self.archive[worst_index][1]:
                        self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_parameters(self, fitness):
        # Adjust F_scale based on convergence rate
        avg_fitness_diff = np.mean(np.diff(np.sort(fitness)))
        if avg_fitness_diff < 0.1:  # If convergence is slow
            self.F_scale = min(1.0, self.F_scale + 0.1)
        else:
            self.F_scale = max(0.1, self.F_scale - 0.05)

        #Dynamic Archive Sizing
        self.archive_size = int(200 * (1 - self.best_fitness_overall / 100))
        self.archive_size = max(50, min(self.archive_size, 1000))

        # Adaptive niche radius
        self.niche_radius *= self.niche_reduction_factor


```

### Rank 10 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling factor, intelligent pbest selection, and dynamic archive management for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling factor, intelligent pbest selection, and dynamic archive management for multimodal optimization.
# Code:
class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Dynamically adjusted
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adaptive_archive_management()

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            self.adaptive_parameter_control(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self.select_pbest(population, fitness)
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            offspring[i] = self.crossover(population[i], mutant)

        return offspring

    def crossover(self, x, v):
        jrand = random.randint(0, self.dim - 1)
        y = np.copy(x)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def select_pbest(self, population, fitness):
        #Prioritizes archive members, then diverse solutions from population
        if self.archive:
            archive_fitness = np.array([f for _, f in self.archive])
            best_archive_index = np.argmin(archive_fitness)
            pbest = self.archive[best_archive_index][0]
            
            return pbest
        else:
            return population[np.argmin(fitness)]



    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            self.archive.append((offspring[i], offspring_fitness[i]))


    def adaptive_archive_management(self):
        if len(self.archive) > self.archive_size:
            #Remove solutions based on distance and fitness
            self.archive.sort(key=lambda item: item[1]) #Sort by fitness
            self.archive = self.archive[:int(self.archive_size * 0.8)] #Keep top 80%
            
            #Maintain Diversity (optional but improves exploration in high-D)
            while len(self.archive) < self.archive_size:
              self.archive.append(random.choice(self.archive)) #Duplicate to fill


    def adaptive_parameter_control(self, fitness):
      # Adjust F and CR based on success rate
        std_dev_fitness = np.std(fitness)
        if std_dev_fitness < 0.1:  # Low diversity, increase exploration
            self.F_scale = min(1.0, self.F_scale + 0.1)
            self.CR = max(0.1, self.CR - 0.1)
        elif std_dev_fitness > 0.8:  # High diversity, focus on exploitation
            self.F_scale = max(0.1, self.F_scale - 0.1)
            self.CR = min(0.9, self.CR + 0.1)

```

### Rank 11 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling factor, intelligent pbest selection, and dynamic archive management for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling factor, intelligent pbest selection, and dynamic archive management for multimodal optimization.
# Code:

class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 100  # Dynamically adjusted
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.cr = 0.9 #Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adaptive Archive Size
            self.archive_size = int(100 + 50 * (1 - self.eval_count / self.budget)) # Reduce archive later
            self.archive = self.manage_archive()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        
        for i in range(self.population_size):
            # Intelligent pbest selection (weighted by fitness and distance)
            if self.archive:
                distances = np.linalg.norm(self.archive[:, 0] - population[i], axis=1)
                weights = np.exp(-distances / np.std(distances)) * (1/self.archive[:,1])
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            #Adaptive scaling factor based on solution quality
            self.F_scale = 0.5 + 0.3 * np.random.rand() * (1-np.exp(-fitness[i]/10))  

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            
            # Binomial Crossover
            j_rand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.cr or j == j_rand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]

            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def manage_archive(self):
        if len(self.archive) > self.archive_size :
            # maintain diversity using crowding
            sorted_archive = sorted(self.archive, key=lambda item: item[1]) #sort by fitness
            return sorted_archive[:self.archive_size]
        else:
            return self.archive

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 16:59:52 INFO Full response text: **Analysis:**

Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveMultimodalDE` (last code block), we see that the best uses an archive to maintain diversity and guide the search, while the worst relies solely on niching and adaptive parameter control, lacking a mechanism for long-term memory of good solutions.  `(second best)` `AdaptiveWeightedArchiveDE` vs (second worst) `AdaptiveArchiveDE_Enhanced`, both use archives, but the second-best employs weighted pbest selection, giving preference to better solutions in the archive, an element missing in the second worst. Comparing (1st) vs (2nd), we see that the best algorithm uses a more sophisticated archive update strategy that prioritizes both fitness and diversity, whereas the second best focuses primarily on fitness. (3rd) `AdaptiveArchiveDE_Enhanced` vs (4th) `AdaptiveWeightedArchiveDE` (second code block), both use adaptive scaling and archives, but the third-best has a more sophisticated archive management and pbest selection compared to the fourth, making the fourth lack in the selection strategy.  Comparing (second worst) `AdaptiveArchiveDE_Enhanced` vs (worst) `AdaptiveMultimodalDE` (last code block), both utilize adaptive parameters; however, the second worst integrates an archive for memory, which is absent in the worst. Overall: The top-performing algorithms consistently utilize archives to store and selectively retrieve promising solutions, combining this with adaptive parameter control and intelligent pbest selection strategies for robust exploration and exploitation. The lower-performing algorithms lack these key components, leading to less effective optimization.


**Experience:**

Effective population design for complex optimization problems requires careful balance between exploration and exploitation.  Archives are crucial for storing and utilizing historical information, while adaptive parameter control helps maintain a dynamic search strategy.  Weighted pbest selection and diversity-aware archive management improve solution quality and prevent premature convergence.

2025-06-23 16:59:54 INFO Full response text: * **Keywords:**  Adaptive Exploration-Exploitation,  Archive Management,  Parameter Control,  Diversity Metrics

* **Advice:** Focus on quantifiable metrics for exploration/exploitation balance (e.g.,  coverage of search space, distance between solutions). Design adaptive mechanisms that dynamically adjust based on these metrics, not just pre-defined schedules.  Explore novel archive update strategies beyond simple addition/deletion (e.g.,  clustering, density-based methods).

* **Avoid:** Vague terms like "sophisticated," "robust," "intelligent."  Avoid relying solely on intuition for parameter tuning; instead, use rigorous experimentation and statistical analysis.  Don't simply integrate existing components without considering synergistic interactions.

* **Explanation:** The current self-reflection lacks concrete design choices.  The ineffective reflections are overly general and lack specific, measurable improvements.  The improved heuristics will be driven by data and clearly defined objectives, moving away from subjective assessments.

2025-06-23 16:59:54 INFO Generating offspring via Crossover...
2025-06-23 17:03:39 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
AdaptiveMultimodalDE
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: Differential Evolution with adaptive scaling factor and niching to tackle multimodal landscapes.
# Code:
class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.niche_radius = 0.2  # Initial niche radius
        self.population = None
        self.F_scale = 0.5
        self.niche_centers = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        self.niche_centers = [self.best_solution_overall]

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_population(offspring, offspring_fitness)
            self.update_niches()
            self.adapt_niche_radius()
            self.adapt_F_scale()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_niche_radius': self.niche_radius,
            'num_niches': len(self.niche_centers)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            #Intelligent pbest selection:  Weighted probability based on proximity to niches
            weights = np.array([np.linalg.norm(self.population[i] - center) for center in self.niche_centers])
            weights = 1.0 / (weights + 1e-9) # Avoid division by zero. Invert to get higher weight for closer centers
            weights /= np.sum(weights) # Normalize into probability distribution

            pbest_index = np.random.choice(len(self.niche_centers), p=weights)
            pbest = self.niche_centers[pbest_index]


            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_population(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        self.population = combined_population[indices[:self.population_size]]
        self.best_solution_overall = self.population[np.argmin(combined_fitness)]
        self.best_fitness_overall = np.min(combined_fitness)

    def update_niches(self):
        # Maintain niches, remove redundant ones:
        new_centers = []
        for sol in self.population:
            is_close = False
            for center in self.niche_centers:
                if np.linalg.norm(sol - center) < self.niche_radius:
                    is_close = True
                    break
            if not is_close:
                new_centers.append(sol)
        self.niche_centers.extend(new_centers)
        #Remove redundant niches
        self.niche_centers = [center for i, center in enumerate(self.niche_centers) if all(np.linalg.norm(center - other_center) > self.niche_radius for j, other_center in enumerate(self.niche_centers) if i != j)]



    def adapt_niche_radius(self):
        # Reduce niche radius as optimization progresses
        self.niche_radius *= 0.99 #Slow decay
        self.niche_radius = max(self.niche_radius, 0.01) # Minimum radius


    def adapt_F_scale(self):
        #Adapt F based on exploration/exploitation
        self.F_scale = 0.5 + 0.3 * random.random()  # Some variation
        #In future iterations, a more sophisticated adaptation could be implemented to better respond to the local landscape
        #For instance, this could depend on the convergence rate of the algorithm.


def objective_function(X):
    # Placeholder for your actual f24 objective function.  Replace this.
    return np.sum(X**2, axis=1) #Sphere function for testing


### Worse code
EnhancedArchiveGuidedDE
import numpy as np
import random

# Name: EnhancedArchiveGuidedDE
# Description: Differential Evolution with adaptive archive and weighted pbest selection for multimodal optimization.
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(8.17 * self.dim) #tuned multiplier
        self.archive_size = 270 # tuned size
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9
        self.archive_update_threshold = 0.1 #fraction of archive to replace

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            if self.best_fitness_overall < acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        
        #Adapt F based on success rate.
        success_rate = np.mean(offspring_fitness < fitness) if len(offspring_fitness)>0 else 0
        self.F_scale = max(0.1, min(1.0, self.F_scale + 0.1 * (success_rate - 0.2)))

        for i in range(self.population_size):
            if self.archive:
                weights = np.exp(-np.array([f for _, f in self.archive])) #Weighted by fitness
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        num_to_replace = int(self.archive_update_threshold * self.archive_size)
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Replace worst solutions based on fitness, favoring diversity implicitly through random selection
                indices_to_replace = np.random.choice(len(self.archive), size=num_to_replace, replace=False)
                if offspring_fitness[i] < np.max([f for _,f in self.archive]):
                    self.archive[random.choice(indices_to_replace)] = (offspring[i], offspring_fitness[i])


### Analyze & experience
- Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveMultimodalDE` (last code block), we see that the best uses an archive to maintain diversity and guide the search, while the worst relies solely on niching and adaptive parameter control, lacking a mechanism for long-term memory of good solutions.  `(second best)` `AdaptiveWeightedArchiveDE` vs (second worst) `AdaptiveArchiveDE_Enhanced`, both use archives, but the second-best employs weighted pbest selection, giving preference to better solutions in the archive, an element missing in the second worst. Comparing (1st) vs (2nd), we see that the best algorithm uses a more sophisticated archive update strategy that prioritizes both fitness and diversity, whereas the second best focuses primarily on fitness. (3rd) `AdaptiveArchiveDE_Enhanced` vs (4th) `AdaptiveWeightedArchiveDE` (second code block), both use adaptive scaling and archives, but the third-best has a more sophisticated archive management and pbest selection compared to the fourth, making the fourth lack in the selection strategy.  Comparing (second worst) `AdaptiveArchiveDE_Enhanced` vs (worst) `AdaptiveMultimodalDE` (last code block), both utilize adaptive parameters; however, the second worst integrates an archive for memory, which is absent in the worst. Overall: The top-performing algorithms consistently utilize archives to store and selectively retrieve promising solutions, combining this with adaptive parameter control and intelligent pbest selection strategies for robust exploration and exploitation. The lower-performing algorithms lack these key components, leading to less effective optimization.
- * **Keywords:**  Adaptive Exploration-Exploitation,  Archive Management,  Parameter Control,  Diversity Metrics

* **Advice:** Focus on quantifiable metrics for exploration/exploitation balance (e.g.,  coverage of search space, distance between solutions). Design adaptive mechanisms that dynamically adjust based on these metrics, not just pre-defined schedules.  Explore novel archive update strategies beyond simple addition/deletion (e.g.,  clustering, density-based methods).

* **Avoid:** Vague terms like "sophisticated," "robust," "intelligent."  Avoid relying solely on intuition for parameter tuning; instead, use rigorous experimentation and statistical analysis.  Don't simply integrate existing components without considering synergistic interactions.

* **Explanation:** The current self-reflection lacks concrete design choices.  The ineffective reflections are overly general and lack specific, measurable improvements.  The improved heuristics will be driven by data and clearly defined objectives, moving away from subjective assessments.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 17:03:39 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
AdaptiveArchiveDE_withDiversity
import numpy as np
import random

# Name: AdaptiveArchiveDE_withDiversity
# Description: Differential Evolution with adaptive scaling and archive management prioritizing both fitness and diversity.
# Code:

class AdaptiveArchiveDE_withDiversity:
    """
    Differential Evolution algorithm with adaptive scaling factor and archive management.
    Prioritizes both solution quality and diversity within the archive.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # Common heuristic
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor.  Slight variation added for robustness.
        self.F_scale = 0.5 + 0.3 * np.random.rand()

        for i in range(self.population_size):
            #Weighted pbest selection from archive (if available).  Better solutions get higher probability.
            if self.archive:
                weights = np.exp(-np.array([f for _, f in self.archive])) # higher fitness = lower weight, more likely to be chosen
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity and fitness using a simple distance metric (Euclidean).
                worst_index = np.argmax([f for _, f in self.archive])
                distances = np.array([np.linalg.norm(offspring[i] - sol) for sol, _ in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or np.min(distances) > 5: #Maintain diversity
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Adaptive Exploration-Exploitation,  Archive Management,  Parameter Control,  Diversity Metrics

* **Advice:** Focus on quantifiable metrics for exploration/exploitation balance (e.g.,  coverage of search space, distance between solutions). Design adaptive mechanisms that dynamically adjust based on these metrics, not just pre-defined schedules.  Explore novel archive update strategies beyond simple addition/deletion (e.g.,  clustering, density-based methods).

* **Avoid:** Vague terms like "sophisticated," "robust," "intelligent."  Avoid relying solely on intuition for parameter tuning; instead, use rigorous experimentation and statistical analysis.  Don't simply integrate existing components without considering synergistic interactions.

* **Explanation:** The current self-reflection lacks concrete design choices.  The ineffective reflections are overly general and lack specific, measurable improvements.  The improved heuristics will be driven by data and clearly defined objectives, moving away from subjective assessments.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 17:04:31 INFO Perform Harmony Search...
