2025-06-21 17:13:15 INFO Using LLM api key #AIzaSyCK6miE77n6z7PUf0RNgj8seMiiVET-wqk)
2025-06-21 17:13:15 INFO Using LLM api key #AIzaSyCK6miE77n6z7PUf0RNgj8seMiiVET-wqk)
2025-06-21 17:13:15 INFO Using LLM api key #AIzaSyARJfdVOsI9AKUK6gxvUszL_bn5Z_lr5Wg)
2025-06-21 17:13:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:13:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:13:24 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:13:24 ERROR Can not run the algorithm
2025-06-21 17:13:24 INFO Run function 24 complete. FEHistory len: 20, AOCC: 0.0000
2025-06-21 17:13:24 INFO FeHistory: [133.1674053  171.81735238 222.97440673 169.25746892 192.89859421
 203.68561391 197.11169815 183.13820091 206.96638987 194.53599137
 153.63190023 189.43453091 240.22092848 167.40821801 183.29709486
 190.54468704 253.71258462 184.80232265 209.27173564 207.21029769]
2025-06-21 17:13:24 INFO Expected Optimum FE: -100
2025-06-21 17:13:24 INFO Unimodal AOCC mean: nan
2025-06-21 17:13:24 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:13:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:13:24 INFO AOCC mean: 0.0000
2025-06-21 17:13:24 INFO Using LLM api key #AIzaSyARJfdVOsI9AKUK6gxvUszL_bn5Z_lr5Wg)
2025-06-21 17:13:33 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:13:44 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:13:44 INFO FeHistory: [200.09350122 193.58629464 171.66914696 ...  78.60542109  85.75044521
  86.60246781]
2025-06-21 17:13:44 INFO Expected Optimum FE: -100
2025-06-21 17:13:44 INFO Unimodal AOCC mean: nan
2025-06-21 17:13:44 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:13:44 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:13:44 INFO AOCC mean: 0.0000
2025-06-21 17:13:44 INFO Using LLM api key #AIzaSyCK6miE77n6z7PUf0RNgj8seMiiVET-wqk)
2025-06-21 17:13:48 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:13:48 INFO FeHistory: [173.28327083 203.68471878 155.5478728  ... 101.85204236 101.85204236
 101.85204236]
2025-06-21 17:13:48 INFO Expected Optimum FE: -100
2025-06-21 17:13:48 INFO Unimodal AOCC mean: nan
2025-06-21 17:13:48 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:13:48 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:13:48 INFO AOCC mean: 0.0000
2025-06-21 17:13:48 INFO Using LLM api key #AIzaSyARJfdVOsI9AKUK6gxvUszL_bn5Z_lr5Wg)
2025-06-21 17:13:51 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:13:56 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:14:03 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:14:03 INFO FeHistory: [199.03199464 175.43672869 173.47729366 ... 179.20793062 198.79257229
 199.45651454]
2025-06-21 17:14:03 INFO Expected Optimum FE: -100
2025-06-21 17:14:03 INFO Unimodal AOCC mean: nan
2025-06-21 17:14:03 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:14:03 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:14:03 INFO AOCC mean: 0.0000
2025-06-21 17:14:03 INFO Using LLM api key #AIzaSyCK6miE77n6z7PUf0RNgj8seMiiVET-wqk)
2025-06-21 17:14:10 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0236
2025-06-21 17:14:10 INFO FeHistory: [196.6624572  169.17517096 207.42748488 ... -60.2225389  -61.10107024
 -64.04069291]
2025-06-21 17:14:10 INFO Expected Optimum FE: -100
2025-06-21 17:14:10 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
from sklearn.cluster import KMeans

class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100 # Adjust as needed
        self.F = 0.8 # Differential weight (mutation strength)
        self.CR = 0.9 # Crossover rate

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        for i in range(self.population_size):
            if fitness_values[i] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[i]
                self.best_solution_overall = self.population[i]

        while self.eval_count < self.budget:
            # Adaptive Mutation Strength
            diversity = np.std(self.population)
            self.F = 0.5 + 0.5 * np.exp(-diversity) # Decreases F as diversity decreases


            offspring = np.zeros_like(self.population)
            for i in range(self.population_size):
                # Differential Evolution Mutation
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Boundary Handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                j_rand = np.random.randint(0, self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == j_rand:
                        offspring[i, j] = mutant[j]
                    else:
                        offspring[i, j] = self.population[i, j]


            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection
            for i in range(self.population_size):
                if offspring_fitness[i] < fitness_values[i]:
                    self.population[i] = offspring[i]
                    fitness_values[i] = offspring_fitness[i]
                    if fitness_values[i] < self.best_fitness_overall:
                        self.best_fitness_overall = fitness_values[i]
                        self.best_solution_overall = self.population[i]


            # Clustering to escape local optima (periodically)
            if self.eval_count % (self.budget // 10) == 0: #Check every 10% of the budget
                kmeans = KMeans(n_clusters=5, random_state=0).fit(self.population) # Adjust number of clusters as needed
                cluster_centers = kmeans.cluster_centers_
                for center in cluster_centers:
                    self.population = np.vstack([self.population, center]) # Add cluster center to population
                    fitness_values = np.append(fitness_values, objective_function(center.reshape(1,-1)))
                    self.eval_count+=1
                    if fitness_values[-1] < self.best_fitness_overall:
                        self.best_fitness_overall = fitness_values[-1]
                        self.best_solution_overall = center

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

2025-06-21 17:14:10 INFO Unimodal AOCC mean: nan
2025-06-21 17:14:10 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:14:10 INFO Multimodal (multiple components) AOCC mean: 0.0236
2025-06-21 17:14:10 INFO AOCC mean: 0.0236
2025-06-21 17:14:10 INFO Using LLM api key #AIzaSyARJfdVOsI9AKUK6gxvUszL_bn5Z_lr5Wg)
2025-06-21 17:14:11 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:14:13 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0234
2025-06-21 17:14:13 INFO FeHistory: [191.83444179 199.43993706 191.07535697 ... -52.75529066 -48.84906362
 -57.02429768]
2025-06-21 17:14:13 INFO Expected Optimum FE: -100
2025-06-21 17:14:13 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
from scipy.cluster.hierarchy import linkage, fcluster

class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.F = 0.8 # Initial mutation factor
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Calculate diversity
            diversity = np.mean(np.std(population, axis=0))

            # Adapt mutation factor based on diversity
            self.F = 0.5 + 0.5 * np.exp(-diversity)

            # Differential Evolution
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)
                while a == i or b == i or c == i:
                    a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                crosspoints = np.random.rand(self.dim) < self.CR
                offspring[i] = np.where(crosspoints, mutant, population[i])

            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection
            for i in range(self.population_size):
                if offspring_fitness[i] < fitness[i]:
                    fitness[i] = offspring_fitness[i]
                    population[i] = offspring[i]

            #Clustering to escape local optima
            if self.eval_count % (self.population_size * 5) == 0: #check every 5 generations
                linkage_matrix = linkage(population, method='ward')
                clusters = fcluster(linkage_matrix, t=0.5*np.max(linkage_matrix[:,2]), criterion='distance') # Adjust t as needed
                
                #Introduce diversity by selecting points from less populated clusters. 
                cluster_counts = np.bincount(clusters)
                indices_to_replace = np.where(clusters == np.argmin(cluster_counts))[0]
                for index in indices_to_replace:
                    population[index] = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                    fitness[index] = objective_function(population[index].reshape(1,-1))[0]
                    self.eval_count += 1

            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

2025-06-21 17:14:13 INFO Unimodal AOCC mean: nan
2025-06-21 17:14:13 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:14:13 INFO Multimodal (multiple components) AOCC mean: 0.0234
2025-06-21 17:14:13 INFO AOCC mean: 0.0234
2025-06-21 17:14:13 INFO Using LLM api key #AIzaSyCK6miE77n6z7PUf0RNgj8seMiiVET-wqk)
2025-06-21 17:14:17 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:14:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:14:41 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0116
2025-06-21 17:14:41 INFO FeHistory: [213.79909597 183.70852992 215.67610265 ... -43.84314746 -32.64703524
 -34.24254072]
2025-06-21 17:14:41 INFO Expected Optimum FE: -100
2025-06-21 17:14:41 INFO Unimodal AOCC mean: nan
2025-06-21 17:14:41 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:14:41 INFO Multimodal (multiple components) AOCC mean: 0.0116
2025-06-21 17:14:41 INFO AOCC mean: 0.0116
2025-06-21 17:14:41 INFO Using LLM api key #AIzaSyARJfdVOsI9AKUK6gxvUszL_bn5Z_lr5Wg)
2025-06-21 17:14:44 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:14:44 INFO FeHistory: [203.86908524 166.06684282 191.10507601 ... 128.35621864 162.0005586
 117.3365009 ]
2025-06-21 17:14:44 INFO Expected Optimum FE: -100
2025-06-21 17:14:44 INFO Unimodal AOCC mean: nan
2025-06-21 17:14:44 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:14:44 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:14:44 INFO AOCC mean: 0.0000
2025-06-21 17:14:44 INFO Using LLM api key #AIzaSyCK6miE77n6z7PUf0RNgj8seMiiVET-wqk)
2025-06-21 17:14:48 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:14:52 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:15:11 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:15:11 INFO FeHistory: [225.86251095 211.86182359 176.15900615 ... 175.7469589  176.82224304
 200.93117205]
2025-06-21 17:15:11 INFO Expected Optimum FE: -100
2025-06-21 17:15:11 INFO Unimodal AOCC mean: nan
2025-06-21 17:15:11 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:15:11 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:15:11 INFO AOCC mean: 0.0000
2025-06-21 17:15:11 INFO Using LLM api key #AIzaSyARJfdVOsI9AKUK6gxvUszL_bn5Z_lr5Wg)
2025-06-21 17:15:11 INFO [TIMEOUT] Evaluation exceeded 60 seconds and was skipped.
2025-06-21 17:15:15 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0226
2025-06-21 17:15:15 INFO FeHistory: [175.2824934  180.58694043 163.60777143 ... -76.71815763 -76.69307725
 -76.71859775]
2025-06-21 17:15:15 INFO Expected Optimum FE: -100
2025-06-21 17:15:15 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Differential Evolution crossover rate
        self.niche_radius = 0.1 # Adjust based on problem scaling.


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Selection with Niching
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((self.fitness_values, offspring_fitness))
            
            sorted_indices = np.argsort(combined_fitness)
            
            new_population = []
            new_fitness = []
            
            for i in sorted_indices:
                is_duplicate = False
                for j in range(len(new_population)):
                    if np.linalg.norm(combined_population[i] - new_population[j]) < self.niche_radius:
                         is_duplicate = True
                         break
                if not is_duplicate:
                    new_population.append(combined_population[i])
                    new_fitness.append(combined_fitness[i])
                    if len(new_population) >= self.population_size:
                        break


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness)

            best_index = np.argmin(self.fitness_values)
            if self.fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness_values[best_index]

            #Adaptive Mutation (adjust F based on progress)
            if self.eval_count % (self.budget //10) == 0: #adjust every 10% of the budget
                if self.best_fitness_overall < np.median(self.fitness_values):
                  self.F *= 0.9  # Reduce exploration if making good progress
                else:
                  self.F *= 1.1 #Increase exploration if stuck

            self.F = max(0.1, min(1, self.F)) #keep F within reasonable range



        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == b or b == c or a ==c:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            
            #Bound Constraints Handling
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            crossover_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crossover_points, mutant, self.population[i])
        return offspring
2025-06-21 17:15:15 INFO Unimodal AOCC mean: nan
2025-06-21 17:15:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:15:15 INFO Multimodal (multiple components) AOCC mean: 0.0226
2025-06-21 17:15:15 INFO AOCC mean: 0.0226
2025-06-21 17:15:15 INFO Using LLM api key #AIzaSyCK6miE77n6z7PUf0RNgj8seMiiVET-wqk)
2025-06-21 17:15:17 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:15:17 INFO FeHistory: [172.42719937 173.4142515  188.82994812 ...  71.43864882  71.43864882
  71.43864882]
2025-06-21 17:15:17 INFO Expected Optimum FE: -100
2025-06-21 17:15:17 INFO Unimodal AOCC mean: nan
2025-06-21 17:15:17 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:15:17 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:15:17 INFO AOCC mean: 0.0000
2025-06-21 17:15:17 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:15:25 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-21 17:15:36 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:15:36 INFO FeHistory: [118.88812195 196.85857388 192.53728312 ... 141.7895615  107.87708222
 112.4908334 ]
2025-06-21 17:15:36 INFO Expected Optimum FE: -100
2025-06-21 17:15:36 INFO Unimodal AOCC mean: nan
2025-06-21 17:15:36 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:15:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:15:36 INFO AOCC mean: 0.0000
2025-06-21 17:16:07 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-21 17:16:07 INFO FeHistory: [154.92704452 181.08581104 196.66589952 ...  65.5200094   77.51122048
  84.43186667]
2025-06-21 17:16:07 INFO Expected Optimum FE: -100
2025-06-21 17:16:07 INFO Unimodal AOCC mean: nan
2025-06-21 17:16:07 INFO Multimodal (single component) AOCC mean: nan
2025-06-21 17:16:07 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-21 17:16:07 INFO AOCC mean: 0.0000
