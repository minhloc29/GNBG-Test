2025-06-23 09:19:04 INFO Initializing first population
2025-06-23 09:19:04 INFO Initializing population from 8 seed files...
2025-06-23 09:28:11 INFO Started evolutionary loop, best so far: 0.14294861551599297
2025-06-23 09:28:11 INFO Population length is: 8
2025-06-23 09:28:11 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-23 09:28:11 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.4295e-01 |             AOCC Score on Unimodal instances: 2.3405e-01 |             AOCC Score on Multimodal instances with a single component: 1.2391e-01 |             AOCC Score on Multimodal instances with multiple components: 7.0888e-02)
# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 2 (Overall AOCC Score: 1.2670e-01 |             AOCC Score on Unimodal instances: 2.0754e-01 |             AOCC Score on Multimodal instances with a single component: 1.2235e-01 |             AOCC Score on Multimodal instances with multiple components: 5.0195e-02)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 3 (Overall AOCC Score: 1.2519e-01 |             AOCC Score on Unimodal instances: 2.0751e-01 |             AOCC Score on Multimodal instances with a single component: 1.1885e-01 |             AOCC Score on Multimodal instances with multiple components: 4.9211e-02)
# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 4 (Overall AOCC Score: 1.2252e-01 |             AOCC Score on Unimodal instances: 2.4759e-01 |             AOCC Score on Multimodal instances with a single component: 1.1997e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 5 (Overall AOCC Score: 1.2181e-01 |             AOCC Score on Unimodal instances: 2.0592e-01 |             AOCC Score on Multimodal instances with a single component: 1.2376e-01 |             AOCC Score on Multimodal instances with multiple components: 3.5767e-02)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 6 (Overall AOCC Score: 1.1860e-01 |             AOCC Score on Unimodal instances: 1.9795e-01 |             AOCC Score on Multimodal instances with a single component: 1.1178e-01 |             AOCC Score on Multimodal instances with multiple components: 4.6082e-02)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 7 (Overall AOCC Score: 1.1328e-01 |             AOCC Score on Unimodal instances: 2.0771e-01 |             AOCC Score on Multimodal instances with a single component: 1.0893e-01 |             AOCC Score on Multimodal instances with multiple components: 2.3208e-02)
# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 8 (Overall AOCC Score: 1.0645e-01 |             AOCC Score on Unimodal instances: 2.0180e-01 |             AOCC Score on Multimodal instances with a single component: 1.1754e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:28:16 INFO Full response text: **Analysis:**

Comparing (best) `AdaptiveGaussianArchiveEA` vs (worst) `AdaptiveMultimodalOptimizerImproved`, we see that the best algorithm uses an archive to maintain diversity and prevent premature convergence, a crucial element missing in the worst algorithm.  The best algorithm also employs more sophisticated recombination and mutation strategies (Gaussian-based) compared to the simpler local search and perturbation strategies of the worst.  (second best) `AdaptiveGaussianSamplingEA` vs (second worst) `AdaptiveGaussianMutationDE`, the second-best algorithm, while lacking an archive, still uses adaptive Gaussian sampling and recombination for efficient exploration and exploitation, superior to the mutation-based approach of the second-worst which lacks sufficient diversity management. Comparing (1st) vs (2nd), we see that the archive in `AdaptiveGaussianArchiveEA` significantly improves performance, especially on multimodal problems with multiple components.  (3rd) `AdaptiveGaussianSamplingEAwithArchive` vs (4th) `AdaptiveDifferentialEvolutionWithEnhancedInitialization`, both utilize archives, but the third-best uses adaptive Gaussian sampling, which outperforms the DE strategy of the fourth-best, particularly on multimodal problems.  Comparing (second worst) vs (worst), we see the improved search mechanism of AdaptiveGaussianMutationDE using DE and adaptive Gaussian mutation, demonstrating better performance than the basic local search approach and simulated annealing in AdaptiveMultimodalOptimizerImproved. Overall: The top performers leverage adaptive Gaussian sampling and archives to efficiently explore and exploit the search space, demonstrating the importance of these techniques for complex multimodal problems.  The lower-ranked algorithms lack these features or use less effective methods like simple local search.

**Experience:**

Effective population generation for high-dimensional problems necessitates strategies for maintaining diversity (archives) and efficiently exploiting promising regions (adaptive Gaussian mechanisms).  Combining global exploration (adaptive sampling) with local exploitation (e.g., DE or Gaussian mutation) consistently outperforms simpler approaches, especially when dealing with numerous local optima.

2025-06-23 09:28:18 INFO Full response text: * **Keywords:**  Diversity, Exploitation, Exploration, High-dimensionality, Gaussian processes, Differential Evolution (DE), Adaptive sampling.

* **Advice:** Focus on adaptive mechanisms that dynamically balance global exploration (e.g.,  Latin Hypercube Sampling) and local exploitation (e.g.,  covariance matrix adaptation for Gaussian mutations).  Incorporate elitism and archive strategies to maintain promising solutions and prevent premature convergence.  Consider using model-based approaches like Gaussian processes to guide the search.

* **Avoid:**  Static parameter settings; relying solely on local search; neglecting diversity;  ignoring the high-dimensionality's curse.

* **Explanation:**  Effective heuristics for high-dimensional problems require dynamic adaptation to the problem landscape.  Static methods often fail to escape local optima in complex spaces.  The balance between exploration and exploitation is crucial, and maintaining diversity is essential to avoid premature convergence.  The use of adaptive mechanisms and model-based guidance significantly improves performance.

2025-06-23 09:28:18 INFO Generating offspring via Crossover...
2025-06-23 09:37:45 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveMultimodalOptimizerImproved
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability









### Worse code
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

### Analyze & experience
- Comparing (best) `AdaptiveGaussianArchiveEA` vs (worst) `AdaptiveMultimodalOptimizerImproved`, we see that the best algorithm uses an archive to maintain diversity and prevent premature convergence, a crucial element missing in the worst algorithm.  The best algorithm also employs more sophisticated recombination and mutation strategies (Gaussian-based) compared to the simpler local search and perturbation strategies of the worst.  (second best) `AdaptiveGaussianSamplingEA` vs (second worst) `AdaptiveGaussianMutationDE`, the second-best algorithm, while lacking an archive, still uses adaptive Gaussian sampling and recombination for efficient exploration and exploitation, superior to the mutation-based approach of the second-worst which lacks sufficient diversity management. Comparing (1st) vs (2nd), we see that the archive in `AdaptiveGaussianArchiveEA` significantly improves performance, especially on multimodal problems with multiple components.  (3rd) `AdaptiveGaussianSamplingEAwithArchive` vs (4th) `AdaptiveDifferentialEvolutionWithEnhancedInitialization`, both utilize archives, but the third-best uses adaptive Gaussian sampling, which outperforms the DE strategy of the fourth-best, particularly on multimodal problems.  Comparing (second worst) vs (worst), we see the improved search mechanism of AdaptiveGaussianMutationDE using DE and adaptive Gaussian mutation, demonstrating better performance than the basic local search approach and simulated annealing in AdaptiveMultimodalOptimizerImproved. Overall: The top performers leverage adaptive Gaussian sampling and archives to efficiently explore and exploit the search space, demonstrating the importance of these techniques for complex multimodal problems.  The lower-ranked algorithms lack these features or use less effective methods like simple local search.
- * **Keywords:**  Diversity, Exploitation, Exploration, High-dimensionality, Gaussian processes, Differential Evolution (DE), Adaptive sampling.

* **Advice:** Focus on adaptive mechanisms that dynamically balance global exploration (e.g.,  Latin Hypercube Sampling) and local exploitation (e.g.,  covariance matrix adaptation for Gaussian mutations).  Incorporate elitism and archive strategies to maintain promising solutions and prevent premature convergence.  Consider using model-based approaches like Gaussian processes to guide the search.

* **Avoid:**  Static parameter settings; relying solely on local search; neglecting diversity;  ignoring the high-dimensionality's curse.

* **Explanation:**  Effective heuristics for high-dimensional problems require dynamic adaptation to the problem landscape.  Static methods often fail to escape local optima in complex spaces.  The balance between exploration and exploitation is crucial, and maintaining diversity is essential to avoid premature convergence.  The use of adaptive mechanisms and model-based guidance significantly improves performance.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:37:45 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Diversity, Exploitation, Exploration, High-dimensionality, Gaussian processes, Differential Evolution (DE), Adaptive sampling.

* **Advice:** Focus on adaptive mechanisms that dynamically balance global exploration (e.g.,  Latin Hypercube Sampling) and local exploitation (e.g.,  covariance matrix adaptation for Gaussian mutations).  Incorporate elitism and archive strategies to maintain promising solutions and prevent premature convergence.  Consider using model-based approaches like Gaussian processes to guide the search.

* **Avoid:**  Static parameter settings; relying solely on local search; neglecting diversity;  ignoring the high-dimensionality's curse.

* **Explanation:**  Effective heuristics for high-dimensional problems require dynamic adaptation to the problem landscape.  Static methods often fail to escape local optima in complex spaces.  The balance between exploration and exploitation is crucial, and maintaining diversity is essential to avoid premature convergence.  The use of adaptive mechanisms and model-based guidance significantly improves performance.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 09:47:02 INFO Perform Harmony Search...
2025-06-23 09:47:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:13 ERROR Can not run the algorithm
2025-06-23 09:47:13 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 09:47:13 INFO FeHistory: [-701.30951973]
2025-06-23 09:47:13 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 351.85197292266366, archive_size: int = 398.29160353728787, sigma_decay: float = 0.9048978519216166, sigma_init_factor: float = 0.1305708462752357):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:13 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:13 ERROR Can not run the algorithm
2025-06-23 09:47:14 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0916
2025-06-23 09:47:14 INFO FeHistory: [-222.13863265]
2025-06-23 09:47:14 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:14 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:14 ERROR Can not run the algorithm
2025-06-23 09:47:14 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:14 INFO FeHistory: [206.42094279]
2025-06-23 09:47:14 INFO Expected Optimum FE: -100
2025-06-23 09:47:14 INFO Unimodal AOCC mean: 0.1739
2025-06-23 09:47:14 INFO Multimodal (single component) AOCC mean: 0.0916
2025-06-23 09:47:14 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:14 INFO AOCC mean: 0.0885
2025-06-23 09:47:14 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:14 ERROR Can not run the algorithm
2025-06-23 09:47:14 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1746
2025-06-23 09:47:14 INFO FeHistory: [-701.33609205]
2025-06-23 09:47:14 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:14 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 384.221818814428, archive_size: int = 191.1179542452867, sigma_decay: float = 0.9821694960796639, sigma_init_factor: float = 0.9567051293342729):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:14 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:14 ERROR Can not run the algorithm
2025-06-23 09:47:14 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0901
2025-06-23 09:47:14 INFO FeHistory: [-221.70797889]
2025-06-23 09:47:14 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:14 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:14 ERROR Can not run the algorithm
2025-06-23 09:47:14 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:14 INFO FeHistory: [207.91442039]
2025-06-23 09:47:14 INFO Expected Optimum FE: -100
2025-06-23 09:47:14 INFO Unimodal AOCC mean: 0.1746
2025-06-23 09:47:14 INFO Multimodal (single component) AOCC mean: 0.0901
2025-06-23 09:47:14 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:14 INFO AOCC mean: 0.0882
2025-06-23 09:47:14 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:14 ERROR Can not run the algorithm
2025-06-23 09:47:14 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1750
2025-06-23 09:47:14 INFO FeHistory: [-701.3552925]
2025-06-23 09:47:14 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:14 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 738.4024865117939, archive_size: int = 278.0533713678392, sigma_decay: float = 0.9063967801646217, sigma_init_factor: float = 0.23340049825073):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:14 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:14 ERROR Can not run the algorithm
2025-06-23 09:47:15 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0905
2025-06-23 09:47:15 INFO FeHistory: [-221.83069377]
2025-06-23 09:47:15 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:15 ERROR Can not run the algorithm
2025-06-23 09:47:15 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:15 INFO FeHistory: [213.9681236]
2025-06-23 09:47:15 INFO Expected Optimum FE: -100
2025-06-23 09:47:15 INFO Unimodal AOCC mean: 0.1750
2025-06-23 09:47:15 INFO Multimodal (single component) AOCC mean: 0.0905
2025-06-23 09:47:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:15 INFO AOCC mean: 0.0885
2025-06-23 09:47:15 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:15 ERROR Can not run the algorithm
2025-06-23 09:47:15 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1732
2025-06-23 09:47:15 INFO FeHistory: [-701.27717985]
2025-06-23 09:47:15 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:15 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 153.14998563010948, archive_size: int = 985.4702474224974, sigma_decay: float = 0.9461295515879702, sigma_init_factor: float = 0.40254825289416796):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:15 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:15 ERROR Can not run the algorithm
2025-06-23 09:47:15 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0895
2025-06-23 09:47:15 INFO FeHistory: [-221.55411047]
2025-06-23 09:47:15 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:15 ERROR Can not run the algorithm
2025-06-23 09:47:15 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:15 INFO FeHistory: [217.64746835]
2025-06-23 09:47:15 INFO Expected Optimum FE: -100
2025-06-23 09:47:15 INFO Unimodal AOCC mean: 0.1732
2025-06-23 09:47:15 INFO Multimodal (single component) AOCC mean: 0.0895
2025-06-23 09:47:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:15 INFO AOCC mean: 0.0876
2025-06-23 09:47:15 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:15 ERROR Can not run the algorithm
2025-06-23 09:47:15 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 09:47:15 INFO FeHistory: [-701.32883138]
2025-06-23 09:47:15 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:15 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 730.0265020279618, archive_size: int = 468.03960745579866, sigma_decay: float = 0.9889500262984708, sigma_init_factor: float = 0.527122201323226):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:15 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:15 ERROR Can not run the algorithm
2025-06-23 09:47:16 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0898
2025-06-23 09:47:16 INFO FeHistory: [-221.64570552]
2025-06-23 09:47:16 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:16 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:16 ERROR Can not run the algorithm
2025-06-23 09:47:16 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:16 INFO FeHistory: [173.2999256]
2025-06-23 09:47:16 INFO Expected Optimum FE: -100
2025-06-23 09:47:16 INFO Unimodal AOCC mean: 0.1744
2025-06-23 09:47:16 INFO Multimodal (single component) AOCC mean: 0.0898
2025-06-23 09:47:16 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:16 INFO AOCC mean: 0.0881
2025-06-23 09:47:16 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:16 ERROR Can not run the algorithm
2025-06-23 09:47:16 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 09:47:16 INFO FeHistory: [-701.29689039]
2025-06-23 09:47:16 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:16 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 913.0439521904303, archive_size: int = 1178.7444213190386, sigma_decay: float = 1.005884276746328, sigma_init_factor: float = 0.06557388969619679):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:16 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:16 ERROR Can not run the algorithm
2025-06-23 09:47:16 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0900
2025-06-23 09:47:16 INFO FeHistory: [-221.69027725]
2025-06-23 09:47:16 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:16 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:16 ERROR Can not run the algorithm
2025-06-23 09:47:16 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:16 INFO FeHistory: [188.7380482]
2025-06-23 09:47:16 INFO Expected Optimum FE: -100
2025-06-23 09:47:16 INFO Unimodal AOCC mean: 0.1736
2025-06-23 09:47:16 INFO Multimodal (single component) AOCC mean: 0.0900
2025-06-23 09:47:16 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:16 INFO AOCC mean: 0.0879
2025-06-23 09:47:16 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:16 ERROR Can not run the algorithm
2025-06-23 09:47:16 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1752
2025-06-23 09:47:16 INFO FeHistory: [-701.36276411]
2025-06-23 09:47:16 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:16 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 902.1424140923173, archive_size: int = 793.0152113514126, sigma_decay: float = 0.9016010110707149, sigma_init_factor: float = 0.8231709250212976):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:16 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:16 ERROR Can not run the algorithm
2025-06-23 09:47:17 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0937
2025-06-23 09:47:17 INFO FeHistory: [-222.72972377]
2025-06-23 09:47:17 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:17 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:17 ERROR Can not run the algorithm
2025-06-23 09:47:17 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:17 INFO FeHistory: [189.25923508]
2025-06-23 09:47:17 INFO Expected Optimum FE: -100
2025-06-23 09:47:17 INFO Unimodal AOCC mean: 0.1752
2025-06-23 09:47:17 INFO Multimodal (single component) AOCC mean: 0.0937
2025-06-23 09:47:17 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:17 INFO AOCC mean: 0.0896
2025-06-23 09:47:17 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:17 ERROR Can not run the algorithm
2025-06-23 09:47:17 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 09:47:17 INFO FeHistory: [-701.30414014]
2025-06-23 09:47:17 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:17 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 395.8148524273168, archive_size: int = 172.34220725129967, sigma_decay: float = 0.9119527249843223, sigma_init_factor: float = 0.527122201323226):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:17 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:17 ERROR Can not run the algorithm
2025-06-23 09:47:17 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0948
2025-06-23 09:47:17 INFO FeHistory: [-223.00113744]
2025-06-23 09:47:17 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:17 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:17 ERROR Can not run the algorithm
2025-06-23 09:47:17 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:17 INFO FeHistory: [195.45142456]
2025-06-23 09:47:17 INFO Expected Optimum FE: -100
2025-06-23 09:47:17 INFO Unimodal AOCC mean: 0.1738
2025-06-23 09:47:17 INFO Multimodal (single component) AOCC mean: 0.0948
2025-06-23 09:47:17 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:17 INFO AOCC mean: 0.0895
2025-06-23 09:47:17 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:17 ERROR Can not run the algorithm
2025-06-23 09:47:17 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1737
2025-06-23 09:47:17 INFO FeHistory: [-701.29978017]
2025-06-23 09:47:17 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:17 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 952.4925200984646, archive_size: int = 42.14460487428886, sigma_decay: float = 0.9063967801646217, sigma_init_factor: float = 0.6326438403750042):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:17 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:17 ERROR Can not run the algorithm
2025-06-23 09:47:18 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0900
2025-06-23 09:47:18 INFO FeHistory: [-221.67826197]
2025-06-23 09:47:18 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:18 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:18 ERROR Can not run the algorithm
2025-06-23 09:47:18 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:18 INFO FeHistory: [214.11852269]
2025-06-23 09:47:18 INFO Expected Optimum FE: -100
2025-06-23 09:47:18 INFO Unimodal AOCC mean: 0.1737
2025-06-23 09:47:18 INFO Multimodal (single component) AOCC mean: 0.0900
2025-06-23 09:47:18 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:18 INFO AOCC mean: 0.0879
2025-06-23 09:47:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:47:18 ERROR Can not run the algorithm
2025-06-23 09:47:18 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 09:47:18 INFO FeHistory: [-701.32794636]
2025-06-23 09:47:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:47:18 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 442.4749728083182, archive_size: int = 606.2715252345095, sigma_decay: float = 0.9320377499089133, sigma_init_factor: float = 0.1573198735789061):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:47:18 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:47:18 ERROR Can not run the algorithm
2025-06-23 09:47:18 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0874
2025-06-23 09:47:18 INFO FeHistory: [-220.90482574]
2025-06-23 09:47:18 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:47:18 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:47:18 ERROR Can not run the algorithm
2025-06-23 09:47:18 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:47:18 INFO FeHistory: [171.81397817]
2025-06-23 09:47:18 INFO Expected Optimum FE: -100
2025-06-23 09:47:18 INFO Unimodal AOCC mean: 0.1744
2025-06-23 09:47:18 INFO Multimodal (single component) AOCC mean: 0.0874
2025-06-23 09:47:18 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:47:18 INFO AOCC mean: 0.0872
2025-06-23 09:47:18 INFO Generation 1, best so far: 0.14294861551599297
2025-06-23 09:47:18 INFO Population length is: 7
2025-06-23 09:47:18 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-23 09:47:18 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.6402e-02 |             AOCC Score on Unimodal instances: 1.8043e-01 |             AOCC Score on Multimodal instances with a single component: 1.0878e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithLatinHypercubeInitialization
# Description: Combines Differential Evolution with Latin Hypercube Sampling for initialization and an adaptive mutation strategy to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: AdaptiveDEwithLatinHypercubeInitialization
# Description:  Combines Differential Evolution with Latin Hypercube Sampling for initialization and an adaptive mutation strategy to efficiently explore and exploit multimodal landscapes.
# Code:
class AdaptiveDEwithLatinHypercubeInitialization:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive_size = 200
        self.archive = []
        self.mutation_scale = 0.5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        # Latin Hypercube Sampling for diverse initialization
        sampler = qmc.LatinHypercube(self.dim)
        sample = sampler.random(self.population_size)
        population = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )
            self._update_best(offspring, offspring_fitness)
            self.mutation_scale *= 0.98 #Adaptive Mutation scaling

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_distinct_indices(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            trial = self._crossover(population[i], mutant)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring


    def _select_distinct_indices(self, i, pop_size):
        a, b, c = np.random.choice(pop_size, 3, replace=False)
        while a == i:
            a = np.random.choice(pop_size)
        return a, b, c

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 2 (Overall AOCC Score: 9.2757e-02 |             AOCC Score on Unimodal instances: 1.7493e-01 |             AOCC Score on Multimodal instances with a single component: 1.0334e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveDE
# Description: Combines Differential Evolution with adaptive Gaussian sampling and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np

class AdaptiveGaussianArchiveDE:
    """
    Combines Differential Evolution (DE) with adaptive Gaussian sampling and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian sigma
        self.sigma_decay = 0.99 # Adaptive decay for sigma
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            # Differential Evolution
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Gaussian Mutation for Diversity
            gaussian_offspring = self._gaussian_mutation(population)
            gaussian_fitness = objective_function(gaussian_offspring)
            self.eval_count += self.population_size // 2


            # Combine and select
            combined_pop = np.vstack((offspring, gaussian_offspring, population))
            combined_fit = np.concatenate((offspring_fitness, gaussian_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self.archive = self._update_archive(population, fitness)
            self._update_best(population, fitness)
            self.sigma *= self.sigma_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness):
        new_population = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                new_population[i] = trial
            else:
                new_population[i] = population[i]
        return new_population


    def _gaussian_mutation(self, population):
        num_mutants = self.population_size // 2
        mutants = population[:num_mutants] + np.random.normal(0, self.sigma, size=(num_mutants, self.dim))
        return np.clip(mutants, self.lower_bounds, self.upper_bounds)

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness):
        combined = np.column_stack((population, fitness))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 3 (Overall AOCC Score: 9.2093e-02 |             AOCC Score on Unimodal instances: 1.7604e-01 |             AOCC Score on Multimodal instances with a single component: 1.0024e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveGaussianDE
# Description: Combines Differential Evolution, adaptive Gaussian mutation, and an archive for efficient multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveGaussianDE
# Description: Combines Differential Evolution, adaptive Gaussian mutation, and an archive for efficient multimodal optimization.
# Code:
class ArchiveGuidedAdaptiveGaussianDE:
    """
    Combines Differential Evolution (DE), adaptive Gaussian mutation, and an archive for efficient multimodal optimization.  
    It balances exploration and exploitation by using DE for global search and Gaussian mutation for local refinement, 
    while the archive maintains diversity and prevents premature convergence.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # Heuristic
        self.archive_size = 200
        self.archive = []
        self.sigma = 0.5  # Initial Gaussian mutation scale
        self.sigma_decay = 0.99 #Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self._update_archive(offspring, offspring_fitness)
            
            # Selection using a combination of DE and Gaussian-mutated solutions
            combined_pop = np.concatenate((self.population, offspring))
            combined_fit = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fit)
            self.population = combined_pop[indices[:self.population_size]]
            fitness = combined_fit[indices[:self.population_size]]

            self._update_best(self.population, fitness)
            self.sigma *= self.sigma_decay #Adaptive Gaussian mutation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            #Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            #Incorporate Archive if not empty
            if self.archive.size > 0:
              archive_member = self.archive[random.randint(0, len(self.archive)-1)][0]
              offspring[i] = population[i] + 0.5*(archive_member - population[i] + population[a] - population[b])
            else:
              offspring[i] = population[i] + 0.5*(population[a] - population[b])


            #Adaptive Gaussian Mutation
            offspring[i] += np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _update_best(self, population, fitness):
        if np.min(fitness) < self.best_fitness_overall:
            self.best_fitness_overall = np.min(fitness)
            self.best_solution_overall = population[np.argmin(fitness)]
```

### Rank 4 (Overall AOCC Score: 9.1198e-02 |             AOCC Score on Unimodal instances: 1.7494e-01 |             AOCC Score on Multimodal instances with a single component: 9.8658e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: Combines adaptive Gaussian sampling with an archive for efficient exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np

class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to efficiently explore and exploit multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=200):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(self.archive)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, archive):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(archive), tournament_size, replace=False)
            winner_index = tournament[np.argmin([sol[1] for sol in archive][tournament])]
            selected_parents.append(archive[winner_index][0])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, solutions, fitness_values):
        new_entries = list(zip(solutions, fitness_values))
        self.archive.extend(new_entries)
        self.archive.sort(key=lambda x: x[1])
        self.archive = self.archive[:self.archive_size]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 5 (Overall AOCC Score: 9.0724e-02 |             AOCC Score on Unimodal instances: 1.7504e-01 |             AOCC Score on Multimodal instances with a single component: 9.7133e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: Combines adaptive Gaussian sampling with an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveGaussianArchiveEA
# Description: Combines adaptive Gaussian sampling with an archive for robust multimodal optimization.
# Code:
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)

            self._update_best(population, fitness_values)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.archive_size), :-1]
    
    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size-len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

```

### Rank 6 (Overall AOCC Score: 8.9647e-02 |             AOCC Score on Unimodal instances: 1.7520e-01 |             AOCC Score on Multimodal instances with a single component: 9.3739e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 902.1424140923173, archive_size: int = 793.0152113514126, sigma_decay: float = 0.9016010110707149, sigma_init_factor: float = 0.8231709250212976):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:47:22 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveDEwithLatinHypercubeInitialization vs (worst) AdaptiveGaussianArchiveEA (second version), we see that Latin Hypercube Sampling for initialization provides a more diverse starting population, leading to better exploration, while the adaptive mutation strategy in AdaptiveDE allows for efficient exploitation. The second version of AdaptiveGaussianArchiveEA lacks these features, resulting in poorer performance.  (second best) AdaptiveGaussianArchiveDE vs (second worst) AdaptiveGaussianArchiveEA (first version) shows that incorporating both DE and Gaussian mutation, along with an archive, is more effective than relying solely on Gaussian-based operators and an archive.  Comparing (1st) vs (2nd), we see that the adaptive mutation in AdaptiveDE is superior to the fixed F and CR values in AdaptiveGaussianArchiveDE. (3rd) ArchiveGuidedAdaptiveGaussianDE vs (4th) AdaptiveGaussianArchiveEA (first version) shows that a more sophisticated combination of DE and Gaussian mutation with archive guidance improves performance. Comparing (second worst) vs (worst), we see that even small changes to parameter values and less sophisticated archive updating in the second AdaptiveGaussianArchiveEA can significantly degrade performance. Overall: The best-performing algorithms leverage Latin Hypercube Sampling for diverse initialization, adaptive mutation strategies, and a well-managed archive to balance exploration and exploitation effectively.  The worse-performing algorithms often rely on simpler Gaussian-based mutations and selection methods, resulting in suboptimal performance. The use of DE is demonstrably beneficial.


**Experience:**

Adaptive parameter scaling, diverse population initialization, and the careful balance between exploration and exploitation are crucial in high-dimensional multimodal optimization.  An effective archive management strategy is essential for maintaining diversity and preventing premature convergence.

2025-06-23 09:47:24 INFO Full response text: **Keywords:**  Heuristic Design, Multimodal Optimization, High-Dimensional Search, Diversity Preservation, Exploration-Exploitation

**Advice:** Focus on novel mechanisms for adaptive parameter scaling that are *not* Gaussian-based. Explore archive management strategies beyond simple population-size limits; consider fitness-based or topological approaches.  Investigate non-standard exploration methods that avoid uniform or grid-based sampling.  Quantify the balance between exploration and exploitation mathematically rather than relying on intuition.

**Avoid:**  Gaussian mutations, DE variants, adaptive sampling (unless significantly novel),  explicit mention of archives as simple diversity-preserving mechanisms,  vague statements about "outperforming simpler approaches."

**Explanation:** The ineffective reflection relies on well-established methods.  To earn the large reward,  the new heuristics must offer genuinely innovative approaches to the challenges of high-dimensional multimodal optimization, going beyond incremental improvements to existing techniques.  A rigorous, quantifiable approach is key.

2025-06-23 09:47:24 INFO Generating offspring via Crossover...
2025-06-23 09:48:39 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveGaussianArchiveEA
import numpy as np

class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to efficiently explore and exploit multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=200):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(self.archive)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, archive):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(archive), tournament_size, replace=False)
            winner_index = tournament[np.argmin([sol[1] for sol in archive][tournament])]
            selected_parents.append(archive[winner_index][0])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, solutions, fitness_values):
        new_entries = list(zip(solutions, fitness_values))
        self.archive.extend(new_entries)
        self.archive.sort(key=lambda x: x[1])
        self.archive = self.archive[:self.archive_size]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]


### Worse code
AdaptiveGaussianArchiveDE
import numpy as np

class AdaptiveGaussianArchiveDE:
    """
    Combines Differential Evolution (DE) with adaptive Gaussian sampling and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian sigma
        self.sigma_decay = 0.99 # Adaptive decay for sigma
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            # Differential Evolution
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Gaussian Mutation for Diversity
            gaussian_offspring = self._gaussian_mutation(population)
            gaussian_fitness = objective_function(gaussian_offspring)
            self.eval_count += self.population_size // 2


            # Combine and select
            combined_pop = np.vstack((offspring, gaussian_offspring, population))
            combined_fit = np.concatenate((offspring_fitness, gaussian_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self.archive = self._update_archive(population, fitness)
            self._update_best(population, fitness)
            self.sigma *= self.sigma_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness):
        new_population = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                new_population[i] = trial
            else:
                new_population[i] = population[i]
        return new_population


    def _gaussian_mutation(self, population):
        num_mutants = self.population_size // 2
        mutants = population[:num_mutants] + np.random.normal(0, self.sigma, size=(num_mutants, self.dim))
        return np.clip(mutants, self.lower_bounds, self.upper_bounds)

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness):
        combined = np.column_stack((population, fitness))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])


### Analyze & experience
- Comparing (best) AdaptiveDEwithLatinHypercubeInitialization vs (worst) AdaptiveGaussianArchiveEA (second version), we see that Latin Hypercube Sampling for initialization provides a more diverse starting population, leading to better exploration, while the adaptive mutation strategy in AdaptiveDE allows for efficient exploitation. The second version of AdaptiveGaussianArchiveEA lacks these features, resulting in poorer performance.  (second best) AdaptiveGaussianArchiveDE vs (second worst) AdaptiveGaussianArchiveEA (first version) shows that incorporating both DE and Gaussian mutation, along with an archive, is more effective than relying solely on Gaussian-based operators and an archive.  Comparing (1st) vs (2nd), we see that the adaptive mutation in AdaptiveDE is superior to the fixed F and CR values in AdaptiveGaussianArchiveDE. (3rd) ArchiveGuidedAdaptiveGaussianDE vs (4th) AdaptiveGaussianArchiveEA (first version) shows that a more sophisticated combination of DE and Gaussian mutation with archive guidance improves performance. Comparing (second worst) vs (worst), we see that even small changes to parameter values and less sophisticated archive updating in the second AdaptiveGaussianArchiveEA can significantly degrade performance. Overall: The best-performing algorithms leverage Latin Hypercube Sampling for diverse initialization, adaptive mutation strategies, and a well-managed archive to balance exploration and exploitation effectively.  The worse-performing algorithms often rely on simpler Gaussian-based mutations and selection methods, resulting in suboptimal performance. The use of DE is demonstrably beneficial.
- **Keywords:**  Heuristic Design, Multimodal Optimization, High-Dimensional Search, Diversity Preservation, Exploration-Exploitation

**Advice:** Focus on novel mechanisms for adaptive parameter scaling that are *not* Gaussian-based. Explore archive management strategies beyond simple population-size limits; consider fitness-based or topological approaches.  Investigate non-standard exploration methods that avoid uniform or grid-based sampling.  Quantify the balance between exploration and exploitation mathematically rather than relying on intuition.

**Avoid:**  Gaussian mutations, DE variants, adaptive sampling (unless significantly novel),  explicit mention of archives as simple diversity-preserving mechanisms,  vague statements about "outperforming simpler approaches."

**Explanation:** The ineffective reflection relies on well-established methods.  To earn the large reward,  the new heuristics must offer genuinely innovative approaches to the challenges of high-dimensional multimodal optimization, going beyond incremental improvements to existing techniques.  A rigorous, quantifiable approach is key.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:48:39 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Heuristic Design, Multimodal Optimization, High-Dimensional Search, Diversity Preservation, Exploration-Exploitation

**Advice:** Focus on novel mechanisms for adaptive parameter scaling that are *not* Gaussian-based. Explore archive management strategies beyond simple population-size limits; consider fitness-based or topological approaches.  Investigate non-standard exploration methods that avoid uniform or grid-based sampling.  Quantify the balance between exploration and exploitation mathematically rather than relying on intuition.

**Avoid:**  Gaussian mutations, DE variants, adaptive sampling (unless significantly novel),  explicit mention of archives as simple diversity-preserving mechanisms,  vague statements about "outperforming simpler approaches."

**Explanation:** The ineffective reflection relies on well-established methods.  To earn the large reward,  the new heuristics must offer genuinely innovative approaches to the challenges of high-dimensional multimodal optimization, going beyond incremental improvements to existing techniques.  A rigorous, quantifiable approach is key.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 09:49:22 INFO Perform Harmony Search...
2025-06-23 09:49:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:33 ERROR Can not run the algorithm
2025-06-23 09:49:33 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 09:49:33 INFO FeHistory: [-701.29695922]
2025-06-23 09:49:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:33 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 428.45738927046256, archive_size: int = 517.8898943603788, sigma_decay: float = 0.8679777705113899, initial_sigma_multiplier: float = 0.3292899156720783):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:33 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:33 ERROR Can not run the algorithm
2025-06-23 09:49:33 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0922
2025-06-23 09:49:33 INFO FeHistory: [-222.32236969]
2025-06-23 09:49:33 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:34 ERROR Can not run the algorithm
2025-06-23 09:49:34 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:34 INFO FeHistory: [166.83959441]
2025-06-23 09:49:34 INFO Expected Optimum FE: -100
2025-06-23 09:49:34 INFO Unimodal AOCC mean: 0.1736
2025-06-23 09:49:34 INFO Multimodal (single component) AOCC mean: 0.0922
2025-06-23 09:49:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:34 INFO AOCC mean: 0.0886
2025-06-23 09:49:34 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:34 ERROR Can not run the algorithm
2025-06-23 09:49:34 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1734
2025-06-23 09:49:34 INFO FeHistory: [-701.28959299]
2025-06-23 09:49:34 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:34 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 562.0694685817049, archive_size: int = 830.8583873895849, sigma_decay: float = 0.8693163052900642, initial_sigma_multiplier: float = 0.18386824178346184):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:34 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:34 ERROR Can not run the algorithm
2025-06-23 09:49:34 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0924
2025-06-23 09:49:34 INFO FeHistory: [-222.36661289]
2025-06-23 09:49:34 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:34 ERROR Can not run the algorithm
2025-06-23 09:49:34 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:34 INFO FeHistory: [205.93003784]
2025-06-23 09:49:34 INFO Expected Optimum FE: -100
2025-06-23 09:49:34 INFO Unimodal AOCC mean: 0.1734
2025-06-23 09:49:34 INFO Multimodal (single component) AOCC mean: 0.0924
2025-06-23 09:49:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:34 INFO AOCC mean: 0.0886
2025-06-23 09:49:34 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:34 ERROR Can not run the algorithm
2025-06-23 09:49:34 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1737
2025-06-23 09:49:34 INFO FeHistory: [-701.29859108]
2025-06-23 09:49:34 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:34 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 940.8527055687055, archive_size: int = 295.16177581100436, sigma_decay: float = 0.9525721683757008, initial_sigma_multiplier: float = 0.8752143394518782):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:34 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:34 ERROR Can not run the algorithm
2025-06-23 09:49:35 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0941
2025-06-23 09:49:35 INFO FeHistory: [-222.83833111]
2025-06-23 09:49:35 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:35 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:35 ERROR Can not run the algorithm
2025-06-23 09:49:35 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:35 INFO FeHistory: [183.87056334]
2025-06-23 09:49:35 INFO Expected Optimum FE: -100
2025-06-23 09:49:35 INFO Unimodal AOCC mean: 0.1737
2025-06-23 09:49:35 INFO Multimodal (single component) AOCC mean: 0.0941
2025-06-23 09:49:35 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:35 INFO AOCC mean: 0.0893
2025-06-23 09:49:35 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:35 ERROR Can not run the algorithm
2025-06-23 09:49:35 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 09:49:35 INFO FeHistory: [-701.33020381]
2025-06-23 09:49:35 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:35 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 251.28328644470082, archive_size: int = 315.6386473001231, sigma_decay: float = 0.8980259742847463, initial_sigma_multiplier: float = 0.6543723685250173):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:35 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:35 ERROR Can not run the algorithm
2025-06-23 09:49:35 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0897
2025-06-23 09:49:35 INFO FeHistory: [-221.61739347]
2025-06-23 09:49:35 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:35 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:35 ERROR Can not run the algorithm
2025-06-23 09:49:35 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:35 INFO FeHistory: [211.08811118]
2025-06-23 09:49:35 INFO Expected Optimum FE: -100
2025-06-23 09:49:35 INFO Unimodal AOCC mean: 0.1744
2025-06-23 09:49:35 INFO Multimodal (single component) AOCC mean: 0.0897
2025-06-23 09:49:35 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:35 INFO AOCC mean: 0.0881
2025-06-23 09:49:35 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:35 ERROR Can not run the algorithm
2025-06-23 09:49:35 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1732
2025-06-23 09:49:35 INFO FeHistory: [-701.27929159]
2025-06-23 09:49:35 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:35 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 356.2083596134695, archive_size: int = 736.0259136560289, sigma_decay: float = 0.984726852766839, initial_sigma_multiplier: float = 0.27186977091605236):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:35 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:35 ERROR Can not run the algorithm
2025-06-23 09:49:36 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0995
2025-06-23 09:49:36 INFO FeHistory: [-224.16693359]
2025-06-23 09:49:36 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:36 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:36 ERROR Can not run the algorithm
2025-06-23 09:49:36 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:36 INFO FeHistory: [201.59194494]
2025-06-23 09:49:36 INFO Expected Optimum FE: -100
2025-06-23 09:49:36 INFO Unimodal AOCC mean: 0.1732
2025-06-23 09:49:36 INFO Multimodal (single component) AOCC mean: 0.0995
2025-06-23 09:49:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:36 INFO AOCC mean: 0.0909
2025-06-23 09:49:36 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:36 ERROR Can not run the algorithm
2025-06-23 09:49:36 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 09:49:36 INFO FeHistory: [-701.29783601]
2025-06-23 09:49:36 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:36 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 695.1910533563976, archive_size: int = 356.190445660277, sigma_decay: float = 0.9633660247072161, initial_sigma_multiplier: float = 0.27186977091605236):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:36 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:36 ERROR Can not run the algorithm
2025-06-23 09:49:36 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0866
2025-06-23 09:49:36 INFO FeHistory: [-220.67823286]
2025-06-23 09:49:36 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:36 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:36 ERROR Can not run the algorithm
2025-06-23 09:49:36 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:36 INFO FeHistory: [169.49876108]
2025-06-23 09:49:36 INFO Expected Optimum FE: -100
2025-06-23 09:49:36 INFO Unimodal AOCC mean: 0.1736
2025-06-23 09:49:36 INFO Multimodal (single component) AOCC mean: 0.0866
2025-06-23 09:49:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:36 INFO AOCC mean: 0.0868
2025-06-23 09:49:36 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:36 ERROR Can not run the algorithm
2025-06-23 09:49:36 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 09:49:36 INFO FeHistory: [-701.29186096]
2025-06-23 09:49:36 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:36 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 940.8527055687055, archive_size: int = 57.701104295010516, sigma_decay: float = 0.845884235783486, initial_sigma_multiplier: float = 0.6543723685250173):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:36 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:36 ERROR Can not run the algorithm
2025-06-23 09:49:37 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0968
2025-06-23 09:49:37 INFO FeHistory: [-223.51819572]
2025-06-23 09:49:37 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:37 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:37 ERROR Can not run the algorithm
2025-06-23 09:49:37 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:37 INFO FeHistory: [193.33124448]
2025-06-23 09:49:37 INFO Expected Optimum FE: -100
2025-06-23 09:49:37 INFO Unimodal AOCC mean: 0.1735
2025-06-23 09:49:37 INFO Multimodal (single component) AOCC mean: 0.0968
2025-06-23 09:49:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:37 INFO AOCC mean: 0.0901
2025-06-23 09:49:37 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:37 ERROR Can not run the algorithm
2025-06-23 09:49:37 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 09:49:37 INFO FeHistory: [-701.29620632]
2025-06-23 09:49:37 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:37 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 271.8951450040577, archive_size: int = 736.0259136560289, sigma_decay: float = 0.8741749990981382, initial_sigma_multiplier: float = 0.47062103817875267):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:37 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:37 ERROR Can not run the algorithm
2025-06-23 09:49:37 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0912
2025-06-23 09:49:37 INFO FeHistory: [-222.04455924]
2025-06-23 09:49:37 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:37 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:37 ERROR Can not run the algorithm
2025-06-23 09:49:37 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:37 INFO FeHistory: [212.59081713]
2025-06-23 09:49:37 INFO Expected Optimum FE: -100
2025-06-23 09:49:37 INFO Unimodal AOCC mean: 0.1736
2025-06-23 09:49:37 INFO Multimodal (single component) AOCC mean: 0.0912
2025-06-23 09:49:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:37 INFO AOCC mean: 0.0883
2025-06-23 09:49:37 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:37 ERROR Can not run the algorithm
2025-06-23 09:49:37 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1749
2025-06-23 09:49:37 INFO FeHistory: [-701.35045313]
2025-06-23 09:49:37 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:37 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 428.45738927046256, archive_size: int = 57.701104295010516, sigma_decay: float = 0.8612598171458236, initial_sigma_multiplier: float = 0.7240142166261954):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:37 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:37 ERROR Can not run the algorithm
2025-06-23 09:49:38 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0955
2025-06-23 09:49:38 INFO FeHistory: [-223.18993541]
2025-06-23 09:49:38 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:38 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:38 ERROR Can not run the algorithm
2025-06-23 09:49:38 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:38 INFO FeHistory: [148.00214167]
2025-06-23 09:49:38 INFO Expected Optimum FE: -100
2025-06-23 09:49:38 INFO Unimodal AOCC mean: 0.1749
2025-06-23 09:49:38 INFO Multimodal (single component) AOCC mean: 0.0955
2025-06-23 09:49:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:38 INFO AOCC mean: 0.0901
2025-06-23 09:49:38 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:49:38 ERROR Can not run the algorithm
2025-06-23 09:49:38 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1733
2025-06-23 09:49:38 INFO FeHistory: [-701.28502251]
2025-06-23 09:49:38 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:49:38 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 409.41905095846016, archive_size: int = 851.8855257938833, sigma_decay: float = 0.9615885392412933, initial_sigma_multiplier: float = 0.6724473422077342):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:49:38 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:49:38 ERROR Can not run the algorithm
2025-06-23 09:49:38 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0945
2025-06-23 09:49:38 INFO FeHistory: [-222.94021912]
2025-06-23 09:49:38 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:49:38 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:49:38 ERROR Can not run the algorithm
2025-06-23 09:49:38 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:49:38 INFO FeHistory: [139.81955132]
2025-06-23 09:49:38 INFO Expected Optimum FE: -100
2025-06-23 09:49:38 INFO Unimodal AOCC mean: 0.1733
2025-06-23 09:49:38 INFO Multimodal (single component) AOCC mean: 0.0945
2025-06-23 09:49:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:49:38 INFO AOCC mean: 0.0893
2025-06-23 09:49:38 INFO Generation 2, best so far: 0.14294861551599297
2025-06-23 09:49:38 INFO Population length is: 7
2025-06-23 09:49:38 INFO --- Performing Long-Term Reflection at Generation 3 ---
2025-06-23 09:49:38 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.3419e-02 |             AOCC Score on Unimodal instances: 1.7531e-01 |             AOCC Score on Multimodal instances with a single component: 1.0495e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: Combines Latin Hypercube sampling, adaptive mutation, and a fitness-based archive for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

class AdaptiveMultimodalOptimizer:
    """
    Combines Latin Hypercube sampling, adaptive mutation, and a fitness-based archive for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.mutation_rate = 0.1 #Initial mutation rate
        self.mutation_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._mutate_population(population, self.mutation_rate)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness, offspring_fitness)))

            #Selection based on archive
            selected_indices = np.random.choice(len(self.archive), size=self.population_size, replace=False, p=self._get_selection_probabilities())
            population = np.array([self.archive[i][0] for i in selected_indices])
            fitness = np.array([self.archive[i][1] for i in selected_indices])
            self._update_best(population, fitness)
            self.mutation_rate *= self.mutation_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _mutate_population(self, population, mutation_rate):
        offspring = population + np.random.normal(0, mutation_rate * (self.upper_bounds - self.lower_bounds), size=population.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness):
        combined = np.column_stack((population, fitness))
        self.archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                self.archive.append(sol)
        self.archive.sort(key=lambda x: x[-1])
        return np.array(self.archive[:self.archive_size])
    
    def _get_selection_probabilities(self):
        min_fitness = self.archive[:, -1].min()
        max_fitness = self.archive[:, -1].max()
        
        if max_fitness == min_fitness: #handle case where all fitnesses are same
            return np.ones(len(self.archive)) / len(self.archive)
        
        fitness_diffs = max_fitness - self.archive[:, -1]
        probabilities = fitness_diffs / fitness_diffs.sum()
        return probabilities

```

### Rank 2 (Overall AOCC Score: 9.2919e-02 |             AOCC Score on Unimodal instances: 1.7590e-01 |             AOCC Score on Multimodal instances with a single component: 1.0285e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: LatinHypercubeAdaptiveDEArchive
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and an archive for robust multimodal optimization.
# Code:
```python
# Name: LatinHypercubeAdaptiveDEArchive
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and an archive for robust multimodal optimization.
# Code:
import numpy as np
from scipy.stats import qmc

class LatinHypercubeAdaptiveDEArchive:
    """
    Combines Latin Hypercube sampling, adaptive differential evolution, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5 #Initial scaling factor for DE
        self.CR = 0.9 #Initial crossover rate for DE

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        sampler = qmc.LatinHypercube(self.dim)
        population = sampler.random(self.population_size)
        population = population * (self.upper_bounds - self.lower_bounds) + self.lower_bounds
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(self.archive)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((self.archive, offspring)), np.concatenate((self._get_fitness_from_archive(), offspring_fitness)))
            self._adaptive_parameters()
            self._update_best(self.archive)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self, archive):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_three_different(archive)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(archive[0][0], mutant) #Using best solution from archive as target
            offspring.append(trial)
        return np.array(offspring)


    def _select_three_different(self, archive):
        indices = np.random.choice(len(archive), 3, replace=False)
        return archive[indices][:,0]

    def _crossover(self, target, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        return np.where(crosspoints, mutant, target)

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.archive_size), :-1]

    def _adaptive_parameters(self):
        # Simple adaptive strategy: Adjust F and CR based on success rate
        if len(self.archive)>10:
            success_rate = np.mean(self._get_fitness_from_archive()[10:] < self._get_fitness_from_archive()[:10])
            self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.2)))
            self.CR = max(0.0, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

    def _get_fitness_from_archive(self):
        return self.archive[:,-1]

    def _update_best(self, archive):
        best_index = np.argmin(archive[:,-1])
        if archive[best_index,-1] < self.best_fitness_overall:
            self.best_fitness_overall = archive[best_index,-1]
            self.best_solution_overall = archive[best_index, :-1]

```

### Rank 3 (Overall AOCC Score: 9.2776e-02 |             AOCC Score on Unimodal instances: 1.7584e-01 |             AOCC Score on Multimodal instances with a single component: 1.0249e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: LatinHypercubeDEwithAdaptiveScaling
# Description: Combines Latin Hypercube sampling, Differential Evolution, and adaptive scaling for robust multimodal optimization.
# Code:
```python
# Name: LatinHypercubeDEwithAdaptiveScaling
# Description: Combines Latin Hypercube sampling, Differential Evolution, and adaptive scaling for robust multimodal optimization.
# Code:
import numpy as np

class LatinHypercubeDEwithAdaptiveScaling:
    """
    Combines Latin Hypercube sampling, Differential Evolution, and adaptive scaling for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.scale_factor = 1.0 # Adaptive scaling factor
        self.scale_decay = 0.95


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = self._latin_hypercube_sampling(1)[0]
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling(self.population_size)
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_pop = np.vstack((offspring, population))
            combined_fit = np.concatenate((offspring_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self._update_best(population, fitness)
            self.scale_factor *= self.scale_decay
            self.F *= self.scale_factor # Adaptive F scaling
            self.CR *= self.scale_factor # Adaptive CR Scaling

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _latin_hypercube_sampling(self, num_samples):
        dim = self.dim
        samples = np.zeros((num_samples, dim))
        for i in range(dim):
            indices = np.random.permutation(num_samples)
            values = np.linspace(0,1, num_samples+1)
            samples[:,i] = (values[indices] + values[indices+1])/2 * (self.upper_bounds[i] - self.lower_bounds[i]) + self.lower_bounds[i]
        return samples


    def _differential_evolution(self, population, fitness):
        new_population = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                new_population[i] = trial
            else:
                new_population[i] = population[i]
        return new_population

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)

```

### Rank 4 (Overall AOCC Score: 9.2265e-02 |             AOCC Score on Unimodal instances: 1.7548e-01 |             AOCC Score on Multimodal instances with a single component: 1.0132e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: LatinHypercubeAdaptiveDEArchiveEA
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and an archive for robust multimodal optimization.
# Code:
```python
# Name: LatinHypercubeAdaptiveDEArchiveEA
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and an archive for robust multimodal optimization.
# Code:
import numpy as np
from scipy.stats import qmc

class LatinHypercubeAdaptiveDEArchiveEA:
    """
    Combines Latin Hypercube Sampling, adaptive Differential Evolution, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5 # Initial scaling factor for DE
        self.CR = 0.9 # Initial crossover rate for DE
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_different(population, i)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.archive_size), :-1]

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptation: adjust F and CR based on success rate
        success_rate = np.mean(fitness_values[:self.population_size //2] < fitness_values[self.population_size //2:])

        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate-0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 5 (Overall AOCC Score: 9.1999e-02 |             AOCC Score on Unimodal instances: 1.7528e-01 |             AOCC Score on Multimodal instances with a single component: 1.0072e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveHypercubeDifferentialEvolution
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a topological archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import cdist

# Name: AdaptiveHypercubeDifferentialEvolution
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a topological archive for multimodal optimization.
# Code:
class AdaptiveHypercubeDifferentialEvolution:
    """
    Combines Latin Hypercube sampling, adaptive differential evolution, and a topological archive for efficient multimodal optimization.  Employs an adaptive scaling factor and crossover rate to balance exploration and exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 100, archive_size: int = 200):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.5 # Initial DE scaling factor
        self.CR = 0.7 # Initial DE crossover rate
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_pop = np.vstack((offspring, population))
            combined_fit = np.concatenate((offspring_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self.archive = self._update_archive(population, fitness)
            self._update_best(population, fitness)
            self._adapt_parameters(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        samples = np.zeros((self.population_size, self.dim))
        for i in range(self.dim):
            perm = np.random.permutation(self.population_size)
            for j in range(self.population_size):
                samples[j,i] = (perm[j] + np.random.rand()) / self.population_size
        return samples * (self.upper_bounds - self.lower_bounds) + self.lower_bounds

    def _differential_evolution(self, population, fitness):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring


    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness):
        combined = np.column_stack((population, fitness))
        distances = cdist(combined[:, :-1], self.archive[:, :-1])
        min_distances = np.min(distances, axis=1)
        to_add = combined[min_distances > 1e-2]
        new_archive = np.vstack((self.archive, to_add))
        new_archive = new_archive[np.argsort(new_archive[:, -1])][:self.archive_size]
        self.archive = new_archive
        return new_archive


    def _adapt_parameters(self, population, fitness):
        avg_fitness = np.mean(fitness)
        std_fitness = np.std(fitness)
        if std_fitness < 0.1 * (self.upper_bounds - self.lower_bounds).mean():
            self.F = max(0.1, self.F * 0.9)
            self.CR = max(0.1, self.CR * 0.9)
        else:
            self.F = min(1.0, self.F * 1.1)
            self.CR = min(1.0, self.CR * 1.1)

```

### Rank 6 (Overall AOCC Score: 9.0903e-02 |             AOCC Score on Unimodal instances: 1.7320e-01 |             AOCC Score on Multimodal instances with a single component: 9.9510e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 356.2083596134695, archive_size: int = 736.0259136560289, sigma_decay: float = 0.984726852766839, initial_sigma_multiplier: float = 0.27186977091605236):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) 
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:49:43 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveMultimodalOptimizer vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveMultimodalOptimizer uses Latin Hypercube sampling for initial population generation, which is known to be more space-filling than random sampling used in AdaptiveGaussianArchiveEA.  AdaptiveMultimodalOptimizer also incorporates an adaptive mutation rate and a fitness-based archive for more efficient exploration and exploitation.  AdaptiveGaussianArchiveEA relies on simpler Gaussian mutation and tournament selection, leading to potentially less effective exploration.  

(second best) LatinHypercubeAdaptiveDEArchive vs (second worst) AdaptiveHypercubeDifferentialEvolution: LatinHypercubeAdaptiveDEArchive uses an adaptive differential evolution strategy that adjusts its parameters (F and CR) based on the success rate, making it more robust to different problem landscapes. AdaptiveHypercubeDifferentialEvolution also adapts parameters but uses a simpler approach based on fitness standard deviation, which may not be as effective. LatinHypercubeAdaptiveDEArchive's archive is more effective than AdaptiveHypercubeDifferentialEvolution’s topological archive.

Comparing (1st) AdaptiveMultimodalOptimizer vs (2nd) LatinHypercubeAdaptiveDEArchive, we see that AdaptiveMultimodalOptimizer's adaptive mutation strategy and fitness-based archive are more effective than LatinHypercubeAdaptiveDEArchive's adaptive differential evolution strategy and archive, resulting in a slight performance improvement.

(3rd) LatinHypercubeDEwithAdaptiveScaling vs (4th) LatinHypercubeAdaptiveDEArchiveEA: Both use differential evolution and Latin Hypercube sampling. LatinHypercubeDEwithAdaptiveScaling adapts its scaling factor which directly impacts the mutation strength of DE. LatinHypercubeAdaptiveDEArchiveEA uses a separate archive and adopts a more complex parameter adaptation strategy, but this does not show an advantage in performance.

Comparing (second worst) AdaptiveHypercubeDifferentialEvolution vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveHypercubeDifferentialEvolution uses a topological archive and adaptive DE, which provides better search capabilities in multimodal problems than AdaptiveGaussianArchiveEA's simple Gaussian mutation and archive. However, AdaptiveHypercubeDifferentialEvolution still underperforms significantly compared to top-ranked algorithms. Overall: The top-performing algorithms combine sophisticated initialization (Latin Hypercube Sampling), adaptive parameter control, and effective archive mechanisms.  Simple mutation strategies and less refined archive management lead to significantly worse performance.


**Experience:**

Effective population generation, adaptive parameter tuning (F, CR, mutation rate), and sophisticated archive management are crucial for high-dimensional multimodal optimization.  Adaptive mechanisms that dynamically adjust exploration/exploitation balance improve robustness and efficiency across diverse problem landscapes.

2025-06-23 09:49:45 INFO Full response text: **Keywords:**  Adaptive operators,  High-dimensional multimodal optimization,  Exploration-exploitation balance,  Diversity preservation.

**Advice:** Focus on designing operators that dynamically adjust based on *actual* performance feedback (not pre-defined rules). Explore novel archive management techniques beyond simple storing; consider mechanisms that prioritize and utilize archived solutions intelligently.  Quantify exploration/exploitation trade-off for adaptive control.

**Avoid:**  Generic statements about diversity and exploration/exploitation.  Avoid pre-conceived notions of "best" operators (e.g., DE or Gaussian). Don't rely on heuristics based on problem dimensionality alone.

**Explanation:**  The ineffective reflection relies on known good practices.  To design better heuristics, we need to move beyond established methods and focus on dynamically adapting based on runtime data and learning from the optimization process itself.  This requires a principled approach to quantifying and controlling the exploration/exploitation trade-off and developing innovative archive management strategies.  The goal is a self-improving optimizer.

2025-06-23 09:49:45 INFO Generating offspring via Crossover...
2025-06-23 09:51:14 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveHypercubeDifferentialEvolution
import numpy as np
from scipy.spatial.distance import cdist

# Name: AdaptiveHypercubeDifferentialEvolution
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a topological archive for multimodal optimization.
# Code:
class AdaptiveHypercubeDifferentialEvolution:
    """
    Combines Latin Hypercube sampling, adaptive differential evolution, and a topological archive for efficient multimodal optimization.  Employs an adaptive scaling factor and crossover rate to balance exploration and exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 100, archive_size: int = 200):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.5 # Initial DE scaling factor
        self.CR = 0.7 # Initial DE crossover rate
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_pop = np.vstack((offspring, population))
            combined_fit = np.concatenate((offspring_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self.archive = self._update_archive(population, fitness)
            self._update_best(population, fitness)
            self._adapt_parameters(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        samples = np.zeros((self.population_size, self.dim))
        for i in range(self.dim):
            perm = np.random.permutation(self.population_size)
            for j in range(self.population_size):
                samples[j,i] = (perm[j] + np.random.rand()) / self.population_size
        return samples * (self.upper_bounds - self.lower_bounds) + self.lower_bounds

    def _differential_evolution(self, population, fitness):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring


    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness):
        combined = np.column_stack((population, fitness))
        distances = cdist(combined[:, :-1], self.archive[:, :-1])
        min_distances = np.min(distances, axis=1)
        to_add = combined[min_distances > 1e-2]
        new_archive = np.vstack((self.archive, to_add))
        new_archive = new_archive[np.argsort(new_archive[:, -1])][:self.archive_size]
        self.archive = new_archive
        return new_archive


    def _adapt_parameters(self, population, fitness):
        avg_fitness = np.mean(fitness)
        std_fitness = np.std(fitness)
        if std_fitness < 0.1 * (self.upper_bounds - self.lower_bounds).mean():
            self.F = max(0.1, self.F * 0.9)
            self.CR = max(0.1, self.CR * 0.9)
        else:
            self.F = min(1.0, self.F * 1.1)
            self.CR = min(1.0, self.CR * 1.1)


### Worse code
LatinHypercubeAdaptiveDEArchive
# Name: LatinHypercubeAdaptiveDEArchive
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and an archive for robust multimodal optimization.
# Code:
import numpy as np
from scipy.stats import qmc

class LatinHypercubeAdaptiveDEArchive:
    """
    Combines Latin Hypercube sampling, adaptive differential evolution, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5 #Initial scaling factor for DE
        self.CR = 0.9 #Initial crossover rate for DE

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        sampler = qmc.LatinHypercube(self.dim)
        population = sampler.random(self.population_size)
        population = population * (self.upper_bounds - self.lower_bounds) + self.lower_bounds
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(self.archive)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((self.archive, offspring)), np.concatenate((self._get_fitness_from_archive(), offspring_fitness)))
            self._adaptive_parameters()
            self._update_best(self.archive)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self, archive):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_three_different(archive)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(archive[0][0], mutant) #Using best solution from archive as target
            offspring.append(trial)
        return np.array(offspring)


    def _select_three_different(self, archive):
        indices = np.random.choice(len(archive), 3, replace=False)
        return archive[indices][:,0]

    def _crossover(self, target, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        return np.where(crosspoints, mutant, target)

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.archive_size), :-1]

    def _adaptive_parameters(self):
        # Simple adaptive strategy: Adjust F and CR based on success rate
        if len(self.archive)>10:
            success_rate = np.mean(self._get_fitness_from_archive()[10:] < self._get_fitness_from_archive()[:10])
            self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.2)))
            self.CR = max(0.0, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

    def _get_fitness_from_archive(self):
        return self.archive[:,-1]

    def _update_best(self, archive):
        best_index = np.argmin(archive[:,-1])
        if archive[best_index,-1] < self.best_fitness_overall:
            self.best_fitness_overall = archive[best_index,-1]
            self.best_solution_overall = archive[best_index, :-1]


### Analyze & experience
- Comparing (best) AdaptiveMultimodalOptimizer vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveMultimodalOptimizer uses Latin Hypercube sampling for initial population generation, which is known to be more space-filling than random sampling used in AdaptiveGaussianArchiveEA.  AdaptiveMultimodalOptimizer also incorporates an adaptive mutation rate and a fitness-based archive for more efficient exploration and exploitation.  AdaptiveGaussianArchiveEA relies on simpler Gaussian mutation and tournament selection, leading to potentially less effective exploration.  

(second best) LatinHypercubeAdaptiveDEArchive vs (second worst) AdaptiveHypercubeDifferentialEvolution: LatinHypercubeAdaptiveDEArchive uses an adaptive differential evolution strategy that adjusts its parameters (F and CR) based on the success rate, making it more robust to different problem landscapes. AdaptiveHypercubeDifferentialEvolution also adapts parameters but uses a simpler approach based on fitness standard deviation, which may not be as effective. LatinHypercubeAdaptiveDEArchive's archive is more effective than AdaptiveHypercubeDifferentialEvolution’s topological archive.

Comparing (1st) AdaptiveMultimodalOptimizer vs (2nd) LatinHypercubeAdaptiveDEArchive, we see that AdaptiveMultimodalOptimizer's adaptive mutation strategy and fitness-based archive are more effective than LatinHypercubeAdaptiveDEArchive's adaptive differential evolution strategy and archive, resulting in a slight performance improvement.

(3rd) LatinHypercubeDEwithAdaptiveScaling vs (4th) LatinHypercubeAdaptiveDEArchiveEA: Both use differential evolution and Latin Hypercube sampling. LatinHypercubeDEwithAdaptiveScaling adapts its scaling factor which directly impacts the mutation strength of DE. LatinHypercubeAdaptiveDEArchiveEA uses a separate archive and adopts a more complex parameter adaptation strategy, but this does not show an advantage in performance.

Comparing (second worst) AdaptiveHypercubeDifferentialEvolution vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveHypercubeDifferentialEvolution uses a topological archive and adaptive DE, which provides better search capabilities in multimodal problems than AdaptiveGaussianArchiveEA's simple Gaussian mutation and archive. However, AdaptiveHypercubeDifferentialEvolution still underperforms significantly compared to top-ranked algorithms. Overall: The top-performing algorithms combine sophisticated initialization (Latin Hypercube Sampling), adaptive parameter control, and effective archive mechanisms.  Simple mutation strategies and less refined archive management lead to significantly worse performance.
- **Keywords:**  Adaptive operators,  High-dimensional multimodal optimization,  Exploration-exploitation balance,  Diversity preservation.

**Advice:** Focus on designing operators that dynamically adjust based on *actual* performance feedback (not pre-defined rules). Explore novel archive management techniques beyond simple storing; consider mechanisms that prioritize and utilize archived solutions intelligently.  Quantify exploration/exploitation trade-off for adaptive control.

**Avoid:**  Generic statements about diversity and exploration/exploitation.  Avoid pre-conceived notions of "best" operators (e.g., DE or Gaussian). Don't rely on heuristics based on problem dimensionality alone.

**Explanation:**  The ineffective reflection relies on known good practices.  To design better heuristics, we need to move beyond established methods and focus on dynamically adapting based on runtime data and learning from the optimization process itself.  This requires a principled approach to quantifying and controlling the exploration/exploitation trade-off and developing innovative archive management strategies.  The goal is a self-improving optimizer.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:51:14 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Adaptive operators,  High-dimensional multimodal optimization,  Exploration-exploitation balance,  Diversity preservation.

**Advice:** Focus on designing operators that dynamically adjust based on *actual* performance feedback (not pre-defined rules). Explore novel archive management techniques beyond simple storing; consider mechanisms that prioritize and utilize archived solutions intelligently.  Quantify exploration/exploitation trade-off for adaptive control.

**Avoid:**  Generic statements about diversity and exploration/exploitation.  Avoid pre-conceived notions of "best" operators (e.g., DE or Gaussian). Don't rely on heuristics based on problem dimensionality alone.

**Explanation:**  The ineffective reflection relies on known good practices.  To design better heuristics, we need to move beyond established methods and focus on dynamically adapting based on runtime data and learning from the optimization process itself.  This requires a principled approach to quantifying and controlling the exploration/exploitation trade-off and developing innovative archive management strategies.  The goal is a self-improving optimizer.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 09:58:36 INFO Perform Harmony Search...
2025-06-23 09:58:47 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:47 ERROR Can not run the algorithm
2025-06-23 09:58:47 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1734
2025-06-23 09:58:47 INFO FeHistory: [-701.28776585]
2025-06-23 09:58:47 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:47 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 688.3261422657287, archive_size: int = 862.6791851450579, sigma_decay: float = 0.9849807134405116, sigma_init_factor: float = 0.253066528854806):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:47 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:47 ERROR Can not run the algorithm
2025-06-23 09:58:47 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0899
2025-06-23 09:58:47 INFO FeHistory: [-221.6673048]
2025-06-23 09:58:47 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:47 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:47 ERROR Can not run the algorithm
2025-06-23 09:58:47 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:47 INFO FeHistory: [184.04783802]
2025-06-23 09:58:47 INFO Expected Optimum FE: -100
2025-06-23 09:58:47 INFO Unimodal AOCC mean: 0.1734
2025-06-23 09:58:47 INFO Multimodal (single component) AOCC mean: 0.0899
2025-06-23 09:58:47 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:47 INFO AOCC mean: 0.0878
2025-06-23 09:58:47 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:47 ERROR Can not run the algorithm
2025-06-23 09:58:48 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 09:58:48 INFO FeHistory: [-701.3102579]
2025-06-23 09:58:48 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:48 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 243.5247372599474, archive_size: int = 93.55794234685045, sigma_decay: float = 0.9540987109514827, sigma_init_factor: float = 0.7348564612213918):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:48 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:48 ERROR Can not run the algorithm
2025-06-23 09:58:48 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0915
2025-06-23 09:58:48 INFO FeHistory: [-222.12178915]
2025-06-23 09:58:48 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:48 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:48 ERROR Can not run the algorithm
2025-06-23 09:58:48 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:48 INFO FeHistory: [203.506252]
2025-06-23 09:58:48 INFO Expected Optimum FE: -100
2025-06-23 09:58:48 INFO Unimodal AOCC mean: 0.1739
2025-06-23 09:58:48 INFO Multimodal (single component) AOCC mean: 0.0915
2025-06-23 09:58:48 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:48 INFO AOCC mean: 0.0885
2025-06-23 09:58:48 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:48 ERROR Can not run the algorithm
2025-06-23 09:58:48 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 09:58:48 INFO FeHistory: [-701.32385266]
2025-06-23 09:58:48 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:48 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 284.63536341333463, archive_size: int = 902.4403501118047, sigma_decay: float = 0.9692550534442268, sigma_init_factor: float = 0.5720778089616718):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:48 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:48 ERROR Can not run the algorithm
2025-06-23 09:58:48 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0842
2025-06-23 09:58:48 INFO FeHistory: [-219.89229758]
2025-06-23 09:58:48 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:48 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:48 ERROR Can not run the algorithm
2025-06-23 09:58:48 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:48 INFO FeHistory: [173.63066742]
2025-06-23 09:58:48 INFO Expected Optimum FE: -100
2025-06-23 09:58:48 INFO Unimodal AOCC mean: 0.1743
2025-06-23 09:58:48 INFO Multimodal (single component) AOCC mean: 0.0842
2025-06-23 09:58:48 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:48 INFO AOCC mean: 0.0862
2025-06-23 09:58:48 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:48 ERROR Can not run the algorithm
2025-06-23 09:58:49 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 09:58:49 INFO FeHistory: [-701.29502561]
2025-06-23 09:58:49 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:49 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 882.8204646833894, archive_size: int = 246.43128245435886, sigma_decay: float = 0.919354306430214, sigma_init_factor: float = 0.6412044687930071):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:49 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:49 ERROR Can not run the algorithm
2025-06-23 09:58:49 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0865
2025-06-23 09:58:49 INFO FeHistory: [-220.62886024]
2025-06-23 09:58:49 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:49 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:49 ERROR Can not run the algorithm
2025-06-23 09:58:49 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:49 INFO FeHistory: [192.23125979]
2025-06-23 09:58:49 INFO Expected Optimum FE: -100
2025-06-23 09:58:49 INFO Unimodal AOCC mean: 0.1736
2025-06-23 09:58:49 INFO Multimodal (single component) AOCC mean: 0.0865
2025-06-23 09:58:49 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:49 INFO AOCC mean: 0.0867
2025-06-23 09:58:49 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:49 ERROR Can not run the algorithm
2025-06-23 09:58:49 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1740
2025-06-23 09:58:49 INFO FeHistory: [-701.31145874]
2025-06-23 09:58:49 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:49 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 994.4077321507206, archive_size: int = 750.9818288082585, sigma_decay: float = 0.9574199258877505, sigma_init_factor: float = 0.2431957472328996):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:49 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:49 ERROR Can not run the algorithm
2025-06-23 09:58:49 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0908
2025-06-23 09:58:49 INFO FeHistory: [-221.91532566]
2025-06-23 09:58:49 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:49 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:49 ERROR Can not run the algorithm
2025-06-23 09:58:49 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:49 INFO FeHistory: [183.22438894]
2025-06-23 09:58:49 INFO Expected Optimum FE: -100
2025-06-23 09:58:49 INFO Unimodal AOCC mean: 0.1740
2025-06-23 09:58:49 INFO Multimodal (single component) AOCC mean: 0.0908
2025-06-23 09:58:49 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:49 INFO AOCC mean: 0.0882
2025-06-23 09:58:50 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:50 ERROR Can not run the algorithm
2025-06-23 09:58:50 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1741
2025-06-23 09:58:50 INFO FeHistory: [-701.31780156]
2025-06-23 09:58:50 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:50 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 119.15732917195035, archive_size: int = 750.9818288082585, sigma_decay: float = 0.9964808951852252, sigma_init_factor: float = 0.9877239063898084):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:50 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:50 ERROR Can not run the algorithm
2025-06-23 09:58:50 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0969
2025-06-23 09:58:50 INFO FeHistory: [-223.54390381]
2025-06-23 09:58:50 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:50 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:50 ERROR Can not run the algorithm
2025-06-23 09:58:50 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:50 INFO FeHistory: [224.09652242]
2025-06-23 09:58:50 INFO Expected Optimum FE: -100
2025-06-23 09:58:50 INFO Unimodal AOCC mean: 0.1741
2025-06-23 09:58:50 INFO Multimodal (single component) AOCC mean: 0.0969
2025-06-23 09:58:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:50 INFO AOCC mean: 0.0903
2025-06-23 09:58:50 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:50 ERROR Can not run the algorithm
2025-06-23 09:58:50 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 09:58:50 INFO FeHistory: [-701.32623591]
2025-06-23 09:58:50 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:50 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 689.1133001824008, archive_size: int = 386.9958413258255, sigma_decay: float = 0.9809146567601505, sigma_init_factor: float = 0.22652180401779187):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:50 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:50 ERROR Can not run the algorithm
2025-06-23 09:58:50 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0922
2025-06-23 09:58:50 INFO FeHistory: [-222.30055285]
2025-06-23 09:58:50 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:50 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:50 ERROR Can not run the algorithm
2025-06-23 09:58:51 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:51 INFO FeHistory: [236.54657893]
2025-06-23 09:58:51 INFO Expected Optimum FE: -100
2025-06-23 09:58:51 INFO Unimodal AOCC mean: 0.1743
2025-06-23 09:58:51 INFO Multimodal (single component) AOCC mean: 0.0922
2025-06-23 09:58:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:51 INFO AOCC mean: 0.0888
2025-06-23 09:58:51 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:51 ERROR Can not run the algorithm
2025-06-23 09:58:51 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1740
2025-06-23 09:58:51 INFO FeHistory: [-701.31334742]
2025-06-23 09:58:51 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:51 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 688.3261422657287, archive_size: int = 750.9818288082585, sigma_decay: float = 0.9190819357598001, sigma_init_factor: float = 0.7772959960784775):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:51 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:51 ERROR Can not run the algorithm
2025-06-23 09:58:51 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0873
2025-06-23 09:58:51 INFO FeHistory: [-220.89325395]
2025-06-23 09:58:51 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:51 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:51 ERROR Can not run the algorithm
2025-06-23 09:58:51 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:51 INFO FeHistory: [197.45423801]
2025-06-23 09:58:51 INFO Expected Optimum FE: -100
2025-06-23 09:58:51 INFO Unimodal AOCC mean: 0.1740
2025-06-23 09:58:51 INFO Multimodal (single component) AOCC mean: 0.0873
2025-06-23 09:58:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:51 INFO AOCC mean: 0.0871
2025-06-23 09:58:51 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:51 ERROR Can not run the algorithm
2025-06-23 09:58:51 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 09:58:51 INFO FeHistory: [-701.29812897]
2025-06-23 09:58:51 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:51 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 689.1133001824008, archive_size: int = 922.8080393916736, sigma_decay: float = 1.0011897077334413, sigma_init_factor: float = 0.3949335317827781):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:51 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:51 ERROR Can not run the algorithm
2025-06-23 09:58:51 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0877
2025-06-23 09:58:51 INFO FeHistory: [-221.00880928]
2025-06-23 09:58:51 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:51 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:51 ERROR Can not run the algorithm
2025-06-23 09:58:52 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:52 INFO FeHistory: [195.79097404]
2025-06-23 09:58:52 INFO Expected Optimum FE: -100
2025-06-23 09:58:52 INFO Unimodal AOCC mean: 0.1736
2025-06-23 09:58:52 INFO Multimodal (single component) AOCC mean: 0.0877
2025-06-23 09:58:52 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:52 INFO AOCC mean: 0.0871
2025-06-23 09:58:52 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:58:52 ERROR Can not run the algorithm
2025-06-23 09:58:52 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 09:58:52 INFO FeHistory: [-701.29259034]
2025-06-23 09:58:52 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:58:52 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 208.58721958269817, archive_size: int = 750.9818288082585, sigma_decay: float = 0.9849807134405116, sigma_init_factor: float = 0.09002580592869891):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 09:58:52 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:58:52 ERROR Can not run the algorithm
2025-06-23 09:58:52 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0929
2025-06-23 09:58:52 INFO FeHistory: [-222.49766858]
2025-06-23 09:58:52 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:58:52 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:58:52 ERROR Can not run the algorithm
2025-06-23 09:58:52 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 09:58:52 INFO FeHistory: [215.42107544]
2025-06-23 09:58:52 INFO Expected Optimum FE: -100
2025-06-23 09:58:52 INFO Unimodal AOCC mean: 0.1735
2025-06-23 09:58:52 INFO Multimodal (single component) AOCC mean: 0.0929
2025-06-23 09:58:52 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:58:52 INFO AOCC mean: 0.0888
2025-06-23 09:58:52 INFO Generation 3, best so far: 0.14294861551599297
2025-06-23 09:58:52 INFO Population length is: 7
2025-06-23 09:58:52 INFO --- Performing Long-Term Reflection at Generation 4 ---
2025-06-23 09:58:52 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.4470e-02 |             AOCC Score on Unimodal instances: 1.7590e-01 |             AOCC Score on Multimodal instances with a single component: 1.0751e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: LatinHypercubeAdaptiveDEArchiveEA_Improved
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a fitness-based archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: LatinHypercubeAdaptiveDEArchiveEA_Improved
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a fitness-based archive for robust multimodal optimization.
# Code:
class LatinHypercubeAdaptiveDEArchiveEA_Improved:
    """
    Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a fitness-based archive for robust multimodal optimization.  Improves upon previous versions by incorporating a more sophisticated archive management and adaptive parameter control.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # Initial scaling factor for DE
        self.CR = 0.9  # Initial crossover rate for DE
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.archive_diversity_threshold = 0.1 #threshold for archive diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_different(population, i)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        #Maintain archive diversity: remove similar solutions
        self._maintain_archive_diversity(sorted_data)
        return sorted_data[:min(len(sorted_data), self.archive_size), :-1]

    def _maintain_archive_diversity(self, sorted_data):
      if len(sorted_data) > self.archive_size:
        #Simple diversity maintenance: remove solutions that are too close to existing ones.
        archive = sorted_data[:self.archive_size,:-1]
        to_remove = []
        for i in range(self.archive_size, len(sorted_data)):
          for j in range(len(archive)):
            if np.linalg.norm(sorted_data[i,:-1] - archive[j]) < self.archive_diversity_threshold:
              to_remove.append(i)
              break
        sorted_data = np.delete(sorted_data, to_remove, axis = 0)

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        # Adaptive parameter control based on success rate and archive diversity
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        archive_diversity = np.mean(np.linalg.norm(self.archive[1:] - self.archive[:-1], axis=1)) if len(self.archive) > 1 else 0
        
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5) + 0.05 * (self.archive_diversity_threshold - archive_diversity)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))


def objective_function(X):
    #Example objective function (replace with your actual benchmark functions)
    return np.sum(X**2, axis=1)


```

### Rank 2 (Overall AOCC Score: 9.3951e-02 |             AOCC Score on Unimodal instances: 1.7558e-01 |             AOCC Score on Multimodal instances with a single component: 1.0627e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: LatinHypercubeAdaptiveDEArchiveEA_Improved
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a dynamic archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: LatinHypercubeAdaptiveDEArchiveEA_Improved
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a dynamic archive for robust multimodal optimization.
# Code:
class LatinHypercubeAdaptiveDEArchiveEA_Improved:
    """
    Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a dynamic archive for robust multimodal optimization.  Improves upon previous versions by dynamically managing archive size and adaptively adjusting DE parameters based on exploration/exploitation balance.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.max_archive_size = 200  # Maximum archive size
        self.F = 0.5  # Initial scaling factor for DE
        self.CR = 0.9  # Initial crossover rate for DE
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.exploration_rate = 0.8 # Initial exploration rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate: #Exploration vs. Exploitation
                a, b, c = self._select_different_archive(population,i) #Explore archive
            else:
                a, b, c = self._select_different(population, i) #Exploit current population
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_different_archive(self,population,i):
        indices = np.random.choice(len(self.archive),3,replace=False)
        return self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]


    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.max_archive_size), :-1]

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        #Monitor the diversity of the population. Lower diversity indicates a need for more exploration.
        diversity = np.std(population, axis=0).mean()
        if diversity < 0.2 * (self.upper_bounds.mean()- self.lower_bounds.mean()): #Threshold for low diversity
            self.exploration_rate = min(1,self.exploration_rate + 0.05) #Increase exploration
        else:
            self.exploration_rate = max(0.1,self.exploration_rate - 0.05) #Decrease exploration

        #Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size //2] < fitness_values[self.population_size //2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate-0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))



def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)
```

### Rank 3 (Overall AOCC Score: 9.2436e-02 |             AOCC Score on Unimodal instances: 1.7507e-01 |             AOCC Score on Multimodal instances with a single component: 1.0224e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: LatinHypercubeDEwithAdaptiveArchive
# Description: Combines Latin Hypercube sampling, Differential Evolution, and an adaptive archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: LatinHypercubeDEwithAdaptiveArchive
# Description: Combines Latin Hypercube sampling, Differential Evolution, and an adaptive archive for robust multimodal optimization.
# Code:
class LatinHypercubeDEwithAdaptiveArchive:
    """
    Combines Latin Hypercube sampling, Differential Evolution, and an adaptive archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.scale_factor = 1.0  # Adaptive scaling factor
        self.scale_decay = 0.95
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            initial_sample = self.sampler.random(n=1)
            self.best_solution_overall = self._scale_sample(initial_sample)[0]
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling(self.population_size)
        fitness = objective_function(population)
        self.eval_count += self.population_size
        
        self.archive = self._update_archive(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_pop = np.vstack((offspring, population))
            combined_fit = np.concatenate((offspring_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self._update_best(population, fitness)
            self.scale_factor *= self.scale_decay
            self.F *= self.scale_factor  # Adaptive F scaling
            self.CR *= self.scale_factor  # Adaptive CR Scaling
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness, offspring_fitness)))

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _latin_hypercube_sampling(self, num_samples):
        sample = self.sampler.random(n=num_samples)
        return self._scale_sample(sample)

    def _scale_sample(self, sample):
        return sample * (self.upper_bounds - self.lower_bounds) + self.lower_bounds

    def _differential_evolution(self, population, fitness):
        new_population = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                new_population[i] = trial
            else:
                new_population[i] = population[i]
        return new_population

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Prioritize adding solutions near the best found solution
        distances_to_best = np.linalg.norm(population - self.best_solution_overall, axis=1)
        combined = combined[np.argsort(distances_to_best)]
        
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

def objective_function(x):  #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)

```

### Rank 4 (Overall AOCC Score: 9.2383e-02 |             AOCC Score on Unimodal instances: 1.7521e-01 |             AOCC Score on Multimodal instances with a single component: 1.0194e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLatinHypercubeDifferentialEvolutionArchive
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: AdaptiveLatinHypercubeDifferentialEvolutionArchive
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for robust multimodal optimization.
# Code:
class AdaptiveLatinHypercubeDifferentialEvolutionArchive:
    """
    Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for robust multimodal optimization.  Adapts DE parameters (F, CR) based on archive performance.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size:int=100, archive_size:int=200):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.5  # Initial DE scaling factor
        self.CR = 0.9  # Initial DE crossover rate
        self.archive = np.empty((0, dim + 1)) # Initialize empty archive

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        # Initialize population using Latin Hypercube Sampling
        sampler = qmc.LatinHypercube(self.dim)
        population = sampler.random(self.population_size)
        population = population * (self.upper_bounds - self.lower_bounds) + self.lower_bounds
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(self.archive)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((self.archive[:, :-1], offspring)), np.concatenate((self.archive[:, -1], offspring_fitness)))
            self._adapt_parameters()
            self._update_best(self.archive)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self, archive):
        offspring = []
        for _ in range(self.population_size):
            a, b, c = self._select_three_different(archive)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(archive[0, :-1], mutant) #Using best solution from archive as target
            offspring.append(trial)
        return np.array(offspring)

    def _select_three_different(self, archive):
        indices = np.random.choice(len(archive), 3, replace=False)
        return archive[indices, :-1]

    def _crossover(self, target, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        return np.where(crosspoints, mutant, target)

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.archive_size)]

    def _adapt_parameters(self):
        if len(self.archive) > 10:
            success_rate = np.mean(self.archive[10:, -1] < self.archive[:10, -1])
            self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.2)))
            self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

    def _update_best(self, archive):
        best_index = np.argmin(archive[:, -1])
        if archive[best_index, -1] < self.best_fitness_overall:
            self.best_fitness_overall = archive[best_index, -1]
            self.best_solution_overall = archive[best_index, :-1]

```

### Rank 5 (Overall AOCC Score: 9.2224e-02 |             AOCC Score on Unimodal instances: 1.7545e-01 |             AOCC Score on Multimodal instances with a single component: 1.0123e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLatinHypercubeDE
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: AdaptiveLatinHypercubeDE
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for multimodal optimization.
# Code:
class AdaptiveLatinHypercubeDE:
    """
    Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 100, archive_size: int = 200):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.population_size = population_size
        self.archive_size = archive_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.5  # Initial DE scaling factor
        self.CR = 0.9  # Initial DE crossover rate
        self.archive = []
        self.archive_capacity = archive_size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness, offspring_fitness)))
            
            # Selection: Prioritize archive solutions
            selected_indices = np.random.choice(len(self.archive), size=self.population_size, replace=False, p=self._get_selection_probabilities())
            population = np.array([self.archive[i][:-1] for i in selected_indices])
            fitness = np.array([self.archive[i][-1] for i in selected_indices])

            self._update_best(population, fitness)
            self._adapt_parameters(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            offspring[i] = trial
        return offspring

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness):
        combined = np.column_stack((population, fitness))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])  # Sort by fitness
        self.archive = np.array(new_archive[:self.archive_capacity])
        return self.archive

    def _get_selection_probabilities(self):
        min_fitness = self.archive[:, -1].min()
        max_fitness = self.archive[:, -1].max()
        if max_fitness == min_fitness:
            return np.ones(len(self.archive)) / len(self.archive)
        fitness_diffs = max_fitness - self.archive[:, -1]
        probabilities = fitness_diffs / fitness_diffs.sum()
        return probabilities


    def _adapt_parameters(self, population, fitness):
        #Adapt F and CR based on success rate in DE
        success_rate = np.mean(fitness < objective_function(population))
        if success_rate < 0.2:
            self.F *= 0.9
            self.CR *= 0.9
        elif success_rate > 0.8:
            self.F *= 1.1
            self.CR *= 1.1

        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
```

### Rank 6 (Overall AOCC Score: 9.0342e-02 |             AOCC Score on Unimodal instances: 1.7411e-01 |             AOCC Score on Multimodal instances with a single component: 9.6914e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 119.15732917195035, archive_size: int = 750.9818288082585, sigma_decay: float = 0.9964808951852252, sigma_init_factor: float = 0.9877239063898084):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:58:57 INFO Full response text: **Analysis:**

Comparing (best) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 1) vs (worst) `AdaptiveGaussianArchiveEA` (Rank 6), we see the former uses more sophisticated DE and archive management, including adaptive parameter control and archive diversity maintenance, resulting in significantly better performance across unimodal and multimodal functions. The latter relies on simpler Gaussian mutation and tournament selection, lacking the adaptive mechanisms and robust exploration/exploitation balance of the top-ranked algorithm.

(second best) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 2) vs (second worst) `AdaptiveLatinHypercubeDE` (Rank 5): Both utilize Latin Hypercube sampling and DE, but Rank 2 incorporates dynamic archive size and exploration/exploitation control, which improves performance on multimodal problems. Rank 5 has a simpler adaptive mechanism based only on success rate, resulting in less efficient exploration.

Comparing (1st) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 1) vs (2nd) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 2), we see that the minor difference lies in the archive management. The first has a more robust archive diversity handling which is more effective overall.

(3rd) `LatinHypercubeDEwithAdaptiveArchive` (Rank 3) vs (4th) `AdaptiveLatinHypercubeDifferentialEvolutionArchive` (Rank 4):  Rank 3 uses a more comprehensive adaptive scaling strategy that adjusts both the scaling factor (F) and crossover rate (CR) in DE, and its archive management prioritizes solutions near the best found solutions. Rank 4 only adapts parameters based on archive performance and the selection of DE parents relies only on the archive.


Comparing (second worst) `AdaptiveLatinHypercubeDE` (Rank 5) vs (worst) `AdaptiveGaussianArchiveEA` (Rank 6), we see Rank 5 uses DE which is more effective than the simple Gaussian mutation in Rank 6. Rank 5's adaptive mechanism, though simpler than Rank 1 and 2, still provides better adaptation than Rank 6's fixed sigma decay.


Overall: The best-performing algorithms consistently leverage sophisticated adaptive mechanisms in both differential evolution and archive management, emphasizing archive diversity to escape local optima and efficiently explore high-dimensional spaces. Simpler methods struggle in these aspects, particularly on challenging multimodal problems.


**Experience:**

The key to designing better heuristics lies in combining robust sampling methods (like Latin Hypercube) with powerful adaptive optimization algorithms (e.g., improved Differential Evolution) and sophisticated archive management strategies that prioritize diversity while maintaining exploration-exploitation balance.  Adaptive parameter control based on multiple factors (success rate, diversity) is crucial.

2025-06-23 09:58:59 INFO Full response text: * **Keywords:**  Latin Hypercube Sampling, Adaptive Differential Evolution, Archive Diversity, Exploration-Exploitation Balance, Adaptive Parameter Control.

* **Advice:** Focus on robust sampling (Latin Hypercube) to ensure good initial coverage of the search space.  Prioritize adaptive algorithms (like improved DE) that dynamically adjust parameters based on multiple performance metrics (not just one, like success rate). Design archive management to actively maintain diversity and prevent premature convergence.  Carefully balance exploration and exploitation dynamically.

* **Avoid:**  Vague terms like "effective population generation" and "sophisticated archive management." Avoid simply restating the need for exploration/exploitation balance without specifying mechanisms.  Don't focus on generic adaptive parameter tuning without specifying the *factors* driving the adaptation.

* **Explanation:** The ineffective reflections are too general.  The revised approach provides concrete, actionable steps towards better heuristics by specifying precise methods and emphasizing the importance of multiple, dynamically adjusted control parameters based on measurable factors (e.g., success rate, diversity metrics within the archive).  This promotes a more rigorous and less subjective approach to heuristic design.

2025-06-23 09:58:59 INFO Generating offspring via Crossover...
2025-06-23 10:03:54 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveLatinHypercubeDE
import numpy as np
from scipy.stats import qmc

# Name: AdaptiveLatinHypercubeDE
# Description: Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for multimodal optimization.
# Code:
class AdaptiveLatinHypercubeDE:
    """
    Combines Latin Hypercube sampling, adaptive differential evolution, and a fitness-based archive for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 100, archive_size: int = 200):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.population_size = population_size
        self.archive_size = archive_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.5  # Initial DE scaling factor
        self.CR = 0.9  # Initial DE crossover rate
        self.archive = []
        self.archive_capacity = archive_size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness, offspring_fitness)))
            
            # Selection: Prioritize archive solutions
            selected_indices = np.random.choice(len(self.archive), size=self.population_size, replace=False, p=self._get_selection_probabilities())
            population = np.array([self.archive[i][:-1] for i in selected_indices])
            fitness = np.array([self.archive[i][-1] for i in selected_indices])

            self._update_best(population, fitness)
            self._adapt_parameters(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            offspring[i] = trial
        return offspring

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness):
        combined = np.column_stack((population, fitness))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])  # Sort by fitness
        self.archive = np.array(new_archive[:self.archive_capacity])
        return self.archive

    def _get_selection_probabilities(self):
        min_fitness = self.archive[:, -1].min()
        max_fitness = self.archive[:, -1].max()
        if max_fitness == min_fitness:
            return np.ones(len(self.archive)) / len(self.archive)
        fitness_diffs = max_fitness - self.archive[:, -1]
        probabilities = fitness_diffs / fitness_diffs.sum()
        return probabilities


    def _adapt_parameters(self, population, fitness):
        #Adapt F and CR based on success rate in DE
        success_rate = np.mean(fitness < objective_function(population))
        if success_rate < 0.2:
            self.F *= 0.9
            self.CR *= 0.9
        elif success_rate > 0.8:
            self.F *= 1.1
            self.CR *= 1.1

        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)

### Worse code
LatinHypercubeDEwithAdaptiveArchive
import numpy as np
from scipy.stats import qmc

# Name: LatinHypercubeDEwithAdaptiveArchive
# Description: Combines Latin Hypercube sampling, Differential Evolution, and an adaptive archive for robust multimodal optimization.
# Code:
class LatinHypercubeDEwithAdaptiveArchive:
    """
    Combines Latin Hypercube sampling, Differential Evolution, and an adaptive archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.scale_factor = 1.0  # Adaptive scaling factor
        self.scale_decay = 0.95
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            initial_sample = self.sampler.random(n=1)
            self.best_solution_overall = self._scale_sample(initial_sample)[0]
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling(self.population_size)
        fitness = objective_function(population)
        self.eval_count += self.population_size
        
        self.archive = self._update_archive(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_pop = np.vstack((offspring, population))
            combined_fit = np.concatenate((offspring_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self._update_best(population, fitness)
            self.scale_factor *= self.scale_decay
            self.F *= self.scale_factor  # Adaptive F scaling
            self.CR *= self.scale_factor  # Adaptive CR Scaling
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness, offspring_fitness)))

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _latin_hypercube_sampling(self, num_samples):
        sample = self.sampler.random(n=num_samples)
        return self._scale_sample(sample)

    def _scale_sample(self, sample):
        return sample * (self.upper_bounds - self.lower_bounds) + self.lower_bounds

    def _differential_evolution(self, population, fitness):
        new_population = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                new_population[i] = trial
            else:
                new_population[i] = population[i]
        return new_population

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Prioritize adding solutions near the best found solution
        distances_to_best = np.linalg.norm(population - self.best_solution_overall, axis=1)
        combined = combined[np.argsort(distances_to_best)]
        
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

def objective_function(x):  #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)


### Analyze & experience
- Comparing (best) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 1) vs (worst) `AdaptiveGaussianArchiveEA` (Rank 6), we see the former uses more sophisticated DE and archive management, including adaptive parameter control and archive diversity maintenance, resulting in significantly better performance across unimodal and multimodal functions. The latter relies on simpler Gaussian mutation and tournament selection, lacking the adaptive mechanisms and robust exploration/exploitation balance of the top-ranked algorithm.

(second best) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 2) vs (second worst) `AdaptiveLatinHypercubeDE` (Rank 5): Both utilize Latin Hypercube sampling and DE, but Rank 2 incorporates dynamic archive size and exploration/exploitation control, which improves performance on multimodal problems. Rank 5 has a simpler adaptive mechanism based only on success rate, resulting in less efficient exploration.

Comparing (1st) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 1) vs (2nd) `LatinHypercubeAdaptiveDEArchiveEA_Improved` (Rank 2), we see that the minor difference lies in the archive management. The first has a more robust archive diversity handling which is more effective overall.

(3rd) `LatinHypercubeDEwithAdaptiveArchive` (Rank 3) vs (4th) `AdaptiveLatinHypercubeDifferentialEvolutionArchive` (Rank 4):  Rank 3 uses a more comprehensive adaptive scaling strategy that adjusts both the scaling factor (F) and crossover rate (CR) in DE, and its archive management prioritizes solutions near the best found solutions. Rank 4 only adapts parameters based on archive performance and the selection of DE parents relies only on the archive.


Comparing (second worst) `AdaptiveLatinHypercubeDE` (Rank 5) vs (worst) `AdaptiveGaussianArchiveEA` (Rank 6), we see Rank 5 uses DE which is more effective than the simple Gaussian mutation in Rank 6. Rank 5's adaptive mechanism, though simpler than Rank 1 and 2, still provides better adaptation than Rank 6's fixed sigma decay.


Overall: The best-performing algorithms consistently leverage sophisticated adaptive mechanisms in both differential evolution and archive management, emphasizing archive diversity to escape local optima and efficiently explore high-dimensional spaces. Simpler methods struggle in these aspects, particularly on challenging multimodal problems.
- * **Keywords:**  Latin Hypercube Sampling, Adaptive Differential Evolution, Archive Diversity, Exploration-Exploitation Balance, Adaptive Parameter Control.

* **Advice:** Focus on robust sampling (Latin Hypercube) to ensure good initial coverage of the search space.  Prioritize adaptive algorithms (like improved DE) that dynamically adjust parameters based on multiple performance metrics (not just one, like success rate). Design archive management to actively maintain diversity and prevent premature convergence.  Carefully balance exploration and exploitation dynamically.

* **Avoid:**  Vague terms like "effective population generation" and "sophisticated archive management." Avoid simply restating the need for exploration/exploitation balance without specifying mechanisms.  Don't focus on generic adaptive parameter tuning without specifying the *factors* driving the adaptation.

* **Explanation:** The ineffective reflections are too general.  The revised approach provides concrete, actionable steps towards better heuristics by specifying precise methods and emphasizing the importance of multiple, dynamically adjusted control parameters based on measurable factors (e.g., success rate, diversity metrics within the archive).  This promotes a more rigorous and less subjective approach to heuristic design.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 10:03:54 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Latin Hypercube Sampling, Adaptive Differential Evolution, Archive Diversity, Exploration-Exploitation Balance, Adaptive Parameter Control.

* **Advice:** Focus on robust sampling (Latin Hypercube) to ensure good initial coverage of the search space.  Prioritize adaptive algorithms (like improved DE) that dynamically adjust parameters based on multiple performance metrics (not just one, like success rate). Design archive management to actively maintain diversity and prevent premature convergence.  Carefully balance exploration and exploitation dynamically.

* **Avoid:**  Vague terms like "effective population generation" and "sophisticated archive management." Avoid simply restating the need for exploration/exploitation balance without specifying mechanisms.  Don't focus on generic adaptive parameter tuning without specifying the *factors* driving the adaptation.

* **Explanation:** The ineffective reflections are too general.  The revised approach provides concrete, actionable steps towards better heuristics by specifying precise methods and emphasizing the importance of multiple, dynamically adjusted control parameters based on measurable factors (e.g., success rate, diversity metrics within the archive).  This promotes a more rigorous and less subjective approach to heuristic design.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 10:04:18 INFO Perform Harmony Search...
2025-06-23 10:04:30 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:30 ERROR Can not run the algorithm
2025-06-23 10:04:30 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1745
2025-06-23 10:04:30 INFO FeHistory: [-701.3332209]
2025-06-23 10:04:30 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:30 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 240.43868637934986, archive_size: int = 851.7319165611618, sigma_decay: float = 0.9500290805189988, initial_sigma_multiplier: float = 0.614356612286511):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:30 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:30 ERROR Can not run the algorithm
2025-06-23 10:04:30 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0876
2025-06-23 10:04:30 INFO FeHistory: [-220.96671879]
2025-06-23 10:04:30 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:30 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:30 ERROR Can not run the algorithm
2025-06-23 10:04:30 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:30 INFO FeHistory: [160.13670662]
2025-06-23 10:04:30 INFO Expected Optimum FE: -100
2025-06-23 10:04:30 INFO Unimodal AOCC mean: 0.1745
2025-06-23 10:04:30 INFO Multimodal (single component) AOCC mean: 0.0876
2025-06-23 10:04:30 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:30 INFO AOCC mean: 0.0874
2025-06-23 10:04:30 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:30 ERROR Can not run the algorithm
2025-06-23 10:04:31 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 10:04:31 INFO FeHistory: [-701.32444348]
2025-06-23 10:04:31 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:31 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 381.9994770674106, archive_size: int = 925.870844426532, sigma_decay: float = 0.9220323519262398, initial_sigma_multiplier: float = 0.7930529837140358):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:31 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:31 ERROR Can not run the algorithm
2025-06-23 10:04:31 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0899
2025-06-23 10:04:31 INFO FeHistory: [-221.654202]
2025-06-23 10:04:31 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:31 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:31 ERROR Can not run the algorithm
2025-06-23 10:04:31 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:31 INFO FeHistory: [180.41531961]
2025-06-23 10:04:31 INFO Expected Optimum FE: -100
2025-06-23 10:04:31 INFO Unimodal AOCC mean: 0.1743
2025-06-23 10:04:31 INFO Multimodal (single component) AOCC mean: 0.0899
2025-06-23 10:04:31 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:31 INFO AOCC mean: 0.0880
2025-06-23 10:04:31 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:31 ERROR Can not run the algorithm
2025-06-23 10:04:31 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 10:04:31 INFO FeHistory: [-701.30459155]
2025-06-23 10:04:31 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:31 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 332.083461826361, archive_size: int = 393.714635418725, sigma_decay: float = 0.9221542674842472, initial_sigma_multiplier: float = 0.6120196334230239):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:31 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:31 ERROR Can not run the algorithm
2025-06-23 10:04:31 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0893
2025-06-23 10:04:31 INFO FeHistory: [-221.47919113]
2025-06-23 10:04:31 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:31 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:31 ERROR Can not run the algorithm
2025-06-23 10:04:31 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:31 INFO FeHistory: [208.72407738]
2025-06-23 10:04:31 INFO Expected Optimum FE: -100
2025-06-23 10:04:31 INFO Unimodal AOCC mean: 0.1738
2025-06-23 10:04:31 INFO Multimodal (single component) AOCC mean: 0.0893
2025-06-23 10:04:31 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:31 INFO AOCC mean: 0.0877
2025-06-23 10:04:31 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:31 ERROR Can not run the algorithm
2025-06-23 10:04:32 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1740
2025-06-23 10:04:32 INFO FeHistory: [-701.31139766]
2025-06-23 10:04:32 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:32 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 468.8388178699401, archive_size: int = 859.2972249267616, sigma_decay: float = 0.9684730860969691, initial_sigma_multiplier: float = 0.8165641541281597):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:32 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:32 ERROR Can not run the algorithm
2025-06-23 10:04:32 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0895
2025-06-23 10:04:32 INFO FeHistory: [-221.53449022]
2025-06-23 10:04:32 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:32 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:32 ERROR Can not run the algorithm
2025-06-23 10:04:32 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:32 INFO FeHistory: [166.11258373]
2025-06-23 10:04:32 INFO Expected Optimum FE: -100
2025-06-23 10:04:32 INFO Unimodal AOCC mean: 0.1740
2025-06-23 10:04:32 INFO Multimodal (single component) AOCC mean: 0.0895
2025-06-23 10:04:32 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:32 INFO AOCC mean: 0.0878
2025-06-23 10:04:32 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:32 ERROR Can not run the algorithm
2025-06-23 10:04:32 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 10:04:32 INFO FeHistory: [-701.30515942]
2025-06-23 10:04:32 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:32 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 125.90703720286001, archive_size: int = 730.0158236306913, sigma_decay: float = 0.9441357411784469, initial_sigma_multiplier: float = 0.28885268584456214):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:32 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:32 ERROR Can not run the algorithm
2025-06-23 10:04:32 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0903
2025-06-23 10:04:32 INFO FeHistory: [-221.78694818]
2025-06-23 10:04:32 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:32 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:32 ERROR Can not run the algorithm
2025-06-23 10:04:32 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:32 INFO FeHistory: [204.13466833]
2025-06-23 10:04:32 INFO Expected Optimum FE: -100
2025-06-23 10:04:32 INFO Unimodal AOCC mean: 0.1738
2025-06-23 10:04:32 INFO Multimodal (single component) AOCC mean: 0.0903
2025-06-23 10:04:32 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:32 INFO AOCC mean: 0.0880
2025-06-23 10:04:32 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:32 ERROR Can not run the algorithm
2025-06-23 10:04:33 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 10:04:33 INFO FeHistory: [-701.30889873]
2025-06-23 10:04:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:33 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 240.43868637934986, archive_size: int = 957.2408116103392, sigma_decay: float = 0.9712666231162645, initial_sigma_multiplier: float = 0.7930529837140358):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:33 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:33 ERROR Can not run the algorithm
2025-06-23 10:04:33 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0889
2025-06-23 10:04:33 INFO FeHistory: [-221.36742074]
2025-06-23 10:04:33 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:33 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:33 ERROR Can not run the algorithm
2025-06-23 10:04:33 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:33 INFO FeHistory: [181.76897701]
2025-06-23 10:04:33 INFO Expected Optimum FE: -100
2025-06-23 10:04:33 INFO Unimodal AOCC mean: 0.1739
2025-06-23 10:04:33 INFO Multimodal (single component) AOCC mean: 0.0889
2025-06-23 10:04:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:33 INFO AOCC mean: 0.0876
2025-06-23 10:04:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:33 ERROR Can not run the algorithm
2025-06-23 10:04:33 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 10:04:33 INFO FeHistory: [-701.31039998]
2025-06-23 10:04:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:33 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 285.19872692240716, archive_size: int = 859.2972249267616, sigma_decay: float = 0.9879431491279245, initial_sigma_multiplier: float = 0.6027925349564937):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:33 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:33 ERROR Can not run the algorithm
2025-06-23 10:04:33 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0926
2025-06-23 10:04:33 INFO FeHistory: [-222.435459]
2025-06-23 10:04:33 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:33 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:33 ERROR Can not run the algorithm
2025-06-23 10:04:33 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:33 INFO FeHistory: [190.90751088]
2025-06-23 10:04:33 INFO Expected Optimum FE: -100
2025-06-23 10:04:33 INFO Unimodal AOCC mean: 0.1739
2025-06-23 10:04:33 INFO Multimodal (single component) AOCC mean: 0.0926
2025-06-23 10:04:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:33 INFO AOCC mean: 0.0889
2025-06-23 10:04:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:33 ERROR Can not run the algorithm
2025-06-23 10:04:34 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1740
2025-06-23 10:04:34 INFO FeHistory: [-701.31506337]
2025-06-23 10:04:34 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:34 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 468.8388178699401, archive_size: int = 859.2972249267616, sigma_decay: float = 0.9879431491279245, initial_sigma_multiplier: float = 0.6027925349564937):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:34 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:34 ERROR Can not run the algorithm
2025-06-23 10:04:34 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0935
2025-06-23 10:04:34 INFO FeHistory: [-222.6634371]
2025-06-23 10:04:34 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:34 ERROR Can not run the algorithm
2025-06-23 10:04:34 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:34 INFO FeHistory: [174.259983]
2025-06-23 10:04:34 INFO Expected Optimum FE: -100
2025-06-23 10:04:34 INFO Unimodal AOCC mean: 0.1740
2025-06-23 10:04:34 INFO Multimodal (single component) AOCC mean: 0.0935
2025-06-23 10:04:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:34 INFO AOCC mean: 0.0892
2025-06-23 10:04:34 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:34 ERROR Can not run the algorithm
2025-06-23 10:04:34 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1756
2025-06-23 10:04:34 INFO FeHistory: [-701.37729535]
2025-06-23 10:04:34 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:34 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 744.9965353923094, archive_size: int = 369.5906353363831, sigma_decay: float = 0.9879431491279245, initial_sigma_multiplier: float = 0.6994684338651689):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:34 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:34 ERROR Can not run the algorithm
2025-06-23 10:04:34 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0877
2025-06-23 10:04:34 INFO FeHistory: [-221.01057594]
2025-06-23 10:04:34 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:34 ERROR Can not run the algorithm
2025-06-23 10:04:34 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:34 INFO FeHistory: [197.03536794]
2025-06-23 10:04:34 INFO Expected Optimum FE: -100
2025-06-23 10:04:34 INFO Unimodal AOCC mean: 0.1756
2025-06-23 10:04:34 INFO Multimodal (single component) AOCC mean: 0.0877
2025-06-23 10:04:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:34 INFO AOCC mean: 0.0878
2025-06-23 10:04:34 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:04:34 ERROR Can not run the algorithm
2025-06-23 10:04:35 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 10:04:35 INFO FeHistory: [-701.29643669]
2025-06-23 10:04:35 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:04:35 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 541.5569906889133, archive_size: int = 859.2972249267616, sigma_decay: float = 0.9672179951298461, initial_sigma_multiplier: float = 0.40919628081702064):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:04:35 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:04:35 ERROR Can not run the algorithm
2025-06-23 10:04:35 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0902
2025-06-23 10:04:35 INFO FeHistory: [-221.73921889]
2025-06-23 10:04:35 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:04:35 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:04:35 ERROR Can not run the algorithm
2025-06-23 10:04:35 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:04:35 INFO FeHistory: [167.7641461]
2025-06-23 10:04:35 INFO Expected Optimum FE: -100
2025-06-23 10:04:35 INFO Unimodal AOCC mean: 0.1736
2025-06-23 10:04:35 INFO Multimodal (single component) AOCC mean: 0.0902
2025-06-23 10:04:35 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:04:35 INFO AOCC mean: 0.0879
2025-06-23 10:04:35 INFO Generation 4, best so far: 0.14294861551599297
2025-06-23 10:04:35 INFO Population length is: 7
2025-06-23 10:04:35 INFO --- Performing Long-Term Reflection at Generation 5 ---
2025-06-23 10:04:35 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.3311e-02 |             AOCC Score on Unimodal instances: 1.7549e-01 |             AOCC Score on Multimodal instances with a single component: 1.0444e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: HybridLatinHypercubeDEArchiveEA
# Description: Combines Latin Hypercube sampling, adaptive Differential Evolution, and a diversity-preserving archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

class HybridLatinHypercubeDEArchiveEA:
    """
    Combines Latin Hypercube sampling, adaptive Differential Evolution, and a diversity-preserving archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.max_archive_size = 200
        self.F = 0.5  # Initial scaling factor for DE
        self.CR = 0.9  # Initial crossover rate for DE
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.exploration_rate = 0.8 # Initial exploration rate
        self.diversity_threshold = 0.2 # Threshold for low diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate: #Exploration vs. Exploitation
                a, b, c = self._select_different_archive(population,i) #Explore archive
            else:
                a, b, c = self._select_different(population, i) #Exploit current population
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_different_archive(self,population,i):
        indices = np.random.choice(len(self.archive),3,replace=False)
        return self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]


    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        
        #Diversity preservation:  Remove similar solutions from the archive
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            is_unique = True
            for j in range(len(new_archive)):
                if np.linalg.norm(sorted_data[i,:-1] - new_archive[j][:-1]) < 0.1: # Adjust distance threshold as needed.
                    is_unique = False
                    break
            if is_unique:
                new_archive.append(sorted_data[i])

        return np.array(new_archive[:min(len(new_archive), self.max_archive_size)])[:, :-1]


    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        #Monitor the diversity of the population. Lower diversity indicates a need for more exploration.
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (self.upper_bounds.mean()- self.lower_bounds.mean()): #Threshold for low diversity
            self.exploration_rate = min(1,self.exploration_rate + 0.05) #Increase exploration
        else:
            self.exploration_rate = max(0.1,self.exploration_rate - 0.05) #Decrease exploration

        #Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size //2] < fitness_values[self.population_size //2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate-0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)
```

### Rank 2 (Overall AOCC Score: 9.3025e-02 |             AOCC Score on Unimodal instances: 1.7583e-01 |             AOCC Score on Multimodal instances with a single component: 1.0325e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLatinHypercubeDEArchiveEA
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a fitness-based archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: AdaptiveLatinHypercubeDEArchiveEA
# Description: Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a fitness-based archive for robust multimodal optimization.
# Code:
class AdaptiveLatinHypercubeDEArchiveEA:
    """
    Combines Latin Hypercube Sampling, adaptive Differential Evolution, and a fitness-based archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 100, archive_size: int = 200, archive_diversity_threshold: float = 0.1):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive_diversity_threshold = archive_diversity_threshold
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.5  # Initial DE scaling factor
        self.CR = 0.9  # Initial DE crossover rate
        self.archive = np.empty((0, dim + 1))  # Initialize empty archive
        self.sampler = qmc.LatinHypercube(d=self.dim)

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        # Initialize population using Latin Hypercube Sampling
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(self.archive)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((self.archive[:, :-1], offspring)), np.concatenate((self.archive[:, -1], offspring_fitness)))
            self._adapt_parameters()
            self._update_best(self.archive)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        return qmc.scale(sample, self.lower_bounds, self.upper_bounds)

    def _differential_evolution(self, archive):
        offspring = []
        for _ in range(self.population_size):
            a, b, c = self._select_three_different(archive)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(archive[0, :-1], mutant)  # Using best solution from archive as target
            offspring.append(trial)
        return np.array(offspring)

    def _select_three_different(self, archive):
        indices = np.random.choice(len(archive), 3, replace=False)
        return archive[indices, :-1]

    def _crossover(self, target, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        return np.where(crosspoints, mutant, target)

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        sorted_data = self._maintain_archive_diversity(sorted_data)
        return sorted_data[:min(len(sorted_data), self.archive_size)]

    def _maintain_archive_diversity(self, sorted_data):
        if len(sorted_data) > self.archive_size:
            archive = sorted_data[:self.archive_size, :-1]
            distances = np.linalg.norm(sorted_data[self.archive_size:, :-1][:, np.newaxis, :] - archive[np.newaxis, :, :], axis=2)
            min_distances = np.min(distances, axis=1)
            indices_to_keep = np.argsort(min_distances)[::-1][:self.archive_size - len(archive)]
            to_add = sorted_data[self.archive_size:][indices_to_keep]
            sorted_data = np.vstack((sorted_data[:self.archive_size],to_add))
        return sorted_data

    def _adapt_parameters(self):
        if len(self.archive) > 10:
            success_rate = np.mean(self.archive[10:, -1] < self.archive[:10, -1])
            archive_diversity = np.mean(np.linalg.norm(self.archive[1:, :-1] - self.archive[:-1, :-1], axis=1)) if len(self.archive) > 1 else 0
            self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.2) + 0.05 * (self.archive_diversity_threshold - archive_diversity)))
            self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

    def _update_best(self, archive):
        best_index = np.argmin(archive[:, -1])
        if archive[best_index, -1] < self.best_fitness_overall:
            self.best_fitness_overall = archive[best_index, -1]
            self.best_solution_overall = archive[best_index, :-1]

def objective_function(X):
    #Example objective function (replace with your actual benchmark functions)
    return np.sum(X**2, axis=1)
```

### Rank 3 (Overall AOCC Score: 9.2587e-02 |             AOCC Score on Unimodal instances: 1.7521e-01 |             AOCC Score on Multimodal instances with a single component: 1.0255e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLatinHypercubeDE
# Description: Combines Latin Hypercube Sampling, Adaptive Differential Evolution, and archive diversity management for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveLatinHypercubeDE
# Description: Combines Latin Hypercube Sampling, Adaptive Differential Evolution, and archive diversity management for robust multimodal optimization.
# Code:
class AdaptiveLatinHypercubeDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adaptive_parameter_control(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        samples = np.zeros((self.population_size, self.dim))
        for i in range(self.dim):
            order = np.random.permutation(self.population_size)
            for j in range(self.population_size):
                samples[j, i] = (order[j] + np.random.uniform()) / self.population_size
        return samples * (self.upper_bounds - self.lower_bounds) + self.lower_bounds

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_differents(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_differents(self, exclude, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        n = np.random.rand(self.dim) < self.CR
        return np.where(n, v, x)
    
    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        if len(new_archive) > self.archive_size:
             new_archive = self._cull_archive(new_archive)
        return np.array(new_archive)

    def _cull_archive(self, archive):
        # Maintain diversity using distance-based selection
        distances = pdist(np.array([x[:-1] for x in archive]))
        distances_matrix = squareform(distances)
        to_remove = []
        while len(archive) > self.archive_size:
            min_dist = np.min(distances_matrix)
            row, col = np.unravel_index(np.argmin(distances_matrix), distances_matrix.shape)
            if distances_matrix[row,col] == min_dist:
                if archive[row][-1] > archive[col][-1]:
                    to_remove.append(row)
                else:
                    to_remove.append(col)
            distances_matrix[row, :] = np.inf
            distances_matrix[:, row] = np.inf
            distances_matrix[col, :] = np.inf
            distances_matrix[:, col] = np.inf
            
        new_archive = np.array([x for i, x in enumerate(archive) if i not in to_remove])
        return new_archive

    def _adaptive_parameter_control(self, population, fitness_values):
        # Simple adaptation: Adjust F and CR based on success rate
        success_rate = np.mean(offspring_fitness < fitness_values)
        if success_rate < 0.1:
            self.F *= 0.95
            self.CR *= 0.95
        elif success_rate > 0.9:
            self.F *= 1.05
            self.CR *= 1.05
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)



```

### Rank 4 (Overall AOCC Score: 9.2251e-02 |             AOCC Score on Unimodal instances: 1.7537e-01 |             AOCC Score on Multimodal instances with a single component: 1.0138e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLatinHypercubeDEwithArchiveDiversity
# Description: Combines Latin Hypercube sampling, adaptive Differential Evolution, and archive diversity for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

class AdaptiveLatinHypercubeDEwithArchiveDiversity:
    """
    Combines Latin Hypercube sampling, adaptive Differential Evolution, and archive diversity management for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.scale_factor = 1.0  # Adaptive scaling factor
        self.scale_decay = 0.95
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.acceptance_threshold = 1e-6


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            initial_sample = self.sampler.random(n=1)
            self.best_solution_overall = self._scale_sample(initial_sample)[0]
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling(self.population_size)
        fitness = objective_function(population)
        self.eval_count += self.population_size
        
        self.archive = self._update_archive(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_pop = np.vstack((offspring, population))
            combined_fit = np.concatenate((offspring_fitness, fitness))
            sorted_indices = np.argsort(combined_fit)
            population = combined_pop[sorted_indices[:self.population_size]]
            fitness = combined_fit[sorted_indices[:self.population_size]]

            self._update_best(population, fitness)
            self.scale_factor *= self.scale_decay
            self.F *= self.scale_factor  # Adaptive F scaling
            self.CR *= self.scale_factor  # Adaptive CR Scaling
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness, offspring_fitness)))

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _latin_hypercube_sampling(self, num_samples):
        sample = self.sampler.random(n=num_samples)
        return self._scale_sample(sample)

    def _scale_sample(self, sample):
        return sample * (self.upper_bounds - self.lower_bounds) + self.lower_bounds

    def _differential_evolution(self, population, fitness):
        new_population = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness[0] < fitness[i]:
                new_population[i] = trial
            else:
                new_population[i] = population[i]
        return new_population

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Prioritize adding solutions near the best found solution and maintain diversity
        distances_to_best = np.linalg.norm(population - self.best_solution_overall, axis=1)
        combined = combined[np.argsort(distances_to_best)]
        
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        
        #Maintain diversity by adding solutions based on distance in solution space
        if len(new_archive)> self.archive_size:
            new_archive = self._maintain_diversity(new_archive, self.archive_size)
        
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _maintain_diversity(self, archive, max_size):
        archive = np.array(archive)
        if len(archive) <= max_size:
            return archive
        
        selected_archive = [archive[0]] #add the best solution
        remaining_archive = archive[1:]

        while len(selected_archive) < max_size and len(remaining_archive)>0:
            best_index = 0
            max_distance = 0
            
            for i in range(len(remaining_archive)):
                min_distance = np.min(np.linalg.norm(remaining_archive[i][:-1] - selected_archive[:,:-1], axis = 1))
                if min_distance > max_distance:
                    max_distance = min_distance
                    best_index = i

            selected_archive.append(remaining_archive[best_index])
            remaining_archive = np.delete(remaining_archive, best_index, axis=0)
        
        return np.array(selected_archive)


def objective_function(x):  #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)
```

### Rank 5 (Overall AOCC Score: 9.1874e-02 |             AOCC Score on Unimodal instances: 1.7504e-01 |             AOCC Score on Multimodal instances with a single component: 1.0058e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLatinHypercubeDE
# Description: Combines Latin Hypercube Sampling, Adaptive Differential Evolution, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: AdaptiveLatinHypercubeDE
# Description: Combines Latin Hypercube Sampling, Adaptive Differential Evolution, and an archive for robust multimodal optimization.

class AdaptiveLatinHypercubeDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim, seed=42) # Fixed seed for reproducibility


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values) #Adaptive Parameter Control

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Select 3 distinct random individuals (excluding current one)
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)
            a, b, c = population[indices]
            mutant = a + self.F * (b - c)

            #Crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptive strategy: Adjust F and CR based on success rate
        success_rate = np.mean(offspring_fitness < fitness_values) #consider previous generation
        if success_rate < 0.1: # Reduce F and increase CR for better exploitation
            self.F *= 0.9
            self.CR *= 1.1
        elif success_rate > 0.9: # Increase F and reduce CR for better exploration
            self.F *= 1.1
            self.CR *= 0.9
        self.F = np.clip(self.F, 0.1, 1.0) # Constrain F
        self.CR = np.clip(self.CR, 0.1, 1.0) # Constrain CR

```

### Rank 6 (Overall AOCC Score: 8.9179e-02 |             AOCC Score on Unimodal instances: 1.7405e-01 |             AOCC Score on Multimodal instances with a single component: 9.3491e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 468.8388178699401, archive_size: int = 859.2972249267616, sigma_decay: float = 0.9879431491279245, initial_sigma_multiplier: float = 0.6027925349564937):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 10:04:40 INFO Full response text: **Analysis:**

Comparing `HybridLatinHypercubeDEArchiveEA` (best) vs `AdaptiveGaussianArchiveEA` (worst), we see that the best utilizes adaptive Differential Evolution, a more sophisticated optimization technique than the simple Gaussian mutation in the worst.  The best also incorporates a diversity-preserving archive, dynamically adjusting exploration/exploitation, while the worst uses a less effective archive update strategy and a fixed sigma decay. `HybridLatinHypercubeDEArchiveEA` shows more sophisticated parameter adaptation based on population diversity and success rate, improving the balance between exploration and exploitation.

`AdaptiveLatinHypercubeDEArchiveEA` (second best) vs `AdaptiveLatinHypercubeDE` (second worst) shows similar approaches but the second best uses a fitness-based archive update, favoring better solutions which is more efficient than the distance based culling in the second worst. The adaptive parameter control in `AdaptiveLatinHypercubeDEArchiveEA` is more comprehensive, considering archive diversity directly whereas the second worst has a simpler approach based on success rate only.

Comparing `HybridLatinHypercubeDEArchiveEA` (1st) vs `AdaptiveLatinHypercubeDEArchiveEA` (2nd), we see that the primary difference lies in the archive management and parameter adaptation strategies. The best's diversity-preserving archive actively maintains exploration, while the second best relies on a fitness-based approach which might lose diversity. The best also adaptively changes exploration rate based on diversity and adjusts the DE parameters.


`AdaptiveLatinHypercubeDE` (3rd) vs `AdaptiveLatinHypercubeDEwithArchiveDiversity` (4th) highlights the impact of archive management on performance. The third-ranked algorithm uses a more robust method for maintaining archive diversity, removing solutions close together to maintain a wider range. The fourth-ranked algorithm's diversity maintenance is less robust, and its adaptive parameter control lacks the fine-grained approach of the better algorithms.


Comparing `AdaptiveLatinHypercubeDEwithArchiveDiversity` (second worst) vs `AdaptiveGaussianArchiveEA` (worst), we see significant differences in the mutation and selection strategies. The second worst employs a Differential Evolution strategy coupled with an adaptive parameter control, while the worst uses a simple Gaussian mutation with a fixed decay rate and tournament selection.  The second worst also has a more sophisticated archive management strategy.


Overall: The top-performing algorithms leverage adaptive Differential Evolution, diverse archive management strategies (emphasizing both fitness and diversity), and sophisticated parameter adaptation mechanisms that balance exploration and exploitation effectively.  The lower-ranked algorithms exhibit simpler mutation/recombination techniques, less robust archive management, and less adaptive parameter control, resulting in inferior performance.


**Experience:**

Effective heuristics require a balance of exploration and exploitation, achieved through sophisticated mutation/recombination operators and intelligent archive management, along with adaptive parameter control tailored to the problem landscape.  Diversity preservation in the archive is crucial for escaping local optima in multimodal problems.

2025-06-23 10:04:42 INFO Full response text: * **Keywords:**  Adaptive parameter control, diversity preservation, exploration-exploitation balance, archive management, multimodal optimization.

* **Advice:** Focus on designing novel mutation/recombination operators that directly address diversity loss and premature convergence. Develop adaptive mechanisms that dynamically adjust operator parameters based on real-time assessment of population diversity and exploration success, going beyond simple success rate metrics. Explore alternative archive management strategies beyond simple size limits. Investigate the use of problem-specific knowledge to guide the exploration-exploitation balance.

* **Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, and DE/Gaussian mutations.  Avoid repeating well-known best practices without novel contributions.  Don't focus solely on population generation;  the entire optimization loop needs improvement.

* **Explanation:**  The provided ineffective self-reflections lack concrete, actionable ideas.  To design better heuristics, we must move beyond established methods and delve into specific mechanisms for adaptive control and diversity maintenance, leveraging problem-specific insights whenever possible.  The focus should be on *how* to achieve better balance, not simply stating that balance is important.

2025-06-23 10:04:42 INFO Generating offspring via Crossover...
2025-06-23 10:15:18 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
HybridLatinHypercubeDEArchiveEA
import numpy as np
from scipy.stats import qmc

class HybridLatinHypercubeDEArchiveEA:
    """
    Combines Latin Hypercube sampling, adaptive Differential Evolution, and a diversity-preserving archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.max_archive_size = 200
        self.F = 0.5  # Initial scaling factor for DE
        self.CR = 0.9  # Initial crossover rate for DE
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.exploration_rate = 0.8 # Initial exploration rate
        self.diversity_threshold = 0.2 # Threshold for low diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate: #Exploration vs. Exploitation
                a, b, c = self._select_different_archive(population,i) #Explore archive
            else:
                a, b, c = self._select_different(population, i) #Exploit current population
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_different_archive(self,population,i):
        indices = np.random.choice(len(self.archive),3,replace=False)
        return self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]


    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        
        #Diversity preservation:  Remove similar solutions from the archive
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            is_unique = True
            for j in range(len(new_archive)):
                if np.linalg.norm(sorted_data[i,:-1] - new_archive[j][:-1]) < 0.1: # Adjust distance threshold as needed.
                    is_unique = False
                    break
            if is_unique:
                new_archive.append(sorted_data[i])

        return np.array(new_archive[:min(len(new_archive), self.max_archive_size)])[:, :-1]


    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        #Monitor the diversity of the population. Lower diversity indicates a need for more exploration.
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (self.upper_bounds.mean()- self.lower_bounds.mean()): #Threshold for low diversity
            self.exploration_rate = min(1,self.exploration_rate + 0.05) #Increase exploration
        else:
            self.exploration_rate = max(0.1,self.exploration_rate - 0.05) #Decrease exploration

        #Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size //2] < fitness_values[self.population_size //2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate-0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)

### Worse code
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Analyze & experience
- Comparing `HybridLatinHypercubeDEArchiveEA` (best) vs `AdaptiveGaussianArchiveEA` (worst), we see that the best utilizes adaptive Differential Evolution, a more sophisticated optimization technique than the simple Gaussian mutation in the worst.  The best also incorporates a diversity-preserving archive, dynamically adjusting exploration/exploitation, while the worst uses a less effective archive update strategy and a fixed sigma decay. `HybridLatinHypercubeDEArchiveEA` shows more sophisticated parameter adaptation based on population diversity and success rate, improving the balance between exploration and exploitation.

`AdaptiveLatinHypercubeDEArchiveEA` (second best) vs `AdaptiveLatinHypercubeDE` (second worst) shows similar approaches but the second best uses a fitness-based archive update, favoring better solutions which is more efficient than the distance based culling in the second worst. The adaptive parameter control in `AdaptiveLatinHypercubeDEArchiveEA` is more comprehensive, considering archive diversity directly whereas the second worst has a simpler approach based on success rate only.

Comparing `HybridLatinHypercubeDEArchiveEA` (1st) vs `AdaptiveLatinHypercubeDEArchiveEA` (2nd), we see that the primary difference lies in the archive management and parameter adaptation strategies. The best's diversity-preserving archive actively maintains exploration, while the second best relies on a fitness-based approach which might lose diversity. The best also adaptively changes exploration rate based on diversity and adjusts the DE parameters.


`AdaptiveLatinHypercubeDE` (3rd) vs `AdaptiveLatinHypercubeDEwithArchiveDiversity` (4th) highlights the impact of archive management on performance. The third-ranked algorithm uses a more robust method for maintaining archive diversity, removing solutions close together to maintain a wider range. The fourth-ranked algorithm's diversity maintenance is less robust, and its adaptive parameter control lacks the fine-grained approach of the better algorithms.


Comparing `AdaptiveLatinHypercubeDEwithArchiveDiversity` (second worst) vs `AdaptiveGaussianArchiveEA` (worst), we see significant differences in the mutation and selection strategies. The second worst employs a Differential Evolution strategy coupled with an adaptive parameter control, while the worst uses a simple Gaussian mutation with a fixed decay rate and tournament selection.  The second worst also has a more sophisticated archive management strategy.


Overall: The top-performing algorithms leverage adaptive Differential Evolution, diverse archive management strategies (emphasizing both fitness and diversity), and sophisticated parameter adaptation mechanisms that balance exploration and exploitation effectively.  The lower-ranked algorithms exhibit simpler mutation/recombination techniques, less robust archive management, and less adaptive parameter control, resulting in inferior performance.
- * **Keywords:**  Adaptive parameter control, diversity preservation, exploration-exploitation balance, archive management, multimodal optimization.

* **Advice:** Focus on designing novel mutation/recombination operators that directly address diversity loss and premature convergence. Develop adaptive mechanisms that dynamically adjust operator parameters based on real-time assessment of population diversity and exploration success, going beyond simple success rate metrics. Explore alternative archive management strategies beyond simple size limits. Investigate the use of problem-specific knowledge to guide the exploration-exploitation balance.

* **Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, and DE/Gaussian mutations.  Avoid repeating well-known best practices without novel contributions.  Don't focus solely on population generation;  the entire optimization loop needs improvement.

* **Explanation:**  The provided ineffective self-reflections lack concrete, actionable ideas.  To design better heuristics, we must move beyond established methods and delve into specific mechanisms for adaptive control and diversity maintenance, leveraging problem-specific insights whenever possible.  The focus should be on *how* to achieve better balance, not simply stating that balance is important.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 10:15:18 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Adaptive parameter control, diversity preservation, exploration-exploitation balance, archive management, multimodal optimization.

* **Advice:** Focus on designing novel mutation/recombination operators that directly address diversity loss and premature convergence. Develop adaptive mechanisms that dynamically adjust operator parameters based on real-time assessment of population diversity and exploration success, going beyond simple success rate metrics. Explore alternative archive management strategies beyond simple size limits. Investigate the use of problem-specific knowledge to guide the exploration-exploitation balance.

* **Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, and DE/Gaussian mutations.  Avoid repeating well-known best practices without novel contributions.  Don't focus solely on population generation;  the entire optimization loop needs improvement.

* **Explanation:**  The provided ineffective self-reflections lack concrete, actionable ideas.  To design better heuristics, we must move beyond established methods and delve into specific mechanisms for adaptive control and diversity maintenance, leveraging problem-specific insights whenever possible.  The focus should be on *how* to achieve better balance, not simply stating that balance is important.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 10:25:58 INFO Perform Harmony Search...
2025-06-23 10:26:09 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:26:09 ERROR Can not run the algorithm
2025-06-23 10:26:09 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1741
2025-06-23 10:26:09 INFO FeHistory: [-701.31642394]
2025-06-23 10:26:09 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:26:09 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 277.86831070047907, archive_size: int = 159.55897211349804, sigma_decay: float = 0.9151858372239505, sigma_init_factor: float = 0.2777001497378324):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:26:09 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:26:09 ERROR Can not run the algorithm
2025-06-23 10:26:10 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0901
2025-06-23 10:26:10 INFO FeHistory: [-221.72380515]
2025-06-23 10:26:10 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:26:10 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:26:10 ERROR Can not run the algorithm
2025-06-23 10:26:10 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:26:10 INFO FeHistory: [203.28196216]
2025-06-23 10:26:10 INFO Expected Optimum FE: -100
2025-06-23 10:26:10 INFO Unimodal AOCC mean: 0.1741
2025-06-23 10:26:10 INFO Multimodal (single component) AOCC mean: 0.0901
2025-06-23 10:26:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:26:10 INFO AOCC mean: 0.0881
2025-06-23 10:26:10 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:26:10 ERROR Can not run the algorithm
2025-06-23 10:26:10 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 10:26:10 INFO FeHistory: [-701.29001287]
2025-06-23 10:26:10 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:26:10 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 703.9425058362211, archive_size: int = 629.17768333304, sigma_decay: float = 0.963992431669364, sigma_init_factor: float = 0.43937556842401215):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:26:10 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:26:10 ERROR Can not run the algorithm
2025-06-23 10:26:10 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0894
2025-06-23 10:26:10 INFO FeHistory: [-221.52474261]
2025-06-23 10:26:10 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:26:10 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:26:10 ERROR Can not run the algorithm
2025-06-23 10:26:10 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:26:10 INFO FeHistory: [214.87208441]
2025-06-23 10:26:10 INFO Expected Optimum FE: -100
2025-06-23 10:26:10 INFO Unimodal AOCC mean: 0.1735
2025-06-23 10:26:10 INFO Multimodal (single component) AOCC mean: 0.0894
2025-06-23 10:26:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:26:10 INFO AOCC mean: 0.0876
2025-06-23 10:26:10 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:26:10 ERROR Can not run the algorithm
2025-06-23 10:26:10 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 10:26:10 INFO FeHistory: [-701.29351974]
2025-06-23 10:26:10 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:26:10 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 975.8399885797285, archive_size: int = 375.0740466486721, sigma_decay: float = 0.9415498126133318, sigma_init_factor: float = 0.2378083795895988):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:26:10 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:26:10 ERROR Can not run the algorithm
2025-06-23 10:26:11 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0936
2025-06-23 10:26:11 INFO FeHistory: [-222.69659925]
2025-06-23 10:26:11 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:26:11 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:26:11 ERROR Can not run the algorithm
2025-06-23 10:26:11 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:26:11 INFO FeHistory: [178.8037643]
2025-06-23 10:26:11 INFO Expected Optimum FE: -100
2025-06-23 10:26:11 INFO Unimodal AOCC mean: 0.1735
2025-06-23 10:26:11 INFO Multimodal (single component) AOCC mean: 0.0936
2025-06-23 10:26:11 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:26:11 INFO AOCC mean: 0.0890
2025-06-23 10:26:11 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:26:11 ERROR Can not run the algorithm
2025-06-23 10:26:11 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1732
2025-06-23 10:26:11 INFO FeHistory: [-701.27972933]
2025-06-23 10:26:11 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:26:11 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 750.3925187080399, archive_size: int = 185.72191951873592, sigma_decay: float = 0.9717311454416683, sigma_init_factor: float = 0.3465903224936225):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:26:11 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:26:11 ERROR Can not run the algorithm
2025-06-23 10:26:11 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0939
2025-06-23 10:26:11 INFO FeHistory: [-222.78242638]
2025-06-23 10:26:11 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:26:11 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:26:11 ERROR Can not run the algorithm
2025-06-23 10:26:11 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:26:11 INFO FeHistory: [188.84516823]
2025-06-23 10:26:11 INFO Expected Optimum FE: -100
2025-06-23 10:26:11 INFO Unimodal AOCC mean: 0.1732
2025-06-23 10:26:11 INFO Multimodal (single component) AOCC mean: 0.0939
2025-06-23 10:26:11 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:26:11 INFO AOCC mean: 0.0890
2025-06-23 10:26:11 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:26:11 ERROR Can not run the algorithm
2025-06-23 10:26:11 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 10:26:11 INFO FeHistory: [-701.32508412]
2025-06-23 10:26:11 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:26:11 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 987.8128214971305, archive_size: int = 542.4332665982711, sigma_decay: float = 0.9084512914470146, sigma_init_factor: float = 0.901216596486333):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:26:11 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:26:11 ERROR Can not run the algorithm
2025-06-23 10:26:12 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0875
2025-06-23 10:26:12 INFO FeHistory: [-220.95441558]
2025-06-23 10:26:12 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:26:12 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:26:12 ERROR Can not run the algorithm
2025-06-23 10:26:12 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:26:12 INFO FeHistory: [212.19317475]
2025-06-23 10:26:12 INFO Expected Optimum FE: -100
2025-06-23 10:26:12 INFO Unimodal AOCC mean: 0.1743
2025-06-23 10:26:12 INFO Multimodal (single component) AOCC mean: 0.0875
2025-06-23 10:26:12 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:26:12 INFO AOCC mean: 0.0873
2025-06-23 10:26:12 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:26:12 ERROR Can not run the algorithm
2025-06-23 10:26:12 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 10:26:12 INFO FeHistory: [-701.30549744]
2025-06-23 10:26:12 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:26:12 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 975.8399885797285, archive_size: int = 330.5673432057094, sigma_decay: float = 0.9268751868075602, sigma_init_factor: float = 0.5466073716663662):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:26:12 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:26:12 ERROR Can not run the algorithm
2025-06-23 10:26:12 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0932
2025-06-23 10:26:12 INFO FeHistory: [-222.57832158]
2025-06-23 10:26:12 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:26:12 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:26:12 ERROR Can not run the algorithm
2025-06-23 10:26:12 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:26:12 INFO FeHistory: [222.91523681]
2025-06-23 10:26:12 INFO Expected Optimum FE: -100
2025-06-23 10:26:12 INFO Unimodal AOCC mean: 0.1738
2025-06-23 10:26:12 INFO Multimodal (single component) AOCC mean: 0.0932
2025-06-23 10:26:12 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:26:12 INFO AOCC mean: 0.0890
2025-06-23 10:26:12 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:26:12 ERROR Can not run the algorithm
2025-06-23 10:26:12 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 10:26:12 INFO FeHistory: [-701.3280789]
2025-06-23 10:26:12 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:26:12 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 703.9425058362211, archive_size: int = 159.55897211349804, sigma_decay: float = 0.9437708465711627, sigma_init_factor: float = 0.2848944847968684):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:26:12 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:26:12 ERROR Can not run the algorithm
2025-06-23 10:26:13 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0942
2025-06-23 10:26:13 INFO FeHistory: [-222.86466642]
2025-06-23 10:26:13 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:26:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:26:13 ERROR Can not run the algorithm
2025-06-23 10:41:24 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:41:24 INFO FeHistory: [202.08171715]
2025-06-23 10:41:24 INFO Expected Optimum FE: -100
2025-06-23 10:41:24 INFO Unimodal AOCC mean: 0.1744
2025-06-23 10:41:24 INFO Multimodal (single component) AOCC mean: 0.0942
2025-06-23 10:41:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:41:24 INFO AOCC mean: 0.0895
2025-06-23 10:41:24 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:41:24 ERROR Can not run the algorithm
2025-06-23 10:41:24 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 10:41:24 INFO FeHistory: [-701.32709612]
2025-06-23 10:41:24 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:41:24 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 975.8399885797285, archive_size: int = 185.72191951873592, sigma_decay: float = 0.9437708465711627, sigma_init_factor: float = 0.5048813051381438):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:41:24 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:41:24 ERROR Can not run the algorithm
2025-06-23 10:41:24 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0900
2025-06-23 10:41:24 INFO FeHistory: [-221.67751598]
2025-06-23 10:41:24 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:41:24 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:41:24 ERROR Can not run the algorithm
2025-06-23 10:41:25 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:41:25 INFO FeHistory: [183.55829738]
2025-06-23 10:41:25 INFO Expected Optimum FE: -100
2025-06-23 10:41:25 INFO Unimodal AOCC mean: 0.1743
2025-06-23 10:41:25 INFO Multimodal (single component) AOCC mean: 0.0900
2025-06-23 10:41:25 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:41:25 INFO AOCC mean: 0.0881
2025-06-23 10:41:25 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:41:25 ERROR Can not run the algorithm
2025-06-23 10:41:25 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 10:41:25 INFO FeHistory: [-701.29301603]
2025-06-23 10:41:25 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:41:25 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 909.5482922345858, archive_size: int = 152.3039296969681, sigma_decay: float = 0.9573845616681647, sigma_init_factor: float = 0.6084492894909621):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:41:25 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:41:25 ERROR Can not run the algorithm
2025-06-23 10:41:25 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0844
2025-06-23 10:41:25 INFO FeHistory: [-219.94460622]
2025-06-23 10:41:25 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:41:25 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:41:25 ERROR Can not run the algorithm
2025-06-23 10:41:25 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:41:25 INFO FeHistory: [177.45806402]
2025-06-23 10:41:25 INFO Expected Optimum FE: -100
2025-06-23 10:41:25 INFO Unimodal AOCC mean: 0.1735
2025-06-23 10:41:25 INFO Multimodal (single component) AOCC mean: 0.0844
2025-06-23 10:41:25 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:41:25 INFO AOCC mean: 0.0860
2025-06-23 10:41:25 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:41:25 ERROR Can not run the algorithm
2025-06-23 10:41:25 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1746
2025-06-23 10:41:25 INFO FeHistory: [-701.33712556]
2025-06-23 10:41:25 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:41:25 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 975.8399885797285, archive_size: int = 36.27646460083583, sigma_decay: float = 0.9437708465711627, sigma_init_factor: float = 0.6287810498539854):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:41:25 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:41:25 ERROR Can not run the algorithm
2025-06-23 10:41:25 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0905
2025-06-23 10:41:25 INFO FeHistory: [-221.84573275]
2025-06-23 10:41:25 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:41:25 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:41:25 ERROR Can not run the algorithm
2025-06-23 10:41:26 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:41:26 INFO FeHistory: [194.28332551]
2025-06-23 10:41:26 INFO Expected Optimum FE: -100
2025-06-23 10:41:26 INFO Unimodal AOCC mean: 0.1746
2025-06-23 10:41:26 INFO Multimodal (single component) AOCC mean: 0.0905
2025-06-23 10:41:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:41:26 INFO AOCC mean: 0.0884
2025-06-23 10:41:26 INFO Generation 5, best so far: 0.14294861551599297
2025-06-23 10:41:26 INFO Population length is: 7
2025-06-23 10:41:26 INFO --- Performing Long-Term Reflection at Generation 6 ---
2025-06-23 10:41:26 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.3929e-02 |             AOCC Score on Unimodal instances: 1.7570e-01 |             AOCC Score on Multimodal instances with a single component: 1.0609e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithDiversityControl
# Description: A differential evolution algorithm with adaptive mutation and crossover rates and diversity preservation using crowding and a niching strategy.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithDiversityControl
# Description: A differential evolution algorithm with adaptive mutation and crossover rates and diversity preservation using crowding and a niching strategy.

class AdaptiveDifferentialEvolutionWithDiversityControl:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weighting factor
        self.CR = 0.9  # Crossover rate
        self.niche_radius = 0.2  # Radius for niching

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)

            # Adaptive Parameter Control (adjust F and CR based on success rate)
            success_rate = np.sum(offspring_fitness < fitness_values) / self.population_size
            self.F = max(0.1, self.F + 0.1 * (success_rate - 0.2))  # Increase F if success rate is high
            self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.2))) #Increase CR if success rate is high
            self.niche_radius = self.niche_radius * (1 + 0.05 * (1 - success_rate)) #Increase niching radius if success rate is low


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            # Select three distinct vectors different from the current vector
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)

            # Mutation
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            # Crossover
            jrand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]
        return offspring


    def _selection(self, population, fitness_values, offspring, offspring_fitness):
      # Crowding Selection with Niching
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        new_population = np.zeros_like(population)
        new_fitness = np.zeros_like(fitness_values)

        for i in range(self.population_size):
            # Find nearest neighbor in the current population
            distances = np.linalg.norm(population - combined_population[i], axis=1)
            nearest_index = np.argmin(distances)

            # Replace if offspring is better
            if combined_fitness[i] < combined_fitness[nearest_index]:
                new_population[i] = combined_population[i]
                new_fitness[i] = combined_fitness[i]
            else:
                new_population[i] = population[nearest_index]
                new_fitness[i] = fitness_values[nearest_index]

        return new_population, new_fitness

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 2 (Overall AOCC Score: 9.2075e-02 |             AOCC Score on Unimodal instances: 1.7511e-01 |             AOCC Score on Multimodal instances with a single component: 1.0112e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDE_LHS_Archive
# Description: Combines adaptive Differential Evolution, Latin Hypercube Sampling, and a diversity-preserving archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform
from scipy.stats import qmc

# Name: AdaptiveDE_LHS_Archive
# Description: Combines adaptive Differential Evolution, Latin Hypercube Sampling, and a diversity-preserving archive for robust multimodal optimization.
# Code:
class AdaptiveDE_LHS_Archive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.exploration_rate = 0.8  # Initial exploration rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:  # Exploration vs. Exploitation
                a, b, c = self._select_different_archive(i)  # Explore archive
            else:
                a, b, c = self._select_different(i)  # Exploit current population
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]
    
    def _select_different_archive(self, exclude):
        candidates = list(range(len(self.archive)))
        if len(candidates) < 3:
            return self._select_different(exclude) # Fallback to population if archive too small
        np.random.shuffle(candidates)
        return [self.archive[i][:-1] for i in candidates[:3]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        #Diversity preservation (cull similar solutions)
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            is_unique = True
            for j in range(len(new_archive)):
                if np.linalg.norm(sorted_data[i, :-1] - new_archive[j][:-1]) < 0.1:
                    is_unique = False
                    break
            if is_unique:
                new_archive.append(sorted_data[i])
        
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        #Monitor the diversity of the population. Lower diversity indicates a need for more exploration.
        diversity = np.std(population, axis=0).mean()
        diversity_threshold = 0.2 * (self.upper_bounds.mean() - self.lower_bounds.mean())
        if diversity < diversity_threshold:  # Threshold for low diversity
            self.exploration_rate = min(1, self.exploration_rate + 0.05)  # Increase exploration
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration

        # Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 3 (Overall AOCC Score: 9.1879e-02 |             AOCC Score on Unimodal instances: 1.7506e-01 |             AOCC Score on Multimodal instances with a single component: 1.0058e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithFitnessBasedArchive
# Description: Combines adaptive Differential Evolution with a fitness-based archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform
from scipy.stats import qmc

# Name: AdaptiveDEwithFitnessBasedArchive
# Description: Combines adaptive Differential Evolution with a fitness-based archive for robust multimodal optimization.
# Code:
class AdaptiveDEwithFitnessBasedArchive:
    """
    Adaptive Differential Evolution with a fitness-based archive for multimodal optimization.
    Combines adaptive DE parameters and a fitness-based archive update strategy for efficient exploration and exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim, seed=42)

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)
            a, b, c = population[indices]
            mutant = a + self.F * (b - c)
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1]) # Sort by fitness
        return np.array(new_archive[:self.archive_size])

    def _adapt_parameters(self, population, fitness_values):
        #Adapt F and CR based on archive diversity and success rate
        archive_diversity = np.mean(pdist(np.array([x[:-1] for x in self.archive]))) if len(self.archive) > 1 else 1.0
        success_rate = np.mean(offspring_fitness < fitness_values)
        if success_rate < 0.2 and archive_diversity < 0.5: # Increase exploration
             self.F = min(self.F * 1.1, 1.0)
             self.CR = max(self.CR * 0.9, 0.1)
        elif success_rate > 0.8 and archive_diversity > 0.8: # Increase exploitation
            self.F = max(self.F * 0.9, 0.1)
            self.CR = min(self.CR * 1.1, 1.0)
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)

```

### Rank 4 (Overall AOCC Score: 9.1700e-02 |             AOCC Score on Unimodal instances: 1.7490e-01 |             AOCC Score on Multimodal instances with a single component: 1.0020e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: HybridDEArchiveEA
# Description: Combines Differential Evolution with a diversity-preserving archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class HybridDEArchiveEA:
    """
    Combines Differential Evolution (DE) with a diversity-preserving archive 
    to handle multimodal optimization problems effectively.  Uses adaptive 
    parameter control and a hybrid exploration-exploitation strategy.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.max_archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.exploration_rate = 0.8 # Initial exploration rate
        self.diversity_threshold = 0.1 # Threshold for low diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(population, i)
            else:
                a, b, c = self._select_different(population, i)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_different_archive(self, population, i):
        if len(self.archive) < 3:
            return self._select_different(population,i) #Fallback to population selection if archive is too small
        indices = np.random.choice(len(self.archive), 3, replace=False)
        return self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            if not np.allclose(sorted_data[i, :-1], np.array(new_archive)[:, :-1], atol=1e-6).any():
                new_archive.append(sorted_data[i])
        return np.array(new_archive[:min(len(new_archive), self.max_archive_size)])[:, :-1]


    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        # Diversity-based adaptation
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (self.upper_bounds.mean() - self.lower_bounds.mean()):
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        # Success rate based adaptation (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)
```

### Rank 5 (Overall AOCC Score: 9.1436e-02 |             AOCC Score on Unimodal instances: 1.7527e-01 |             AOCC Score on Multimodal instances with a single component: 9.9037e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: HybridDEArchiveEA
# Description: Hybrid Differential Evolution with adaptive archive for robust multimodal optimization.
# Code:
```python
# Name: HybridDEArchiveEA
# Description: Hybrid Differential Evolution with adaptive archive for robust multimodal optimization.

import numpy as np
from scipy.spatial.distance import cdist

class HybridDEArchiveEA:
    """
    Combines Differential Evolution (DE) with an adaptive archive to balance exploration and exploitation in multimodal landscapes.  Uses Latin Hypercube sampling for initialization and adaptive parameter control.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5
        self.CR = 0.9
        self.archive = []
        self.exploration_rate = 0.8
        self.diversity_threshold = 0.2


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        # Latin Hypercube Sampling for initial diversity
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample


    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(population,i)
            else:
                a, b, c = self._select_different(population, i)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_different_archive(self, population, i):
        indices = np.random.choice(len(self.archive), 3, replace=False)
        return self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        new_archive = []
        for sol in sorted_data:
            distances = cdist([sol[:-1]], self.archive)
            if len(new_archive) < self.archive_size and np.all(distances > 0.1):  # Adjust distance threshold
                new_archive.append(sol)

        return np.array(new_archive)[:,:-1]

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        #Monitor the diversity of the population. Lower diversity indicates a need for more exploration.
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (self.upper_bounds.mean() - self.lower_bounds.mean()):
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        #Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size //2] < fitness_values[self.population_size //2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate-0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

from scipy.stats import qmc
def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)

```

### Rank 6 (Overall AOCC Score: 8.9536e-02 |             AOCC Score on Unimodal instances: 1.7436e-01 |             AOCC Score on Multimodal instances with a single component: 9.4250e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 703.9425058362211, archive_size: int = 159.55897211349804, sigma_decay: float = 0.9437708465711627, sigma_init_factor: float = 0.2848944847968684):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 10:41:47 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveDifferentialEvolutionWithDiversityControl vs (worst) AdaptiveGaussianArchiveEA, we see that the top performer uses a more sophisticated DE strategy with adaptive mutation and crossover, incorporating niching and crowding for diversity maintenance.  The worst performer uses simpler Gaussian mutation and tournament selection, lacking adaptive parameter control beyond sigma decay.  (second best) AdaptiveDE_LHS_Archive vs (second worst) HybridDEArchiveEA show similar trends; AdaptiveDE_LHS_Archive leverages LHS for initial diversity and an archive for long-term preservation, while HybridDEArchiveEA uses a less sophisticated archive and exploration-exploitation strategy. Comparing (1st) vs (2nd), we see that AdaptiveDifferentialEvolutionWithDiversityControl's direct diversity control mechanisms are more effective than AdaptiveDE_LHS_Archive's reliance on LHS and archive for diversity.  (3rd) AdaptiveDEwithFitnessBasedArchive vs (4th) HybridDEArchiveEA reveals similar approaches but with different archive update methods, where AdaptiveDEwithFitnessBasedArchive's fitness-based update proves slightly superior. Comparing (second worst) HybridDEArchiveEA vs (worst) AdaptiveGaussianArchiveEA, the difference lies in the sophistication of the DE implementation and the archive management. HybridDEArchiveEA employs a DE with adaptive parameters and a diversity-preserving archive update that is better than the simpler adaptive Gaussian sampling with a less sophisticated archive of AdaptiveGaussianArchiveEA. Overall: The best-performing algorithms emphasize adaptive parameter control, sophisticated DE variations, and effective diversity management through niching, crowding, and well-designed archive strategies.  Simpler methods like basic Gaussian mutation and tournament selection perform considerably worse, highlighting the importance of advanced techniques for tackling complex multimodal problems.

**Experience:**

Effective population generation for high-dimensional problems requires sophisticated strategies that balance exploration and exploitation, utilizing adaptive parameter control and diversity preservation mechanisms within the EA.  Advanced DE variants combined with diverse population initialization and effective archive management are key for tackling challenging landscapes.

2025-06-23 10:41:49 INFO Full response text: **Keywords:**  Adaptive Exploration-Exploitation, High-Dimensional Optimization, Diversity Preservation, Parameter Control

**Advice:** Focus on novel mechanisms for dynamically adjusting exploration/exploitation based on *quantifiable metrics* (e.g., fitness distribution,  distance metrics in the search space),  not just qualitative observations.  Explore advanced archive management beyond simple size limits (e.g.,  crowding, Pareto dominance). Develop rigorous testing methodologies across diverse high-dimensional benchmarks.

**Avoid:** Vague terms like "sophisticated," "powerful," and "intelligent."  Avoid generic statements about exploration/exploitation balance without specifying concrete implementations.  Don't simply restate existing approaches.

**Explanation:**  The ineffective reflections lack concrete, measurable objectives and actionable strategies.  The key is to move beyond general principles to specific, testable hypotheses and innovative algorithm designs supported by empirical evidence.  Quantifiable metrics are crucial for evaluating and improving the heuristics' effectiveness.  This will involve designing new algorithms or significantly improving existing ones to address the limitations of existing approaches in high-dimensional landscapes.

2025-06-23 10:41:49 INFO Generating offspring via Crossover...
2025-06-23 10:44:22 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
HybridDEArchiveEA
# Name: HybridDEArchiveEA
# Description: Hybrid Differential Evolution with adaptive archive for robust multimodal optimization.

import numpy as np
from scipy.spatial.distance import cdist

class HybridDEArchiveEA:
    """
    Combines Differential Evolution (DE) with an adaptive archive to balance exploration and exploitation in multimodal landscapes.  Uses Latin Hypercube sampling for initialization and adaptive parameter control.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5
        self.CR = 0.9
        self.archive = []
        self.exploration_rate = 0.8
        self.diversity_threshold = 0.2


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        # Latin Hypercube Sampling for initial diversity
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample


    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(population,i)
            else:
                a, b, c = self._select_different(population, i)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_different_archive(self, population, i):
        indices = np.random.choice(len(self.archive), 3, replace=False)
        return self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        new_archive = []
        for sol in sorted_data:
            distances = cdist([sol[:-1]], self.archive)
            if len(new_archive) < self.archive_size and np.all(distances > 0.1):  # Adjust distance threshold
                new_archive.append(sol)

        return np.array(new_archive)[:,:-1]

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        #Monitor the diversity of the population. Lower diversity indicates a need for more exploration.
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (self.upper_bounds.mean() - self.lower_bounds.mean()):
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        #Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size //2] < fitness_values[self.population_size //2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate-0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

from scipy.stats import qmc
def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)


### Worse code
HybridDEArchiveEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

class HybridDEArchiveEA:
    """
    Combines Differential Evolution (DE) with a diversity-preserving archive 
    to handle multimodal optimization problems effectively.  Uses adaptive 
    parameter control and a hybrid exploration-exploitation strategy.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.max_archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.exploration_rate = 0.8 # Initial exploration rate
        self.diversity_threshold = 0.1 # Threshold for low diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(population, i)
            else:
                a, b, c = self._select_different(population, i)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_different_archive(self, population, i):
        if len(self.archive) < 3:
            return self._select_different(population,i) #Fallback to population selection if archive is too small
        indices = np.random.choice(len(self.archive), 3, replace=False)
        return self.archive[indices[0]], self.archive[indices[1]], self.archive[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            if not np.allclose(sorted_data[i, :-1], np.array(new_archive)[:, :-1], atol=1e-6).any():
                new_archive.append(sorted_data[i])
        return np.array(new_archive[:min(len(new_archive), self.max_archive_size)])[:, :-1]


    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        # Diversity-based adaptation
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (self.upper_bounds.mean() - self.lower_bounds.mean()):
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        # Success rate based adaptation (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)

### Analyze & experience
- Comparing (best) AdaptiveDifferentialEvolutionWithDiversityControl vs (worst) AdaptiveGaussianArchiveEA, we see that the top performer uses a more sophisticated DE strategy with adaptive mutation and crossover, incorporating niching and crowding for diversity maintenance.  The worst performer uses simpler Gaussian mutation and tournament selection, lacking adaptive parameter control beyond sigma decay.  (second best) AdaptiveDE_LHS_Archive vs (second worst) HybridDEArchiveEA show similar trends; AdaptiveDE_LHS_Archive leverages LHS for initial diversity and an archive for long-term preservation, while HybridDEArchiveEA uses a less sophisticated archive and exploration-exploitation strategy. Comparing (1st) vs (2nd), we see that AdaptiveDifferentialEvolutionWithDiversityControl's direct diversity control mechanisms are more effective than AdaptiveDE_LHS_Archive's reliance on LHS and archive for diversity.  (3rd) AdaptiveDEwithFitnessBasedArchive vs (4th) HybridDEArchiveEA reveals similar approaches but with different archive update methods, where AdaptiveDEwithFitnessBasedArchive's fitness-based update proves slightly superior. Comparing (second worst) HybridDEArchiveEA vs (worst) AdaptiveGaussianArchiveEA, the difference lies in the sophistication of the DE implementation and the archive management. HybridDEArchiveEA employs a DE with adaptive parameters and a diversity-preserving archive update that is better than the simpler adaptive Gaussian sampling with a less sophisticated archive of AdaptiveGaussianArchiveEA. Overall: The best-performing algorithms emphasize adaptive parameter control, sophisticated DE variations, and effective diversity management through niching, crowding, and well-designed archive strategies.  Simpler methods like basic Gaussian mutation and tournament selection perform considerably worse, highlighting the importance of advanced techniques for tackling complex multimodal problems.
- **Keywords:**  Adaptive Exploration-Exploitation, High-Dimensional Optimization, Diversity Preservation, Parameter Control

**Advice:** Focus on novel mechanisms for dynamically adjusting exploration/exploitation based on *quantifiable metrics* (e.g., fitness distribution,  distance metrics in the search space),  not just qualitative observations.  Explore advanced archive management beyond simple size limits (e.g.,  crowding, Pareto dominance). Develop rigorous testing methodologies across diverse high-dimensional benchmarks.

**Avoid:** Vague terms like "sophisticated," "powerful," and "intelligent."  Avoid generic statements about exploration/exploitation balance without specifying concrete implementations.  Don't simply restate existing approaches.

**Explanation:**  The ineffective reflections lack concrete, measurable objectives and actionable strategies.  The key is to move beyond general principles to specific, testable hypotheses and innovative algorithm designs supported by empirical evidence.  Quantifiable metrics are crucial for evaluating and improving the heuristics' effectiveness.  This will involve designing new algorithms or significantly improving existing ones to address the limitations of existing approaches in high-dimensional landscapes.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 10:44:22 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Adaptive Exploration-Exploitation, High-Dimensional Optimization, Diversity Preservation, Parameter Control

**Advice:** Focus on novel mechanisms for dynamically adjusting exploration/exploitation based on *quantifiable metrics* (e.g., fitness distribution,  distance metrics in the search space),  not just qualitative observations.  Explore advanced archive management beyond simple size limits (e.g.,  crowding, Pareto dominance). Develop rigorous testing methodologies across diverse high-dimensional benchmarks.

**Avoid:** Vague terms like "sophisticated," "powerful," and "intelligent."  Avoid generic statements about exploration/exploitation balance without specifying concrete implementations.  Don't simply restate existing approaches.

**Explanation:**  The ineffective reflections lack concrete, measurable objectives and actionable strategies.  The key is to move beyond general principles to specific, testable hypotheses and innovative algorithm designs supported by empirical evidence.  Quantifiable metrics are crucial for evaluating and improving the heuristics' effectiveness.  This will involve designing new algorithms or significantly improving existing ones to address the limitations of existing approaches in high-dimensional landscapes.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 10:53:11 INFO Perform Harmony Search...
2025-06-23 10:53:22 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:22 ERROR Can not run the algorithm
2025-06-23 10:53:23 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1741
2025-06-23 10:53:23 INFO FeHistory: [-701.3158189]
2025-06-23 10:53:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:23 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 127.95470159603059, archive_size: int = 221.47157958601719, sigma_decay: float = 0.8322225700973394, initial_sigma_multiplier: float = 0.2501595232279358):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:23 ERROR Can not run the algorithm
2025-06-23 10:53:23 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0939
2025-06-23 10:53:23 INFO FeHistory: [-222.76555209]
2025-06-23 10:53:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:23 ERROR Can not run the algorithm
2025-06-23 10:53:23 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:23 INFO FeHistory: [126.12728811]
2025-06-23 10:53:23 INFO Expected Optimum FE: -100
2025-06-23 10:53:23 INFO Unimodal AOCC mean: 0.1741
2025-06-23 10:53:23 INFO Multimodal (single component) AOCC mean: 0.0939
2025-06-23 10:53:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:23 INFO AOCC mean: 0.0893
2025-06-23 10:53:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:23 ERROR Can not run the algorithm
2025-06-23 10:53:23 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1740
2025-06-23 10:53:23 INFO FeHistory: [-701.31234027]
2025-06-23 10:53:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:23 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 539.0592976522892, archive_size: int = 206.49843144238707, sigma_decay: float = 0.8754662710137232, initial_sigma_multiplier: float = 0.8424902396781155):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:23 ERROR Can not run the algorithm
2025-06-23 10:53:23 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0979
2025-06-23 10:53:23 INFO FeHistory: [-223.78779958]
2025-06-23 10:53:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:23 ERROR Can not run the algorithm
2025-06-23 10:53:23 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:23 INFO FeHistory: [197.0390696]
2025-06-23 10:53:23 INFO Expected Optimum FE: -100
2025-06-23 10:53:23 INFO Unimodal AOCC mean: 0.1740
2025-06-23 10:53:23 INFO Multimodal (single component) AOCC mean: 0.0979
2025-06-23 10:53:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:23 INFO AOCC mean: 0.0906
2025-06-23 10:53:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:23 ERROR Can not run the algorithm
2025-06-23 10:53:24 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1742
2025-06-23 10:53:24 INFO FeHistory: [-701.31999117]
2025-06-23 10:53:24 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:24 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 452.9998720701201, archive_size: int = 292.55453404257366, sigma_decay: float = 0.940751122801283, initial_sigma_multiplier: float = 0.3186651792401718):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:24 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:24 ERROR Can not run the algorithm
2025-06-23 10:53:24 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0908
2025-06-23 10:53:24 INFO FeHistory: [-221.93133272]
2025-06-23 10:53:24 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:24 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:24 ERROR Can not run the algorithm
2025-06-23 10:53:24 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:24 INFO FeHistory: [140.10369418]
2025-06-23 10:53:24 INFO Expected Optimum FE: -100
2025-06-23 10:53:24 INFO Unimodal AOCC mean: 0.1742
2025-06-23 10:53:24 INFO Multimodal (single component) AOCC mean: 0.0908
2025-06-23 10:53:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:24 INFO AOCC mean: 0.0883
2025-06-23 10:53:24 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:24 ERROR Can not run the algorithm
2025-06-23 10:53:24 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 10:53:24 INFO FeHistory: [-701.30795096]
2025-06-23 10:53:24 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:24 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 152.25515026821316, archive_size: int = 987.7227814202213, sigma_decay: float = 0.8799669269596517, initial_sigma_multiplier: float = 0.10667542663331514):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:24 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:24 ERROR Can not run the algorithm
2025-06-23 10:53:24 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0979
2025-06-23 10:53:24 INFO FeHistory: [-223.78071437]
2025-06-23 10:53:24 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:24 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:24 ERROR Can not run the algorithm
2025-06-23 10:53:24 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:24 INFO FeHistory: [171.35949321]
2025-06-23 10:53:24 INFO Expected Optimum FE: -100
2025-06-23 10:53:24 INFO Unimodal AOCC mean: 0.1739
2025-06-23 10:53:24 INFO Multimodal (single component) AOCC mean: 0.0979
2025-06-23 10:53:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:24 INFO AOCC mean: 0.0906
2025-06-23 10:53:24 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:24 ERROR Can not run the algorithm
2025-06-23 10:53:25 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 10:53:25 INFO FeHistory: [-701.32633975]
2025-06-23 10:53:25 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:25 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 897.4543976165602, archive_size: int = 557.3409774966768, sigma_decay: float = 0.9668239937875348, initial_sigma_multiplier: float = 0.8068849364156022):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:25 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:25 ERROR Can not run the algorithm
2025-06-23 10:53:25 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0870
2025-06-23 10:53:25 INFO FeHistory: [-220.80277253]
2025-06-23 10:53:25 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:25 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:25 ERROR Can not run the algorithm
2025-06-23 10:53:25 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:25 INFO FeHistory: [164.10445831]
2025-06-23 10:53:25 INFO Expected Optimum FE: -100
2025-06-23 10:53:25 INFO Unimodal AOCC mean: 0.1743
2025-06-23 10:53:25 INFO Multimodal (single component) AOCC mean: 0.0870
2025-06-23 10:53:25 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:25 INFO AOCC mean: 0.0871
2025-06-23 10:53:25 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:25 ERROR Can not run the algorithm
2025-06-23 10:53:25 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1732
2025-06-23 10:53:25 INFO FeHistory: [-701.27753323]
2025-06-23 10:53:25 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:25 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 625.9297665675053, archive_size: int = 292.55453404257366, sigma_decay: float = 0.940751122801283, initial_sigma_multiplier: float = 0.37680856753194086):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:25 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:25 ERROR Can not run the algorithm
2025-06-23 10:53:25 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0924
2025-06-23 10:53:25 INFO FeHistory: [-222.37737885]
2025-06-23 10:53:25 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:25 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:25 ERROR Can not run the algorithm
2025-06-23 10:53:25 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:25 INFO FeHistory: [204.76160294]
2025-06-23 10:53:25 INFO Expected Optimum FE: -100
2025-06-23 10:53:25 INFO Unimodal AOCC mean: 0.1732
2025-06-23 10:53:25 INFO Multimodal (single component) AOCC mean: 0.0924
2025-06-23 10:53:25 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:25 INFO AOCC mean: 0.0885
2025-06-23 10:53:25 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:25 ERROR Can not run the algorithm
2025-06-23 10:53:26 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1737
2025-06-23 10:53:26 INFO FeHistory: [-701.30039656]
2025-06-23 10:53:26 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:26 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 539.0592976522892, archive_size: int = 292.55453404257366, sigma_decay: float = 0.9006895221491983, initial_sigma_multiplier: float = 0.41489922762062326):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:26 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:26 ERROR Can not run the algorithm
2025-06-23 10:53:26 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0953
2025-06-23 10:53:26 INFO FeHistory: [-223.13091352]
2025-06-23 10:53:26 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:26 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:26 ERROR Can not run the algorithm
2025-06-23 10:53:26 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:26 INFO FeHistory: [164.66746775]
2025-06-23 10:53:26 INFO Expected Optimum FE: -100
2025-06-23 10:53:26 INFO Unimodal AOCC mean: 0.1737
2025-06-23 10:53:26 INFO Multimodal (single component) AOCC mean: 0.0953
2025-06-23 10:53:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:26 INFO AOCC mean: 0.0897
2025-06-23 10:53:26 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:26 ERROR Can not run the algorithm
2025-06-23 10:53:26 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 10:53:26 INFO FeHistory: [-701.3294293]
2025-06-23 10:53:26 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:26 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 0.1845264113373588, archive_size: int = 843.8481862319668, sigma_decay: float = 0.9008575058742336, initial_sigma_multiplier: float = 0.7592701334129676):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:26 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:26 ERROR Can not run the algorithm
2025-06-23 10:53:26 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0952
2025-06-23 10:53:26 INFO FeHistory: [-223.11030106]
2025-06-23 10:53:26 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:26 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:26 ERROR Can not run the algorithm
2025-06-23 10:53:26 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:26 INFO FeHistory: [190.88501812]
2025-06-23 10:53:26 INFO Expected Optimum FE: -100
2025-06-23 10:53:26 INFO Unimodal AOCC mean: 0.1744
2025-06-23 10:53:26 INFO Multimodal (single component) AOCC mean: 0.0952
2025-06-23 10:53:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:26 INFO AOCC mean: 0.0899
2025-06-23 10:53:26 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:26 ERROR Can not run the algorithm
2025-06-23 10:53:27 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1742
2025-06-23 10:53:27 INFO FeHistory: [-701.31961631]
2025-06-23 10:53:27 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:27 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = -100.94708574157164, archive_size: int = 408.201065593081, sigma_decay: float = 0.9008575058742336, initial_sigma_multiplier: float = 0.7605952851189253):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:27 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:27 ERROR Can not run the algorithm
2025-06-23 10:53:27 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.1021
2025-06-23 10:53:27 INFO FeHistory: [-224.76099024]
2025-06-23 10:53:27 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:27 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = -100.94708574157164, archive_size: int = 408.201065593081, sigma_decay: float = 0.9008575058742336, initial_sigma_multiplier: float = 0.7605952851189253):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:27 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:27 ERROR Can not run the algorithm
2025-06-23 10:53:27 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:27 INFO FeHistory: [206.69865646]
2025-06-23 10:53:27 INFO Expected Optimum FE: -100
2025-06-23 10:53:27 INFO Unimodal AOCC mean: 0.1742
2025-06-23 10:53:27 INFO Multimodal (single component) AOCC mean: 0.1021
2025-06-23 10:53:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:27 INFO AOCC mean: 0.0921
2025-06-23 10:53:27 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 10:53:27 ERROR Can not run the algorithm
2025-06-23 10:53:27 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1737
2025-06-23 10:53:27 INFO FeHistory: [-701.30220888]
2025-06-23 10:53:27 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 10:53:27 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 539.0592976522892, archive_size: int = 984.1637665405573, sigma_decay: float = 0.8891557945309101, initial_sigma_multiplier: float = 0.47887727702814903):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 10:53:27 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 10:53:27 ERROR Can not run the algorithm
2025-06-23 10:53:27 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0945
2025-06-23 10:53:27 INFO FeHistory: [-222.93711559]
2025-06-23 10:53:27 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 10:53:27 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 10:53:27 ERROR Can not run the algorithm
2025-06-23 10:53:27 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 10:53:27 INFO FeHistory: [205.20949388]
2025-06-23 10:53:27 INFO Expected Optimum FE: -100
2025-06-23 10:53:27 INFO Unimodal AOCC mean: 0.1737
2025-06-23 10:53:27 INFO Multimodal (single component) AOCC mean: 0.0945
2025-06-23 10:53:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 10:53:27 INFO AOCC mean: 0.0894
2025-06-23 10:53:27 INFO Generation 6, best so far: 0.14294861551599297
2025-06-23 10:53:27 INFO Population length is: 7
2025-06-23 10:53:27 INFO --- Performing Long-Term Reflection at Generation 7 ---
2025-06-23 10:53:27 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.3759e-02 |             AOCC Score on Unimodal instances: 1.7569e-01 |             AOCC Score on Multimodal instances with a single component: 1.0559e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEWithFitnessBasedCrowdingArchive
# Description: Adaptive Differential Evolution using a fitness-based crowding archive for multimodal optimization.
# Code:
```python
# Name: AdaptiveDEWithFitnessBasedCrowdingArchive
# Description: Adaptive Differential Evolution using a fitness-based crowding archive for multimodal optimization.

import numpy as np
from scipy.spatial.distance import cdist

class AdaptiveDEWithFitnessBasedCrowdingArchive:
    """
    Combines Differential Evolution (DE) with an adaptive archive that uses fitness-based crowding to maintain diversity.  
    Adaptive parameter control balances exploration and exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5
        self.CR = 0.9
        self.archive = []
        self.exploration_rate = 0.8
        self.diversity_threshold = 0.2


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_different(population, i)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Fitness-based crowding: Prioritize solutions with better fitness.
        sorted_data = combined[combined[:, -1].argsort()]

        new_archive = []
        for sol in sorted_data:
            if len(new_archive) < self.archive_size:
                new_archive.append(sol)
            else: #Crowding
                distances = cdist([sol[:-1]], np.array(new_archive)[:,:-1])
                closest_index = np.argmin(distances)
                if sol[-1] < new_archive[closest_index][-1]:
                    new_archive[closest_index] = sol

        return np.array(new_archive)[:,:-1]

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            population = np.vstack((archive, self._initialize_population()[:self.population_size - len(archive)]))
            fitness_values = objective_function(population)
            self.eval_count += len(fitness_values)
        else:
            population = archive[:self.population_size]
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
        return population, fitness_values

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (self.upper_bounds.mean() - self.lower_bounds.mean()):
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        #Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size //2] < fitness_values[self.population_size //2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate-0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))


def objective_function(x): #Example objective function, replace with your GNBG functions
    return np.sum(x**2, axis=1)

```

### Rank 2 (Overall AOCC Score: 9.3221e-02 |             AOCC Score on Unimodal instances: 1.7520e-01 |             AOCC Score on Multimodal instances with a single component: 1.0446e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCrowding
# Description: Differential evolution enhanced with adaptive mutation and crowding archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithCrowding
# Description: Differential evolution enhanced with adaptive mutation and crowding archive for multimodal optimization.
# Code:

class AdaptiveDifferentialEvolutionWithCrowding:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.archive = []
        self.adaptive_factor = 1.0


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population = self._crowding(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(population, fitness_values)
            self._adapt_parameters(fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_distinct(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring


    def _select_distinct(self, exclude_index, population_size):
        indices = np.random.choice(population_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(population_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, v, x)

    def _crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        
        new_population = []
        for i in range(0, len(combined), 2):
          parent1 = combined[i]
          parent2 = combined[i+1]
          fit1 = combined_fitness[i]
          fit2 = combined_fitness[i+1]
          if fit1 < fit2:
            new_population.append(parent1)
          else:
            new_population.append(parent2)

        return np.array(new_population[:self.population_size])

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.concatenate((self.archive, combined))
        else:
            distances = pdist(self.archive[:, :-1])
            distances = squareform(distances)
            for sol in combined:
                closest = np.argmin(distances[self.archive.shape[0]-1,:])
                if sol[-1] < self.archive[closest][-1]:
                    self.archive[closest] = sol
        return self.archive

    def _adapt_parameters(self, fitness_values):
        std_dev = np.std(fitness_values)
        if std_dev < 1e-3:
            self.F *= 1.1
            self.CR *= 0.9
        elif std_dev > 10:
            self.F *= 0.9
            self.CR *= 1.1
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)

```

### Rank 3 (Overall AOCC Score: 9.2562e-02 |             AOCC Score on Unimodal instances: 1.7572e-01 |             AOCC Score on Multimodal instances with a single component: 1.0197e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithFitnessBasedArchiveAndDiversityControl
# Description: Adaptive Differential Evolution with a fitness-based archive and diversity control for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform
from scipy.stats import qmc

# Name: AdaptiveDEwithFitnessBasedArchiveAndDiversityControl
# Description: Adaptive Differential Evolution with a fitness-based archive and diversity control for multimodal optimization.
# Code:
class AdaptiveDEwithFitnessBasedArchiveAndDiversityControl:
    """
    Combines adaptive Differential Evolution (DE) with a fitness-based archive and diversity control 
    to efficiently explore and exploit multimodal landscapes.  The algorithm adapts its parameters 
    based on the population's diversity and the success rate of the DE operations.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.diversity_threshold = 0.2 * (self.upper_bounds.mean() - self.lower_bounds.mean()) # Adjust as needed
        self.exploration_rate = 0.8


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample


    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(i)
            else:
                a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _select_different_archive(self, exclude):
        candidates = list(range(len(self.archive)))
        if len(candidates) < 3:
            return self._select_different(exclude)
        np.random.shuffle(candidates)
        return [self.archive[i][:-1] for i in candidates[:3]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            is_unique = True
            for j in range(len(new_archive)):
                if np.linalg.norm(sorted_data[i, :-1] - new_archive[j][:-1]) < 0.1:
                    is_unique = False
                    break
            if is_unique:
                new_archive.append(sorted_data[i])
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold:
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 4 (Overall AOCC Score: 9.2098e-02 |             AOCC Score on Unimodal instances: 1.7416e-01 |             AOCC Score on Multimodal instances with a single component: 1.0214e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = -100.94708574157164, archive_size: int = 408.201065593081, sigma_decay: float = 0.9008575058742336, initial_sigma_multiplier: float = 0.7605952851189253):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size:int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size:int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 5 (Overall AOCC Score: 9.1874e-02 |             AOCC Score on Unimodal instances: 1.7504e-01 |             AOCC Score on Multimodal instances with a single component: 1.0058e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithFitnessAndDiversityArchive
# Description: Adaptive Differential Evolution with fitness-based archive and diversity control.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform
from scipy.stats import qmc

# Name: AdaptiveDEwithFitnessAndDiversityArchive
# Description: Adaptive Differential Evolution with fitness-based archive and diversity control.
# Code:
class AdaptiveDEwithFitnessAndDiversityArchive:
    """
    Combines adaptive DE, a fitness-based archive, and diversity control for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8
        self.CR = 0.9
        self.archive = []
        self.diversity_threshold = 0.1 # Minimum average distance in archive
        self.sampler = qmc.LatinHypercube(d=self.dim, seed=42)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)
            a, b, c = population[indices]
            mutant = a + self.F * (b - c)
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        
        # Diversity Control: Remove solutions if diversity is too low.
        if len(new_archive)>1:
            archive_diversity = np.mean(pdist(np.array([x[:-1] for x in new_archive])))
            if archive_diversity < self.diversity_threshold:
                new_archive = self._reduce_archive(new_archive)
        
        new_archive.sort(key=lambda x: x[-1])  # Sort by fitness
        return np.array(new_archive[:self.archive_size])

    def _reduce_archive(self, archive):
        #Remove solutions to improve diversity (simple approach: remove worst)
        archive.sort(key=lambda x: x[-1],reverse=True) #Sort by fitness (worst first)
        return archive[len(archive)//2:] #remove half of the worst


    def _adapt_parameters(self, population, fitness_values):
        #Adapt F and CR based on archive diversity and success rate
        archive_diversity = np.mean(pdist(np.array([x[:-1] for x in self.archive]))) if len(self.archive) > 1 else 1.0
        success_rate = np.mean(offspring_fitness < fitness_values)
        if success_rate < 0.2 and archive_diversity < 0.5:  # Increase exploration
            self.F = min(self.F * 1.1, 1.0)
            self.CR = max(self.CR * 0.9, 0.1)
        elif success_rate > 0.8 and archive_diversity > 0.8:  # Increase exploitation
            self.F = max(self.F * 0.9, 0.1)
            self.CR = min(self.CR * 1.1, 1.0)
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)

```

### Rank 6 (Overall AOCC Score: 9.1867e-02 |             AOCC Score on Unimodal instances: 1.7521e-01 |             AOCC Score on Multimodal instances with a single component: 1.0039e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDE_LHS_with_Crowding
# Description: Combines adaptive Differential Evolution, Latin Hypercube Sampling, and a crowding archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform
from scipy.stats import qmc

# Name: AdaptiveDE_LHS_with_Crowding
# Description: Combines adaptive Differential Evolution, Latin Hypercube Sampling, and a crowding archive for robust multimodal optimization.
# Code:
class AdaptiveDE_LHS_with_Crowding:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.exploration_rate = 0.8  # Initial exploration rate
        self.crowding_factor = 0.1 # Parameter to control crowding pressure


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_crowding(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:  # Exploration vs. Exploitation
                a, b, c = self._select_different_archive(i)  # Explore archive
            else:
                a, b, c = self._select_different(i)  # Exploit current population
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _select_different_archive(self, exclude):
        candidates = list(range(len(self.archive)))
        if len(candidates) < 3:
            return self._select_different(exclude) # Fallback to population if archive too small
        np.random.shuffle(candidates)
        return [self.archive[i][:-1] for i in candidates[:3]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        next_gen = []
        next_fit = []
        
        for i in range(0, len(combined_pop), 2):
            candidate1 = combined_pop[i]
            candidate2 = combined_pop[i+1]
            fit1 = combined_fit[i]
            fit2 = combined_fit[i+1]
            
            if fit1 < fit2:
                next_gen.append(candidate1)
                next_fit.append(fit1)
            else:
                next_gen.append(candidate2)
                next_fit.append(fit2)

        
        return np.array(next_gen[:self.population_size]), np.array(next_fit[:self.population_size])


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        #Crowding based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            distances = np.linalg.norm(sorted_data[i, :-1] - np.array([x[:-1] for x in new_archive]), axis=1)
            closest_index = np.argmin(distances)
            if distances[closest_index] > self.crowding_factor * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
                new_archive.append(sorted_data[i])
            elif sorted_data[i,-1] < new_archive[closest_index][-1]:
                new_archive[closest_index] = sorted_data[i]
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        #Adaptive parameter control based on exploration/exploitation balance
        #Monitor the diversity of the population. Lower diversity indicates a need for more exploration.
        diversity = np.std(population, axis=0).mean()
        diversity_threshold = 0.2 * (self.upper_bounds.mean() - self.lower_bounds.mean())
        if diversity < diversity_threshold:  # Threshold for low diversity
            self.exploration_rate = min(1, self.exploration_rate + 0.05)  # Increase exploration
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration

        # Adjust F and CR based on success rate (exploitation)
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 10:53:32 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveDEWithFitnessBasedCrowdingArchive vs (worst) AdaptiveDE_LHS_with_Crowding, we see that the best utilizes a fitness-based crowding archive which directly incorporates fitness into the archive update, whereas the worst uses a crowding mechanism based on distance and a less sophisticated fitness-based archive update.  The best also includes adaptive parameter control based on population diversity and success rate. The worst does adaptive parameter control but it's less sophisticated.

(second best) AdaptiveDifferentialEvolutionWithCrowding vs (second worst) AdaptiveGaussianArchiveEA: The second-best uses an adaptive mutation strategy and a crowding archive which is more effective in handling multimodal problems than the adaptive Gaussian archive in the second-worst. AdaptiveDifferentialEvolutionWithCrowding also adapts parameters based on standard deviation of fitness values. AdaptiveGaussianArchiveEA uses a simpler tournament selection and less refined adaptation.

Comparing (1st) AdaptiveDEWithFitnessBasedCrowdingArchive vs (2nd) AdaptiveDifferentialEvolutionWithCrowding, we see that both use adaptive parameter control and crowding. However, the first uses a more refined fitness-based crowding in its archive, leading to better performance. Its parameter adaptation is also more nuanced, reacting to both success rate and diversity.

(3rd) AdaptiveDEwithFitnessBasedArchiveAndDiversityControl vs (4th) AdaptiveGaussianArchiveEA: The third-best utilizes Latin Hypercube Sampling for better initial population diversity and incorporates both fitness-based archive and diversity control.  In contrast, the fourth-best relies on a simpler Gaussian mutation strategy and tournament selection, showing it's less sophisticated in handling complex multimodal problems. Its archive update is also less sophisticated, simply appending solutions if they are not already present.

Comparing (second worst) AdaptiveGaussianArchiveEA vs (worst) AdaptiveDE_LHS_with_Crowding, we see that AdaptiveGaussianArchiveEA employs a Gaussian mutation strategy and a simpler crowding based approach.  AdaptiveDE_LHS_with_Crowding  uses more sophisticated DE operations with exploration/exploitation balance and its crowding strategy considers both distance and fitness. AdaptiveGaussianArchiveEA's parameter adaptation is much simpler.

Overall: The top-performing algorithms consistently incorporate fitness-based crowding archives and adaptive parameter control mechanisms, suggesting these features are crucial for efficiently handling complex multimodal landscapes. Algorithms with more sophisticated parameter adaptation and explicit diversity control tend to perform better.  The use of Latin Hypercube Sampling for initial population generation also provides advantages.

**Experience:**

Prioritizing fitness-based archive updates and sophisticated parameter adaptation strategies significantly improves performance.  Combining these with techniques like Latin Hypercube Sampling to ensure good initial diversity is highly beneficial for solving high-dimensional multimodal optimization problems.

2025-06-23 10:53:34 INFO Full response text: **Keywords:**  Fitness-based archiving, parameter adaptation, Latin Hypercube Sampling (LHS), high-dimensional multimodal optimization, diversity preservation.

**Advice:** Focus on developing novel fitness-based archive update rules that prioritize diverse, high-fitness solutions. Explore advanced parameter adaptation schemes that dynamically adjust based on real-time performance metrics (e.g., success rate, convergence indicators).  Investigate how LHS can be integrated with these adaptive strategies for robust initialization in high-dimensional spaces.  Quantify the impact of each component.

**Avoid:**  Generic statements about "exploration-exploitation balance," "adaptive mechanisms,"  and "diverse population initialization" without concrete implementations or metrics.  Avoid redundant phrasing common in the ineffective self-reflection.   Do not simply restate existing techniques.

**Explanation:**  The ineffective examples lack specificity and actionable insights.  The provided "current self-reflection" is a better starting point because it identifies *specific* methods (LHS, fitness-based archiving, parameter adaptation). The goal is to build upon these specifics to develop novel, precisely defined and testable heuristics, rather than general pronouncements about optimization.

2025-06-23 10:53:34 INFO Generating offspring via Crossover...
2025-06-23 10:57:45 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveDifferentialEvolutionWithCrowding
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithCrowding
# Description: Differential evolution enhanced with adaptive mutation and crowding archive for multimodal optimization.
# Code:

class AdaptiveDifferentialEvolutionWithCrowding:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.archive = []
        self.adaptive_factor = 1.0


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population = self._crowding(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(population, fitness_values)
            self._adapt_parameters(fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_distinct(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring


    def _select_distinct(self, exclude_index, population_size):
        indices = np.random.choice(population_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(population_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, v, x)

    def _crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        
        new_population = []
        for i in range(0, len(combined), 2):
          parent1 = combined[i]
          parent2 = combined[i+1]
          fit1 = combined_fitness[i]
          fit2 = combined_fitness[i+1]
          if fit1 < fit2:
            new_population.append(parent1)
          else:
            new_population.append(parent2)

        return np.array(new_population[:self.population_size])

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.concatenate((self.archive, combined))
        else:
            distances = pdist(self.archive[:, :-1])
            distances = squareform(distances)
            for sol in combined:
                closest = np.argmin(distances[self.archive.shape[0]-1,:])
                if sol[-1] < self.archive[closest][-1]:
                    self.archive[closest] = sol
        return self.archive

    def _adapt_parameters(self, fitness_values):
        std_dev = np.std(fitness_values)
        if std_dev < 1e-3:
            self.F *= 1.1
            self.CR *= 0.9
        elif std_dev > 10:
            self.F *= 0.9
            self.CR *= 1.1
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)


### Worse code
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Analyze & experience
- Comparing (best) AdaptiveDEWithFitnessBasedCrowdingArchive vs (worst) AdaptiveDE_LHS_with_Crowding, we see that the best utilizes a fitness-based crowding archive which directly incorporates fitness into the archive update, whereas the worst uses a crowding mechanism based on distance and a less sophisticated fitness-based archive update.  The best also includes adaptive parameter control based on population diversity and success rate. The worst does adaptive parameter control but it's less sophisticated.

(second best) AdaptiveDifferentialEvolutionWithCrowding vs (second worst) AdaptiveGaussianArchiveEA: The second-best uses an adaptive mutation strategy and a crowding archive which is more effective in handling multimodal problems than the adaptive Gaussian archive in the second-worst. AdaptiveDifferentialEvolutionWithCrowding also adapts parameters based on standard deviation of fitness values. AdaptiveGaussianArchiveEA uses a simpler tournament selection and less refined adaptation.

Comparing (1st) AdaptiveDEWithFitnessBasedCrowdingArchive vs (2nd) AdaptiveDifferentialEvolutionWithCrowding, we see that both use adaptive parameter control and crowding. However, the first uses a more refined fitness-based crowding in its archive, leading to better performance. Its parameter adaptation is also more nuanced, reacting to both success rate and diversity.

(3rd) AdaptiveDEwithFitnessBasedArchiveAndDiversityControl vs (4th) AdaptiveGaussianArchiveEA: The third-best utilizes Latin Hypercube Sampling for better initial population diversity and incorporates both fitness-based archive and diversity control.  In contrast, the fourth-best relies on a simpler Gaussian mutation strategy and tournament selection, showing it's less sophisticated in handling complex multimodal problems. Its archive update is also less sophisticated, simply appending solutions if they are not already present.

Comparing (second worst) AdaptiveGaussianArchiveEA vs (worst) AdaptiveDE_LHS_with_Crowding, we see that AdaptiveGaussianArchiveEA employs a Gaussian mutation strategy and a simpler crowding based approach.  AdaptiveDE_LHS_with_Crowding  uses more sophisticated DE operations with exploration/exploitation balance and its crowding strategy considers both distance and fitness. AdaptiveGaussianArchiveEA's parameter adaptation is much simpler.

Overall: The top-performing algorithms consistently incorporate fitness-based crowding archives and adaptive parameter control mechanisms, suggesting these features are crucial for efficiently handling complex multimodal landscapes. Algorithms with more sophisticated parameter adaptation and explicit diversity control tend to perform better.  The use of Latin Hypercube Sampling for initial population generation also provides advantages.
- **Keywords:**  Fitness-based archiving, parameter adaptation, Latin Hypercube Sampling (LHS), high-dimensional multimodal optimization, diversity preservation.

**Advice:** Focus on developing novel fitness-based archive update rules that prioritize diverse, high-fitness solutions. Explore advanced parameter adaptation schemes that dynamically adjust based on real-time performance metrics (e.g., success rate, convergence indicators).  Investigate how LHS can be integrated with these adaptive strategies for robust initialization in high-dimensional spaces.  Quantify the impact of each component.

**Avoid:**  Generic statements about "exploration-exploitation balance," "adaptive mechanisms,"  and "diverse population initialization" without concrete implementations or metrics.  Avoid redundant phrasing common in the ineffective self-reflection.   Do not simply restate existing techniques.

**Explanation:**  The ineffective examples lack specificity and actionable insights.  The provided "current self-reflection" is a better starting point because it identifies *specific* methods (LHS, fitness-based archiving, parameter adaptation). The goal is to build upon these specifics to develop novel, precisely defined and testable heuristics, rather than general pronouncements about optimization.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 10:57:45 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Fitness-based archiving, parameter adaptation, Latin Hypercube Sampling (LHS), high-dimensional multimodal optimization, diversity preservation.

**Advice:** Focus on developing novel fitness-based archive update rules that prioritize diverse, high-fitness solutions. Explore advanced parameter adaptation schemes that dynamically adjust based on real-time performance metrics (e.g., success rate, convergence indicators).  Investigate how LHS can be integrated with these adaptive strategies for robust initialization in high-dimensional spaces.  Quantify the impact of each component.

**Avoid:**  Generic statements about "exploration-exploitation balance," "adaptive mechanisms,"  and "diverse population initialization" without concrete implementations or metrics.  Avoid redundant phrasing common in the ineffective self-reflection.   Do not simply restate existing techniques.

**Explanation:**  The ineffective examples lack specificity and actionable insights.  The provided "current self-reflection" is a better starting point because it identifies *specific* methods (LHS, fitness-based archiving, parameter adaptation). The goal is to build upon these specifics to develop novel, precisely defined and testable heuristics, rather than general pronouncements about optimization.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 11:15:10 INFO Perform Harmony Search...
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:15:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:15:23 ERROR Can not run the algorithm
2025-06-23 11:15:23 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 11:15:23 INFO FeHistory: []
2025-06-23 11:15:23 INFO Expected Optimum FE: -100
2025-06-23 11:15:23 INFO Unimodal AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:15:23 INFO AOCC mean: 0.0000
2025-06-23 11:15:23 INFO Generation 7, best so far: 0.14294861551599297
2025-06-23 11:15:23 INFO Population length is: 7
2025-06-23 11:15:23 INFO --- Performing Long-Term Reflection at Generation 8 ---
2025-06-23 11:15:23 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.6339e-02 |             AOCC Score on Unimodal instances: 1.8048e-01 |             AOCC Score on Multimodal instances with a single component: 1.0854e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLHS_DE_ArchiveEA
# Description: 
# Code:
```python
import numpy as np
from scipy.stats import qmc

class AdaptiveLHS_DE_ArchiveEA:
    """
    Combines Adaptive Latin Hypercube Sampling (LHS), Differential Evolution (DE), and a fitness-based archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9 # DE crossover rate
        self.lhs_sampler = qmc.LatinHypercube(self.dim)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        sample = self.lhs_sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, self.population_size)
            v = population[a] + self.F * (population[b] - population[c])
            offspring[i] = np.clip(np.where(np.random.rand(self.dim) < self.CR, v, population[i]), self.lower_bounds, self.upper_bounds)
        return offspring


    def _select_different(self, i, n):
        candidates = np.arange(n)
        candidates = candidates[candidates != i]
        np.random.shuffle(candidates)
        return candidates[:3]

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])  # Sort by fitness
        return np.array(new_archive[:self.archive_size])

```

### Rank 2 (Overall AOCC Score: 9.5467e-02 |             AOCC Score on Unimodal instances: 1.7794e-01 |             AOCC Score on Multimodal instances with a single component: 1.0846e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDE_LHS_FitnessCrowding
# Description: Combines adaptive Differential Evolution, Latin Hypercube Sampling, and a fitness-based crowding archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc

# Name: AdaptiveDE_LHS_FitnessCrowding
# Description: Combines adaptive Differential Evolution, Latin Hypercube Sampling, and a fitness-based crowding archive for robust multimodal optimization.
# Code:
class AdaptiveDE_LHS_FitnessCrowding:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.exploration_rate = 0.8  # Initial exploration rate
        self.diversity_threshold = 0.2  # Threshold for diversity control

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_crowding(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        new_archive = [sorted_data[0]]
        for i in range(1,len(sorted_data)):
            if sorted_data[i,-1] < new_archive[-1][-1]:
                new_archive[-1] = sorted_data[i]
            else:
                new_archive.append(sorted_data[i])

        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        #Diversity based adaptation
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        #Success rate based adaptation
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 3 (Overall AOCC Score: 9.4051e-02 |             AOCC Score on Unimodal instances: 1.7505e-01 |             AOCC Score on Multimodal instances with a single component: 1.0710e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithFitnessBasedCrowdingAndLHS
# Description: Adaptive Differential Evolution with fitness-based crowding and Latin Hypercube Sampling for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc
from scipy.spatial.distance import cdist

# Name: AdaptiveDEwithFitnessBasedCrowdingAndLHS
# Description: Adaptive Differential Evolution with fitness-based crowding and Latin Hypercube Sampling for multimodal optimization.
# Code:
class AdaptiveDEwithFitnessBasedCrowdingAndLHS:
    """
    Combines adaptive Differential Evolution (DE), fitness-based crowding, and Latin Hypercube Sampling (LHS)
    for efficient multimodal optimization.  Adapts parameters based on population diversity and success rate.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.diversity_threshold = 0.2 * (self.upper_bounds.mean() - self.lower_bounds.mean())
        self.exploration_rate = 0.8
        self.crowding_factor = 0.1 # Controls crowding pressure


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_crowding(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(i)
            else:
                a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _select_different_archive(self, exclude):
        candidates = list(range(len(self.archive)))
        if len(candidates) < 3:
            return self._select_different(exclude)
        np.random.shuffle(candidates)
        return [self.archive[i][:-1] for i in candidates[:3]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        #Crowding based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            distances = cdist(sorted_data[i, :-1].reshape(1, -1), np.array([x[:-1] for x in new_archive]))
            closest_index = np.argmin(distances)
            if distances[closest_index] > self.crowding_factor * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
                new_archive.append(sorted_data[i])
            elif sorted_data[i,-1] < new_archive[closest_index][-1]:
                new_archive[closest_index] = sorted_data[i]
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold:
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))
```

### Rank 4 (Overall AOCC Score: 9.2577e-02 |             AOCC Score on Unimodal instances: 1.7519e-01 |             AOCC Score on Multimodal instances with a single component: 1.0254e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEWithFitnessBasedCrowdingAndGaussian
# Description: Differential evolution with adaptive parameters, fitness-based crowding, and Gaussian mutation for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDEWithFitnessBasedCrowdingAndGaussian
# Description: Differential evolution with adaptive parameters, fitness-based crowding, and Gaussian mutation for multimodal optimization.
# Code:
class AdaptiveDEWithFitnessBasedCrowdingAndGaussian:
    """
    Combines adaptive differential evolution, fitness-based crowding archive, and Gaussian mutation for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.archive = []
        self.adaptive_factor = 1.0
        self.gaussian_mutation_rate = 0.1 #probability of applying gaussian mutation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population = self._crowding(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(population, fitness_values)
            self._adapt_parameters(fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_distinct(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            #Gaussian mutation
            if np.random.rand() < self.gaussian_mutation_rate:
                trial += np.random.normal(0, self.adaptive_factor * 0.1 * (self.upper_bounds - self.lower_bounds), self.dim)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
            offspring[i] = trial
        return offspring

    def _select_distinct(self, exclude_index, population_size):
        indices = np.random.choice(population_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(population_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, v, x)

    def _crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        
        new_population = []
        for i in range(0, len(combined), 2):
            parent1 = combined[i]
            parent2 = combined[i+1]
            fit1 = combined_fitness[i]
            fit2 = combined_fitness[i+1]
            if fit1 < fit2:
                new_population.append(parent1)
            else:
                new_population.append(parent2)

        return np.array(new_population[:self.population_size])


    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.concatenate((self.archive, combined))
        else:
            distances = pdist(self.archive[:, :-1])
            distances = squareform(distances)
            for sol in combined:
                closest = np.argmin(distances[self.archive.shape[0]-1,:])
                if sol[-1] < self.archive[closest][-1]:
                    self.archive[closest] = sol
        return self.archive

    def _adapt_parameters(self, fitness_values):
        std_dev = np.std(fitness_values)
        if std_dev < 1e-3:
            self.F *= 1.1
            self.CR *= 0.9
        elif std_dev > 10:
            self.F *= 0.9
            self.CR *= 1.1
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
        self.adaptive_factor = 1.0 / (1 + std_dev) #Adaptive factor based on diversity


```

### Rank 5 (Overall AOCC Score: 9.1588e-02 |             AOCC Score on Unimodal instances: 1.7543e-01 |             AOCC Score on Multimodal instances with a single component: 9.9337e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEWithFitnessBasedCrowdingAndGaussian
# Description: Differential evolution with fitness-based crowding and Gaussian mutation for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDEWithFitnessBasedCrowdingAndGaussian
# Description: Differential evolution with fitness-based crowding and Gaussian mutation for multimodal optimization.
# Code:
class AdaptiveDEWithFitnessBasedCrowdingAndGaussian:
    """
    Combines adaptive differential evolution with a fitness-based crowding archive and Gaussian mutation 
    to enhance exploration and exploitation in high-dimensional multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.archive = []
        self.sigma = 0.1*(self.upper_bounds - self.lower_bounds) # Initial Gaussian mutation std dev
        self.sigma_decay = 0.99


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._gaussian_mutation(offspring) # Add Gaussian mutation
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population = self._crowding(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(population, fitness_values)
            self._adapt_parameters(fitness_values)
            self.sigma *= self.sigma_decay # Decay Gaussian mutation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_distinct(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_distinct(self, exclude_index, population_size):
        indices = np.random.choice(population_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(population_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, v, x)

    def _crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined = np.column_stack((np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness))))
        sorted_indices = np.argsort(combined[:, -1])
        return combined[sorted_indices[:self.population_size], :-1]


    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.concatenate((self.archive, combined))
        else:
            self.archive = self._fitness_based_crowding(self.archive, combined)
        return self.archive

    def _fitness_based_crowding(self, archive, new_solutions):
      combined = np.concatenate((archive, new_solutions))
      sorted_combined = combined[np.argsort(combined[:,-1])]
      return sorted_combined[:self.archive_size]


    def _adapt_parameters(self, fitness_values):
        std_dev = np.std(fitness_values)
        if std_dev < 1e-3:
            self.F *= 1.1
            self.CR *= 0.9
        elif std_dev > 10:
            self.F *= 0.9
            self.CR *= 1.1
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)

```

### Rank 6 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 544.5786550011951, archive_size: int = 703.8417646312901, sigma_decay: float = 0.9485566093575784,
                 acceptance_threshold: float = 4.267480574659941e-05, initial_sigma_multiplier: float = 0.9639469767265944, tournament_size: int = 5.566293240765627):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive = []

    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:15:29 INFO Full response text: **Analysis:**

Comparing AdaptiveLHS_DE_ArchiveEA (best) vs AdaptiveGaussianArchiveEA (worst), we see that the best uses Differential Evolution (DE), a powerful optimization technique, while the worst relies on Gaussian mutation, which is less effective in high-dimensional spaces.  The best also incorporates Latin Hypercube Sampling (LHS) for better initial population diversity, unlike the worst. The best algorithm uses a more sophisticated selection mechanism (DE-based selection) compared to the worst's simple tournament selection. The archive management in AdaptiveLHS_DE_ArchiveEA is more refined, preventing duplicate entries and prioritizes the best solutions within its capacity, unlike AdaptiveGaussianArchiveEA.

AdaptiveDE_LHS_FitnessCrowding (second best) vs AdaptiveDEWithFitnessBasedCrowdingAndGaussian (second worst) shows that AdaptiveDE_LHS_FitnessCrowding's fitness-based crowding mechanism, although it doesn't explicitly calculate distances, effectively maintains diversity. The second worst, while also using crowding, is less efficient in preserving diversity. AdaptiveDE_LHS_FitnessCrowding adaptively adjusts exploration and exploitation based on diversity, making it more robust.

Comparing AdaptiveLHS_DE_ArchiveEA (1st) vs AdaptiveDE_LHS_FitnessCrowding (2nd), we see a slight difference in performance. Both use LHS and DE, but the archive management and parameter adaptation strategies differ. AdaptiveLHS_DE_ArchiveEA's archive explicitly avoids duplicates, enhancing the exploration, while AdaptiveDE_LHS_FitnessCrowding uses a simpler crowding approach. AdaptiveLHS_DE_ArchiveEA's DE parameters are fixed, unlike AdaptiveDE_LHS_FitnessCrowding, suggesting fixed parameters might be preferable.

AdaptiveDEwithFitnessBasedCrowdingAndLHS (3rd) vs AdaptiveDEWithFitnessBasedCrowdingAndGaussian (4th) highlights that AdaptiveDEwithFitnessBasedCrowdingAndLHS's crowding mechanism leverages distance calculations for more precise diversity preservation; AdaptiveDEWithFitnessBasedCrowdingAndGaussian's simpler approach could lead to premature convergence.  Both use adaptive parameters, but the adaptive strategies differ slightly.

Comparing AdaptiveDEWithFitnessBasedCrowdingAndGaussian (second worst) vs AdaptiveGaussianArchiveEA (worst), we see that the second worst uses Differential Evolution alongside Gaussian mutation, providing a hybrid approach that's more robust than the pure Gaussian approach of the worst. Both use archive-based strategies but AdaptiveDEWithFitnessBasedCrowdingAndGaussian's crowding scheme dynamically manages the archive, avoiding redundant entries more efficiently.

Overall: The top-performing algorithms effectively combine sophisticated sampling methods (LHS), powerful optimization techniques (DE), and robust archive management strategies that balance exploration and exploitation. Adaptive parameter tuning further enhances the adaptability and robustness of these algorithms to diverse problem landscapes. Simpler approaches like pure Gaussian mutation and less refined crowding strategies lack this balance.


**Experience:**

Combining multiple advanced techniques, including adaptive parameter control and robust archive management, is crucial for solving high-dimensional, multimodal problems.  Careful design of the archive, including efficient methods to maintain diversity,  is vital for preventing premature convergence.

2025-06-23 11:15:31 INFO Full response text: **Keywords:**  High-dimensional multimodal optimization, archive diversity, adaptive parameter control, exploration-exploitation balance,  novelty search.

**Advice:** Focus on designing novel archive management strategies that prioritize *novelty* rather than just fitness. Explore alternative adaptive parameter control methods beyond simple success rate metrics (e.g., information-theoretic approaches).  Incorporate mechanisms for escaping local optima proactively, rather than reactively (e.g., simulated annealing or chaos-based operators). Investigate the use of non-parametric methods to handle the high dimensionality.

**Avoid:**  Repetitive phrasing of existing techniques ("adaptive parameter control," "exploration-exploitation balance," "diverse population").  Overemphasis on Differential Evolution; explore broader classes of algorithms. Avoid fitness-centric archive management; consider novelty, diversity, and coverage.  Avoid generic statements without concrete examples or novel ideas.

**Explanation:** The provided text largely restates known good practices. To earn the $999K, a proposal must offer genuinely *novel* heuristics. This means moving beyond simple combinations of existing techniques and proposing new methods for archive management, adaptive control, and handling high dimensionality.  The emphasis should be on originality and demonstrably superior performance over state-of-the-art methods.

2025-06-23 11:15:31 INFO Generating offspring via Crossover...
2025-06-23 11:16:37 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveDEWithFitnessBasedCrowdingAndGaussian
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDEWithFitnessBasedCrowdingAndGaussian
# Description: Differential evolution with fitness-based crowding and Gaussian mutation for multimodal optimization.
# Code:
class AdaptiveDEWithFitnessBasedCrowdingAndGaussian:
    """
    Combines adaptive differential evolution with a fitness-based crowding archive and Gaussian mutation 
    to enhance exploration and exploitation in high-dimensional multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.archive = []
        self.sigma = 0.1*(self.upper_bounds - self.lower_bounds) # Initial Gaussian mutation std dev
        self.sigma_decay = 0.99


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._gaussian_mutation(offspring) # Add Gaussian mutation
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population = self._crowding(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(population, fitness_values)
            self._adapt_parameters(fitness_values)
            self.sigma *= self.sigma_decay # Decay Gaussian mutation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_distinct(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_distinct(self, exclude_index, population_size):
        indices = np.random.choice(population_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(population_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, v, x)

    def _crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined = np.column_stack((np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness))))
        sorted_indices = np.argsort(combined[:, -1])
        return combined[sorted_indices[:self.population_size], :-1]


    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.concatenate((self.archive, combined))
        else:
            self.archive = self._fitness_based_crowding(self.archive, combined)
        return self.archive

    def _fitness_based_crowding(self, archive, new_solutions):
      combined = np.concatenate((archive, new_solutions))
      sorted_combined = combined[np.argsort(combined[:,-1])]
      return sorted_combined[:self.archive_size]


    def _adapt_parameters(self, fitness_values):
        std_dev = np.std(fitness_values)
        if std_dev < 1e-3:
            self.F *= 1.1
            self.CR *= 0.9
        elif std_dev > 10:
            self.F *= 0.9
            self.CR *= 1.1
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)


### Worse code
AdaptiveDEwithFitnessBasedCrowdingAndLHS
import numpy as np
from scipy.stats import qmc
from scipy.spatial.distance import cdist

# Name: AdaptiveDEwithFitnessBasedCrowdingAndLHS
# Description: Adaptive Differential Evolution with fitness-based crowding and Latin Hypercube Sampling for multimodal optimization.
# Code:
class AdaptiveDEwithFitnessBasedCrowdingAndLHS:
    """
    Combines adaptive Differential Evolution (DE), fitness-based crowding, and Latin Hypercube Sampling (LHS)
    for efficient multimodal optimization.  Adapts parameters based on population diversity and success rate.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.diversity_threshold = 0.2 * (self.upper_bounds.mean() - self.lower_bounds.mean())
        self.exploration_rate = 0.8
        self.crowding_factor = 0.1 # Controls crowding pressure


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_crowding(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(i)
            else:
                a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _select_different_archive(self, exclude):
        candidates = list(range(len(self.archive)))
        if len(candidates) < 3:
            return self._select_different(exclude)
        np.random.shuffle(candidates)
        return [self.archive[i][:-1] for i in candidates[:3]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_crowding(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        #Crowding based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            distances = cdist(sorted_data[i, :-1].reshape(1, -1), np.array([x[:-1] for x in new_archive]))
            closest_index = np.argmin(distances)
            if distances[closest_index] > self.crowding_factor * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
                new_archive.append(sorted_data[i])
            elif sorted_data[i,-1] < new_archive[closest_index][-1]:
                new_archive[closest_index] = sorted_data[i]
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        diversity = np.std(population, axis=0).mean()
        if diversity < self.diversity_threshold:
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

### Analyze & experience
- Comparing AdaptiveLHS_DE_ArchiveEA (best) vs AdaptiveGaussianArchiveEA (worst), we see that the best uses Differential Evolution (DE), a powerful optimization technique, while the worst relies on Gaussian mutation, which is less effective in high-dimensional spaces.  The best also incorporates Latin Hypercube Sampling (LHS) for better initial population diversity, unlike the worst. The best algorithm uses a more sophisticated selection mechanism (DE-based selection) compared to the worst's simple tournament selection. The archive management in AdaptiveLHS_DE_ArchiveEA is more refined, preventing duplicate entries and prioritizes the best solutions within its capacity, unlike AdaptiveGaussianArchiveEA.

AdaptiveDE_LHS_FitnessCrowding (second best) vs AdaptiveDEWithFitnessBasedCrowdingAndGaussian (second worst) shows that AdaptiveDE_LHS_FitnessCrowding's fitness-based crowding mechanism, although it doesn't explicitly calculate distances, effectively maintains diversity. The second worst, while also using crowding, is less efficient in preserving diversity. AdaptiveDE_LHS_FitnessCrowding adaptively adjusts exploration and exploitation based on diversity, making it more robust.

Comparing AdaptiveLHS_DE_ArchiveEA (1st) vs AdaptiveDE_LHS_FitnessCrowding (2nd), we see a slight difference in performance. Both use LHS and DE, but the archive management and parameter adaptation strategies differ. AdaptiveLHS_DE_ArchiveEA's archive explicitly avoids duplicates, enhancing the exploration, while AdaptiveDE_LHS_FitnessCrowding uses a simpler crowding approach. AdaptiveLHS_DE_ArchiveEA's DE parameters are fixed, unlike AdaptiveDE_LHS_FitnessCrowding, suggesting fixed parameters might be preferable.

AdaptiveDEwithFitnessBasedCrowdingAndLHS (3rd) vs AdaptiveDEWithFitnessBasedCrowdingAndGaussian (4th) highlights that AdaptiveDEwithFitnessBasedCrowdingAndLHS's crowding mechanism leverages distance calculations for more precise diversity preservation; AdaptiveDEWithFitnessBasedCrowdingAndGaussian's simpler approach could lead to premature convergence.  Both use adaptive parameters, but the adaptive strategies differ slightly.

Comparing AdaptiveDEWithFitnessBasedCrowdingAndGaussian (second worst) vs AdaptiveGaussianArchiveEA (worst), we see that the second worst uses Differential Evolution alongside Gaussian mutation, providing a hybrid approach that's more robust than the pure Gaussian approach of the worst. Both use archive-based strategies but AdaptiveDEWithFitnessBasedCrowdingAndGaussian's crowding scheme dynamically manages the archive, avoiding redundant entries more efficiently.

Overall: The top-performing algorithms effectively combine sophisticated sampling methods (LHS), powerful optimization techniques (DE), and robust archive management strategies that balance exploration and exploitation. Adaptive parameter tuning further enhances the adaptability and robustness of these algorithms to diverse problem landscapes. Simpler approaches like pure Gaussian mutation and less refined crowding strategies lack this balance.
- **Keywords:**  High-dimensional multimodal optimization, archive diversity, adaptive parameter control, exploration-exploitation balance,  novelty search.

**Advice:** Focus on designing novel archive management strategies that prioritize *novelty* rather than just fitness. Explore alternative adaptive parameter control methods beyond simple success rate metrics (e.g., information-theoretic approaches).  Incorporate mechanisms for escaping local optima proactively, rather than reactively (e.g., simulated annealing or chaos-based operators). Investigate the use of non-parametric methods to handle the high dimensionality.

**Avoid:**  Repetitive phrasing of existing techniques ("adaptive parameter control," "exploration-exploitation balance," "diverse population").  Overemphasis on Differential Evolution; explore broader classes of algorithms. Avoid fitness-centric archive management; consider novelty, diversity, and coverage.  Avoid generic statements without concrete examples or novel ideas.

**Explanation:** The provided text largely restates known good practices. To earn the $999K, a proposal must offer genuinely *novel* heuristics. This means moving beyond simple combinations of existing techniques and proposing new methods for archive management, adaptive control, and handling high dimensionality.  The emphasis should be on originality and demonstrably superior performance over state-of-the-art methods.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:16:37 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  High-dimensional multimodal optimization, archive diversity, adaptive parameter control, exploration-exploitation balance,  novelty search.

**Advice:** Focus on designing novel archive management strategies that prioritize *novelty* rather than just fitness. Explore alternative adaptive parameter control methods beyond simple success rate metrics (e.g., information-theoretic approaches).  Incorporate mechanisms for escaping local optima proactively, rather than reactively (e.g., simulated annealing or chaos-based operators). Investigate the use of non-parametric methods to handle the high dimensionality.

**Avoid:**  Repetitive phrasing of existing techniques ("adaptive parameter control," "exploration-exploitation balance," "diverse population").  Overemphasis on Differential Evolution; explore broader classes of algorithms. Avoid fitness-centric archive management; consider novelty, diversity, and coverage.  Avoid generic statements without concrete examples or novel ideas.

**Explanation:** The provided text largely restates known good practices. To earn the $999K, a proposal must offer genuinely *novel* heuristics. This means moving beyond simple combinations of existing techniques and proposing new methods for archive management, adaptive control, and handling high dimensionality.  The emphasis should be on originality and demonstrably superior performance over state-of-the-art methods.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 11:16:58 INFO Perform Harmony Search...
2025-06-23 11:17:09 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:09 ERROR Can not run the algorithm
2025-06-23 11:17:09 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1745
2025-06-23 11:17:09 INFO FeHistory: [-701.33387053]
2025-06-23 11:17:09 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:09 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 378.6956989249662, archive_size: int = 389.1167129717474, sigma_decay: float = 0.8072705976477792, sigma_init_factor: float = 0.3840656214139444):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:09 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:09 ERROR Can not run the algorithm
2025-06-23 11:17:09 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0882
2025-06-23 11:17:09 INFO FeHistory: [-221.15510637]
2025-06-23 11:17:09 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:09 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:09 ERROR Can not run the algorithm
2025-06-23 11:17:09 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:09 INFO FeHistory: [186.00454358]
2025-06-23 11:17:09 INFO Expected Optimum FE: -100
2025-06-23 11:17:09 INFO Unimodal AOCC mean: 0.1745
2025-06-23 11:17:09 INFO Multimodal (single component) AOCC mean: 0.0882
2025-06-23 11:17:09 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:09 INFO AOCC mean: 0.0876
2025-06-23 11:17:10 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:10 ERROR Can not run the algorithm
2025-06-23 11:17:10 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 11:17:10 INFO FeHistory: [-701.32623036]
2025-06-23 11:17:10 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:10 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 780.6201226359335, archive_size: int = 580.9388856353937, sigma_decay: float = 0.8399744394811193, sigma_init_factor: float = 0.8683004660744945):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:10 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:10 ERROR Can not run the algorithm
2025-06-23 11:17:10 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0920
2025-06-23 11:17:10 INFO FeHistory: [-222.24675083]
2025-06-23 11:17:10 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:10 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:10 ERROR Can not run the algorithm
2025-06-23 11:17:10 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:10 INFO FeHistory: [209.66212867]
2025-06-23 11:17:10 INFO Expected Optimum FE: -100
2025-06-23 11:17:10 INFO Unimodal AOCC mean: 0.1743
2025-06-23 11:17:10 INFO Multimodal (single component) AOCC mean: 0.0920
2025-06-23 11:17:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:10 INFO AOCC mean: 0.0888
2025-06-23 11:17:10 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:10 ERROR Can not run the algorithm
2025-06-23 11:17:10 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1741
2025-06-23 11:17:10 INFO FeHistory: [-701.31555975]
2025-06-23 11:17:10 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:10 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 502.9285017202818, archive_size: int = 682.2196245157767, sigma_decay: float = 0.8148081060762545, sigma_init_factor: float = 0.20987598381277422):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:10 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:10 ERROR Can not run the algorithm
2025-06-23 11:17:10 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0916
2025-06-23 11:17:10 INFO FeHistory: [-222.14429903]
2025-06-23 11:17:10 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:10 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:10 ERROR Can not run the algorithm
2025-06-23 11:17:11 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:11 INFO FeHistory: [160.08898406]
2025-06-23 11:17:11 INFO Expected Optimum FE: -100
2025-06-23 11:17:11 INFO Unimodal AOCC mean: 0.1741
2025-06-23 11:17:11 INFO Multimodal (single component) AOCC mean: 0.0916
2025-06-23 11:17:11 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:11 INFO AOCC mean: 0.0886
2025-06-23 11:17:11 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:11 ERROR Can not run the algorithm
2025-06-23 11:17:11 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 11:17:11 INFO FeHistory: [-701.29415536]
2025-06-23 11:17:11 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:11 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 283.1937382050815, archive_size: int = 852.1937659182572, sigma_decay: float = 0.9311322747484485, sigma_init_factor: float = 0.946925518044622):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:11 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:11 ERROR Can not run the algorithm
2025-06-23 11:17:11 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0896
2025-06-23 11:17:11 INFO FeHistory: [-221.58762155]
2025-06-23 11:17:11 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:11 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:11 ERROR Can not run the algorithm
2025-06-23 11:17:11 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:11 INFO FeHistory: [177.04509655]
2025-06-23 11:17:11 INFO Expected Optimum FE: -100
2025-06-23 11:17:11 INFO Unimodal AOCC mean: 0.1735
2025-06-23 11:17:11 INFO Multimodal (single component) AOCC mean: 0.0896
2025-06-23 11:17:11 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:11 INFO AOCC mean: 0.0877
2025-06-23 11:17:11 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:11 ERROR Can not run the algorithm
2025-06-23 11:17:11 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1734
2025-06-23 11:17:11 INFO FeHistory: [-701.28904818]
2025-06-23 11:17:11 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:11 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 394.46895328947977, archive_size: int = 181.19472251216206, sigma_decay: float = 0.9879039069519177, sigma_init_factor: float = 0.5632776913342986):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:11 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:11 ERROR Can not run the algorithm
2025-06-23 11:17:11 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0907
2025-06-23 11:17:11 INFO FeHistory: [-221.89986953]
2025-06-23 11:17:11 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:11 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:11 ERROR Can not run the algorithm
2025-06-23 11:17:12 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:12 INFO FeHistory: [192.46718884]
2025-06-23 11:17:12 INFO Expected Optimum FE: -100
2025-06-23 11:17:12 INFO Unimodal AOCC mean: 0.1734
2025-06-23 11:17:12 INFO Multimodal (single component) AOCC mean: 0.0907
2025-06-23 11:17:12 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:12 INFO AOCC mean: 0.0881
2025-06-23 11:17:12 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:12 ERROR Can not run the algorithm
2025-06-23 11:17:12 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 11:17:12 INFO FeHistory: [-701.2940338]
2025-06-23 11:17:12 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:12 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 780.6201226359335, archive_size: int = 733.1802066047351, sigma_decay: float = 0.8148081060762545, sigma_init_factor: float = 0.20987598381277422):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:12 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:12 ERROR Can not run the algorithm
2025-06-23 11:17:12 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0888
2025-06-23 11:17:12 INFO FeHistory: [-221.3269759]
2025-06-23 11:17:12 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:12 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:12 ERROR Can not run the algorithm
2025-06-23 11:17:12 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:12 INFO FeHistory: [236.49378735]
2025-06-23 11:17:12 INFO Expected Optimum FE: -100
2025-06-23 11:17:12 INFO Unimodal AOCC mean: 0.1735
2025-06-23 11:17:12 INFO Multimodal (single component) AOCC mean: 0.0888
2025-06-23 11:17:12 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:12 INFO AOCC mean: 0.0874
2025-06-23 11:17:12 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:12 ERROR Can not run the algorithm
2025-06-23 11:17:12 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1742
2025-06-23 11:17:12 INFO FeHistory: [-701.32184008]
2025-06-23 11:17:12 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:12 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 502.9285017202818, archive_size: int = 746.385006395113, sigma_decay: float = 0.9277691968066994, sigma_init_factor: float = 0.946925518044622):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:12 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:12 ERROR Can not run the algorithm
2025-06-23 11:17:12 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0917
2025-06-23 11:17:12 INFO FeHistory: [-222.17347688]
2025-06-23 11:17:12 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:12 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:12 ERROR Can not run the algorithm
2025-06-23 11:17:13 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:13 INFO FeHistory: [190.02306501]
2025-06-23 11:17:13 INFO Expected Optimum FE: -100
2025-06-23 11:17:13 INFO Unimodal AOCC mean: 0.1742
2025-06-23 11:17:13 INFO Multimodal (single component) AOCC mean: 0.0917
2025-06-23 11:17:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:13 INFO AOCC mean: 0.0886
2025-06-23 11:17:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:13 ERROR Can not run the algorithm
2025-06-23 11:17:13 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1745
2025-06-23 11:17:13 INFO FeHistory: [-701.33521797]
2025-06-23 11:17:13 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 462.58963174917614, archive_size: int = 852.1937659182572, sigma_decay: float = 0.9294736610508859, sigma_init_factor: float = 0.8683004660744945):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:13 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:13 ERROR Can not run the algorithm
2025-06-23 11:17:13 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0959
2025-06-23 11:17:13 INFO FeHistory: [-223.2832653]
2025-06-23 11:17:13 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:13 ERROR Can not run the algorithm
2025-06-23 11:17:13 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:13 INFO FeHistory: [199.25204297]
2025-06-23 11:17:13 INFO Expected Optimum FE: -100
2025-06-23 11:17:13 INFO Unimodal AOCC mean: 0.1745
2025-06-23 11:17:13 INFO Multimodal (single component) AOCC mean: 0.0959
2025-06-23 11:17:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:13 INFO AOCC mean: 0.0901
2025-06-23 11:17:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:13 ERROR Can not run the algorithm
2025-06-23 11:17:13 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 11:17:13 INFO FeHistory: [-701.32843307]
2025-06-23 11:17:13 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 757.9733920581302, archive_size: int = 682.2196245157767, sigma_decay: float = 0.8514496348871564, sigma_init_factor: float = 0.9974379916841589):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:13 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:13 ERROR Can not run the algorithm
2025-06-23 11:17:13 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0968
2025-06-23 11:17:13 INFO FeHistory: [-223.50377749]
2025-06-23 11:17:13 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:13 ERROR Can not run the algorithm
2025-06-23 11:17:14 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:14 INFO FeHistory: [200.46213747]
2025-06-23 11:17:14 INFO Expected Optimum FE: -100
2025-06-23 11:17:14 INFO Unimodal AOCC mean: 0.1744
2025-06-23 11:17:14 INFO Multimodal (single component) AOCC mean: 0.0968
2025-06-23 11:17:14 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:14 INFO AOCC mean: 0.0904
2025-06-23 11:17:14 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:17:14 ERROR Can not run the algorithm
2025-06-23 11:17:14 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1747
2025-06-23 11:17:14 INFO FeHistory: [-701.34231591]
2025-06-23 11:17:14 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:17:14 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 622.493980844947, archive_size: int = 682.2196245157767, sigma_decay: float = 0.9277691968066994, sigma_init_factor: float = 0.20987598381277422):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:17:14 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:17:14 ERROR Can not run the algorithm
2025-06-23 11:17:14 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0910
2025-06-23 11:17:14 INFO FeHistory: [-221.98891397]
2025-06-23 11:17:14 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:17:14 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:17:14 ERROR Can not run the algorithm
2025-06-23 11:17:14 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:17:14 INFO FeHistory: [187.04032001]
2025-06-23 11:17:14 INFO Expected Optimum FE: -100
2025-06-23 11:17:14 INFO Unimodal AOCC mean: 0.1747
2025-06-23 11:17:14 INFO Multimodal (single component) AOCC mean: 0.0910
2025-06-23 11:17:14 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:17:14 INFO AOCC mean: 0.0886
2025-06-23 11:17:14 INFO Generation 8, best so far: 0.14294861551599297
2025-06-23 11:17:14 INFO Population length is: 7
2025-06-23 11:17:14 INFO --- Performing Long-Term Reflection at Generation 9 ---
2025-06-23 11:17:14 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.3048e-02 |             AOCC Score on Unimodal instances: 1.7529e-01 |             AOCC Score on Multimodal instances with a single component: 1.0385e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDE_LHS_NoveltyArchiveEA
# Description: Combines adaptive DE, LHS, and a novelty-based archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import cdist
from scipy.stats import qmc

# Name: AdaptiveDE_LHS_NoveltyArchiveEA
# Description: Combines adaptive DE, LHS, and a novelty-based archive for multimodal optimization.
# Code:

class AdaptiveDE_LHS_NoveltyArchiveEA:
    """
    Combines adaptive Differential Evolution (DE), Latin Hypercube Sampling (LHS), and a novelty-based archive 
    to efficiently explore and exploit multimodal landscapes.  Adapts DE parameters based on diversity and success rate.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5
        self.CR = 0.9
        self.archive = []
        self.sampler = qmc.LatinHypercube(d=self.dim)
        self.exploration_rate = 0.8
        self.novelty_weight = 0.1 #weight for novelty in archive selection


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_novelty(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _latin_hypercube_sampling(self):
        sample = self.sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_novelty(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        # Novelty Calculation
        if len(self.archive) > 0:
            novelties = np.max(cdist(combined_pop, self.archive[:, :-1]), axis=1)  #Max distance to existing archive members
        else:
            novelties = np.zeros(len(combined_pop))

        #Weighted combination of fitness and novelty
        weighted_scores = combined_fit + self.novelty_weight * novelties

        sorted_indices = np.argsort(weighted_scores)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Prioritize novelty in archive update
        if len(self.archive) > 0:
            novelties = np.max(cdist(population, self.archive[:, :-1]), axis=1)
            combined = np.column_stack((combined, novelties))
            sorted_data = combined[combined[:, -1].argsort()]
        else:
             sorted_data = combined[combined[:, -1].argsort()]

        new_archive = [sorted_data[0]]
        for i in range(1,len(sorted_data)):
            if sorted_data[i,-1] < new_archive[-1][-1]:
                new_archive[-1] = sorted_data[i]
            else:
                new_archive.append(sorted_data[i])
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        diversity = np.std(population, axis=0).mean()
        if diversity < 0.2 * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))
```

### Rank 2 (Overall AOCC Score: 9.2322e-02 |             AOCC Score on Unimodal instances: 1.7553e-01 |             AOCC Score on Multimodal instances with a single component: 1.0143e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: NoveltyGuidedAdaptiveSearch
# Description: A novel EA that balances exploration and exploitation using a novelty-based archive and adaptive Lévy flights.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: NoveltyGuidedAdaptiveSearch
# Description: A novel EA that balances exploration and exploitation using a novelty-based archive and adaptive Lévy flights.

class NoveltyGuidedAdaptiveSearch:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.alpha = 1.5 # Levy flight parameter
        self.beta = 0.2 # Novelty weighting parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._levy_flight_exploration(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._novelty_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _levy_flight_exploration(self, population):
        step = np.random.levy(self.alpha, size=(self.population_size, self.dim))
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step),axis = 1,keepdims=True)
        offspring = population + step
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _novelty_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        novelty_scores = self._calculate_novelty(combined_pop)
        weighted_scores = combined_fit * (1 - self.beta) + novelty_scores * self.beta
        
        sorted_indices = np.argsort(weighted_scores)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]

        return next_gen, next_fit


    def _calculate_novelty(self, solutions):
        if not self.archive.size:
            return np.zeros(len(solutions))
        
        archive_solutions = self.archive[:, :-1]
        distances = squareform(pdist(solutions, 'euclidean'))
        min_distances = np.min(distances[:, :len(archive_solutions)], axis=1)
        novelty = 1 / (1 + min_distances)
        return novelty


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 3 (Overall AOCC Score: 9.2258e-02 |             AOCC Score on Unimodal instances: 1.7533e-01 |             AOCC Score on Multimodal instances with a single component: 1.0144e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithNoveltyCrowdingAndLHS
# Description: Adaptive Differential Evolution using novelty-based crowding and Latin Hypercube Sampling for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc
from scipy.spatial.distance import cdist

class AdaptiveDEwithNoveltyCrowdingAndLHS:
    """
    Combines adaptive Differential Evolution (DE), novelty-based crowding, and Latin Hypercube Sampling (LHS) for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5
        self.CR = 0.9
        self.archive = []
        self.novelty_threshold = 0.2  # Adjust as needed
        self.exploration_rate = 0.8


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._novelty_based_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _novelty_based_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        next_gen = []
        next_fit = []
        
        for i in range(self.population_size):
            best_candidate = None
            best_novelty = -1

            for j in range(len(combined_pop)):
                novelty = self._calculate_novelty(combined_pop[j], self.archive)
                if best_candidate is None or novelty > best_novelty:
                    best_candidate = j
                    best_novelty = novelty
            
            next_gen.append(combined_pop[best_candidate])
            next_fit.append(combined_fit[best_candidate])

        return np.array(next_gen), np.array(next_fit)

    def _calculate_novelty(self, solution, archive):
        if not archive.size: return 1.0
        distances = cdist(solution.reshape(1, -1), archive[:, :-1])
        return 1.0 / np.min(distances) if np.min(distances) > 0 else 0.0


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        # Novelty based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            novelty = self._calculate_novelty(sorted_data[i, :-1], np.array(new_archive)[:,:-1])
            if novelty > self.novelty_threshold:
                new_archive.append(sorted_data[i])
                
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        diversity = np.std(population, axis=0).mean()
        if diversity < self.novelty_threshold:
            self.exploration_rate = min(1, self.exploration_rate + 0.05)
        else:
            self.exploration_rate = max(0.1, self.exploration_rate - 0.05)

        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 4 (Overall AOCC Score: 9.2065e-02 |             AOCC Score on Unimodal instances: 1.7529e-01 |             AOCC Score on Multimodal instances with a single component: 1.0091e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: NoveltyGuidedAdaptiveSearch
# Description: Employs novelty search guided by an adaptive covariance matrix to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: NoveltyGuidedAdaptiveSearch
# Description: Employs novelty search guided by an adaptive covariance matrix to efficiently explore and exploit multimodal landscapes.

class NoveltyGuidedAdaptiveSearch:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.covariance_matrix = np.eye(self.dim)  # Initialize covariance matrix
        self.novelty_weight = 0.5  # Initial weight for novelty
        self.alpha = 0.1 # Learning rate for covariance matrix

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.archive = self._update_archive(np.vstack((self.archive[:, :-1], offspring)), np.concatenate((self.archive[:, -1], offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_covariance_matrix()
            self._adjust_novelty_weight()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self):
        parent = self.archive[np.random.randint(len(self.archive)), :-1]
        offspring = np.random.multivariate_normal(parent, self.covariance_matrix)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        # Novelty-based selection:  Prioritize solutions that are far from existing ones.

        if len(self.archive) < self.archive_size:
            self.archive = combined
        else:
            distances = pdist(combined[:, :-1])
            distances_matrix = squareform(distances)
            novelty_scores = np.mean(distances_matrix, axis=0)
            combined = np.column_stack((combined, novelty_scores))
            combined = combined[np.argsort(combined[:, -1])][::-1] #Sort by novelty
            self.archive = combined[:self.archive_size]

        return self.archive

    def _adapt_covariance_matrix(self):
        # Adaptive covariance matrix based on recent successful solutions.
        recent_solutions = self.archive[:int(0.2 * self.archive_size), :-1] # Consider top 20% from archive
        if len(recent_solutions) > 0:
            mean = np.mean(recent_solutions, axis=0)
            cov = np.cov(recent_solutions, rowvar=False)
            self.covariance_matrix = (1 - self.alpha) * self.covariance_matrix + self.alpha * cov

    def _adjust_novelty_weight(self):
        # Dynamically adjust the novelty weight based on exploration vs. exploitation needs.
        # This is a heuristic, and other strategies could be used here.
        #For example, adjust based on the diversity of the archive or the rate of fitness improvement.
        if self.eval_count > self.budget / 2 and np.std(self.archive[:, -1]) < 1:  # If later stage and fitness is converging
            self.novelty_weight *= 0.9  # Decrease novelty weight if converging
        elif self.eval_count < self.budget / 4: #If in early stages increase novelty weight.
            self.novelty_weight *=1.1
        self.novelty_weight = np.clip(self.novelty_weight, 0.1, 0.9) #Clamp the value.


```

### Rank 5 (Overall AOCC Score: 9.1431e-02 |             AOCC Score on Unimodal instances: 1.7540e-01 |             AOCC Score on Multimodal instances with a single component: 9.8892e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithNoveltyArchiveAndLHS
# Description: Adaptive Differential Evolution using LHS initialization and a novelty-based archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import qmc
from scipy.spatial.distance import cdist

# Name: AdaptiveDEwithNoveltyArchiveAndLHS
# Description: Adaptive Differential Evolution using LHS initialization and a novelty-based archive for multimodal optimization.
# Code:
class AdaptiveDEwithNoveltyArchiveAndLHS:
    """
    Combines adaptive Differential Evolution (DE) with Latin Hypercube Sampling (LHS) initialization 
    and a novelty-based archive for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.novelty_threshold = 0.1 # Controls novelty pressure
        self.exploration_rate = 0.8


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_novelty(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                a, b, c = self._select_different_archive(i)
            else:
                a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _select_different_archive(self, exclude):
        candidates = list(range(len(self.archive)))
        if len(candidates) < 3:
            return self._select_different(exclude)
        np.random.shuffle(candidates)
        return [self.archive[i][:-1] for i in candidates[:3]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_novelty(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        next_gen = []
        next_fit = []
        
        for i in range(self.population_size):
            best_idx = np.argmin(combined_fit)
            next_gen.append(combined_pop[best_idx])
            next_fit.append(combined_fit[best_idx])
            combined_pop = np.delete(combined_pop, best_idx, axis=0)
            combined_fit = np.delete(combined_fit, best_idx)

        return np.array(next_gen), np.array(next_fit)


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        new_archive = []
        for i in range(len(combined)):
            novel = True
            distances = cdist(combined[i, :-1].reshape(1, -1), np.array([x[:-1] for x in self.archive]))
            if len(self.archive) > 0 and np.min(distances) < self.novelty_threshold * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
                novel = False
            if novel and len(new_archive) < self.archive_size:
                new_archive.append(combined[i])
        
        return np.array(new_archive)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 6 (Overall AOCC Score: 9.0373e-02 |             AOCC Score on Unimodal instances: 1.7437e-01 |             AOCC Score on Multimodal instances with a single component: 9.6752e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 757.9733920581302, archive_size: int = 682.2196245157767, sigma_decay: float = 0.8514496348871564, sigma_init_factor: float = 0.9974379916841589):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:17:19 INFO Full response text: **Analysis:**

Comparing AdaptiveDE_LHS_NoveltyArchiveEA (best) vs AdaptiveGaussianArchiveEA (worst), we see that the top performer utilizes adaptive DE, LHS sampling, and a novelty archive for a more sophisticated exploration and exploitation balance. The worst algorithm uses a simpler Gaussian mutation and tournament selection, lacking the adaptive mechanisms and advanced archive management of the best one.  AdaptiveDE_LHS_NoveltyArchiveEA's adaptive parameter tuning based on population diversity and success rates contributes significantly to its superior performance.

NoveltyGuidedAdaptiveSearch (2nd best) vs AdaptiveDEwithNoveltyArchiveAndLHS (second worst): The second-best algorithm incorporates adaptive Lévy flights for exploration alongside novelty-based selection, whereas the second-worst combines adaptive DE with LHS and a novelty archive but lacks the efficient exploration strategy of Lévy flights.

Comparing AdaptiveDE_LHS_NoveltyArchiveEA (1st) vs NoveltyGuidedAdaptiveSearch (2nd), we see that AdaptiveDE_LHS_NoveltyArchiveEA's use of LHS for population initialization and the more refined archive management (novelty weighting) lead to slightly better results than Lévy flights alone.

AdaptiveDEwithNoveltyCrowdingAndLHS (3rd) vs NoveltyGuidedAdaptiveSearch (4th): Both use adaptive DE and novelty concepts.  However, the 3rd-ranked algorithm uses a more refined crowding mechanism that better manages diversity compared to the 4th-ranked algorithm's covariance matrix approach. The covariance matrix approach might be prone to premature convergence.

Comparing AdaptiveDEwithNoveltyArchiveAndLHS (second worst) vs AdaptiveGaussianArchiveEA (worst), we see that the second worst still uses DE and a novelty archive, providing a stronger framework than the simple Gaussian mutation of the worst.

Overall: The best-performing algorithms consistently incorporate adaptive parameter control, sophisticated population initialization (LHS), and effective archive management techniques based on novelty to improve both exploration and exploitation across various GNBG function groups.  Simpler approaches lacking such components struggle with complex multimodal problems.


**Experience:**

Effective heuristics necessitate adaptive parameter control, diverse population initialization, and efficient archive management techniques which balance exploration and exploitation.  Sophisticated search mechanisms like Lévy flights or adaptive DE, combined with novelty-based archive updates, prove crucial for high-dimensional multimodal optimization.

2025-06-23 11:17:21 INFO Full response text: * **Keywords:**  Adaptive parameter control,  novelty-based archive,  Lévy flights,  exploration-exploitation balance, high-dimensional multimodal optimization,  diversity preservation.

* **Advice:** Focus on developing novel archive management techniques that prioritize novelty or diversity *beyond* simple fitness-based selection. Investigate less-explored search mechanisms (e.g., beyond DE and Gaussian mutations).  Explore the use of  meta-learning to dynamically adapt the exploration-exploitation balance based on problem characteristics.

* **Avoid:** Redundant emphasis on already established techniques (DE, Gaussian mutations, Latin Hypercube).  Over-reliance on fitness as the sole criterion for archive updates or parameter adaptation.  Generic statements about exploration/exploitation balance without concrete mechanisms.

* **Explanation:** The existing reflections repetitively highlight known effective components.  A better heuristic requires pushing beyond these well-trodden paths.  The focus should be on creating genuinely novel methods for population generation, archive management, and search, and especially on intelligent, adaptive mechanisms that learn and respond to the problem landscape in real-time.  The key to unlocking a significantly improved heuristic lies in originality and adaptive intelligence.

2025-06-23 11:17:21 INFO Generating offspring via Crossover...
2025-06-23 11:19:48 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 757.9733920581302, archive_size: int = 682.2196245157767, sigma_decay: float = 0.8514496348871564, sigma_init_factor: float = 0.9974379916841589):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = sigma_init_factor * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values,atol: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=atol) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Worse code
NoveltyGuidedAdaptiveSearch
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: NoveltyGuidedAdaptiveSearch
# Description: A novel EA that balances exploration and exploitation using a novelty-based archive and adaptive Lévy flights.

class NoveltyGuidedAdaptiveSearch:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.alpha = 1.5 # Levy flight parameter
        self.beta = 0.2 # Novelty weighting parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._levy_flight_exploration(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._novelty_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _levy_flight_exploration(self, population):
        step = np.random.levy(self.alpha, size=(self.population_size, self.dim))
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step),axis = 1,keepdims=True)
        offspring = population + step
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _novelty_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        novelty_scores = self._calculate_novelty(combined_pop)
        weighted_scores = combined_fit * (1 - self.beta) + novelty_scores * self.beta
        
        sorted_indices = np.argsort(weighted_scores)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]

        return next_gen, next_fit


    def _calculate_novelty(self, solutions):
        if not self.archive.size:
            return np.zeros(len(solutions))
        
        archive_solutions = self.archive[:, :-1]
        distances = squareform(pdist(solutions, 'euclidean'))
        min_distances = np.min(distances[:, :len(archive_solutions)], axis=1)
        novelty = 1 / (1 + min_distances)
        return novelty


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]


### Analyze & experience
- Comparing AdaptiveDE_LHS_NoveltyArchiveEA (best) vs AdaptiveGaussianArchiveEA (worst), we see that the top performer utilizes adaptive DE, LHS sampling, and a novelty archive for a more sophisticated exploration and exploitation balance. The worst algorithm uses a simpler Gaussian mutation and tournament selection, lacking the adaptive mechanisms and advanced archive management of the best one.  AdaptiveDE_LHS_NoveltyArchiveEA's adaptive parameter tuning based on population diversity and success rates contributes significantly to its superior performance.

NoveltyGuidedAdaptiveSearch (2nd best) vs AdaptiveDEwithNoveltyArchiveAndLHS (second worst): The second-best algorithm incorporates adaptive Lévy flights for exploration alongside novelty-based selection, whereas the second-worst combines adaptive DE with LHS and a novelty archive but lacks the efficient exploration strategy of Lévy flights.

Comparing AdaptiveDE_LHS_NoveltyArchiveEA (1st) vs NoveltyGuidedAdaptiveSearch (2nd), we see that AdaptiveDE_LHS_NoveltyArchiveEA's use of LHS for population initialization and the more refined archive management (novelty weighting) lead to slightly better results than Lévy flights alone.

AdaptiveDEwithNoveltyCrowdingAndLHS (3rd) vs NoveltyGuidedAdaptiveSearch (4th): Both use adaptive DE and novelty concepts.  However, the 3rd-ranked algorithm uses a more refined crowding mechanism that better manages diversity compared to the 4th-ranked algorithm's covariance matrix approach. The covariance matrix approach might be prone to premature convergence.

Comparing AdaptiveDEwithNoveltyArchiveAndLHS (second worst) vs AdaptiveGaussianArchiveEA (worst), we see that the second worst still uses DE and a novelty archive, providing a stronger framework than the simple Gaussian mutation of the worst.

Overall: The best-performing algorithms consistently incorporate adaptive parameter control, sophisticated population initialization (LHS), and effective archive management techniques based on novelty to improve both exploration and exploitation across various GNBG function groups.  Simpler approaches lacking such components struggle with complex multimodal problems.
- * **Keywords:**  Adaptive parameter control,  novelty-based archive,  Lévy flights,  exploration-exploitation balance, high-dimensional multimodal optimization,  diversity preservation.

* **Advice:** Focus on developing novel archive management techniques that prioritize novelty or diversity *beyond* simple fitness-based selection. Investigate less-explored search mechanisms (e.g., beyond DE and Gaussian mutations).  Explore the use of  meta-learning to dynamically adapt the exploration-exploitation balance based on problem characteristics.

* **Avoid:** Redundant emphasis on already established techniques (DE, Gaussian mutations, Latin Hypercube).  Over-reliance on fitness as the sole criterion for archive updates or parameter adaptation.  Generic statements about exploration/exploitation balance without concrete mechanisms.

* **Explanation:** The existing reflections repetitively highlight known effective components.  A better heuristic requires pushing beyond these well-trodden paths.  The focus should be on creating genuinely novel methods for population generation, archive management, and search, and especially on intelligent, adaptive mechanisms that learn and respond to the problem landscape in real-time.  The key to unlocking a significantly improved heuristic lies in originality and adaptive intelligence.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:19:48 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Adaptive parameter control,  novelty-based archive,  Lévy flights,  exploration-exploitation balance, high-dimensional multimodal optimization,  diversity preservation.

* **Advice:** Focus on developing novel archive management techniques that prioritize novelty or diversity *beyond* simple fitness-based selection. Investigate less-explored search mechanisms (e.g., beyond DE and Gaussian mutations).  Explore the use of  meta-learning to dynamically adapt the exploration-exploitation balance based on problem characteristics.

* **Avoid:** Redundant emphasis on already established techniques (DE, Gaussian mutations, Latin Hypercube).  Over-reliance on fitness as the sole criterion for archive updates or parameter adaptation.  Generic statements about exploration/exploitation balance without concrete mechanisms.

* **Explanation:** The existing reflections repetitively highlight known effective components.  A better heuristic requires pushing beyond these well-trodden paths.  The focus should be on creating genuinely novel methods for population generation, archive management, and search, and especially on intelligent, adaptive mechanisms that learn and respond to the problem landscape in real-time.  The key to unlocking a significantly improved heuristic lies in originality and adaptive intelligence.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 11:20:08 INFO Perform Harmony Search...
2025-06-23 11:20:19 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:19 ERROR Can not run the algorithm
2025-06-23 11:20:19 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 11:20:19 INFO FeHistory: [-701.29534901]
2025-06-23 11:20:19 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:19 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 95.46394678916646, archive_size: int = 678.530933299549, sigma_decay: float = 0.9700752573952256, initial_sigma_multiplier: float = 0.22897489732747905):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:19 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:19 ERROR Can not run the algorithm
2025-06-23 11:20:19 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0935
2025-06-23 11:20:19 INFO FeHistory: [-222.67666293]
2025-06-23 11:20:19 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:20 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:20 ERROR Can not run the algorithm
2025-06-23 11:20:20 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:20 INFO FeHistory: [135.78628959]
2025-06-23 11:20:20 INFO Expected Optimum FE: -100
2025-06-23 11:20:20 INFO Unimodal AOCC mean: 0.1736
2025-06-23 11:20:20 INFO Multimodal (single component) AOCC mean: 0.0935
2025-06-23 11:20:20 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:20 INFO AOCC mean: 0.0890
2025-06-23 11:20:20 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:20 ERROR Can not run the algorithm
2025-06-23 11:20:20 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 11:20:20 INFO FeHistory: [-701.30688706]
2025-06-23 11:20:20 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:20 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 230.73694095398287, archive_size: int = 216.93453598059085, sigma_decay: float = 0.9700241435706577, initial_sigma_multiplier: float = 0.21382287023794938):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:20 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:20 ERROR Can not run the algorithm
2025-06-23 11:20:20 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0894
2025-06-23 11:20:20 INFO FeHistory: [-221.51528889]
2025-06-23 11:20:20 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:20 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:20 ERROR Can not run the algorithm
2025-06-23 11:20:20 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:20 INFO FeHistory: [204.32335814]
2025-06-23 11:20:20 INFO Expected Optimum FE: -100
2025-06-23 11:20:20 INFO Unimodal AOCC mean: 0.1739
2025-06-23 11:20:20 INFO Multimodal (single component) AOCC mean: 0.0894
2025-06-23 11:20:20 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:20 INFO AOCC mean: 0.0877
2025-06-23 11:20:20 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:20 ERROR Can not run the algorithm
2025-06-23 11:20:20 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1740
2025-06-23 11:20:20 INFO FeHistory: [-701.31139844]
2025-06-23 11:20:20 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:20 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 462.0973095041887, archive_size: int = 810.4853094484447, sigma_decay: float = 0.9793332672774789, initial_sigma_multiplier: float = 0.3152461834724742):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:20 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:20 ERROR Can not run the algorithm
2025-06-23 11:20:21 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0929
2025-06-23 11:20:21 INFO FeHistory: [-222.49138251]
2025-06-23 11:20:21 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:21 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:21 ERROR Can not run the algorithm
2025-06-23 11:20:21 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:21 INFO FeHistory: [186.33179542]
2025-06-23 11:20:21 INFO Expected Optimum FE: -100
2025-06-23 11:20:21 INFO Unimodal AOCC mean: 0.1740
2025-06-23 11:20:21 INFO Multimodal (single component) AOCC mean: 0.0929
2025-06-23 11:20:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:21 INFO AOCC mean: 0.0889
2025-06-23 11:20:21 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:21 ERROR Can not run the algorithm
2025-06-23 11:20:21 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1748
2025-06-23 11:20:21 INFO FeHistory: [-701.34783321]
2025-06-23 11:20:21 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:21 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 756.1872516033116, archive_size: int = 84.42509744955768, sigma_decay: float = 0.9709892761154294, initial_sigma_multiplier: float = 0.7778691942384663):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:21 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:21 ERROR Can not run the algorithm
2025-06-23 11:20:21 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0904
2025-06-23 11:20:21 INFO FeHistory: [-221.81128241]
2025-06-23 11:20:21 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:21 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:21 ERROR Can not run the algorithm
2025-06-23 11:20:21 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:21 INFO FeHistory: [146.98058921]
2025-06-23 11:20:21 INFO Expected Optimum FE: -100
2025-06-23 11:20:21 INFO Unimodal AOCC mean: 0.1748
2025-06-23 11:20:21 INFO Multimodal (single component) AOCC mean: 0.0904
2025-06-23 11:20:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:21 INFO AOCC mean: 0.0884
2025-06-23 11:20:21 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:21 ERROR Can not run the algorithm
2025-06-23 11:20:21 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1734
2025-06-23 11:20:21 INFO FeHistory: [-701.28704644]
2025-06-23 11:20:21 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:21 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 399.25668289498196, archive_size: int = 158.44495654051087, sigma_decay: float = 0.9041016317142083, initial_sigma_multiplier: float = 0.7772584411557341):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:21 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:21 ERROR Can not run the algorithm
2025-06-23 11:20:22 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0914
2025-06-23 11:20:22 INFO FeHistory: [-222.09898467]
2025-06-23 11:20:22 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:22 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:22 ERROR Can not run the algorithm
2025-06-23 11:20:22 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:22 INFO FeHistory: [200.72775528]
2025-06-23 11:20:22 INFO Expected Optimum FE: -100
2025-06-23 11:20:22 INFO Unimodal AOCC mean: 0.1734
2025-06-23 11:20:22 INFO Multimodal (single component) AOCC mean: 0.0914
2025-06-23 11:20:22 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:22 INFO AOCC mean: 0.0883
2025-06-23 11:20:22 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:22 ERROR Can not run the algorithm
2025-06-23 11:20:22 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1737
2025-06-23 11:20:22 INFO FeHistory: [-701.3023234]
2025-06-23 11:20:22 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:22 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 906.3710339761847, archive_size: int = 150.00990825904788, sigma_decay: float = 0.9709892761154294, initial_sigma_multiplier: float = 0.407912448704542):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:22 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:22 ERROR Can not run the algorithm
2025-06-23 11:20:22 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0929
2025-06-23 11:20:22 INFO FeHistory: [-222.5081432]
2025-06-23 11:20:22 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:22 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:22 ERROR Can not run the algorithm
2025-06-23 11:20:22 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:22 INFO FeHistory: [202.53912343]
2025-06-23 11:20:22 INFO Expected Optimum FE: -100
2025-06-23 11:20:22 INFO Unimodal AOCC mean: 0.1737
2025-06-23 11:20:22 INFO Multimodal (single component) AOCC mean: 0.0929
2025-06-23 11:20:22 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:22 INFO AOCC mean: 0.0889
2025-06-23 11:20:22 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:22 ERROR Can not run the algorithm
2025-06-23 11:20:22 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 11:20:22 INFO FeHistory: [-701.3064146]
2025-06-23 11:20:22 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:22 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 595.7910029169807, archive_size: int = 158.44495654051087, sigma_decay: float = 0.9801646494854325, initial_sigma_multiplier: float = 0.407912448704542):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:22 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:22 ERROR Can not run the algorithm
2025-06-23 11:20:23 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0907
2025-06-23 11:20:23 INFO FeHistory: [-221.89966702]
2025-06-23 11:20:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:23 ERROR Can not run the algorithm
2025-06-23 11:20:23 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:23 INFO FeHistory: [203.45775839]
2025-06-23 11:20:23 INFO Expected Optimum FE: -100
2025-06-23 11:20:23 INFO Unimodal AOCC mean: 0.1738
2025-06-23 11:20:23 INFO Multimodal (single component) AOCC mean: 0.0907
2025-06-23 11:20:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:23 INFO AOCC mean: 0.0882
2025-06-23 11:20:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:23 ERROR Can not run the algorithm
2025-06-23 11:20:23 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1734
2025-06-23 11:20:23 INFO FeHistory: [-701.2887621]
2025-06-23 11:20:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:23 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 787.3220816062195, archive_size: int = 810.4853094484447, sigma_decay: float = 0.9978069599258853, initial_sigma_multiplier: float = 0.9372210974746016):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:23 ERROR Can not run the algorithm
2025-06-23 11:20:23 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0878
2025-06-23 11:20:23 INFO FeHistory: [-221.04666909]
2025-06-23 11:20:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:23 ERROR Can not run the algorithm
2025-06-23 11:20:23 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:23 INFO FeHistory: [178.92761984]
2025-06-23 11:20:23 INFO Expected Optimum FE: -100
2025-06-23 11:20:23 INFO Unimodal AOCC mean: 0.1734
2025-06-23 11:20:23 INFO Multimodal (single component) AOCC mean: 0.0878
2025-06-23 11:20:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:23 INFO AOCC mean: 0.0871
2025-06-23 11:20:23 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:23 ERROR Can not run the algorithm
2025-06-23 11:20:23 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1748
2025-06-23 11:20:23 INFO FeHistory: [-701.34636531]
2025-06-23 11:20:23 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:23 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 399.25668289498196, archive_size: int = 84.42509744955768, sigma_decay: float = 0.9793332672774789, initial_sigma_multiplier: float = 0.7316842498402393):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:23 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:23 ERROR Can not run the algorithm
2025-06-23 11:20:24 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0965
2025-06-23 11:20:24 INFO FeHistory: [-223.42871382]
2025-06-23 11:20:24 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:24 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:24 ERROR Can not run the algorithm
2025-06-23 11:20:24 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:24 INFO FeHistory: [214.15835338]
2025-06-23 11:20:24 INFO Expected Optimum FE: -100
2025-06-23 11:20:24 INFO Unimodal AOCC mean: 0.1748
2025-06-23 11:20:24 INFO Multimodal (single component) AOCC mean: 0.0965
2025-06-23 11:20:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:24 INFO AOCC mean: 0.0904
2025-06-23 11:20:24 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:20:24 ERROR Can not run the algorithm
2025-06-23 11:20:24 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 11:20:24 INFO FeHistory: [-701.31059223]
2025-06-23 11:20:24 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:20:24 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 784.4584668148184, archive_size: int = 225.00644993825995, sigma_decay: float = 0.9051608135276037, initial_sigma_multiplier: float = 0.3816909630354457):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:20:24 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:20:24 ERROR Can not run the algorithm
2025-06-23 11:20:24 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0860
2025-06-23 11:20:24 INFO FeHistory: [-220.48422345]
2025-06-23 11:20:24 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:20:24 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:20:24 ERROR Can not run the algorithm
2025-06-23 11:20:24 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:20:24 INFO FeHistory: [187.1429574]
2025-06-23 11:20:24 INFO Expected Optimum FE: -100
2025-06-23 11:20:24 INFO Unimodal AOCC mean: 0.1739
2025-06-23 11:20:24 INFO Multimodal (single component) AOCC mean: 0.0860
2025-06-23 11:20:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:20:24 INFO AOCC mean: 0.0867
2025-06-23 11:20:24 INFO Generation 9, best so far: 0.14294861551599297
2025-06-23 11:20:24 INFO Population length is: 7
2025-06-23 11:20:24 INFO --- Performing Long-Term Reflection at Generation 10 ---
2025-06-23 11:20:24 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.3145e-02 |             AOCC Score on Unimodal instances: 1.7540e-01 |             AOCC Score on Multimodal instances with a single component: 1.0404e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLevyFlightArchiveEA
# Description: An evolutionary algorithm using adaptive Lévy flights and a novelty-based archive for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveLevyFlightArchiveEA
# Description: An evolutionary algorithm using adaptive Lévy flights and a novelty-based archive for efficient multimodal optimization.

class AdaptiveLevyFlightArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.alpha = 1.5  # Lévy flight exponent
        self.beta = 0.2  # Adaptive scaling factor
        self.novelty_threshold = 0.1 # Adjust as needed

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._levy_flight_generation(population, self.beta)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._update_population(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self.beta = max(0.01, self.beta * 0.95) #Decay beta for exploitation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _levy_flight_generation(self, population, beta):
        step_size = self._levy_flight_step(self.alpha, self.dim) * beta
        u = np.random.choice(len(population), len(population)) # Randomly select from population
        offspring = population[u] + step_size * (np.random.normal(size=(len(population), self.dim)))
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _levy_flight_step(self, alpha, dim):
        u = np.random.normal(0, 1, size=dim)
        v = np.random.normal(0, 1, size=dim)
        step = u / (np.abs(v)**(1/alpha))
        return step

    def _update_population(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        if len(self.archive) == 0:
            self.archive = combined[:min(len(combined),self.archive_size)]
            return self.archive

        distances = pdist(combined[:, :-1], 'euclidean')
        distances = squareform(distances)
        
        #select based on novelty
        new_archive = []
        for i, sol in enumerate(combined):
            novel = True
            for j,arch in enumerate(self.archive):
                if distances[i, len(self.archive)+j] < self.novelty_threshold:
                    novel = False
                    break
            if novel:
                new_archive.append(sol)
                
        self.archive = np.vstack((self.archive, np.array(new_archive)))
        self.archive = self.archive[np.argsort(self.archive[:,-1])][:min(len(self.archive),self.archive_size)]
        return self.archive
```

### Rank 2 (Overall AOCC Score: 9.3112e-02 |             AOCC Score on Unimodal instances: 1.7519e-01 |             AOCC Score on Multimodal instances with a single component: 1.0415e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithNoveltyGuidedArchive
# Description: Adaptive Differential Evolution with novelty-guided archive for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import cdist
from scipy.stats import levy

class AdaptiveDEwithNoveltyGuidedArchive:
    """
    Combines adaptive Differential Evolution (DE) with a novelty-guided archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, novelty_threshold: float = 0.2,
                 F_init: float = 0.5, CR_init: float = 0.9, levy_alpha: float = 1.5):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.novelty_threshold = novelty_threshold
        self.F = F_init
        self.CR = CR_init
        self.archive = []
        self.levy_alpha = levy_alpha


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()  # Using LHS for initialization
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._novelty_based_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        # Latin Hypercube Sampling (LHS) for diverse initialization
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample


    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _novelty_based_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        next_gen = []
        next_fit = []
        
        for i in range(self.population_size):
            best_candidate = None
            best_novelty = -1

            for j in range(len(combined_pop)):
                novelty = self._calculate_novelty(combined_pop[j], self.archive)
                if best_candidate is None or novelty > best_novelty:
                    best_candidate = j
                    best_novelty = novelty
            
            next_gen.append(combined_pop[best_candidate])
            next_fit.append(combined_fit[best_candidate])

        return np.array(next_gen), np.array(next_fit)

    def _calculate_novelty(self, solution, archive):
        if not archive.size: return 1.0
        distances = cdist(solution.reshape(1, -1), archive[:, :-1])
        return 1.0 / np.min(distances) if np.min(distances) > 0 else 0.0


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        # Novelty based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            novelty = self._calculate_novelty(sorted_data[i, :-1], np.array(new_archive)[:,:-1])
            if novelty > self.novelty_threshold:
                new_archive.append(sorted_data[i])
                
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        # Adaptive parameter control based on population diversity and success rate
        diversity = np.std(population, axis=0).mean()
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])

        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))
        self.novelty_threshold = max(0.05, min(0.5, self.novelty_threshold + 0.02*(0.5 - success_rate))) #Adjust novelty threshold

from scipy.stats import qmc #import here to avoid error

```

### Rank 3 (Overall AOCC Score: 9.2531e-02 |             AOCC Score on Unimodal instances: 1.7493e-01 |             AOCC Score on Multimodal instances with a single component: 1.0266e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLévyFlightArchiveEA
# Description: An evolutionary algorithm combining adaptive Lévy flights, a novelty-based archive, and dynamic parameter control for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveLévyFlightArchiveEA
# Description: An evolutionary algorithm combining adaptive Lévy flights, a novelty-based archive, and dynamic parameter control for efficient multimodal optimization.

class AdaptiveLévyFlightArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.alpha = 1.5  # Lévy flight exponent
        self.step_size = 0.1 * (self.upper_bounds - self.lower_bounds)
        self.novelty_threshold = 0.1  # Adjust as needed


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._levy_flight_exploration(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._next_generation(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _levy_flight_exploration(self, population):
        offspring = []
        for i in range(self.population_size):
            u = np.random.randn(self.dim)
            v = np.random.randn(self.dim)
            step = (u / (np.abs(v)**(1/self.alpha))) * self.step_size
            new_solution = population[i] + step
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        return next_gen


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)])
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])

        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _adapt_parameters(self, offspring, offspring_fitness):
        # Adaptive step size based on offspring performance (Simple Example)
        mean_fitness_improvement = np.mean(offspring_fitness) - self.best_fitness_overall
        if mean_fitness_improvement < 0:
            self.step_size *= 0.9
        else:
            self.step_size *= 1.1
        self.step_size = np.clip(self.step_size, 0.01 * (self.upper_bounds - self.lower_bounds), 0.5 * (self.upper_bounds - self.lower_bounds))
```

### Rank 4 (Overall AOCC Score: 9.1656e-02 |             AOCC Score on Unimodal instances: 1.7540e-01 |             AOCC Score on Multimodal instances with a single component: 9.9565e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLevyDEwithNoveltyArchiveAndLHS
# Description: Combines adaptive DE with Lévy flights, LHS, and a novelty archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import levy, qmc
from scipy.spatial.distance import cdist

# Name: AdaptiveLevyDEwithNoveltyArchiveAndLHS
# Description: Combines adaptive DE with Lévy flights, LHS, and a novelty archive for multimodal optimization.
# Code:
class AdaptiveLevyDEwithNoveltyArchiveAndLHS:
    """
    Combines adaptive Differential Evolution (DE) with Lévy flight exploration, 
    Latin Hypercube Sampling (LHS) initialization, and a novelty-based archive 
    for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.novelty_threshold = 0.1
        self.levy_alpha = 1.5 # Levy flight parameter
        self.exploration_rate = 0.8 # Balance between DE and Levy


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_novelty(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                a, b, c = self._select_different(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _levy_flight(self, x):
        step = levy.rvs(self.levy_alpha, size=self.dim)
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)


    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_novelty(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        next_gen = []
        next_fit = []
        
        for i in range(self.population_size):
            best_idx = np.argmin(combined_fit)
            next_gen.append(combined_pop[best_idx])
            next_fit.append(combined_fit[best_idx])
            combined_pop = np.delete(combined_pop, best_idx, axis=0)
            combined_fit = np.delete(combined_fit, best_idx)

        return np.array(next_gen), np.array(next_fit)


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        new_archive = []
        for i in range(len(combined)):
            novel = True
            distances = cdist(combined[i, :-1].reshape(1, -1), np.array([x[:-1] for x in self.archive]))
            if len(self.archive) > 0 and np.min(distances) < self.novelty_threshold * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
                novel = False
            if novel and len(new_archive) < self.archive_size:
                new_archive.append(combined[i])
        
        return np.array(new_archive)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 5 (Overall AOCC Score: 9.1515e-02 |             AOCC Score on Unimodal instances: 1.7532e-01 |             AOCC Score on Multimodal instances with a single component: 9.9220e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDELevyNoveltyEA
# Description: Combines adaptive DE, Lévy flights, and novelty-based archive for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDELevyNoveltyEA
# Description: Combines adaptive DE, Lévy flights, and novelty-based archive for efficient multimodal optimization.
class AdaptiveDELevyNoveltyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.alpha = 1.5 # Levy flight parameter
        self.beta = 0.2 # Novelty weighting parameter
        self.k=0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._novelty_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Differential Evolution
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])

            #Levy Flight perturbation
            step = np.random.levy(self.alpha, size=self.dim)
            step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
            offspring[i] += self.k * step
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_three(self, population, i):
      indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
      while i in indices:
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
      return population[indices[0]], population[indices[1]], population[indices[2]]


    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y


    def _novelty_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        novelty_scores = self._calculate_novelty(combined_pop)
        weighted_scores = combined_fit * (1 - self.beta) + novelty_scores * self.beta
        sorted_indices = np.argsort(weighted_scores)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _calculate_novelty(self, solutions):
        if not self.archive.size:
            return np.zeros(len(solutions))
        archive_solutions = self.archive[:, :-1]
        distances = squareform(pdist(solutions, 'euclidean'))
        min_distances = np.min(distances[:, :len(archive_solutions)], axis=1)
        novelty = 1 / (1 + min_distances)
        return novelty

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptation: adjust F and CR based on success rate
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 6 (Overall AOCC Score: 9.0417e-02 |             AOCC Score on Unimodal instances: 1.7480e-01 |             AOCC Score on Multimodal instances with a single component: 9.6450e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 399.25668289498196, archive_size: int = 84.42509744955768, sigma_decay: float = 0.9793332672774789, initial_sigma_multiplier: float = 0.7316842498402393):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values, acceptance_threshold: float = 1e-6):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=acceptance_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:20:30 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveLevyFlightArchiveEA vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveLevyFlightArchiveEA uses Lévy flights for exploration, which is more efficient in high-dimensional spaces than the simple Gaussian mutation in AdaptiveGaussianArchiveEA.  AdaptiveLevyFlightArchiveEA also incorporates an archive to maintain diversity and prevent premature convergence, a feature missing in AdaptiveGaussianArchiveEA. AdaptiveLevyFlightArchiveEA's adaptive beta parameter also allows for a balance between exploration and exploitation.

(second best) AdaptiveDEwithNoveltyGuidedArchive vs (second worst) AdaptiveDELevyNoveltyEA: AdaptiveDEwithNoveltyGuidedArchive uses an adaptive differential evolution strategy, which is known to be robust in multimodal optimization problems. The novelty-guided archive helps to maintain diverse solutions while focusing on unexplored areas. AdaptiveDELevyNoveltyEA, on the other hand, combines DE with Lévy flights and a novelty-based archive, but the simpler adaptation strategy and lack of explicit diversity preservation mechanisms in the archive might lead to inferior performance.  AdaptiveDEwithNoveltyGuidedArchive's sophisticated novelty calculation and archive update are also more advanced than the simpler methods of AdaptiveDELevyNoveltyEA.

Comparing (1st) AdaptiveLevyFlightArchiveEA vs (2nd) AdaptiveDEwithNoveltyGuidedArchive, we see that both algorithms utilize archives to maintain diversity and prevent premature convergence. However, AdaptiveLevyFlightArchiveEA uses Lévy flights, a more efficient exploration strategy than the DE used in the second-best algorithm, although the DE is more robust. The adaptive scaling factor in AdaptiveLevyFlightArchiveEA may provide better parameter control than AdaptiveDEwithNoveltyGuidedArchive.


(3rd) AdaptiveLévyFlightArchiveEA vs (4th) AdaptiveLevyDEwithNoveltyArchiveAndLHS:  Both use Lévy flights and archives but differ in their adaptation mechanisms. AdaptiveLévyFlightArchiveEA's dynamic step-size adjustment and simpler selection strategies could contribute to its slightly better performance. AdaptiveLevyDEwithNoveltyArchiveAndLHS's combined DE and Lévy flight approach attempts a balance but doesn't offer the clear improvement seen in the top two algorithms.

Comparing (second worst) AdaptiveDELevyNoveltyEA vs (worst) AdaptiveGaussianArchiveEA, we see a clear difference in sophistication. AdaptiveDELevyNoveltyEA leverages DE and Lévy flights, combining exploration and exploitation more effectively than the purely Gaussian approach of AdaptiveGaussianArchiveEA.  The archive in AdaptiveDELevyNoveltyEA aids in maintaining diversity, unlike AdaptiveGaussianArchiveEA.

Overall: The top-performing algorithms effectively combine exploration strategies (Lévy flights or adaptive DE) with novelty-based archives and adaptive parameter control, demonstrating that a sophisticated balance of exploration and exploitation, combined with effective diversity maintenance are key to solving the GNBG benchmarks.  The less successful methods show that merely combining multiple techniques (like DE and Lévy flights without clear mechanisms for combining them) is not sufficient to achieve good performance.


**Experience:**

Effective population initialization and diversity maintenance are crucial.  Adaptive parameter control and a balance between exploration and exploitation, guided by novelty or other diversity metrics, are key to high performance on complex multimodal problems.  Simply combining algorithms isn't enough; sophisticated integration is essential.

2025-06-23 11:20:32 INFO Full response text: **Keywords:**  Heuristic design, multimodal optimization, exploration-exploitation, diversity, adaptation, parameter control, population initialization.

**Advice:** Focus on *novel* approaches to balancing exploration and exploitation. Investigate metrics beyond simple diversity measures (e.g., consider information-theoretic measures or landscape-aware metrics). Explore less-explored adaptive parameter control strategies (e.g., reinforcement learning for parameter tuning).  Develop rigorous theoretical analysis to guide heuristic design, moving beyond empirical evaluation alone.

**Avoid:**  Redundant phrases like "effective population generation," "adaptive parameter control," and "exploration-exploitation balance." Avoid simply listing known techniques without proposing novel combinations or modifications.  Avoid focusing solely on high-dimensional problems; consider the broader context of multimodal optimization.

**Explanation:** The provided ineffective self-reflections repeatedly mention the same concepts without offering genuinely new insights.  The redefined self-reflection should emphasize *innovative* ways to combine and improve existing techniques, rather than simply reiterating known best practices.  The focus should be on creating fundamentally new heuristics, not just incremental improvements.  Theoretical backing strengthens the design, leading to more robust and reliable heuristics.

2025-06-23 11:20:32 INFO Generating offspring via Crossover...
2025-06-23 11:22:08 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveLevyDEwithNoveltyArchiveAndLHS
import numpy as np
from scipy.stats import levy, qmc
from scipy.spatial.distance import cdist

# Name: AdaptiveLevyDEwithNoveltyArchiveAndLHS
# Description: Combines adaptive DE with Lévy flights, LHS, and a novelty archive for multimodal optimization.
# Code:
class AdaptiveLevyDEwithNoveltyArchiveAndLHS:
    """
    Combines adaptive Differential Evolution (DE) with Lévy flight exploration, 
    Latin Hypercube Sampling (LHS) initialization, and a novelty-based archive 
    for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.archive = []
        self.novelty_threshold = 0.1
        self.levy_alpha = 1.5 # Levy flight parameter
        self.exploration_rate = 0.8 # Balance between DE and Levy


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._latin_hypercube_sampling()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection_with_novelty(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _latin_hypercube_sampling(self):
        sampler = qmc.LatinHypercube(d=self.dim)
        sample = sampler.random(n=self.population_size)
        scaled_sample = qmc.scale(sample, self.lower_bounds, self.upper_bounds)
        return scaled_sample

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                a, b, c = self._select_different(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _levy_flight(self, x):
        step = levy.rvs(self.levy_alpha, size=self.dim)
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)


    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection_with_novelty(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        next_gen = []
        next_fit = []
        
        for i in range(self.population_size):
            best_idx = np.argmin(combined_fit)
            next_gen.append(combined_pop[best_idx])
            next_fit.append(combined_fit[best_idx])
            combined_pop = np.delete(combined_pop, best_idx, axis=0)
            combined_fit = np.delete(combined_fit, best_idx)

        return np.array(next_gen), np.array(next_fit)


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        new_archive = []
        for i in range(len(combined)):
            novel = True
            distances = cdist(combined[i, :-1].reshape(1, -1), np.array([x[:-1] for x in self.archive]))
            if len(self.archive) > 0 and np.min(distances) < self.novelty_threshold * (np.max(self.upper_bounds) - np.min(self.lower_bounds)):
                novel = False
            if novel and len(new_archive) < self.archive_size:
                new_archive.append(combined[i])
        
        return np.array(new_archive)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))


### Worse code
AdaptiveLévyFlightArchiveEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveLévyFlightArchiveEA
# Description: An evolutionary algorithm combining adaptive Lévy flights, a novelty-based archive, and dynamic parameter control for efficient multimodal optimization.

class AdaptiveLévyFlightArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.alpha = 1.5  # Lévy flight exponent
        self.step_size = 0.1 * (self.upper_bounds - self.lower_bounds)
        self.novelty_threshold = 0.1  # Adjust as needed


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._levy_flight_exploration(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._next_generation(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _levy_flight_exploration(self, population):
        offspring = []
        for i in range(self.population_size):
            u = np.random.randn(self.dim)
            v = np.random.randn(self.dim)
            step = (u / (np.abs(v)**(1/self.alpha))) * self.step_size
            new_solution = population[i] + step
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        return next_gen


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)])
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])

        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _adapt_parameters(self, offspring, offspring_fitness):
        # Adaptive step size based on offspring performance (Simple Example)
        mean_fitness_improvement = np.mean(offspring_fitness) - self.best_fitness_overall
        if mean_fitness_improvement < 0:
            self.step_size *= 0.9
        else:
            self.step_size *= 1.1
        self.step_size = np.clip(self.step_size, 0.01 * (self.upper_bounds - self.lower_bounds), 0.5 * (self.upper_bounds - self.lower_bounds))

### Analyze & experience
- Comparing (best) AdaptiveLevyFlightArchiveEA vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveLevyFlightArchiveEA uses Lévy flights for exploration, which is more efficient in high-dimensional spaces than the simple Gaussian mutation in AdaptiveGaussianArchiveEA.  AdaptiveLevyFlightArchiveEA also incorporates an archive to maintain diversity and prevent premature convergence, a feature missing in AdaptiveGaussianArchiveEA. AdaptiveLevyFlightArchiveEA's adaptive beta parameter also allows for a balance between exploration and exploitation.

(second best) AdaptiveDEwithNoveltyGuidedArchive vs (second worst) AdaptiveDELevyNoveltyEA: AdaptiveDEwithNoveltyGuidedArchive uses an adaptive differential evolution strategy, which is known to be robust in multimodal optimization problems. The novelty-guided archive helps to maintain diverse solutions while focusing on unexplored areas. AdaptiveDELevyNoveltyEA, on the other hand, combines DE with Lévy flights and a novelty-based archive, but the simpler adaptation strategy and lack of explicit diversity preservation mechanisms in the archive might lead to inferior performance.  AdaptiveDEwithNoveltyGuidedArchive's sophisticated novelty calculation and archive update are also more advanced than the simpler methods of AdaptiveDELevyNoveltyEA.

Comparing (1st) AdaptiveLevyFlightArchiveEA vs (2nd) AdaptiveDEwithNoveltyGuidedArchive, we see that both algorithms utilize archives to maintain diversity and prevent premature convergence. However, AdaptiveLevyFlightArchiveEA uses Lévy flights, a more efficient exploration strategy than the DE used in the second-best algorithm, although the DE is more robust. The adaptive scaling factor in AdaptiveLevyFlightArchiveEA may provide better parameter control than AdaptiveDEwithNoveltyGuidedArchive.


(3rd) AdaptiveLévyFlightArchiveEA vs (4th) AdaptiveLevyDEwithNoveltyArchiveAndLHS:  Both use Lévy flights and archives but differ in their adaptation mechanisms. AdaptiveLévyFlightArchiveEA's dynamic step-size adjustment and simpler selection strategies could contribute to its slightly better performance. AdaptiveLevyDEwithNoveltyArchiveAndLHS's combined DE and Lévy flight approach attempts a balance but doesn't offer the clear improvement seen in the top two algorithms.

Comparing (second worst) AdaptiveDELevyNoveltyEA vs (worst) AdaptiveGaussianArchiveEA, we see a clear difference in sophistication. AdaptiveDELevyNoveltyEA leverages DE and Lévy flights, combining exploration and exploitation more effectively than the purely Gaussian approach of AdaptiveGaussianArchiveEA.  The archive in AdaptiveDELevyNoveltyEA aids in maintaining diversity, unlike AdaptiveGaussianArchiveEA.

Overall: The top-performing algorithms effectively combine exploration strategies (Lévy flights or adaptive DE) with novelty-based archives and adaptive parameter control, demonstrating that a sophisticated balance of exploration and exploitation, combined with effective diversity maintenance are key to solving the GNBG benchmarks.  The less successful methods show that merely combining multiple techniques (like DE and Lévy flights without clear mechanisms for combining them) is not sufficient to achieve good performance.
- **Keywords:**  Heuristic design, multimodal optimization, exploration-exploitation, diversity, adaptation, parameter control, population initialization.

**Advice:** Focus on *novel* approaches to balancing exploration and exploitation. Investigate metrics beyond simple diversity measures (e.g., consider information-theoretic measures or landscape-aware metrics). Explore less-explored adaptive parameter control strategies (e.g., reinforcement learning for parameter tuning).  Develop rigorous theoretical analysis to guide heuristic design, moving beyond empirical evaluation alone.

**Avoid:**  Redundant phrases like "effective population generation," "adaptive parameter control," and "exploration-exploitation balance." Avoid simply listing known techniques without proposing novel combinations or modifications.  Avoid focusing solely on high-dimensional problems; consider the broader context of multimodal optimization.

**Explanation:** The provided ineffective self-reflections repeatedly mention the same concepts without offering genuinely new insights.  The redefined self-reflection should emphasize *innovative* ways to combine and improve existing techniques, rather than simply reiterating known best practices.  The focus should be on creating fundamentally new heuristics, not just incremental improvements.  Theoretical backing strengthens the design, leading to more robust and reliable heuristics.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:22:08 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Heuristic design, multimodal optimization, exploration-exploitation, diversity, adaptation, parameter control, population initialization.

**Advice:** Focus on *novel* approaches to balancing exploration and exploitation. Investigate metrics beyond simple diversity measures (e.g., consider information-theoretic measures or landscape-aware metrics). Explore less-explored adaptive parameter control strategies (e.g., reinforcement learning for parameter tuning).  Develop rigorous theoretical analysis to guide heuristic design, moving beyond empirical evaluation alone.

**Avoid:**  Redundant phrases like "effective population generation," "adaptive parameter control," and "exploration-exploitation balance." Avoid simply listing known techniques without proposing novel combinations or modifications.  Avoid focusing solely on high-dimensional problems; consider the broader context of multimodal optimization.

**Explanation:** The provided ineffective self-reflections repeatedly mention the same concepts without offering genuinely new insights.  The redefined self-reflection should emphasize *innovative* ways to combine and improve existing techniques, rather than simply reiterating known best practices.  The focus should be on creating fundamentally new heuristics, not just incremental improvements.  Theoretical backing strengthens the design, leading to more robust and reliable heuristics.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 11:44:41 INFO Perform Harmony Search...
2025-06-23 11:44:52 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:52 ERROR Can not run the algorithm
2025-06-23 11:44:52 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1739
2025-06-23 11:44:52 INFO FeHistory: [-701.30991213]
2025-06-23 11:44:52 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:52 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 488.0531870128282, archive_size: int = 842.463314564085, sigma_decay: float = 0.9525001529577479,
                 acceptance_threshold: float = 0.009578459547506727):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:52 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:52 ERROR Can not run the algorithm
2025-06-23 11:44:53 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0920
2025-06-23 11:44:53 INFO FeHistory: [-222.25138455]
2025-06-23 11:44:53 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:53 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:53 ERROR Can not run the algorithm
2025-06-23 11:44:53 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:53 INFO FeHistory: [179.42210411]
2025-06-23 11:44:53 INFO Expected Optimum FE: -100
2025-06-23 11:44:53 INFO Unimodal AOCC mean: 0.1739
2025-06-23 11:44:53 INFO Multimodal (single component) AOCC mean: 0.0920
2025-06-23 11:44:53 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:53 INFO AOCC mean: 0.0886
2025-06-23 11:44:53 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:53 ERROR Can not run the algorithm
2025-06-23 11:44:53 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1732
2025-06-23 11:44:53 INFO FeHistory: [-701.28051469]
2025-06-23 11:44:53 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:53 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 351.942546610934, archive_size: int = 692.1505850877647, sigma_decay: float = 0.9866483651292571,
                 acceptance_threshold: float = 0.0067812887196421956):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:53 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:53 ERROR Can not run the algorithm
2025-06-23 11:44:53 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0899
2025-06-23 11:44:53 INFO FeHistory: [-221.66904197]
2025-06-23 11:44:53 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:53 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:53 ERROR Can not run the algorithm
2025-06-23 11:44:53 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:53 INFO FeHistory: [194.82028858]
2025-06-23 11:44:53 INFO Expected Optimum FE: -100
2025-06-23 11:44:53 INFO Unimodal AOCC mean: 0.1732
2025-06-23 11:44:53 INFO Multimodal (single component) AOCC mean: 0.0899
2025-06-23 11:44:53 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:53 INFO AOCC mean: 0.0877
2025-06-23 11:44:53 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:53 ERROR Can not run the algorithm
2025-06-23 11:44:53 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1728
2025-06-23 11:44:53 INFO FeHistory: [-701.26129178]
2025-06-23 11:44:53 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:53 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 626.2203559138, archive_size: int = 372.06762608215024, sigma_decay: float = 0.9538806025270211,
                 acceptance_threshold: float = 0.009137676055981035):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:53 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:53 ERROR Can not run the algorithm
2025-06-23 11:44:54 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0948
2025-06-23 11:44:54 INFO FeHistory: [-223.01263355]
2025-06-23 11:44:54 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:54 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:54 ERROR Can not run the algorithm
2025-06-23 11:44:54 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:54 INFO FeHistory: [192.55828335]
2025-06-23 11:44:54 INFO Expected Optimum FE: -100
2025-06-23 11:44:54 INFO Unimodal AOCC mean: 0.1728
2025-06-23 11:44:54 INFO Multimodal (single component) AOCC mean: 0.0948
2025-06-23 11:44:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:54 INFO AOCC mean: 0.0892
2025-06-23 11:44:54 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:54 ERROR Can not run the algorithm
2025-06-23 11:44:54 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1740
2025-06-23 11:44:54 INFO FeHistory: [-701.31466808]
2025-06-23 11:44:54 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:54 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 126.65037013349018, archive_size: int = 111.00060761319567, sigma_decay: float = 0.9229715880388911,
                 acceptance_threshold: float = 0.005641087635120949):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:54 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:54 ERROR Can not run the algorithm
2025-06-23 11:44:54 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0951
2025-06-23 11:44:54 INFO FeHistory: [-223.08072475]
2025-06-23 11:44:54 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:54 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:54 ERROR Can not run the algorithm
2025-06-23 11:44:54 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:54 INFO FeHistory: [204.67765499]
2025-06-23 11:44:54 INFO Expected Optimum FE: -100
2025-06-23 11:44:54 INFO Unimodal AOCC mean: 0.1740
2025-06-23 11:44:54 INFO Multimodal (single component) AOCC mean: 0.0951
2025-06-23 11:44:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:54 INFO AOCC mean: 0.0897
2025-06-23 11:44:54 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:54 ERROR Can not run the algorithm
2025-06-23 11:44:54 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1745
2025-06-23 11:44:54 INFO FeHistory: [-701.33394526]
2025-06-23 11:44:54 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:54 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 206.7202472809854, archive_size: int = 145.85902903125228, sigma_decay: float = 0.9605722878070719,
                 acceptance_threshold: float = 0.0015310263766812723):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:54 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:54 ERROR Can not run the algorithm
2025-06-23 11:44:55 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0930
2025-06-23 11:44:55 INFO FeHistory: [-222.52805421]
2025-06-23 11:44:55 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:55 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:55 ERROR Can not run the algorithm
2025-06-23 11:44:55 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:55 INFO FeHistory: [184.92514]
2025-06-23 11:44:55 INFO Expected Optimum FE: -100
2025-06-23 11:44:55 INFO Unimodal AOCC mean: 0.1745
2025-06-23 11:44:55 INFO Multimodal (single component) AOCC mean: 0.0930
2025-06-23 11:44:55 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:55 INFO AOCC mean: 0.0892
2025-06-23 11:44:55 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:55 ERROR Can not run the algorithm
2025-06-23 11:44:55 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 11:44:55 INFO FeHistory: [-701.327273]
2025-06-23 11:44:55 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:55 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 488.0531870128282, archive_size: int = 472.3639550174274, sigma_decay: float = 0.9252434874743535,
                 acceptance_threshold: float = 0.0015310263766812723):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:55 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:55 ERROR Can not run the algorithm
2025-06-23 11:44:55 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0943
2025-06-23 11:44:55 INFO FeHistory: [-222.86528972]
2025-06-23 11:44:55 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:55 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:55 ERROR Can not run the algorithm
2025-06-23 11:44:55 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:55 INFO FeHistory: [169.54010816]
2025-06-23 11:44:55 INFO Expected Optimum FE: -100
2025-06-23 11:44:55 INFO Unimodal AOCC mean: 0.1743
2025-06-23 11:44:55 INFO Multimodal (single component) AOCC mean: 0.0943
2025-06-23 11:44:55 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:55 INFO AOCC mean: 0.0895
2025-06-23 11:44:55 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:55 ERROR Can not run the algorithm
2025-06-23 11:44:56 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1733
2025-06-23 11:44:56 INFO FeHistory: [-701.28440928]
2025-06-23 11:44:56 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:56 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 332.2253990695497, archive_size: int = 111.00060761319567, sigma_decay: float = 0.9781054191331355,
                 acceptance_threshold: float = 0.0006531800844728245):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:56 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:56 ERROR Can not run the algorithm
2025-06-23 11:44:56 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0898
2025-06-23 11:44:56 INFO FeHistory: [-221.63569325]
2025-06-23 11:44:56 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:56 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:56 ERROR Can not run the algorithm
2025-06-23 11:44:56 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:56 INFO FeHistory: [146.76394422]
2025-06-23 11:44:56 INFO Expected Optimum FE: -100
2025-06-23 11:44:56 INFO Unimodal AOCC mean: 0.1733
2025-06-23 11:44:56 INFO Multimodal (single component) AOCC mean: 0.0898
2025-06-23 11:44:56 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:56 INFO AOCC mean: 0.0877
2025-06-23 11:44:56 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:56 ERROR Can not run the algorithm
2025-06-23 11:44:56 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1737
2025-06-23 11:44:56 INFO FeHistory: [-701.30164346]
2025-06-23 11:44:56 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:56 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 206.7202472809854, archive_size: int = 842.463314564085, sigma_decay: float = 0.9088462485415724,
                 acceptance_threshold: float = 0.0015310263766812723):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:56 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:56 ERROR Can not run the algorithm
2025-06-23 11:44:56 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0892
2025-06-23 11:44:56 INFO FeHistory: [-221.45141327]
2025-06-23 11:44:56 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:56 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:56 ERROR Can not run the algorithm
2025-06-23 11:44:56 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:56 INFO FeHistory: [192.7106919]
2025-06-23 11:44:56 INFO Expected Optimum FE: -100
2025-06-23 11:44:56 INFO Unimodal AOCC mean: 0.1737
2025-06-23 11:44:56 INFO Multimodal (single component) AOCC mean: 0.0892
2025-06-23 11:44:56 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:56 INFO AOCC mean: 0.0876
2025-06-23 11:44:56 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:56 ERROR Can not run the algorithm
2025-06-23 11:44:57 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1743
2025-06-23 11:44:57 INFO FeHistory: [-701.32658112]
2025-06-23 11:44:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:57 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 21.323400709827823, archive_size: int = 306.4365011494163, sigma_decay: float = 0.9252434874743535,
                 acceptance_threshold: float = 0.008560870734092564):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:57 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:57 ERROR Can not run the algorithm
2025-06-23 11:44:57 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0914
2025-06-23 11:44:57 INFO FeHistory: [-222.0777775]
2025-06-23 11:44:57 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:57 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:57 ERROR Can not run the algorithm
2025-06-23 11:44:57 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:57 INFO FeHistory: [201.27635795]
2025-06-23 11:44:57 INFO Expected Optimum FE: -100
2025-06-23 11:44:57 INFO Unimodal AOCC mean: 0.1743
2025-06-23 11:44:57 INFO Multimodal (single component) AOCC mean: 0.0914
2025-06-23 11:44:57 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:57 INFO AOCC mean: 0.0886
2025-06-23 11:44:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:44:57 ERROR Can not run the algorithm
2025-06-23 11:44:57 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 11:44:57 INFO FeHistory: [-701.29162624]
2025-06-23 11:44:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:44:57 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 321.77051273686504, archive_size: int = 726.955120959428, sigma_decay: float = 0.9538806025270211,
                 acceptance_threshold: float = 0.009137676055981035):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:44:57 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:44:57 ERROR Can not run the algorithm
2025-06-23 11:44:57 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0925
2025-06-23 11:44:57 INFO FeHistory: [-222.39080842]
2025-06-23 11:44:57 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:44:57 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:44:57 ERROR Can not run the algorithm
2025-06-23 11:44:57 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:44:57 INFO FeHistory: [199.7209289]
2025-06-23 11:44:57 INFO Expected Optimum FE: -100
2025-06-23 11:44:57 INFO Unimodal AOCC mean: 0.1735
2025-06-23 11:44:57 INFO Multimodal (single component) AOCC mean: 0.0925
2025-06-23 11:44:57 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:44:57 INFO AOCC mean: 0.0887
2025-06-23 11:44:57 INFO Generation 10, best so far: 0.14294861551599297
2025-06-23 11:44:57 INFO Population length is: 7
2025-06-23 11:44:57 INFO --- Performing Long-Term Reflection at Generation 11 ---
2025-06-23 11:44:57 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 9.6000e-02 |             AOCC Score on Unimodal instances: 1.7975e-01 |             AOCC Score on Multimodal instances with a single component: 1.0825e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A novel EA employing adaptive covariance matrices and niching to efficiently explore multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import multivariate_normal

# Name: AdaptiveMultimodalOptimizer
# Description: A novel EA employing adaptive covariance matrices and niching to efficiently explore multimodal landscapes.
# Code:

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.num_niches = 10  # Number of niches to maintain
        self.niche_radius = 0.5 * np.mean(self.upper_bounds - self.lower_bounds) # Initial niche radius
        self.covariance_matrices = [np.eye(self.dim) for _ in range(self.num_niches)] # Initialize covariance matrices
        self.niche_centers = self._initialize_niches()

    def _initialize_niches(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.num_niches, self.dim))

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._generate_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            self._update_niches(population, fitness_values)
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            population = np.concatenate((population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))
            
            #Selection (elitism)
            sorted_indices = np.argsort(fitness_values)
            population = population[sorted_indices[:self.population_size]]
            fitness_values = fitness_values[sorted_indices[:self.population_size]]

            self._update_best(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_population(self):
        population = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            niche_index = np.random.randint(0, self.num_niches)
            population[i] = multivariate_normal.rvs(mean=self.niche_centers[niche_index], cov=self.covariance_matrices[niche_index])
        return np.clip(population, self.lower_bounds, self.upper_bounds)


    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            niche_index = np.random.randint(0, self.num_niches)
            offspring[i] = multivariate_normal.rvs(mean=self.niche_centers[niche_index], cov=self.covariance_matrices[niche_index])
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _update_niches(self, population, fitness_values):
        for i in range(self.num_niches):
            closest_individuals = []
            for j in range(len(population)):
                distance = np.linalg.norm(population[j] - self.niche_centers[i])
                if distance < self.niche_radius:
                    closest_individuals.append((population[j], fitness_values[j]))
            
            if closest_individuals:
                closest_individuals.sort(key=lambda x: x[1]) # Sort by fitness
                best_individual = closest_individuals[0][0]
                self.niche_centers[i] = best_individual
                # Update covariance matrix (simplified update)
                self.covariance_matrices[i] = np.cov(np.array([x[0] for x in closest_individuals]).T) + 0.1*np.eye(self.dim)  #add small regularization to prevent singularity.


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

```

### Rank 2 (Overall AOCC Score: 9.2491e-02 |             AOCC Score on Unimodal instances: 1.7528e-01 |             AOCC Score on Multimodal instances with a single component: 1.0219e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDELevyArchiveEA
# Description: Combines adaptive DE, Lévy flights, and a novelty archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDELevyArchiveEA
# Description: Combines adaptive DE, Lévy flights, and a novelty archive for multimodal optimization.
class AdaptiveDELevyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.alpha = 1.5  # Lévy flight parameter
        self.novelty_threshold = 0.1 # Minimum distance for novelty
        self.k = 0.1 #Levy Flight scaling


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_levy = self._generate_offspring_levy(population)
            offspring = np.vstack((offspring_de, offspring_levy))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._selection(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_levy(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            step = np.random.levy(self.alpha, size=self.dim)
            step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
            new_solution = population[i] + self.k * step
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)


    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive
        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)])
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])
        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))
```

### Rank 3 (Overall AOCC Score: 9.2371e-02 |             AOCC Score on Unimodal instances: 1.7507e-01 |             AOCC Score on Multimodal instances with a single component: 1.0204e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLevyDEArchiveEA
# Description: Combines adaptive DE, Lévy flights, and a novelty archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import levy
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveLevyDEArchiveEA
# Description: Combines adaptive DE, Lévy flights, and a novelty archive for multimodal optimization.
# Code:
class AdaptiveLevyDEArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.levy_alpha = 1.5 # Levy flight parameter
        self.exploration_rate = 0.8 # Balance between DE and Levy
        self.novelty_threshold = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                a, b, c = self._select_different(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _levy_flight(self, x):
        step = levy.rvs(self.levy_alpha, size=self.dim)
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:min(len(combined), self.archive_size)]
            return self.archive

        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)]) if len(self.archive)>0 else np.inf
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])

        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 4 (Overall AOCC Score: 9.2292e-02 |             AOCC Score on Unimodal instances: 1.7544e-01 |             AOCC Score on Multimodal instances with a single component: 1.0143e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDELevyFlightArchiveEA
# Description: Combines adaptive DE, Lévy flights, and a novelty archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import levy
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDELevyFlightArchiveEA
# Description: Combines adaptive DE, Lévy flights, and a novelty archive for multimodal optimization.
# Code:
class AdaptiveDELevyFlightArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.alpha = 1.5  # Lévy flight exponent
        self.beta = 0.2  # Lévy flight scaling factor (adaptive)
        self.novelty_threshold = 0.1  # Archive novelty threshold
        self.exploration_rate = 0.8 # Probability of using Levy flight

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                a, b, c = self._select_different(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _levy_flight(self, x):
        step = self._levy_flight_step(self.alpha, self.dim) * self.beta
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)

    def _levy_flight_step(self, alpha, dim):
        u = np.random.normal(0, 1, size=dim)
        v = np.random.normal(0, 1, size=dim)
        step = u / (np.abs(v)**(1/alpha))
        return step

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:min(len(combined), self.archive_size)]
            return self.archive

        distances = pdist(combined[:, :-1], 'euclidean')
        distances = squareform(distances)
        
        new_archive = []
        for i, sol in enumerate(combined):
            novel = True
            for j, arch in enumerate(self.archive):
                if distances[i, len(self.archive) + j] < self.novelty_threshold:
                    novel = False
                    break
            if novel and len(new_archive) < self.archive_size:
                new_archive.append(sol)

        self.archive = np.vstack((self.archive, np.array(new_archive)))
        self.archive = self.archive[np.argsort(self.archive[:, -1])][:min(len(self.archive), self.archive_size)]
        return self.archive

    def _adapt_parameters(self, population, fitness_values):
        #Adapt Beta only.
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.beta = max(0.01, self.beta * (0.95 + 0.1 * (success_rate - 0.5) ))

```

### Rank 5 (Overall AOCC Score: 9.1097e-02 |             AOCC Score on Unimodal instances: 1.7502e-01 |             AOCC Score on Multimodal instances with a single component: 9.8268e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithLevyFlightAndNoveltyArchive
# Description: Combines adaptive Differential Evolution, Lévy flights, and a novelty-guided archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import cdist
from scipy.stats import levy

# Name: AdaptiveDEwithLevyFlightAndNoveltyArchive
# Description: Combines adaptive Differential Evolution, Lévy flights, and a novelty-guided archive for robust multimodal optimization.
# Code:
class AdaptiveDEwithLevyFlightAndNoveltyArchive:
    """
    Combines adaptive Differential Evolution (DE), Lévy flights, and a novelty-guided archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, novelty_threshold: float = 0.2,
                 F_init: float = 0.5, CR_init: float = 0.9, levy_alpha: float = 1.5):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.novelty_threshold = novelty_threshold
        self.F = F_init
        self.CR = CR_init
        self.archive = []
        self.levy_alpha = levy_alpha


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._novelty_based_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Differential Evolution
            a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Levy Flight perturbation
            levy_step = levy.rvs(self.levy_alpha, size=self.dim)
            mutant = mutant + 0.1 * levy_step * (self.upper_bounds - self.lower_bounds) #scale levy step
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _novelty_based_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _calculate_novelty(self, solution, archive):
        if not archive.size: return 1.0
        distances = cdist(solution.reshape(1, -1), archive[:, :-1])
        return 1.0 / np.min(distances) if np.min(distances) > 0 else 0.0


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        # Novelty based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            novelty = self._calculate_novelty(sorted_data[i, :-1], np.array(new_archive)[:,:-1])
            if novelty > self.novelty_threshold:
                new_archive.append(sorted_data[i])
                
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptation for demonstration; replace with more sophisticated methods
        self.F = max(0.1, min(1.0, self.F + 0.1 * np.random.randn()))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * np.random.randn()))
        self.novelty_threshold = max(0.05, min(0.5, self.novelty_threshold + 0.01 * np.random.randn()))

```

### Rank 6 (Overall AOCC Score: 8.9705e-02 |             AOCC Score on Unimodal instances: 1.7404e-01 |             AOCC Score on Multimodal instances with a single component: 9.5079e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 126.65037013349018, archive_size: int = 111.00060761319567, sigma_decay: float = 0.9229715880388911,
                 acceptance_threshold: float = 0.005641087635120949):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:45:01 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveMultimodalOptimizer vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveMultimodalOptimizer uses adaptive covariance matrices and niching, leading to more efficient exploration of multimodal landscapes.  AdaptiveGaussianArchiveEA, on the other hand, relies on simpler Gaussian mutation and tournament selection, which limits its ability to handle complex multimodal problems.  (second best) AdaptiveDELevyArchiveEA vs (second worst) AdaptiveDEwithLevyFlightAndNoveltyArchive show that the former's parameter adaptation and separate Levy flight offspring generation contribute to its better performance. The latter's simpler adaptation and combined DE/Levy offspring generation might hinder its performance. Comparing (1st) AdaptiveMultimodalOptimizer vs (2nd) AdaptiveDELevyArchiveEA, we see that the covariance matrix adaptation in AdaptiveMultimodalOptimizer provides a more focused search compared to the more general exploration of AdaptiveDELevyArchiveEA.  (3rd) AdaptiveLevyDEArchiveEA vs (4th) AdaptiveDELevyFlightArchiveEA highlight similar approaches but AdaptiveLevyDEArchiveEA's simpler Levy flight implementation may be more efficient and stable, unlike AdaptiveDELevyFlightArchiveEA that uses a more complex Levy flight step, showing AdaptiveLevyDEArchiveEA slightly outperforms. Comparing (second worst) AdaptiveDEwithLevyFlightAndNoveltyArchive vs (worst) AdaptiveGaussianArchiveEA, we see that including Levy flights and a novelty archive in AdaptiveDEwithLevyFlightAndNoveltyArchive improves its performance over the purely Gaussian approach of AdaptiveGaussianArchiveEA. Overall:  The best-performing algorithms utilize adaptive mechanisms, incorporating techniques like covariance matrix adaptation and niche creation for effective exploration and exploitation of complex search spaces.  Simple Gaussian mutations and tournament selection strategies prove less effective.

**Experience:**

Adaptive mechanisms are crucial for handling high-dimensional, multimodal problems.  Combining different exploration strategies (like DE and Lévy flights) with sophisticated selection and archive management significantly improves performance.  Careful parameter adaptation is essential for robustness and efficiency.

2025-06-23 11:45:04 INFO Full response text: **Keywords:**  Adaptive mechanisms,  high-dimensional multimodal optimization, exploration-exploitation balance,  novelty search,  parameter control, archive management,  diversity preservation.

**Advice:** Focus on designing novel adaptive mechanisms that dynamically adjust exploration and exploitation based on *real-time* problem feedback,  not just pre-defined rules.   Incorporate metrics beyond simple fitness for archive updates and parameter adjustments (e.g., novelty, distance metrics, entropy). Explore less-explored sampling methods beyond Latin Hypercube.  Develop rigorous testing across diverse benchmark functions.

**Avoid:**  Generic statements about exploration/exploitation balance; vague references to “sophisticated” techniques; relying solely on fitness for decision making;  simply combining existing algorithms without novel integration.

**Explanation:**  The provided text repeatedly emphasizes common concepts without offering concrete, novel approaches.  Effective self-reflection requires identifying the *gaps* in existing knowledge and proposing specific, testable hypotheses for improvement,  not reiterating known best practices.  The focus should be on designing novel adaptive components, not just assembling existing ones. The $999K should be spent on research and development of these novel components, not just on combining known techniques.

2025-06-23 11:45:04 INFO Generating offspring via Crossover...
2025-06-23 11:46:34 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveDEwithLevyFlightAndNoveltyArchive
import numpy as np
from scipy.spatial.distance import cdist
from scipy.stats import levy

# Name: AdaptiveDEwithLevyFlightAndNoveltyArchive
# Description: Combines adaptive Differential Evolution, Lévy flights, and a novelty-guided archive for robust multimodal optimization.
# Code:
class AdaptiveDEwithLevyFlightAndNoveltyArchive:
    """
    Combines adaptive Differential Evolution (DE), Lévy flights, and a novelty-guided archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, novelty_threshold: float = 0.2,
                 F_init: float = 0.5, CR_init: float = 0.9, levy_alpha: float = 1.5):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.novelty_threshold = novelty_threshold
        self.F = F_init
        self.CR = CR_init
        self.archive = []
        self.levy_alpha = levy_alpha


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._novelty_based_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Differential Evolution
            a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Levy Flight perturbation
            levy_step = levy.rvs(self.levy_alpha, size=self.dim)
            mutant = mutant + 0.1 * levy_step * (self.upper_bounds - self.lower_bounds) #scale levy step
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _novelty_based_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _calculate_novelty(self, solution, archive):
        if not archive.size: return 1.0
        distances = cdist(solution.reshape(1, -1), archive[:, :-1])
        return 1.0 / np.min(distances) if np.min(distances) > 0 else 0.0


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        # Novelty based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            novelty = self._calculate_novelty(sorted_data[i, :-1], np.array(new_archive)[:,:-1])
            if novelty > self.novelty_threshold:
                new_archive.append(sorted_data[i])
                
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptation for demonstration; replace with more sophisticated methods
        self.F = max(0.1, min(1.0, self.F + 0.1 * np.random.randn()))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * np.random.randn()))
        self.novelty_threshold = max(0.05, min(0.5, self.novelty_threshold + 0.01 * np.random.randn()))


### Worse code
AdaptiveDELevyArchiveEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDELevyArchiveEA
# Description: Combines adaptive DE, Lévy flights, and a novelty archive for multimodal optimization.
class AdaptiveDELevyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.alpha = 1.5  # Lévy flight parameter
        self.novelty_threshold = 0.1 # Minimum distance for novelty
        self.k = 0.1 #Levy Flight scaling


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_levy = self._generate_offspring_levy(population)
            offspring = np.vstack((offspring_de, offspring_levy))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._selection(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_levy(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            step = np.random.levy(self.alpha, size=self.dim)
            step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
            new_solution = population[i] + self.k * step
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)


    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive
        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)])
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])
        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

### Analyze & experience
- Comparing (best) AdaptiveMultimodalOptimizer vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveMultimodalOptimizer uses adaptive covariance matrices and niching, leading to more efficient exploration of multimodal landscapes.  AdaptiveGaussianArchiveEA, on the other hand, relies on simpler Gaussian mutation and tournament selection, which limits its ability to handle complex multimodal problems.  (second best) AdaptiveDELevyArchiveEA vs (second worst) AdaptiveDEwithLevyFlightAndNoveltyArchive show that the former's parameter adaptation and separate Levy flight offspring generation contribute to its better performance. The latter's simpler adaptation and combined DE/Levy offspring generation might hinder its performance. Comparing (1st) AdaptiveMultimodalOptimizer vs (2nd) AdaptiveDELevyArchiveEA, we see that the covariance matrix adaptation in AdaptiveMultimodalOptimizer provides a more focused search compared to the more general exploration of AdaptiveDELevyArchiveEA.  (3rd) AdaptiveLevyDEArchiveEA vs (4th) AdaptiveDELevyFlightArchiveEA highlight similar approaches but AdaptiveLevyDEArchiveEA's simpler Levy flight implementation may be more efficient and stable, unlike AdaptiveDELevyFlightArchiveEA that uses a more complex Levy flight step, showing AdaptiveLevyDEArchiveEA slightly outperforms. Comparing (second worst) AdaptiveDEwithLevyFlightAndNoveltyArchive vs (worst) AdaptiveGaussianArchiveEA, we see that including Levy flights and a novelty archive in AdaptiveDEwithLevyFlightAndNoveltyArchive improves its performance over the purely Gaussian approach of AdaptiveGaussianArchiveEA. Overall:  The best-performing algorithms utilize adaptive mechanisms, incorporating techniques like covariance matrix adaptation and niche creation for effective exploration and exploitation of complex search spaces.  Simple Gaussian mutations and tournament selection strategies prove less effective.
- **Keywords:**  Adaptive mechanisms,  high-dimensional multimodal optimization, exploration-exploitation balance,  novelty search,  parameter control, archive management,  diversity preservation.

**Advice:** Focus on designing novel adaptive mechanisms that dynamically adjust exploration and exploitation based on *real-time* problem feedback,  not just pre-defined rules.   Incorporate metrics beyond simple fitness for archive updates and parameter adjustments (e.g., novelty, distance metrics, entropy). Explore less-explored sampling methods beyond Latin Hypercube.  Develop rigorous testing across diverse benchmark functions.

**Avoid:**  Generic statements about exploration/exploitation balance; vague references to “sophisticated” techniques; relying solely on fitness for decision making;  simply combining existing algorithms without novel integration.

**Explanation:**  The provided text repeatedly emphasizes common concepts without offering concrete, novel approaches.  Effective self-reflection requires identifying the *gaps* in existing knowledge and proposing specific, testable hypotheses for improvement,  not reiterating known best practices.  The focus should be on designing novel adaptive components, not just assembling existing ones. The $999K should be spent on research and development of these novel components, not just on combining known techniques.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:46:34 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Adaptive mechanisms,  high-dimensional multimodal optimization, exploration-exploitation balance,  novelty search,  parameter control, archive management,  diversity preservation.

**Advice:** Focus on designing novel adaptive mechanisms that dynamically adjust exploration and exploitation based on *real-time* problem feedback,  not just pre-defined rules.   Incorporate metrics beyond simple fitness for archive updates and parameter adjustments (e.g., novelty, distance metrics, entropy). Explore less-explored sampling methods beyond Latin Hypercube.  Develop rigorous testing across diverse benchmark functions.

**Avoid:**  Generic statements about exploration/exploitation balance; vague references to “sophisticated” techniques; relying solely on fitness for decision making;  simply combining existing algorithms without novel integration.

**Explanation:**  The provided text repeatedly emphasizes common concepts without offering concrete, novel approaches.  Effective self-reflection requires identifying the *gaps* in existing knowledge and proposing specific, testable hypotheses for improvement,  not reiterating known best practices.  The focus should be on designing novel adaptive components, not just assembling existing ones. The $999K should be spent on research and development of these novel components, not just on combining known techniques.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 11:56:18 INFO Perform Harmony Search...
2025-06-23 11:56:30 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:30 ERROR Can not run the algorithm
2025-06-23 11:56:30 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1737
2025-06-23 11:56:30 INFO FeHistory: [-701.30151605]
2025-06-23 11:56:30 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:30 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 159.53811910309912, archive_size: int = 981.4511217387885, sigma_decay: float = 0.9610645890064312, initial_sigma_multiplier: float = 0.6046209820470303):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:30 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:30 ERROR Can not run the algorithm
2025-06-23 11:56:30 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0873
2025-06-23 11:56:30 INFO FeHistory: [-220.86947088]
2025-06-23 11:56:30 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:30 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:30 ERROR Can not run the algorithm
2025-06-23 11:56:31 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:31 INFO FeHistory: [167.50494487]
2025-06-23 11:56:31 INFO Expected Optimum FE: -100
2025-06-23 11:56:31 INFO Unimodal AOCC mean: 0.1737
2025-06-23 11:56:31 INFO Multimodal (single component) AOCC mean: 0.0873
2025-06-23 11:56:31 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:31 INFO AOCC mean: 0.0870
2025-06-23 11:56:31 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:31 ERROR Can not run the algorithm
2025-06-23 11:56:31 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 11:56:31 INFO FeHistory: [-701.30462157]
2025-06-23 11:56:31 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:31 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 935.5646426593198, archive_size: int = 254.21431957369555, sigma_decay: float = 0.9437586723627834, initial_sigma_multiplier: float = 0.6984342769644138):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:31 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:31 ERROR Can not run the algorithm
2025-06-23 11:56:31 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0931
2025-06-23 11:56:31 INFO FeHistory: [-222.57011841]
2025-06-23 11:56:31 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:31 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:31 ERROR Can not run the algorithm
2025-06-23 11:56:31 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:31 INFO FeHistory: [194.93685998]
2025-06-23 11:56:31 INFO Expected Optimum FE: -100
2025-06-23 11:56:31 INFO Unimodal AOCC mean: 0.1738
2025-06-23 11:56:31 INFO Multimodal (single component) AOCC mean: 0.0931
2025-06-23 11:56:31 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:31 INFO AOCC mean: 0.0890
2025-06-23 11:56:31 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:31 ERROR Can not run the algorithm
2025-06-23 11:56:31 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 11:56:31 INFO FeHistory: [-701.32809033]
2025-06-23 11:56:31 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:31 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 888.7380311103026, archive_size: int = 715.0093794434213, sigma_decay: float = 0.9776773967450937, initial_sigma_multiplier: float = 0.6174266919168804):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:31 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:31 ERROR Can not run the algorithm
2025-06-23 11:56:31 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0953
2025-06-23 11:56:31 INFO FeHistory: [-223.13549332]
2025-06-23 11:56:31 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:31 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:31 ERROR Can not run the algorithm
2025-06-23 11:56:32 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:32 INFO FeHistory: [173.41370937]
2025-06-23 11:56:32 INFO Expected Optimum FE: -100
2025-06-23 11:56:32 INFO Unimodal AOCC mean: 0.1744
2025-06-23 11:56:32 INFO Multimodal (single component) AOCC mean: 0.0953
2025-06-23 11:56:32 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:32 INFO AOCC mean: 0.0899
2025-06-23 11:56:32 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:32 ERROR Can not run the algorithm
2025-06-23 11:56:32 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 11:56:32 INFO FeHistory: [-701.3028483]
2025-06-23 11:56:32 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:32 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 684.516072172949, archive_size: int = 648.0154133913807, sigma_decay: float = 0.9875529436205777, initial_sigma_multiplier: float = 0.7865543905984796):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:32 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:32 ERROR Can not run the algorithm
2025-06-23 11:56:32 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0968
2025-06-23 11:56:32 INFO FeHistory: [-223.50949981]
2025-06-23 11:56:32 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:32 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:32 ERROR Can not run the algorithm
2025-06-23 11:56:32 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:32 INFO FeHistory: [178.89148258]
2025-06-23 11:56:32 INFO Expected Optimum FE: -100
2025-06-23 11:56:32 INFO Unimodal AOCC mean: 0.1738
2025-06-23 11:56:32 INFO Multimodal (single component) AOCC mean: 0.0968
2025-06-23 11:56:32 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:32 INFO AOCC mean: 0.0902
2025-06-23 11:56:32 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:32 ERROR Can not run the algorithm
2025-06-23 11:56:32 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1736
2025-06-23 11:56:32 INFO FeHistory: [-701.29542645]
2025-06-23 11:56:32 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:32 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 650.250883006388, archive_size: int = 673.8303059608631, sigma_decay: float = 0.9810070186969677, initial_sigma_multiplier: float = 0.948782530536753):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:32 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:32 ERROR Can not run the algorithm
2025-06-23 11:56:32 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0882
2025-06-23 11:56:32 INFO FeHistory: [-221.16635382]
2025-06-23 11:56:32 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:32 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:32 ERROR Can not run the algorithm
2025-06-23 11:56:33 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:33 INFO FeHistory: [180.19902559]
2025-06-23 11:56:33 INFO Expected Optimum FE: -100
2025-06-23 11:56:33 INFO Unimodal AOCC mean: 0.1736
2025-06-23 11:56:33 INFO Multimodal (single component) AOCC mean: 0.0882
2025-06-23 11:56:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:33 INFO AOCC mean: 0.0873
2025-06-23 11:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:33 ERROR Can not run the algorithm
2025-06-23 11:56:33 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1738
2025-06-23 11:56:33 INFO FeHistory: [-701.30562821]
2025-06-23 11:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:33 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 650.250883006388, archive_size: int = 254.21431957369555, sigma_decay: float = 0.9150965730393588, initial_sigma_multiplier: float = 0.3151155877544135):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:33 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:33 ERROR Can not run the algorithm
2025-06-23 11:56:33 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0969
2025-06-23 11:56:33 INFO FeHistory: [-223.53325697]
2025-06-23 11:56:33 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:33 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:33 ERROR Can not run the algorithm
2025-06-23 11:56:33 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:33 INFO FeHistory: [190.14969702]
2025-06-23 11:56:33 INFO Expected Optimum FE: -100
2025-06-23 11:56:33 INFO Unimodal AOCC mean: 0.1738
2025-06-23 11:56:33 INFO Multimodal (single component) AOCC mean: 0.0969
2025-06-23 11:56:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:33 INFO AOCC mean: 0.0902
2025-06-23 11:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:33 ERROR Can not run the algorithm
2025-06-23 11:56:33 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1744
2025-06-23 11:56:33 INFO FeHistory: [-701.33057325]
2025-06-23 11:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:33 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 900.8175711750804, archive_size: int = 16.937506837509623, sigma_decay: float = 0.9875529436205777, initial_sigma_multiplier: float = 0.12404467142283468):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:33 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:33 ERROR Can not run the algorithm
2025-06-23 11:56:33 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0895
2025-06-23 11:56:33 INFO FeHistory: [-221.54060512]
2025-06-23 11:56:33 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:33 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:33 ERROR Can not run the algorithm
2025-06-23 11:56:34 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:34 INFO FeHistory: [178.05818386]
2025-06-23 11:56:34 INFO Expected Optimum FE: -100
2025-06-23 11:56:34 INFO Unimodal AOCC mean: 0.1744
2025-06-23 11:56:34 INFO Multimodal (single component) AOCC mean: 0.0895
2025-06-23 11:56:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:34 INFO AOCC mean: 0.0880
2025-06-23 11:56:34 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:34 ERROR Can not run the algorithm
2025-06-23 11:56:34 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1747
2025-06-23 11:56:34 INFO FeHistory: [-701.34260228]
2025-06-23 11:56:34 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:34 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 868.712853206959, archive_size: int = 460.8944752475521, sigma_decay: float = 0.9617735427862794, initial_sigma_multiplier: float = 0.3295239454925317):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:34 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:34 ERROR Can not run the algorithm
2025-06-23 11:56:34 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0912
2025-06-23 11:56:34 INFO FeHistory: [-222.03673917]
2025-06-23 11:56:34 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:34 ERROR Can not run the algorithm
2025-06-23 11:56:34 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:34 INFO FeHistory: [204.86995753]
2025-06-23 11:56:34 INFO Expected Optimum FE: -100
2025-06-23 11:56:34 INFO Unimodal AOCC mean: 0.1747
2025-06-23 11:56:34 INFO Multimodal (single component) AOCC mean: 0.0912
2025-06-23 11:56:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:34 INFO AOCC mean: 0.0886
2025-06-23 11:56:34 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:34 ERROR Can not run the algorithm
2025-06-23 11:56:34 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1735
2025-06-23 11:56:34 INFO FeHistory: [-701.29340158]
2025-06-23 11:56:34 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:34 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 868.712853206959, archive_size: int = 412.311158974356, sigma_decay: float = 0.9452651693847758, initial_sigma_multiplier: float = 0.6565442326876438):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:34 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:34 ERROR Can not run the algorithm
2025-06-23 11:56:34 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0934
2025-06-23 11:56:34 INFO FeHistory: [-222.64904077]
2025-06-23 11:56:34 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:34 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:34 ERROR Can not run the algorithm
2025-06-23 11:56:35 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:35 INFO FeHistory: [176.28936924]
2025-06-23 11:56:35 INFO Expected Optimum FE: -100
2025-06-23 11:56:35 INFO Unimodal AOCC mean: 0.1735
2025-06-23 11:56:35 INFO Multimodal (single component) AOCC mean: 0.0934
2025-06-23 11:56:35 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:35 INFO AOCC mean: 0.0890
2025-06-23 11:56:35 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:56:35 ERROR Can not run the algorithm
2025-06-23 11:56:35 INFO Run function 2 complete. FEHistory len: 1, AOCC: 0.1741
2025-06-23 11:56:35 INFO FeHistory: [-701.31547101]
2025-06-23 11:56:35 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:56:35 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 829.3397462317139, archive_size: int = 407.0542636039795, sigma_decay: float = 0.9550617242554715, initial_sigma_multiplier: float = 0.6525469613244874):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 11:56:35 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:56:35 ERROR Can not run the algorithm
2025-06-23 11:56:35 INFO Run function 15 complete. FEHistory len: 1, AOCC: 0.0918
2025-06-23 11:56:35 INFO FeHistory: [-222.21358412]
2025-06-23 11:56:35 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:56:35 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:56:35 ERROR Can not run the algorithm
2025-06-23 11:56:35 INFO Run function 24 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 11:56:35 INFO FeHistory: [183.0157683]
2025-06-23 11:56:35 INFO Expected Optimum FE: -100
2025-06-23 11:56:35 INFO Unimodal AOCC mean: 0.1741
2025-06-23 11:56:35 INFO Multimodal (single component) AOCC mean: 0.0918
2025-06-23 11:56:35 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:56:35 INFO AOCC mean: 0.0886
2025-06-23 11:56:35 INFO Generation 11, best so far: 0.14294861551599297
2025-06-23 11:56:35 INFO Population length is: 7
2025-06-23 11:56:35 INFO --- Performing Long-Term Reflection at Generation 12 ---
2025-06-23 11:56:35 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.0249e-01 |             AOCC Score on Unimodal instances: 1.8651e-01 |             AOCC Score on Multimodal instances with a single component: 1.1247e-01 |             AOCC Score on Multimodal instances with multiple components: 8.4950e-03)
# Name: AdaptiveDE_GaussianArchiveEA
# Description: Combines adaptive DE with Gaussian mutation and a novelty archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDE_GaussianArchiveEA
# Description: Combines adaptive DE with Gaussian mutation and a novelty archive for multimodal optimization.

class AdaptiveDE_GaussianArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian sigma
        self.sigma_decay = 0.99 # Gaussian sigma decay rate
        self.novelty_threshold = 0.1 # Minimum distance for novelty


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_gaussian = self._generate_offspring_gaussian(population)
            offspring = np.vstack((offspring_de, offspring_gaussian))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._selection(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self.sigma *= self.sigma_decay # Adapt Gaussian mutation strength

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population[:self.population_size//2])
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_gaussian(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            new_solution = population[i] + np.random.normal(0, self.sigma, self.dim)
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        distances = np.linalg.norm(population[:, np.newaxis, :] - self.archive[:, :-1], axis=2)
        min_distances = np.min(distances, axis=1)

        novel_indices = np.where(min_distances > self.novelty_threshold)[0]
        novel_solutions = combined[novel_indices]

        if len(self.archive) + len(novel_solutions) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 2 (Overall AOCC Score: 9.3902e-02 |             AOCC Score on Unimodal instances: 1.7564e-01 |             AOCC Score on Multimodal instances with a single component: 1.0607e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveNoveltyMultimodalEA
# Description: An evolutionary algorithm using adaptive Gaussian mutation, novelty search, and archive management for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveNoveltyMultimodalEA
# Description: An evolutionary algorithm using adaptive Gaussian mutation, novelty search, and archive management for multimodal optimization.
# Code:
class AdaptiveNoveltyMultimodalEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.98
        self.archive = []
        self.novelty_weight = 0.1  # Initial weight for novelty
        self.novelty_weight_increase_rate = 0.001 #Adaptive Novelty Weight

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            novelty_scores = self._calculate_novelty(offspring)
            combined_scores = offspring_fitness + self.novelty_weight * novelty_scores

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, combined_scores
            )

            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay
            self.novelty_weight = min(1, self.novelty_weight + self.novelty_weight_increase_rate) #Adaptive Novelty increase

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, combined_scores):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, combined_scores))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit[:self.population_size]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _calculate_novelty(self, offspring):
        if not self.archive.size:
            return np.zeros(offspring.shape[0])
        
        archive_solutions = self.archive[:, :-1]
        distances = np.min(squareform(pdist(np.vstack((offspring, archive_solutions)))), axis=0)[:offspring.shape[0]]
        return 1.0 / (distances + 1e-10) #Avoid division by zero

```

### Rank 3 (Overall AOCC Score: 9.3605e-02 |             AOCC Score on Unimodal instances: 1.7527e-01 |             AOCC Score on Multimodal instances with a single component: 1.0554e-01 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCovarianceDEArchiveEA
# Description: Combines adaptive covariance DE, Lévy flights, and a novelty archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import levy, multivariate_normal
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveCovarianceDEArchiveEA
# Description: Combines adaptive covariance DE, Lévy flights, and a novelty archive for multimodal optimization.
# Code:
class AdaptiveCovarianceDEArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.levy_alpha = 1.5 # Levy flight parameter
        self.exploration_rate = 0.8 # Balance between DE and Levy
        self.novelty_threshold = 0.1
        self.covariance_matrix = np.eye(self.dim) #Initial covariance matrix

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self._adapt_covariance(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                a, b, c = self._select_different(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _levy_flight(self, x):
        step = levy.rvs(self.levy_alpha, size=self.dim)
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:min(len(combined), self.archive_size)]
            return self.archive

        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)]) if len(self.archive)>0 else np.inf
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])

        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

    def _adapt_covariance(self, population, fitness_values):
        # Update covariance matrix based on top performing individuals
        top_performers = population[:self.population_size//2]
        self.covariance_matrix = np.cov(top_performers.T) + 0.1 * np.eye(self.dim) #Regularization


```

### Rank 4 (Overall AOCC Score: 9.1742e-02 |             AOCC Score on Unimodal instances: 1.7527e-01 |             AOCC Score on Multimodal instances with a single component: 9.9958e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLevyDEwithNoveltyArchive
# Description: Combines adaptive Differential Evolution, Lévy flights, and a novelty archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import levy

# Name: AdaptiveLevyDEwithNoveltyArchive
# Description: Combines adaptive Differential Evolution, Lévy flights, and a novelty archive for robust multimodal optimization.
# Code:
class AdaptiveLevyDEwithNoveltyArchive:
    """
    Combines adaptive Differential Evolution, Lévy flights, and a novelty archive for multimodal optimization.  Uses adaptive parameters and a novelty-based archive update to balance exploration and exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, novelty_threshold: float = 0.2,
                 F_init: float = 0.5, CR_init: float = 0.9, levy_alpha: float = 1.5):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.novelty_threshold = novelty_threshold
        self.F = F_init
        self.CR = CR_init
        self.archive = []
        self.levy_alpha = levy_alpha


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._novelty_based_selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Levy Flight perturbation
            levy_step = levy.rvs(self.levy_alpha, size=self.dim)
            mutant = mutant + 0.1 * levy_step * (self.upper_bounds - self.lower_bounds)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _novelty_based_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _calculate_novelty(self, solution, archive):
        if not archive.size: return 1.0
        distances = np.linalg.norm(archive[:, :-1] - solution, axis=1)
        return 1.0 / np.min(distances) if np.min(distances) > 0 else 0.0


    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        #Sort by fitness
        sorted_data = combined[combined[:, -1].argsort()]
        
        # Novelty based diversity preservation 
        new_archive = [sorted_data[0]]
        for i in range(1, len(sorted_data)):
            novelty = self._calculate_novelty(sorted_data[i, :-1], np.array(new_archive)[:,:-1])
            if novelty > self.novelty_threshold:
                new_archive.append(sorted_data[i])
                
        return np.array(new_archive[:min(len(new_archive), self.archive_size)])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptation for demonstration; replace with more sophisticated methods
        self.F = max(0.1, min(1.0, self.F + 0.1 * np.random.randn()))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * np.random.randn()))
        self.novelty_threshold = max(0.05, min(0.5, self.novelty_threshold + 0.01 * np.random.randn()))

```

### Rank 5 (Overall AOCC Score: 9.1482e-02 |             AOCC Score on Unimodal instances: 1.7505e-01 |             AOCC Score on Multimodal instances with a single component: 9.9401e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithLevyAndArchive
# Description: Combines adaptive DE, Lévy flights, and an archive for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDEwithLevyAndArchive
# Description: Combines adaptive DE, Lévy flights, and an archive for efficient multimodal optimization.
# Code:
class AdaptiveDEwithLevyAndArchive:
    """
    Combines adaptive differential evolution (DE) with Lévy flights and a novelty archive 
    to enhance exploration and exploitation in multimodal optimization problems.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.levy_alpha = 1.5 # Levy flight parameter
        self.exploration_rate = 0.7 # Probability of using Levy flight


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                offspring[i] = self._differential_evolution(population, i)
        return offspring

    def _levy_flight(self, x):
        step = levy.rvs(self.levy_alpha, size=self.dim)
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)

    def _differential_evolution(self, population, i):
        a, b, c = self._select_different(i, population.shape[0])
        mutant = population[a] + self.F * (population[b] - population[c])
        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return self._crossover(population[i], mutant)

    def _select_different(self, exclude, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.vstack((self.archive, combined))
        else:
            self.archive = np.vstack((self.archive, combined))
            sorted_indices = np.argsort(self.archive[:, -1])
            self.archive = self.archive[sorted_indices][:self.archive_size]

        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

```

### Rank 6 (Overall AOCC Score: 9.0231e-02 |             AOCC Score on Unimodal instances: 1.7382e-01 |             AOCC Score on Multimodal instances with a single component: 9.6871e-02 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 650.250883006388, archive_size: int = 254.21431957369555, sigma_decay: float = 0.9150965730393588, initial_sigma_multiplier: float = 0.3151155877544135):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 11:56:40 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveDE_GaussianArchiveEA vs (worst) AdaptiveGaussianArchiveEA, we see that the best utilizes both Differential Evolution (DE) and Gaussian mutation, offering a blend of local exploitation (Gaussian) and global exploration (DE).  The worst relies solely on Gaussian mutation, limiting its exploration capabilities, especially in high-dimensional spaces. The best also incorporates an archive to maintain diversity and prevent premature convergence.  The worst lacks this crucial feature. (second best) AdaptiveNoveltyMultimodalEA vs (second worst) AdaptiveDEwithLevyAndArchive show a similar pattern; AdaptiveNoveltyMultimodalEA uses adaptive Gaussian mutation and novelty search, promoting exploration of diverse regions. AdaptiveDEwithLevyAndArchive, while incorporating Lévy flights for exploration, lacks the sophisticated adaptive mutation and novelty management. Comparing (1st) vs (2nd), we see that AdaptiveDE_GaussianArchiveEA's combination of DE and Gaussian mutation provides superior exploitation compared to AdaptiveNoveltyMultimodalEA's reliance on Gaussian recombination. (3rd) vs (4th) show similar characteristics to the (1st) vs (2nd) comparison, with AdaptiveCovarianceDEArchiveEA being more robust due to covariance matrix adaptation.  Comparing (second worst) AdaptiveDEwithLevyAndArchive vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveDEwithLevyAndArchive includes DE and Lévy flights, providing broader search than AdaptiveGaussianArchiveEA which only uses Gaussian mutations. Overall: The top-performing algorithms consistently employ adaptive parameter control, archive mechanisms for diversity maintenance, and a blend of exploration (Lévy flights, DE) and exploitation (Gaussian mutation).  The lower-ranking algorithms lack one or more of these key features resulting in lower performance across the GNBG benchmarks.

**Experience:**

Adaptive parameter control, archive management, and a balanced exploration-exploitation strategy are crucial for success in high-dimensional multimodal optimization.  Combining multiple search operators (e.g., DE and Gaussian mutation) often yields superior performance compared to relying on a single operator.

2025-06-23 11:56:42 INFO Full response text: **Keywords:**  Heuristic design, multimodal optimization, high-dimensional search, adaptive control, exploration-exploitation, archive management, diversity, parameter tuning.

**Advice:** Focus on *novel* mechanisms for adaptive parameter control (e.g.,  using problem-specific features to inform adaptation, not just success rate). Develop innovative archive management strategies that go beyond simple diversity metrics (e.g.,  consider topological features or information-theoretic measures). Explore fundamentally new exploration operators rather than simply combining existing ones.  Emphasize rigorous empirical evaluation across diverse benchmark functions.

**Avoid:**  Generic statements about "exploration-exploitation balance," "adaptive parameter control,"  "diverse population," and "efficient archive management."  Avoid simply listing known algorithms or techniques.  Refrain from vague claims of improved performance without specific metrics or comparative studies.

**Explanation:** The provided ineffective self-reflection examples suffer from excessive generality and lack of novel insights.  They reiterate well-known strategies without proposing any specific, original improvements.  The goal is to design truly *novel* heuristics, moving beyond incremental improvements to existing methods.  The revised self-reflection should detail concrete, testable ideas for achieving this.

2025-06-23 11:56:42 INFO Generating offspring via Crossover...
2025-06-23 12:06:42 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 650.250883006388, archive_size: int = 254.21431957369555, sigma_decay: float = 0.9150965730393588, initial_sigma_multiplier: float = 0.3151155877544135):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = sigma_decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8, tournament_size: int = 5) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values, tournament_size=tournament_size)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values, tournament_size: int =5):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Worse code
AdaptiveDE_GaussianArchiveEA
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDE_GaussianArchiveEA
# Description: Combines adaptive DE with Gaussian mutation and a novelty archive for multimodal optimization.

class AdaptiveDE_GaussianArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian sigma
        self.sigma_decay = 0.99 # Gaussian sigma decay rate
        self.novelty_threshold = 0.1 # Minimum distance for novelty


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_gaussian = self._generate_offspring_gaussian(population)
            offspring = np.vstack((offspring_de, offspring_gaussian))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._selection(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self.sigma *= self.sigma_decay # Adapt Gaussian mutation strength

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population[:self.population_size//2])
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_gaussian(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            new_solution = population[i] + np.random.normal(0, self.sigma, self.dim)
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        distances = np.linalg.norm(population[:, np.newaxis, :] - self.archive[:, :-1], axis=2)
        min_distances = np.min(distances, axis=1)

        novel_indices = np.where(min_distances > self.novelty_threshold)[0]
        novel_solutions = combined[novel_indices]

        if len(self.archive) + len(novel_solutions) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))


### Analyze & experience
- Comparing (best) AdaptiveDE_GaussianArchiveEA vs (worst) AdaptiveGaussianArchiveEA, we see that the best utilizes both Differential Evolution (DE) and Gaussian mutation, offering a blend of local exploitation (Gaussian) and global exploration (DE).  The worst relies solely on Gaussian mutation, limiting its exploration capabilities, especially in high-dimensional spaces. The best also incorporates an archive to maintain diversity and prevent premature convergence.  The worst lacks this crucial feature. (second best) AdaptiveNoveltyMultimodalEA vs (second worst) AdaptiveDEwithLevyAndArchive show a similar pattern; AdaptiveNoveltyMultimodalEA uses adaptive Gaussian mutation and novelty search, promoting exploration of diverse regions. AdaptiveDEwithLevyAndArchive, while incorporating Lévy flights for exploration, lacks the sophisticated adaptive mutation and novelty management. Comparing (1st) vs (2nd), we see that AdaptiveDE_GaussianArchiveEA's combination of DE and Gaussian mutation provides superior exploitation compared to AdaptiveNoveltyMultimodalEA's reliance on Gaussian recombination. (3rd) vs (4th) show similar characteristics to the (1st) vs (2nd) comparison, with AdaptiveCovarianceDEArchiveEA being more robust due to covariance matrix adaptation.  Comparing (second worst) AdaptiveDEwithLevyAndArchive vs (worst) AdaptiveGaussianArchiveEA, we see that AdaptiveDEwithLevyAndArchive includes DE and Lévy flights, providing broader search than AdaptiveGaussianArchiveEA which only uses Gaussian mutations. Overall: The top-performing algorithms consistently employ adaptive parameter control, archive mechanisms for diversity maintenance, and a blend of exploration (Lévy flights, DE) and exploitation (Gaussian mutation).  The lower-ranking algorithms lack one or more of these key features resulting in lower performance across the GNBG benchmarks.
- **Keywords:**  Heuristic design, multimodal optimization, high-dimensional search, adaptive control, exploration-exploitation, archive management, diversity, parameter tuning.

**Advice:** Focus on *novel* mechanisms for adaptive parameter control (e.g.,  using problem-specific features to inform adaptation, not just success rate). Develop innovative archive management strategies that go beyond simple diversity metrics (e.g.,  consider topological features or information-theoretic measures). Explore fundamentally new exploration operators rather than simply combining existing ones.  Emphasize rigorous empirical evaluation across diverse benchmark functions.

**Avoid:**  Generic statements about "exploration-exploitation balance," "adaptive parameter control,"  "diverse population," and "efficient archive management."  Avoid simply listing known algorithms or techniques.  Refrain from vague claims of improved performance without specific metrics or comparative studies.

**Explanation:** The provided ineffective self-reflection examples suffer from excessive generality and lack of novel insights.  They reiterate well-known strategies without proposing any specific, original improvements.  The goal is to design truly *novel* heuristics, moving beyond incremental improvements to existing methods.  The revised self-reflection should detail concrete, testable ideas for achieving this.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 12:06:42 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Heuristic design, multimodal optimization, high-dimensional search, adaptive control, exploration-exploitation, archive management, diversity, parameter tuning.

**Advice:** Focus on *novel* mechanisms for adaptive parameter control (e.g.,  using problem-specific features to inform adaptation, not just success rate). Develop innovative archive management strategies that go beyond simple diversity metrics (e.g.,  consider topological features or information-theoretic measures). Explore fundamentally new exploration operators rather than simply combining existing ones.  Emphasize rigorous empirical evaluation across diverse benchmark functions.

**Avoid:**  Generic statements about "exploration-exploitation balance," "adaptive parameter control,"  "diverse population," and "efficient archive management."  Avoid simply listing known algorithms or techniques.  Refrain from vague claims of improved performance without specific metrics or comparative studies.

**Explanation:** The provided ineffective self-reflection examples suffer from excessive generality and lack of novel insights.  They reiterate well-known strategies without proposing any specific, original improvements.  The goal is to design truly *novel* heuristics, moving beyond incremental improvements to existing methods.  The revised self-reflection should detail concrete, testable ideas for achieving this.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
