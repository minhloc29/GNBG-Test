2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 09:14:13 INFO FeHistory: []
2025-06-23 09:14:13 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO Run function 15 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 09:14:13 INFO FeHistory: []
2025-06-23 09:14:13 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 09:14:13 INFO FeHistory: []
2025-06-23 09:14:13 INFO Expected Optimum FE: -100
2025-06-23 09:14:13 INFO Unimodal AOCC mean: 0.0000
2025-06-23 09:14:13 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 09:14:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:14:13 INFO AOCC mean: 0.0000
2025-06-23 09:14:13 INFO Run function 2 complete. FEHistory len: 101, AOCC: 0.1758
2025-06-23 09:14:13 INFO FeHistory: [-701.29442055 -701.32488457 -701.32289266 -701.30376478 -701.31810693
 -701.31996624 -701.32953345 -701.28371643 -701.29363719 -701.38801577
 -701.29998092 -701.31129636 -701.33323255 -701.30568986 -701.29119208
 -701.30323478 -701.30868017 -701.33064853 -701.30201106 -701.3317564
 -701.2958686  -701.32156873 -701.31170464 -701.2950315  -701.28722284
 -701.29722498 -701.32008218 -701.29115487 -701.32422023 -701.31372861
 -701.34009338 -701.28740909 -701.32203795 -701.31427649 -701.34444342
 -701.30260138 -701.27268975 -701.3034118  -701.3121993  -701.29678329
 -701.31282767 -701.31607754 -701.31296902 -701.31055204 -701.34251193
 -701.32047923 -701.31476926 -701.30541305 -701.3285482  -701.31054613
 -701.34040053 -701.3176715  -701.30000498 -701.2931193  -701.28538132
 -701.32511285 -701.29480204 -701.33343125 -701.31983752 -701.30777801
 -701.29705502 -701.32314843 -701.35452009 -701.33013693 -701.3076803
 -701.30909749 -701.33505343 -701.30057073 -701.33355305 -701.29766935
 -701.30172259 -701.29128201 -701.29752886 -701.2825674  -701.31809904
 -701.32089813 -701.28906343 -701.29917611 -701.29558264 -701.3065036
 -701.30383217 -701.29682506 -701.27449823 -701.29929948 -701.3150762
 -701.31765022 -701.30852159 -701.32905352 -701.29675873 -701.30850943
 -701.31474385 -701.3245263  -701.33589029 -701.3131699  -701.2979058
 -701.29204099 -701.27976897 -701.28184162 -701.30795995 -701.27424405
 -701.28585015]
2025-06-23 09:14:13 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:14:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveDE
import numpy as np
import random

# Name: AdaptiveGaussianArchiveDE
# Description: Combines differential evolution, adaptive Gaussian mutation, and an archive for multimodal optimization.

class AdaptiveGaussianArchiveDE:
    """
    Combines differential evolution, adaptive Gaussian mutation, and an archive to escape local optima in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  # Size of the archive
        self.archive = []
        self.sigma = 10.0  # Initial Gaussian mutation standard deviation
        self.sigma_decay = 0.95  # Decay factor for sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive = []
        self.sigma = 10.0  # Reset sigma for each run
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
        self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(population)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness)
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self._update_archive(population, fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        return fitness
    
    def _generate_mutant(self, population):
        a, b, c = self._select_different(len(population))
        mutant = population[a] + 0.8 * (population[b] - population[c]) #Differential Evolution
        mutant += np.random.normal(0, self.sigma, self.dim) #Adaptive Gaussian Mutation
        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return mutant

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < 0.5, v, x)

    def _select_different(self, population_size):
        a, b, c = random.sample(range(population_size), 3)
        while a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness):
        for i in range(len(population)):
            solution = population[i]
            fitness_value = fitness[i]
            self._add_to_archive(solution, fitness_value)

    def _add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:14:13 INFO Run function 2 complete. FEHistory len: 200, AOCC: 0.1753
2025-06-23 09:14:13 INFO FeHistory: [-701.3266012  -701.32981129 -701.29244483 -701.31170189 -701.32541554
 -701.35902306 -701.29049454 -701.30105112 -701.27844423 -701.30386685
 -701.30866311 -701.32401548 -701.32751178 -701.32746294 -701.30657517
 -701.30361989 -701.3100118  -701.32166303 -701.3065943  -701.30622865
 -701.31166311 -701.28912439 -701.30968365 -701.31851046 -701.29326265
 -701.28807786 -701.30664962 -701.33147887 -701.34312773 -701.33484608
 -701.29235522 -701.3214142  -701.30280447 -701.28052351 -701.29498679
 -701.32761761 -701.3143297  -701.31184431 -701.29279629 -701.31625742
 -701.28889781 -701.30091275 -701.31331721 -701.2976977  -701.33913817
 -701.30843458 -701.28760658 -701.29052341 -701.30519261 -701.27658527
 -701.28013014 -701.3051413  -701.28225925 -701.2909365  -701.36811592
 -701.33346296 -701.28223823 -701.34559618 -701.33066829 -701.32284957
 -701.30181484 -701.32025825 -701.34327914 -701.34190655 -701.31461021
 -701.29935656 -701.30739618 -701.32210459 -701.29360228 -701.30482342
 -701.30048696 -701.29224338 -701.30103523 -701.33060471 -701.30682327
 -701.26768927 -701.33606178 -701.334429   -701.29896237 -701.30414349
 -701.36264264 -701.32354888 -701.30370368 -701.32290076 -701.31125661
 -701.29134633 -701.32804404 -701.309147   -701.29916663 -701.29046028
 -701.3524728  -701.33508334 -701.29262828 -701.29918882 -701.31376095
 -701.36502586 -701.30564972 -701.35115175 -701.28467169 -701.2959477
 -701.30379163 -701.28433174 -701.31543409 -701.28174874 -701.28365528
 -701.29773304 -701.30878378 -701.26692677 -701.32124019 -701.28799474
 -701.31973099 -701.2715333  -701.3551495  -701.29374625 -701.25433057
 -701.25852951 -701.28598767 -701.28909313 -701.27842414 -701.28362924
 -701.30266713 -701.26073525 -701.27067753 -701.28491963 -701.29749581
 -701.28062735 -701.31664166 -701.2678468  -701.26169305 -701.28148457
 -701.277907   -701.26541797 -701.31374122 -701.31126887 -701.32100562
 -701.31360484 -701.26746545 -701.28815249 -701.26545796 -701.30982011
 -701.27383199 -701.27888284 -701.25834989 -701.33591473 -701.2601201
 -701.32984474 -701.341037   -701.28396525 -701.27539921 -701.26889052
 -701.28928545 -701.27418979 -701.31192299 -701.29096852 -701.29593151
 -701.2751959  -701.26878593 -701.27128483 -701.27578425 -701.33466403
 -701.29777187 -701.29779906 -701.25456133 -701.31759818 -701.33341604
 -701.31102704 -701.2777855  -701.29114151 -701.27369959 -701.28893164
 -701.26975892 -701.26700743 -701.30764647 -701.29822871 -701.27772039
 -701.28469499 -701.29521138 -701.29375762 -701.29451555 -701.32274788
 -701.28298113 -701.29534653 -701.2971199  -701.31145816 -701.28148857
 -701.27275173 -701.27251215 -701.25551924 -701.25438228 -701.3113935
 -701.2808518  -701.32150166 -701.3130495  -701.32444623 -701.27872461
 -701.24864601 -701.3356215  -701.26205429 -701.30214269 -701.31604305]
2025-06-23 09:14:13 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:14:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveDE
import numpy as np
import random

class AdaptiveGaussianArchiveDE:
    """
    Combines Differential Evolution, adaptive Gaussian mutation, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  # Size of the archive
        self.archive = []
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 10.0 # Initial Gaussian mutation standard deviation
        self.sigma_decay = 0.95 # Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += self.population_size
        
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution
                a, b, c = self._select_different(i, self.population_size)
                mutant = population[a] + self.F * (population[b] - population[c])
                
                #Adaptive Gaussian mutation
                mutant += np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.archive = self._update_archive(population, fitness)
            self.sigma *= self.sigma_decay # Decay sigma

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _select_different(self, index, pop_size):
        a, b, c = random.sample(range(pop_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(pop_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness):
        combined = np.concatenate((np.array(self.archive), population)) if len(self.archive)>0 else population
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness)) if len(self.archive)>0 else fitness
        sorted_indices = np.argsort(combined_fitness)
        return [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]

2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:14:13 INFO Run function 2 complete. FEHistory len: 200, AOCC: 0.1750
2025-06-23 09:14:13 INFO FeHistory: [-701.30848332 -701.32895366 -701.31636718 -701.28603677 -701.3190421
 -701.29606552 -701.29027096 -701.29020873 -701.34945988 -701.32635467
 -701.29824139 -701.3051898  -701.32113953 -701.33992389 -701.31103618
 -701.34951788 -701.31590321 -701.33285438 -701.28116656 -701.32634365
 -701.30474843 -701.32321994 -701.32831913 -701.30343383 -701.29980845
 -701.2994742  -701.28709749 -701.32878016 -701.30787196 -701.30264478
 -701.33175641 -701.34653456 -701.34673622 -701.30973904 -701.29372513
 -701.3152573  -701.29868003 -701.28746994 -701.3224731  -701.32825444
 -701.31384579 -701.32485263 -701.3104696  -701.28887984 -701.31493726
 -701.29183533 -701.2900937  -701.28832927 -701.34965069 -701.31016534
 -701.32026089 -701.33503455 -701.31046353 -701.31280325 -701.3247513
 -701.29979536 -701.28166392 -701.32486257 -701.31717654 -701.31063621
 -701.33707759 -701.32562768 -701.28881654 -701.32452911 -701.32807376
 -701.29940164 -701.29627594 -701.30558023 -701.28625725 -701.29887142
 -701.35654264 -701.29786854 -701.33531919 -701.32332294 -701.29495321
 -701.29914417 -701.30843502 -701.30757353 -701.30428101 -701.30046064
 -701.29140929 -701.31361376 -701.3034369  -701.30815002 -701.2698256
 -701.28804375 -701.27093678 -701.33962167 -701.30814774 -701.30352812
 -701.31942874 -701.28912667 -701.30159531 -701.31663077 -701.32850564
 -701.30905146 -701.31797672 -701.28662998 -701.28977442 -701.29123603
 -701.26729468 -701.30903486 -701.27076582 -701.28350134 -701.31046703
 -701.26321119 -701.29035171 -701.27893334 -701.3001003  -701.30623527
 -701.32323102 -701.29611786 -701.25448427 -701.28665244 -701.28016433
 -701.30483301 -701.3028616  -701.30676069 -701.30094095 -701.29253208
 -701.3040941  -701.26154682 -701.28086359 -701.27561613 -701.31912963
 -701.28188763 -701.29731027 -701.30925716 -701.27458062 -701.2900418
 -701.28899552 -701.30339282 -701.30940327 -701.27407042 -701.2661531
 -701.27886463 -701.28029938 -701.315469   -701.27350869 -701.29427479
 -701.29503362 -701.28832805 -701.27934254 -701.34844367 -701.31483017
 -701.29071187 -701.28552432 -701.27680184 -701.27403905 -701.31451607
 -701.27506421 -701.30224836 -701.2972097  -701.27589706 -701.32302737
 -701.29047805 -701.27715946 -701.27729759 -701.2803009  -701.28595755
 -701.28478434 -701.30284987 -701.28925736 -701.28479168 -701.28098931
 -701.30177851 -701.3000523  -701.29116587 -701.31238008 -701.27382838
 -701.30175498 -701.30717814 -701.32128604 -701.31745818 -701.28438916
 -701.30442007 -701.29608775 -701.27761192 -701.31140078 -701.25287489
 -701.27576872 -701.29954495 -701.27081236 -701.28808379 -701.29532201
 -701.27211624 -701.31869423 -701.33565502 -701.29493029 -701.29588212
 -701.29575146 -701.27442096 -701.28571526 -701.31376744 -701.3024126
 -701.28120059 -701.27408685 -701.26180259 -701.28642537 -701.30958126]
2025-06-23 09:14:13 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:14:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveDE
import numpy as np
import random

class AdaptiveGaussianArchiveDE:
    """
    Combines Differential Evolution with an archive and adaptive Gaussian mutation for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.5  # Initial Gaussian mutation standard deviation
        self.sigma_decay = 0.98 # Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                #Adaptive Gaussian Mutation
                mutant += np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution
                
            # Archive Management
            self._update_archive(population, fitness)
            self.sigma *= self.sigma_decay # Decay sigma

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_sigma': self.sigma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness):
        #Simple Archive: Add top solutions to archive, maintaining diversity 
        combined = np.concatenate((self.archive, population)) if len(self.archive) > 0 else population
        combined_fitness = objective_function(combined) if len(self.archive) == 0 else np.concatenate((np.array([f for _,f in self.archive]), fitness))
        
        sorted_indices = np.argsort(combined_fitness)
        
        self.archive = [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]
        


2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO Run function 15 complete. FEHistory len: 101, AOCC: 0.1002
2025-06-23 09:14:13 INFO FeHistory: [-222.62357597 -222.27000057 -221.64682374 -223.24943787 -220.29486622
 -222.65575496 -220.23128171 -222.83398112 -223.17912525 -223.1089025
 -223.22273754 -222.87410254 -223.04611136 -221.16295436 -222.80508822
 -223.2902369  -221.45511041 -221.19118628 -220.86565989 -222.09450725
 -220.84375996 -223.41642305 -221.42374872 -222.58302681 -223.01201992
 -223.39185626 -221.26529633 -222.87267236 -221.16846078 -222.88523416
 -222.30111251 -222.10664773 -223.05961896 -223.01327818 -222.39407017
 -222.1489724  -220.88173975 -221.08969134 -221.49833942 -220.80835811
 -222.60872238 -220.84878095 -222.59842063 -223.1715815  -222.91840649
 -222.1288822  -221.2716546  -220.58346902 -221.01349949 -220.499325
 -221.11917624 -221.639186   -221.80733697 -223.3233819  -221.62141671
 -222.17980908 -222.5106616  -221.5165796  -223.24423507 -220.42215211
 -222.06550369 -222.21158294 -221.44888547 -222.00308687 -222.25105335
 -222.30254446 -223.00146416 -221.78487996 -221.49108537 -222.79789451
 -222.75679545 -221.99439632 -222.28410128 -220.99531871 -221.9005836
 -222.21834599 -221.13660702 -222.28789187 -224.33711298 -221.7727139
 -220.86654956 -221.21026623 -221.60121634 -221.29210966 -223.51119674
 -222.62430463 -220.4373066  -221.81373602 -221.22461051 -222.5685296
 -221.75729121 -222.12257877 -223.1593556  -221.38818762 -221.96852971
 -223.33335037 -222.74935448 -220.80761902 -222.49826735 -221.49037178
 -221.05218723]
2025-06-23 09:14:13 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:14:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveDE
import numpy as np
import random

# Name: AdaptiveGaussianArchiveDE
# Description: Combines differential evolution, adaptive Gaussian mutation, and an archive for multimodal optimization.

class AdaptiveGaussianArchiveDE:
    """
    Combines differential evolution, adaptive Gaussian mutation, and an archive to escape local optima in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  # Size of the archive
        self.archive = []
        self.sigma = 10.0  # Initial Gaussian mutation standard deviation
        self.sigma_decay = 0.95  # Decay factor for sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive = []
        self.sigma = 10.0  # Reset sigma for each run
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
        self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(population)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness)
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self._update_archive(population, fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        return fitness
    
    def _generate_mutant(self, population):
        a, b, c = self._select_different(len(population))
        mutant = population[a] + 0.8 * (population[b] - population[c]) #Differential Evolution
        mutant += np.random.normal(0, self.sigma, self.dim) #Adaptive Gaussian Mutation
        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return mutant

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < 0.5, v, x)

    def _select_different(self, population_size):
        a, b, c = random.sample(range(population_size), 3)
        while a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness):
        for i in range(len(population)):
            solution = population[i]
            fitness_value = fitness[i]
            self._add_to_archive(solution, fitness_value)

    def _add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:14:13 INFO Run function 15 complete. FEHistory len: 200, AOCC: 0.1011
2025-06-23 09:14:13 INFO FeHistory: [-221.48098493 -220.97707743 -222.76295114 -222.65292895 -220.55938247
 -223.61467444 -221.17176958 -221.46457596 -223.118542   -222.75911853
 -221.65115621 -219.99270687 -221.77972051 -221.44753844 -221.77958054
 -221.76174159 -222.93321523 -222.87532842 -221.213659   -222.31573054
 -220.39092927 -222.2505025  -221.49383222 -222.10630737 -221.67665453
 -221.7602918  -222.81461443 -222.62070635 -221.74036907 -221.71364143
 -221.83598922 -221.3314784  -221.39927449 -223.35824072 -221.31948757
 -221.59246523 -223.62106571 -222.67437755 -222.56491835 -223.27558984
 -223.57529724 -222.15780723 -222.51494106 -222.52588306 -222.04697221
 -221.25829754 -221.15212228 -222.28048759 -222.05052534 -221.57920265
 -222.31250614 -222.10680296 -221.87079299 -222.8186649  -223.5167477
 -220.85642955 -222.24002753 -222.82943268 -221.49894366 -221.3819403
 -221.6141739  -222.28241659 -222.37068035 -221.79523483 -220.89338663
 -222.82018107 -221.2133635  -221.64153732 -222.77855002 -221.22447213
 -222.45114694 -221.59391693 -222.65023622 -222.89097274 -222.16935811
 -222.71614456 -221.9618825  -222.33703388 -223.11992775 -222.24574466
 -222.09001346 -222.99603337 -220.82619512 -221.21508904 -221.63626432
 -221.56240173 -220.38029772 -223.84040934 -222.03369077 -221.26678304
 -223.54756644 -221.85642738 -221.74340794 -221.87571141 -221.08457084
 -222.21057706 -222.51810298 -221.40014832 -222.3883925  -221.05773033
 -223.14628123 -223.60368118 -220.48022799 -220.80645199 -222.01135051
 -221.89631624 -220.01131567 -221.25373116 -220.54758062 -220.80748043
 -220.27084272 -221.73476974 -220.87611077 -221.48885685 -220.06203896
 -221.02035601 -221.89492501 -222.86769088 -222.70894181 -222.65608261
 -221.76181177 -220.71541055 -221.68915409 -220.94147181 -221.66445673
 -220.29510178 -220.84641555 -220.99604083 -223.12805564 -223.09785306
 -221.6737752  -224.07867143 -221.9235591  -221.74384936 -220.70487306
 -224.11938311 -222.76739922 -221.84525068 -221.40312057 -220.74011234
 -221.6483339  -221.41074342 -222.90894859 -223.17434271 -220.04518358
 -220.92415983 -220.22739536 -221.19415065 -220.99186316 -221.51860932
 -221.32868809 -221.86424317 -221.8481667  -221.76674903 -222.31696008
 -221.27047111 -220.94101257 -220.52645206 -222.53272727 -221.14574479
 -221.11623811 -219.8460245  -222.48805869 -221.80992623 -220.84080764
 -221.39309885 -221.79740563 -221.8359679  -223.20112355 -221.34725559
 -221.23678624 -220.23953255 -222.14900425 -219.48365991 -220.99649564
 -221.93500191 -221.21073892 -221.31149844 -222.32219055 -222.38439395
 -223.30979506 -221.17044355 -221.05712445 -222.80414926 -222.168533
 -221.93552705 -221.7915308  -222.75590455 -221.87371193 -222.45161296
 -223.60840688 -222.53851083 -222.90864605 -224.53435369 -222.93058568
 -221.46928835 -223.0656728  -222.64480286 -221.4004856  -221.93365104]
2025-06-23 09:14:13 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:14:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveDE
import numpy as np
import random

class AdaptiveGaussianArchiveDE:
    """
    Combines Differential Evolution, adaptive Gaussian mutation, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  # Size of the archive
        self.archive = []
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 10.0 # Initial Gaussian mutation standard deviation
        self.sigma_decay = 0.95 # Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += self.population_size
        
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution
                a, b, c = self._select_different(i, self.population_size)
                mutant = population[a] + self.F * (population[b] - population[c])
                
                #Adaptive Gaussian mutation
                mutant += np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.archive = self._update_archive(population, fitness)
            self.sigma *= self.sigma_decay # Decay sigma

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _select_different(self, index, pop_size):
        a, b, c = random.sample(range(pop_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(pop_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness):
        combined = np.concatenate((np.array(self.archive), population)) if len(self.archive)>0 else population
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness)) if len(self.archive)>0 else fitness
        sorted_indices = np.argsort(combined_fitness)
        return [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]

2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO Run function 15 complete. FEHistory len: 200, AOCC: 0.1023
2025-06-23 09:14:13 INFO FeHistory: [-224.33258643 -223.63797153 -221.88731203 -220.60822013 -222.08334583
 -222.23785064 -221.85426411 -223.37907115 -223.32479583 -222.3721425
 -220.55286274 -220.98760727 -223.29549728 -221.32781456 -222.97019557
 -222.19841221 -220.4960298  -222.41658521 -220.83225109 -222.29930763
 -223.14675519 -221.7239488  -221.03583806 -222.22156091 -223.09794908
 -222.77851772 -222.45301524 -221.32999012 -222.56234688 -221.10711986
 -222.14903311 -224.07476681 -222.20904305 -224.46893843 -221.84326759
 -221.77983655 -222.33070964 -221.18652812 -221.69846716 -220.61545086
 -222.55486354 -221.68347524 -223.23810136 -223.35603724 -223.11724696
 -221.35257907 -222.9896241  -223.33600704 -221.87806897 -221.92579126
 -222.90790303 -223.51983613 -223.02484587 -221.03115606 -222.5285539
 -221.94795564 -222.55000376 -221.02217384 -222.3316837  -222.33336848
 -224.02245371 -222.38793125 -222.10304499 -222.01859593 -222.15151156
 -223.54876744 -222.69946116 -223.10894804 -220.86404469 -222.88876248
 -220.43417877 -221.8520477  -221.89147173 -221.31653523 -224.03960576
 -223.05182911 -222.55094891 -220.84849838 -221.9733249  -220.89197722
 -221.77806814 -221.66470797 -221.72298464 -222.65418584 -222.1604728
 -223.01697345 -224.14910111 -220.70304404 -222.55731702 -223.1789681
 -221.84885008 -224.01389564 -222.83320862 -223.36101441 -223.33331301
 -222.12930116 -221.82278693 -221.49473254 -221.65502617 -222.32281183
 -221.58241796 -222.23687713 -220.75337852 -220.5199376  -222.20763252
 -221.3710901  -221.41932945 -220.71933803 -222.8976925  -221.35920975
 -222.76139827 -223.11188793 -221.73657767 -222.6513635  -221.98752805
 -222.49046734 -220.99626328 -222.27026225 -222.15352516 -221.39831285
 -222.2468236  -221.37281526 -223.51247658 -223.06753925 -220.2982931
 -222.60124576 -221.57153183 -222.10747016 -220.51911099 -222.34402622
 -222.35216016 -222.67154862 -223.20960207 -220.63879009 -220.39414511
 -222.07719351 -223.11919937 -220.86008192 -221.23047245 -221.92596897
 -223.07139292 -221.22272311 -220.89107637 -221.89391811 -222.93490643
 -221.18189337 -222.04273781 -221.85900757 -220.84384915 -221.14155696
 -222.77292972 -222.89587655 -220.87098324 -222.59996917 -222.58361016
 -221.78643232 -222.5269248  -220.81792996 -221.71690981 -221.97018351
 -222.92271202 -220.5624254  -222.34765101 -221.75864664 -221.8781706
 -220.41790066 -224.80455205 -222.26262955 -221.52594263 -222.06618745
 -220.64861614 -222.96051911 -221.8109509  -222.92401755 -221.42834492
 -223.36854035 -222.24850473 -221.56073635 -220.75501168 -221.69723325
 -221.13682512 -221.64351804 -222.83702498 -223.13953083 -221.30967303
 -222.85658031 -222.40393006 -222.35146995 -223.20186401 -222.1918047
 -223.53745683 -221.45254205 -220.84040548 -221.01593226 -220.4777545
 -221.90890902 -221.1106402  -222.81861884 -221.51522358 -220.92591602]
2025-06-23 09:14:13 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:14:13 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveDE
import numpy as np
import random

class AdaptiveGaussianArchiveDE:
    """
    Combines Differential Evolution with an archive and adaptive Gaussian mutation for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.5  # Initial Gaussian mutation standard deviation
        self.sigma_decay = 0.98 # Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                #Adaptive Gaussian Mutation
                mutant += np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution
                
            # Archive Management
            self._update_archive(population, fitness)
            self.sigma *= self.sigma_decay # Decay sigma

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_sigma': self.sigma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness):
        #Simple Archive: Add top solutions to archive, maintaining diversity 
        combined = np.concatenate((self.archive, population)) if len(self.archive) > 0 else population
        combined_fitness = objective_function(combined) if len(self.archive) == 0 else np.concatenate((np.array([f for _,f in self.archive]), fitness))
        
        sorted_indices = np.argsort(combined_fitness)
        
        self.archive = [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]
        


2025-06-23 09:14:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 ERROR Can not run the algorithm
2025-06-23 09:14:13 INFO Run function 24 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 09:14:13 INFO FeHistory: [194.90964317 221.58592012 182.52977572 219.55548377 189.03119368
 190.04998675 183.27737214 198.77274433 214.20657447 205.48861005
 181.47478846 190.92432647 182.32117072 169.31123002 185.63221055
 191.09995289 180.46739479 237.25805912 163.21300256 203.28052716
 185.11646025 158.61302679 185.67839549 197.04215036 186.8025669
 205.97384563 203.85435819 193.20152528 201.62708625 214.0452659
 188.60238237 188.20951658 190.61636332 193.19118797 193.69537611
 180.15144303 194.75982009 153.39759321 206.18144972 206.7499921
 183.42731929 175.47291238 190.79993046 180.57534752 200.48801266
 241.539473   204.82257079 185.15793893 184.31966035 182.91294726
 177.18577072 213.19877313 182.17188509 218.49135135 169.77884704
 212.35470392 173.75004295 205.91267435 177.61485946 156.60548912
 174.0830846  185.62708371 158.98376611 206.78017871 186.4128429
 127.23278674 161.55908263 195.61265299 174.98506758 192.65732335
 172.40894812 165.54023251 188.2574813  192.47071183 226.87894261
 162.42397826 186.90330143 178.74345488 201.8475325  177.63453765
 134.10707239 191.2877942  204.35285449 186.8416393  197.14741807
 177.67679137 190.74356237 187.59960912 195.43115825 203.94165342
 221.67640423 200.09709485 170.6181845  159.35529293 185.03948006
 197.88059132 200.24491893 209.61238574 194.44504254 180.04512543
 175.28562708]
2025-06-23 09:14:13 INFO Expected Optimum FE: -100
2025-06-23 09:14:13 INFO Unimodal AOCC mean: 0.1758
2025-06-23 09:14:13 INFO Multimodal (single component) AOCC mean: 0.1002
2025-06-23 09:14:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:14:13 INFO AOCC mean: 0.0920
2025-06-23 09:14:13 INFO Run function 24 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 09:14:13 INFO FeHistory: [201.74515698 148.70132252 217.79303246 197.25695706 159.7748194
 162.17056874 189.24729098 217.93613299 183.46155059 181.06204712
 164.71615555 162.82338234 197.89137792 175.34249456 179.37496697
 212.61225197 213.33026494 135.32233213 161.16525191 200.56154505
 198.45081351 183.85484304 172.65873147 177.18080141 193.41242691
 228.29465247 188.12541584 178.88807556 181.47475321 194.87352511
 159.79162557 218.1085873  185.74178359 187.95098105 209.64249666
 175.84383595 166.98362477 183.82776191 179.52585537 196.81237115
 165.11838121 169.12035846 184.21127634 200.15861131 182.75979819
 199.32053304 209.38199179 204.94160973 158.44660116 167.2872844
 192.1458236  219.83180867 155.3806529  188.56021464 195.40012733
 142.82925007 205.19094935 185.87396454 202.81516911 226.94931079
 198.87146235 145.93237667 187.57945092 171.10729815 161.01038736
 214.21236702 206.34397443 204.19849578 187.51430158 211.19744392
 198.30941813 187.45552067 177.65859235 165.0154715  200.35543422
 201.3318464  178.32546586 193.15571795 179.9016991  174.21925447
 238.05599208 215.31287787 177.24638028 201.47403104 162.1570691
 162.31031063 175.91159731 196.29130916 216.29326398 157.69472175
 195.54163098 148.09481896 195.42927174 194.83323127 160.47330594
 208.52123634 212.23878419 184.96329318 204.42474883 219.02618968
 200.21843031 215.07480075 211.58085468 203.57359375 183.64466793
 233.345892   207.14818547 215.10651176 214.61784523 166.10018938
 193.56647299 239.47108343 176.13471733 197.90135382 187.62092661
 215.69507551 190.57600424 203.93063627 191.62122043 170.98015401
 251.9845721  199.82984202 190.75289561 171.10850104 187.69346439
 193.06324035 224.66072651 217.33423537 233.12612979 224.25058875
 184.20451328 190.07233388 210.04201689 269.19319315 185.53124555
 209.71558259 169.09908891 234.33683944 162.54775945 198.31484376
 189.94899856 200.78989465 224.15588932 178.80646683 221.73971961
 202.58692645 203.38318804 205.1245771  215.17238876 240.38572124
 182.06118166 193.63741028 201.15537247 240.00152485 213.82716323
 201.6814511  206.82562812 227.25715259 196.29775853 240.90238692
 216.7759696  167.24478859 210.55886067 226.35320934 189.2681797
 195.73163096 198.03571058 205.09127118 186.45011309 158.8218579
 203.22689371 234.67722924 232.82074955 188.36300854 175.27184738
 217.95393309 209.1898679  167.94794566 196.58445542 215.77590002
 206.58312211 224.69672507 248.50174391 183.80087325 209.59723184
 237.50190753 196.67831362 181.74772736 194.13378172 155.68360769
 180.43938459 207.5017131  180.35964754 224.91814895 207.0455649
 235.64861065 236.42446771 185.59980345 207.03678928 182.51484188]
2025-06-23 09:14:13 INFO Expected Optimum FE: -100
2025-06-23 09:14:13 INFO Unimodal AOCC mean: 0.1753
2025-06-23 09:14:13 INFO Multimodal (single component) AOCC mean: 0.1011
2025-06-23 09:14:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:14:13 INFO AOCC mean: 0.0921
2025-06-23 09:14:13 INFO Run function 24 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 09:14:13 INFO FeHistory: [188.18307696 191.3974642  169.00047363 192.73757987 225.80057712
 201.32349549 197.09593892 212.21678951 203.43235029 177.12610463
 213.92022871 195.35328235 177.03222141 175.06973014 207.31849818
 139.1058051  199.48516884 177.86536612 186.56621866 213.67415168
 201.47015097 180.95293148 212.84014915 149.76094159 211.45958507
 184.67542961 143.35468158 188.0409762  142.07072344 204.3471427
 175.79513245 168.19375877 193.80573323 166.54621002 176.28752039
 235.58766089 202.76508668 247.77958365 212.86449052 233.88328302
 177.84077432 184.58949553 206.93973927 161.57181247 193.34658277
 194.60241734 157.43340041 206.66275986 193.30894977 213.11054966
 203.64790048 186.88734921 179.77444983 213.03218315 226.52068453
 174.05850792 165.40486201 185.74697243 183.00251796 162.4038916
 170.28250507 183.54856804 148.86601085 173.32934536 216.65611292
 171.87004706 213.86348939 149.53196053 137.42125909 179.51054234
 197.57412184 171.36920625 217.95816246 179.50948442 170.77732811
 164.19605162 189.39491216 144.8219443  202.73893608 171.45568722
 210.1788867  196.50763972 195.72795744 243.46765634 173.25606242
 206.92062289 237.67768805 172.29468814 167.98556355 208.54018918
 179.73865955 172.87739579 204.49704325 204.47188209 173.02377561
 175.58426232 180.86903165 150.1675253  181.34476442 198.3212875
 197.85829142 187.28261126 224.14438319 209.38411715 219.64992803
 209.71209348 197.28083311 191.10085188 209.6935046  227.14596218
 181.56816084 212.05651767 205.66567624 202.31678228 220.38397796
 168.30747682 192.17044257 215.73744838 188.95387305 176.94085523
 185.23928339 224.0313641  210.96066663 211.17788452 221.54578901
 159.74348875 187.39657821 200.16039608 156.50154813 188.93045922
 214.55317478 188.5007413  210.18501903 175.49722873 225.35623333
 181.50997602 194.84627025 177.07311151 212.10521033 179.97254691
 167.5258816  220.28573497 177.68946457 184.7141397  209.31671652
 193.86079913 219.93956726 200.77472115 205.8873164  192.30784671
 196.1336434  232.25867378 208.01260794 215.07176788 169.20071811
 204.86196112 181.51089639 202.33475746 181.85178336 193.11949778
 218.146213   185.14514596 180.01342256 194.01052395 240.80346292
 206.81696788 235.75979653 197.02200201 218.30360587 189.50603347
 164.4428711  187.22950992 197.79460119 181.86638213 200.0485314
 211.9909115  240.90809051 185.64861584 219.08176002 260.38829018
 190.75017695 220.08584819 187.42187141 181.66631061 185.96726723
 198.45580935 183.50850907 170.05474917 180.81253348 189.53432519
 196.00272672 180.11953956 186.86785561 192.98148615 247.59024108
 205.13753016 221.46844453 196.56395825 198.57440257 225.55506285]
2025-06-23 09:14:13 INFO Expected Optimum FE: -100
2025-06-23 09:14:13 INFO Unimodal AOCC mean: 0.1750
2025-06-23 09:14:13 INFO Multimodal (single component) AOCC mean: 0.1023
2025-06-23 09:14:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:14:13 INFO AOCC mean: 0.0925
2025-06-23 09:14:18 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.2016
2025-06-23 09:14:18 INFO FeHistory: [-701.27756514 -701.33422986 -701.32093108 ... -702.64292844 -702.64397796
 -702.64844515]
2025-06-23 09:14:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:14:18 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA_Improved
import numpy as np

class AdaptiveGaussianArchiveEA_Improved:
    """
    Combines adaptive Gaussian mutation with an archive for diversity and robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200 # Larger archive for diversity
        self.archive = None
        self.archive_fitness = None
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Higher initial sigma for exploration
        self.sigma_decay = 0.98 # Faster decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.archive = self.population.copy()
        self.archive_fitness = objective_function(self.archive)
        self.eval_count += self.population_size
        self.best_solution_overall = self.archive[np.argmin(self.archive_fitness)]
        self.best_fitness_overall = np.min(self.archive_fitness)

        while self.eval_count < self.budget:
            parents = self.tournament_selection(self.archive_fitness, k=5)
            offspring = self.gaussian_mutation(parents, self.sigma)
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.archive = np.vstack((self.archive, offspring))
            self.archive_fitness = np.concatenate((self.archive_fitness, offspring_fitness))
            
            #Maintain archive size
            sorted_indices = np.argsort(self.archive_fitness)
            self.archive = self.archive[sorted_indices[:self.archive_size]]
            self.archive_fitness = self.archive_fitness[sorted_indices[:self.archive_size]]
            

            # Update best solution
            best_index = np.argmin(self.archive_fitness)
            if self.archive_fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.archive[best_index]
                self.best_fitness_overall = self.archive_fitness[best_index]

            # Adaptive Sigma
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.archive[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

2025-06-23 09:14:18 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:14:23 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1186
2025-06-23 09:14:23 INFO FeHistory: [-221.12125384 -221.13230668 -223.36133123 ... -228.27074257 -228.27074341
 -228.27074325]
2025-06-23 09:14:23 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:14:23 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA_Improved
import numpy as np

class AdaptiveGaussianArchiveEA_Improved:
    """
    Combines adaptive Gaussian mutation with an archive for diversity and robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200 # Larger archive for diversity
        self.archive = None
        self.archive_fitness = None
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Higher initial sigma for exploration
        self.sigma_decay = 0.98 # Faster decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.archive = self.population.copy()
        self.archive_fitness = objective_function(self.archive)
        self.eval_count += self.population_size
        self.best_solution_overall = self.archive[np.argmin(self.archive_fitness)]
        self.best_fitness_overall = np.min(self.archive_fitness)

        while self.eval_count < self.budget:
            parents = self.tournament_selection(self.archive_fitness, k=5)
            offspring = self.gaussian_mutation(parents, self.sigma)
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.archive = np.vstack((self.archive, offspring))
            self.archive_fitness = np.concatenate((self.archive_fitness, offspring_fitness))
            
            #Maintain archive size
            sorted_indices = np.argsort(self.archive_fitness)
            self.archive = self.archive[sorted_indices[:self.archive_size]]
            self.archive_fitness = self.archive_fitness[sorted_indices[:self.archive_size]]
            

            # Update best solution
            best_index = np.argmin(self.archive_fitness)
            if self.archive_fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.archive[best_index]
                self.best_fitness_overall = self.archive_fitness[best_index]

            # Adaptive Sigma
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.archive[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

2025-06-23 09:14:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:14:39 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0191
2025-06-23 09:14:39 INFO FeHistory: [193.12871382 187.31595261 179.96386922 ... -45.96002295 -45.96002307
 -45.96002401]
2025-06-23 09:14:39 INFO Expected Optimum FE: -100
2025-06-23 09:14:39 INFO Unimodal AOCC mean: 0.2016
2025-06-23 09:14:39 INFO Multimodal (single component) AOCC mean: 0.1186
2025-06-23 09:14:39 INFO Multimodal (multiple components) AOCC mean: 0.0191
2025-06-23 09:14:39 INFO AOCC mean: 0.1131
2025-06-23 09:14:58 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:14:58 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:15:04 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.1843
2025-06-23 09:15:04 INFO FeHistory: [-701.28506895 -701.3150201  -701.28587035 ... -701.72619658 -701.72619648
 -701.72619781]
2025-06-23 09:15:04 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:15:04 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithDiversity
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithDiversity
# Description: A differential evolution algorithm that adapts mutation strength and incorporates diversity preservation for multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithDiversity:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.adaptive_factor = 0.9 #Adaptive factor for scaling mutation
        self.diversity_threshold = 0.1 # Threshold to trigger increased exploration

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            
            diversity = self._calculate_diversity(population)
            if diversity < self.diversity_threshold:
                self.F *= 1.1 # Increase exploration if diversity is low
            else:
                self.F *= self.adaptive_factor #Gradually reduce exploration

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Select random indices (excluding self)
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)

            #Differential mutation
            mutant = population[a] + self.F * (population[b] - population[c])

            #Bound checking
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            jrand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]
        return offspring

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _calculate_diversity(self, population):
        distances = pdist(population)
        if len(distances) > 0:
            return np.mean(distances)
        else:
            return 0.0 #Handle empty population case
2025-06-23 09:15:04 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:15:08 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.1803
2025-06-23 09:15:08 INFO FeHistory: [-701.29828671 -701.34449042 -701.36025048 ... -701.55690007 -701.52705221
 -701.560495  ]
2025-06-23 09:15:08 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 09:15:08 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: Differential evolution enhanced with adaptive mutation and clustering for multimodal optimization.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []  # To store diverse solutions
        self.archive_size = 200
        self.clustering_threshold = 0.1 # Adjust as needed

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self.archive = self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, target, pop_size):
        others = list(range(pop_size))
        others.remove(target)
        np.random.shuffle(others)
        return others[0], others[1], others[2]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        if len(self.archive) > 0:
            distances = pdist(np.vstack((self.archive[:, :-1], combined[:, :-1])))
            distance_matrix = squareform(distances)
            
            new_archive = []
            for i, sol in enumerate(combined):
                too_close = False
                for j, arch_sol in enumerate(self.archive):
                    if distance_matrix[len(self.archive) + i][j] < self.clustering_threshold:
                        too_close = True
                        break
                if not too_close:
                    new_archive.append(sol)

            self.archive = np.array(sorted(new_archive + list(self.archive), key=lambda x: x[-1])[:self.archive_size])

        else:
            self.archive = np.array(sorted(list(combined), key=lambda x: x[-1])[:self.archive_size])

        return self.archive
2025-06-23 09:15:08 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 09:15:09 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1162
2025-06-23 09:15:09 INFO FeHistory: [-222.29178347 -222.65962487 -221.92054498 ... -227.60074895 -227.60074489
 -227.60074867]
2025-06-23 09:15:09 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:15:09 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithDiversity
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithDiversity
# Description: A differential evolution algorithm that adapts mutation strength and incorporates diversity preservation for multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithDiversity:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.adaptive_factor = 0.9 #Adaptive factor for scaling mutation
        self.diversity_threshold = 0.1 # Threshold to trigger increased exploration

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            
            diversity = self._calculate_diversity(population)
            if diversity < self.diversity_threshold:
                self.F *= 1.1 # Increase exploration if diversity is low
            else:
                self.F *= self.adaptive_factor #Gradually reduce exploration

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Select random indices (excluding self)
            a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)

            #Differential mutation
            mutant = population[a] + self.F * (population[b] - population[c])

            #Bound checking
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            jrand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]
        return offspring

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _calculate_diversity(self, population):
        distances = pdist(population)
        if len(distances) > 0:
            return np.mean(distances)
        else:
            return 0.0 #Handle empty population case
2025-06-23 09:15:10 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:15:17 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1076
2025-06-23 09:15:17 INFO FeHistory: [-222.19464796 -221.87362899 -223.1899559  ... -222.7022911  -220.81697468
 -222.29772359]
2025-06-23 09:15:17 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 09:15:17 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: Differential evolution enhanced with adaptive mutation and clustering for multimodal optimization.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []  # To store diverse solutions
        self.archive_size = 200
        self.clustering_threshold = 0.1 # Adjust as needed

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self.archive = self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, target, pop_size):
        others = list(range(pop_size))
        others.remove(target)
        np.random.shuffle(others)
        return others[0], others[1], others[2]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        
        if len(self.archive) > 0:
            distances = pdist(np.vstack((self.archive[:, :-1], combined[:, :-1])))
            distance_matrix = squareform(distances)
            
            new_archive = []
            for i, sol in enumerate(combined):
                too_close = False
                for j, arch_sol in enumerate(self.archive):
                    if distance_matrix[len(self.archive) + i][j] < self.clustering_threshold:
                        too_close = True
                        break
                if not too_close:
                    new_archive.append(sol)

            self.archive = np.array(sorted(new_archive + list(self.archive), key=lambda x: x[-1])[:self.archive_size])

        else:
            self.archive = np.array(sorted(list(combined), key=lambda x: x[-1])[:self.archive_size])

        return self.archive
2025-06-23 09:15:17 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 09:15:27 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-23 09:15:27 INFO FeHistory: [183.5129279  199.59211767 166.24729236 ... 294.27609769 219.0739558
 225.120819  ]
2025-06-23 09:15:27 INFO Expected Optimum FE: -100
2025-06-23 09:15:27 INFO Unimodal AOCC mean: 0.1843
2025-06-23 09:15:27 INFO Multimodal (single component) AOCC mean: 0.1162
2025-06-23 09:15:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:15:27 INFO AOCC mean: 0.1002
2025-06-23 09:15:39 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-23 09:15:39 INFO FeHistory: [183.6988461  179.58747983 190.18791658 ...  87.93019731  83.19627621
  57.34541337]
2025-06-23 09:15:39 INFO Expected Optimum FE: -100
2025-06-23 09:15:39 INFO Unimodal AOCC mean: 0.1803
2025-06-23 09:15:39 INFO Multimodal (single component) AOCC mean: 0.1076
2025-06-23 09:15:39 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 09:15:39 INFO AOCC mean: 0.0960
2025-06-23 09:16:48 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:16:48 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 09:16:48 ERROR Can not run the algorithm
