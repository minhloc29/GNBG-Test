2025-06-23 19:10:24 INFO Initializing first population
2025-06-23 19:10:24 INFO Initializing population from 8 seed files...
2025-06-23 19:14:46 INFO Started evolutionary loop, best so far: 0.09189012611784185
2025-06-23 19:14:46 INFO Population length is: 10
2025-06-23 19:14:46 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-23 19:14:46 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 9.1890e-02# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 5.2516e-02# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 3 (Overall AOCC Score on function 24: 5.1654e-02# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 4 (Overall AOCC Score on function 24: 3.6862e-02# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 5 (Overall AOCC Score on function 24: 3.5923e-02# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 6 (Overall AOCC Score on function 24: 2.6075e-02# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) enhanced with adaptive population size and local search to efficiently explore and exploit multimodal landscapes.
# Code:
```python
# Name: AdaptiveMultimodalCMAES
# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) enhanced with adaptive population size and local search to efficiently explore and exploit multimodal landscapes.
# Code:
import numpy as np
from scipy.stats import cauchy

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.lambda_ = 10 * self.dim  # Initial population size, scales with dimensionality
        self.mu = int(self.lambda_ / 2) # number of parents

        self.mean = np.mean([self.lower_bounds, self.upper_bounds], axis=0) # Initial mean
        self.sigma = 0.3 * np.ptp([self.lower_bounds, self.upper_bounds], axis=0).mean() # Initial step size
        self.C = np.eye(self.dim)  # Initial covariance matrix


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        while self.eval_count < self.budget:
            # Generate population
            population = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.lambda_)

            # Bound handling
            population = np.clip(population, self.lower_bounds, self.upper_bounds)

            # Evaluate fitness
            fitness = objective_function(population)
            self.eval_count += self.lambda_

            # Sort and select parents
            sorted_indices = np.argsort(fitness)
            parents = population[sorted_indices[:self.mu]]
            parent_fitness = fitness[sorted_indices[:self.mu]]

            # Update mean
            self.mean = np.average(parents, axis=0, weights=1/parent_fitness)

            # Update covariance matrix (simplified for brevity)
            B = np.zeros((self.dim,self.mu))
            for i in range(self.mu):
                B[:,i] = parents[i,:] - self.mean
            self.C = np.cov(B,rowvar=False) + 0.1*np.eye(self.dim) # adding noise


            # Adapt step size (simplified)
            self.sigma *= np.exp(0.1 * (np.mean(parent_fitness) - np.min(parent_fitness))/np.mean(parent_fitness))


            # Update best solution
            best_solution_index = np.argmin(fitness)
            if fitness[best_solution_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_solution_index]
                self.best_solution_overall = population[best_solution_index]

            # Adaptive population size (crude adjustment for demonstration)
            if self.eval_count > self.budget * 0.7 and self.sigma < 1e-3 :
              self.lambda_ = int(self.lambda_ * 0.5)
              self.mu = int(self.lambda_ / 2)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'lambda': self.lambda_
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 10 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalCMAES
# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) enhanced with adaptive population size and restarts to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import norm

class AdaptiveMultimodalCMAES:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(4 + np.floor(3 * np.log(self.dim))) # Initial population size
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial step size
        self.mean = 0.5 * (self.upper_bounds + self.lower_bounds) # Initial mean
        self.C = np.eye(self.dim) # Initial covariance matrix
        self.pc = np.zeros(self.dim) # Evolution path for mean
        self.ps = np.zeros(self.dim) # Evolution path for covariance matrix
        self.c_c = 4 / (self.dim + 4) # Learning rate for covariance matrix
        self.c_s = (self.c_c * (2 - self.c_c))**0.5 # Learning rate for evolution path
        self.d_s = 1 + self.c_s * ((self.population_size - 1 + 2 / self.population_size)**0.5)
        self.restart_count = 0

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        while self.eval_count < self.budget:
            # Generate population
            z = np.random.randn(self.population_size, self.dim)
            population = self.mean + self.sigma * np.linalg.cholesky(self.C) @ z.T
            population = np.clip(population.T, self.lower_bounds, self.upper_bounds)

            # Evaluate fitness
            fitness = objective_function(population)
            self.eval_count += self.population_size

            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]
                if self.best_fitness_overall <= acceptance_threshold:
                    break

            # Update mean and covariance matrix
            weights = np.array([norm.pdf(x) for x in np.linspace(-1,1,self.population_size)])
            weights = weights / weights.sum()
            mean_old = self.mean
            self.mean = (weights[:, None]*population).sum(axis=0)
            
            y = (population - mean_old) / self.sigma
            self.pc = (1 - self.c_c) * self.pc + self.c_c * ((self.population_size)**0.5) * y[best_index,:]
            self.ps = (1 - self.c_s) * self.ps + self.c_s * ((self.population_size)**0.5) * y[best_index,:]
            self.C = (1 - self.c_c) * self.C + self.c_c * (np.outer(self.pc, self.pc) + (self.c_s**2) * (np.outer(self.ps, self.ps)))
            
            # Adaptive population size (increase if many function evaluations remaining)
            if self.eval_count < 0.8 * self.budget:
                self.population_size = int(min(self.population_size * 1.2, 2*self.dim))
                
            # Restart mechanism (if progress is stalled)
            if self.eval_count > 0.5 * self.budget and (self.best_fitness_overall - fitness[best_index]) < 1e-6 :
                self.restart_count += 1
                self.population_size = int(4 + np.floor(3 * np.log(self.dim)))
                self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
                self.mean = 0.5 * (self.upper_bounds + self.lower_bounds)
                self.C = np.eye(self.dim)
                self.pc = np.zeros(self.dim)
                self.ps = np.zeros(self.dim)
                self.c_c = 4 / (self.dim + 4)
                self.c_s = (self.c_c * (2 - self.c_c))**0.5


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'restarts': self.restart_count
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 19:14:52 INFO Full response text: **Analysis:**

Comparing (best) EnhancedArchiveGuidedDE vs (worst) AdaptiveMultimodalCMAES, we see that EnhancedArchiveGuidedDE uses an archive to store and reuse promising solutions, promoting exploitation, while AdaptiveMultimodalCMAES relies solely on covariance matrix adaptation, potentially lacking the exploitation capability needed for this complex problem.  EnhancedArchiveGuidedDE also incorporates an adaptive scaling factor in its differential evolution strategy, adding robustness. AdaptiveMultimodalCMAES's simpler covariance matrix update and step size adaptation might be insufficient for the ruggedness of f24.

(second best) AdaptiveGaussianSamplingEAwithArchive vs (second worst) AdaptiveDifferentialEvolutionWithEnhancedInitialization: AdaptiveGaussianSamplingEAwithArchive leverages an archive for diversity and better exploration, whereas AdaptiveDifferentialEvolutionWithEnhancedInitialization's local search, while helpful, is not as effective as the archive-based approach for this problem. The adaptive nature of both is a strength, but the archive allows for more targeted exploration.

Comparing (1st) EnhancedArchiveGuidedDE vs (2nd) AdaptiveGaussianSamplingEAwithArchive, we see that both utilize archives, but EnhancedArchiveGuidedDE employs Differential Evolution (DE), which is a more robust global optimizer than the Gaussian sampling in AdaptiveGaussianSamplingEAwithArchive. DE's vector-based operations seem better suited to handling the non-separability. The archive diversity management in EnhancedArchiveGuidedDE is also more sophisticated.

(3rd) AdaptiveGaussianArchiveEA vs (4th) AdaptiveGaussianSamplingEA:  Both use Gaussian sampling and adaptive mutation, but AdaptiveGaussianArchiveEA includes an archive, giving it a clear advantage.  The archive in AdaptiveGaussianArchiveEA provides a memory of past successful solutions, allowing it to direct the search more effectively.

Comparing (second worst) AdaptiveDifferentialEvolutionWithEnhancedInitialization vs (worst) AdaptiveMultimodalCMAES, we see that although both attempt to address multimodality, AdaptiveDifferentialEvolutionWithEnhancedInitialization uses a more refined population initialization near known optima.  However, neither adequately handles the high dimensionality and non-separability of f24, resulting in poor performance.

Overall: The top-performing algorithms consistently leverage archives to maintain diversity and guide the search, while incorporating adaptive mechanisms to adjust to the problem's landscape. Differential Evolution shows particular strength. The worst-performing algorithms lack these key features, relying on simpler strategies less well-suited to the high-dimensionality, non-separability, and ruggedness of f24.


**Experience:**

Effective heuristics for high-dimensional multimodal optimization require a combination of global exploration (e.g., DE, adaptive sampling), local exploitation (archives, local search), and mechanisms to handle non-separability.  Adaptive parameter adjustments and robust archive management are crucial for success on difficult benchmarks like f24.

2025-06-23 19:14:54 INFO Full response text: * **Keywords:**  Multimodal, High-Dimensional, Exploration-Exploitation, Non-separability, Adaptive, Robustness.

* **Advice:** Focus on adaptive mechanisms for balancing exploration and exploitation. Develop robust archive management strategies resistant to premature convergence.  Explore advanced techniques for handling non-separability, such as covariance matrix adaptation or surrogate models.  Rigorous testing on challenging benchmarks (e.g., f24 variants).

* **Avoid:**  Static parameter settings, simplistic archive management (e.g., first-come, first-served), ignoring non-separability, insufficient testing.

* **Explanation:**  Effective heuristics require dynamic adaptation to the problem landscape, robust handling of diverse data, and addressing the inherent complexities of high-dimensional, multimodal spaces.  Static approaches will fail on challenging problems.

2025-06-23 19:14:54 INFO Generating offspring via Crossover...
2025-06-23 19:22:56 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
AdaptiveGaussianSamplingEAwithArchive
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Worse code
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

### Analyze & experience
- Comparing (best) EnhancedArchiveGuidedDE vs (worst) AdaptiveMultimodalCMAES, we see that EnhancedArchiveGuidedDE uses an archive to store and reuse promising solutions, promoting exploitation, while AdaptiveMultimodalCMAES relies solely on covariance matrix adaptation, potentially lacking the exploitation capability needed for this complex problem.  EnhancedArchiveGuidedDE also incorporates an adaptive scaling factor in its differential evolution strategy, adding robustness. AdaptiveMultimodalCMAES's simpler covariance matrix update and step size adaptation might be insufficient for the ruggedness of f24.

(second best) AdaptiveGaussianSamplingEAwithArchive vs (second worst) AdaptiveDifferentialEvolutionWithEnhancedInitialization: AdaptiveGaussianSamplingEAwithArchive leverages an archive for diversity and better exploration, whereas AdaptiveDifferentialEvolutionWithEnhancedInitialization's local search, while helpful, is not as effective as the archive-based approach for this problem. The adaptive nature of both is a strength, but the archive allows for more targeted exploration.

Comparing (1st) EnhancedArchiveGuidedDE vs (2nd) AdaptiveGaussianSamplingEAwithArchive, we see that both utilize archives, but EnhancedArchiveGuidedDE employs Differential Evolution (DE), which is a more robust global optimizer than the Gaussian sampling in AdaptiveGaussianSamplingEAwithArchive. DE's vector-based operations seem better suited to handling the non-separability. The archive diversity management in EnhancedArchiveGuidedDE is also more sophisticated.

(3rd) AdaptiveGaussianArchiveEA vs (4th) AdaptiveGaussianSamplingEA:  Both use Gaussian sampling and adaptive mutation, but AdaptiveGaussianArchiveEA includes an archive, giving it a clear advantage.  The archive in AdaptiveGaussianArchiveEA provides a memory of past successful solutions, allowing it to direct the search more effectively.

Comparing (second worst) AdaptiveDifferentialEvolutionWithEnhancedInitialization vs (worst) AdaptiveMultimodalCMAES, we see that although both attempt to address multimodality, AdaptiveDifferentialEvolutionWithEnhancedInitialization uses a more refined population initialization near known optima.  However, neither adequately handles the high dimensionality and non-separability of f24, resulting in poor performance.

Overall: The top-performing algorithms consistently leverage archives to maintain diversity and guide the search, while incorporating adaptive mechanisms to adjust to the problem's landscape. Differential Evolution shows particular strength. The worst-performing algorithms lack these key features, relying on simpler strategies less well-suited to the high-dimensionality, non-separability, and ruggedness of f24.
- * **Keywords:**  Multimodal, High-Dimensional, Exploration-Exploitation, Non-separability, Adaptive, Robustness.

* **Advice:** Focus on adaptive mechanisms for balancing exploration and exploitation. Develop robust archive management strategies resistant to premature convergence.  Explore advanced techniques for handling non-separability, such as covariance matrix adaptation or surrogate models.  Rigorous testing on challenging benchmarks (e.g., f24 variants).

* **Avoid:**  Static parameter settings, simplistic archive management (e.g., first-come, first-served), ignoring non-separability, insufficient testing.

* **Explanation:**  Effective heuristics require dynamic adaptation to the problem landscape, robust handling of diverse data, and addressing the inherent complexities of high-dimensional, multimodal spaces.  Static approaches will fail on challenging problems.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 19:22:56 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Multimodal, High-Dimensional, Exploration-Exploitation, Non-separability, Adaptive, Robustness.

* **Advice:** Focus on adaptive mechanisms for balancing exploration and exploitation. Develop robust archive management strategies resistant to premature convergence.  Explore advanced techniques for handling non-separability, such as covariance matrix adaptation or surrogate models.  Rigorous testing on challenging benchmarks (e.g., f24 variants).

* **Avoid:**  Static parameter settings, simplistic archive management (e.g., first-come, first-served), ignoring non-separability, insufficient testing.

* **Explanation:**  Effective heuristics require dynamic adaptation to the problem landscape, robust handling of diverse data, and addressing the inherent complexities of high-dimensional, multimodal spaces.  Static approaches will fail on challenging problems.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 19:24:35 INFO Perform Harmony Search...
2025-06-23 19:24:46 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:25:27 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-23 19:25:27 INFO FeHistory: [215.88031614 157.39480336 205.58661017 ...   8.27183781  23.97830742
  23.29652317]
2025-06-23 19:25:27 INFO Expected Optimum FE: -100
2025-06-23 19:25:27 INFO Unimodal AOCC mean: nan
2025-06-23 19:25:27 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:25:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:25:27 INFO AOCC mean: 0.0000
2025-06-23 19:25:27 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:26:06 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0574
2025-06-23 19:26:06 INFO FeHistory: [171.71311928 209.9551199  204.88008866 ... -88.1542117  -85.54989293
 -85.8757405 ]
2025-06-23 19:26:06 INFO Expected Optimum FE: -100
2025-06-23 19:26:06 INFO Unimodal AOCC mean: nan
2025-06-23 19:26:06 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:26:06 INFO Multimodal (multiple components) AOCC mean: 0.0574
2025-06-23 19:26:06 INFO AOCC mean: 0.0574
2025-06-23 19:26:06 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:26:47 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0691
2025-06-23 19:26:47 INFO FeHistory: [177.7934242  172.35680625 208.23256408 ... -96.80423558 -96.17850036
 -96.19471647]
2025-06-23 19:26:47 INFO Expected Optimum FE: -100
2025-06-23 19:26:47 INFO Unimodal AOCC mean: nan
2025-06-23 19:26:47 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:26:47 INFO Multimodal (multiple components) AOCC mean: 0.0691
2025-06-23 19:26:47 INFO AOCC mean: 0.0691
2025-06-23 19:26:47 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:27:30 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0014
2025-06-23 19:27:30 INFO FeHistory: [198.58534731 172.74289098 160.55610646 ...   5.81551449   6.28637412
  11.52135675]
2025-06-23 19:27:30 INFO Expected Optimum FE: -100
2025-06-23 19:27:30 INFO Unimodal AOCC mean: nan
2025-06-23 19:27:30 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:27:30 INFO Multimodal (multiple components) AOCC mean: 0.0014
2025-06-23 19:27:30 INFO AOCC mean: 0.0014
2025-06-23 19:27:30 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:28:08 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0372
2025-06-23 19:28:08 INFO FeHistory: [172.85094983 171.22434936 168.20370535 ... -52.88881629 -53.70833042
 -52.86534592]
2025-06-23 19:28:08 INFO Expected Optimum FE: -100
2025-06-23 19:28:08 INFO Unimodal AOCC mean: nan
2025-06-23 19:28:08 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:28:08 INFO Multimodal (multiple components) AOCC mean: 0.0372
2025-06-23 19:28:08 INFO AOCC mean: 0.0372
2025-06-23 19:28:08 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:28:48 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0571
2025-06-23 19:28:48 INFO FeHistory: [215.82580608 204.67937304 194.94390061 ... -93.91751548 -93.48748399
 -92.67465173]
2025-06-23 19:28:48 INFO Expected Optimum FE: -100
2025-06-23 19:28:48 INFO Unimodal AOCC mean: nan
2025-06-23 19:28:48 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:28:48 INFO Multimodal (multiple components) AOCC mean: 0.0571
2025-06-23 19:28:48 INFO AOCC mean: 0.0571
2025-06-23 19:28:48 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:29:28 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0730
2025-06-23 19:29:28 INFO FeHistory: [199.71576864 196.64349653 185.39656368 ... -97.14976817 -97.00627618
 -97.20531607]
2025-06-23 19:29:28 INFO Expected Optimum FE: -100
2025-06-23 19:29:28 INFO Unimodal AOCC mean: nan
2025-06-23 19:29:28 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:29:28 INFO Multimodal (multiple components) AOCC mean: 0.0730
2025-06-23 19:29:28 INFO AOCC mean: 0.0730
2025-06-23 19:29:28 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:30:06 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0195
2025-06-23 19:30:06 INFO FeHistory: [164.08831985 193.37729271 182.4603995  ... -25.75901941 -27.79166373
 -23.94010962]
2025-06-23 19:30:06 INFO Expected Optimum FE: -100
2025-06-23 19:30:06 INFO Unimodal AOCC mean: nan
2025-06-23 19:30:06 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:30:06 INFO Multimodal (multiple components) AOCC mean: 0.0195
2025-06-23 19:30:06 INFO AOCC mean: 0.0195
2025-06-23 19:30:06 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:30:46 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0485
2025-06-23 19:30:46 INFO FeHistory: [188.9018495  194.32294591 184.85668355 ... -69.52729985 -68.46974418
 -70.83076716]
2025-06-23 19:30:46 INFO Expected Optimum FE: -100
2025-06-23 19:30:46 INFO Unimodal AOCC mean: nan
2025-06-23 19:30:46 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:30:46 INFO Multimodal (multiple components) AOCC mean: 0.0485
2025-06-23 19:30:46 INFO AOCC mean: 0.0485
2025-06-23 19:30:46 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:31:27 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0635
2025-06-23 19:31:27 INFO FeHistory: [193.34273786 211.87555177 201.12421183 ... -95.44474736 -94.80053965
 -95.25648781]
2025-06-23 19:31:27 INFO Expected Optimum FE: -100
2025-06-23 19:31:27 INFO Unimodal AOCC mean: nan
2025-06-23 19:31:27 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:31:27 INFO Multimodal (multiple components) AOCC mean: 0.0635
2025-06-23 19:31:27 INFO AOCC mean: 0.0635
2025-06-23 19:31:27 INFO Generation 1, best so far: 0.09189012611784185
2025-06-23 19:31:27 INFO Population length is: 10
2025-06-23 19:31:27 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-23 19:31:27 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 7.2985e-02# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.817843710945267, archive_size: int = 533.2089397570765, initial_F_scale: float = 0.35086800435926957,
                 acceptance_threshold: float = 8.060604190673736e-06, archive_update_threshold: float = 0.6110359754990626):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 1.1392e-05# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an adaptive archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution (DE) with an adaptive archive to enhance exploration and exploitation in multimodal landscapes.  Uses an adaptive scaling factor and archive management for robustness.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 200 #Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor
        self.F_adaptation_rate = 0.1 #controls how quickly F adapts


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adaptive F scaling based on recent success
            if self.best_fitness_overall < np.mean(fitness):
              self.F_scale += self.F_adaptation_rate * (1-self.F_scale)
            else:
              self.F_scale -= self.F_adaptation_rate * self.F_scale
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9) #Keep F within reasonable bounds


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Select pbest from archive (if available)  Prioritize recent archive members
            if self.archive:
                pbest_index = np.random.choice(len(self.archive), p = [1/len(self.archive)] * len(self.archive) )
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]


            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity and fitness in archive using a weighted approach
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 3 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedGaussianDE
# Description: Combines Differential Evolution with Gaussian mutation and an archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedGaussianDE:
    """
    Combines Differential Evolution (DE) with Gaussian mutation and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds) #Initial Gaussian width
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._gaussian_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            # Select three distinct random individuals (excluding the current one)
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i or a == b or a == c or b == c:
                a, b, c = random.sample(range(self.population_size), 3)

            # Mutation
            mutant = population[a] + self.F * (population[b] - population[c])

            # Crossover
            jrand = random.randint(0, self.dim -1)
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]

        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 4 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an adaptive archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an adaptive archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic for population size
        self.archive_size = 200  # Size of the archive
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor
        self.CR = 0.9 # initial crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adaptive parameters
            self.adapt_parameters(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            # Select pbest from archive (if available), promoting exploitation
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = self._select_different(i, population.shape[0]) # Ensure different indices

            #Differential Evolution Mutation
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            
            #Binomial Crossover
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity and fitness in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def _select_different(self, index: int, population_size:int) -> tuple:
        """Select three distinct indices different from the given index."""
        a, b, c = random.sample(range(population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c

    def adapt_parameters(self, fitness):
        # Simple adaptive strategy: adjust F based on convergence speed
        std_dev = np.std(fitness)
        if std_dev < 0.1: #Adjust threshold as needed
            self.F_scale *= 1.1 #increase exploration if converging too fast
        elif std_dev > 5: #Adjust threshold as needed
            self.F_scale *= 0.9 #reduce exploration if too spread out


```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedDifferentialEvolution
# Description: Combines differential evolution with an archive to enhance exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedDifferentialEvolution:
    """
    Combines differential evolution with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.8 # Differential weight
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)
        self.archive = self._update_archive(self.population, self.fitness_values)


        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(i)
                trial = self._crossover(i, mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    self.fitness_values[i] = trial_fitness
                else:
                    new_population.append(self.population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), self.fitness_values[:len(new_population)])
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            self.population = np.array(new_population)
            self.archive = self._update_archive(np.vstack((self.population,self.archive)), np.concatenate((self.fitness_values, np.array([x[-1] for x in self.archive]))))

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _generate_mutant(self, index):
        a, b, c = self._select_different(index, self.population_size)
        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
        
        #Incorporate archive for exploration
        if len(self.archive) > 0 and random.random() < 0.2: # 20% chance to use archive member
            archive_index = random.randint(0, len(self.archive)-1)
            mutant = self.archive[archive_index][:-1] + self.F * (self.population[b] - self.population[c])

        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, index, mutant):
        trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[index])
        return trial

    def _select_different(self, index, pop_size):
        a, b, c = random.sample(range(pop_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(pop_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedDifferentialEvolution
# Description: Combines differential evolution with an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedDifferentialEvolution:
    """
    Combines differential evolution with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor (adaptive)
        self.CR = 0.9 # Crossover rate
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self._adapt_F() #Adaptive F

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            #Select 3 different individuals
            a, b, c = self._select_different(i, len(population))
            
            #Differential Mutation
            mutant = population[a] + self.F * (population[b] - population[c])

            #Binomial Crossover
            trial = np.copy(population[i])
            j_rand = random.randint(0, self.dim -1)
            for j in range(self.dim):
                if random.random() < self.CR or j == j_rand:
                    trial[j] = mutant[j]

            #Boundary Constraint
            trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
            offspring[i] = trial
        return offspring

    def _select_different(self, current_index, population_size):
        indices = list(range(population_size))
        indices.remove(current_index)
        random.shuffle(indices)
        return indices[0], indices[1], indices[2]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _adapt_F(self):
        # Simple adaptive strategy: reduce F if no improvement
        if self.eval_count > 0 and self.best_fitness_overall == float('inf'): #No improvement
            self.F *= 0.95
        else:
            self.F = max(0.1, min(1, self.F + 0.01 * random.random())) #prevent F from going too high or low.


```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveCovarianceDE
# Description: Differential Evolution with adaptive covariance matrix adaptation for multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveCovarianceDE
# Description: Differential Evolution with adaptive covariance matrix adaptation for multimodal landscapes.
# Code:

class AdaptiveCovarianceDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9  # Crossover rate
        self.covariance_matrix = np.eye(self.dim)  # Initial covariance matrix
        self.learning_rate = 0.1  # Learning rate for covariance adaptation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adapt_covariance_matrix()

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()

        for i in range(self.population_size):
            #Sample from archive with consideration of covariance
            if self.archive:
                weights = np.exp(-np.sum((np.array(self.archive)[:,0] - population[i])**2, axis=1) / (2 * np.mean(np.diag(self.covariance_matrix))))
                weights = weights / np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            trial = np.zeros_like(mutant)
            for j in range(self.dim):
                if np.random.rand() < self.CR:
                    trial[j] = mutant[j]
                else:
                    trial[j] = population[i][j]

            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)

        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_covariance_matrix(self):
        if len(self.archive) > 0:
            archive_solutions = np.array([solution for solution, _ in self.archive])
            mean_solution = np.mean(archive_solutions, axis=0)
            centered_solutions = archive_solutions - mean_solution
            new_covariance = np.cov(centered_solutions, rowvar=False)
            self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * new_covariance
            self.covariance_matrix = 0.5 * (self.covariance_matrix + self.covariance_matrix.T) #Ensure symmetry
            self.covariance_matrix = np.clip(self.covariance_matrix, 1e-6 * np.eye(self.dim), np.inf) #Handle potential singularity

```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveCovarianceMatrixDE
# Description: Differential Evolution with adaptive covariance matrix and guided mutation for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveCovarianceMatrixDE
# Description: Differential Evolution with adaptive covariance matrix and guided mutation for multimodal optimization.
# Code:
class AdaptiveCovarianceMatrixDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.Cr = 0.9  # Crossover rate
        self.covariance_matrix = np.eye(self.dim)  # Initialize covariance matrix
        self.learning_rate = 0.1  # Learning rate for covariance matrix adaptation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adapt_covariance_matrix()

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()

        for i in range(self.population_size):
            # Guided mutation using covariance matrix
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
                mutation = self.F_scale * np.random.multivariate_normal(pbest - population[i], self.covariance_matrix)
            else:
                pbest = population[np.argmin(fitness)]
                mutation = self.F_scale * (pbest - population[i])


            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            trial_vector = population[i] + mutation + population[a] - population[b]
            
            #Crossover
            jrand = np.random.randint(0,self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.Cr or j == jrand:
                    offspring[i,j] = trial_vector[j]
                else:
                    offspring[i,j] = population[i,j]


            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_covariance_matrix(self):
        if len(self.archive) > 0:
            # Simple covariance matrix adaptation (can be improved with more sophisticated methods)
            archive_solutions = np.array([x for x, _ in self.archive])
            mean = np.mean(archive_solutions, axis=0)
            cov = np.cov(archive_solutions, rowvar=False)
            self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov

```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveCovarianceDE
# Description: Differential Evolution with adaptive covariance matrix adaptation for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveCovarianceDE
# Description: Differential Evolution with adaptive covariance matrix adaptation for multimodal optimization.
# Code:
class AdaptiveCovarianceDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate

        # Covariance matrix adaptation
        self.C = np.eye(self.dim)  # Initialize covariance matrix
        self.learning_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adapt_covariance() #Adapt covariance matrix

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()

        for i in range(self.population_size):
            #Use covariance matrix for pbest selection, favoring diverse solutions.
            if self.archive:
                weights = np.exp(-np.sum((np.array(self.archive)[:,0] - population[i])**2 @ np.linalg.inv(self.C), axis=1))
                weights /= np.sum(weights)
                pbest_index = np.random.choice(len(self.archive), p=weights)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            #Differential mutation with adaptive covariance
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            
            #Crossover
            jrand = random.randint(0,self.dim-1)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == jrand:
                    offspring[i,j] = mutant[j]
                else:
                    offspring[i,j] = population[i,j]


            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def adapt_covariance(self):
        if len(self.archive) > 0:
            # Update covariance matrix using successful solutions from the archive.
            #This is a simplified CMA-ES like update.  More sophisticated updates are possible.
            successful_solutions = np.array([x for x,f in self.archive if f < self.best_fitness_overall])
            if len(successful_solutions)>0:
                mean = np.mean(successful_solutions, axis=0)
                diff = successful_solutions - mean
                self.C = (1-self.learning_rate)*self.C + self.learning_rate * (diff.T @ diff) / len(successful_solutions)
                self.C = 0.5 * (self.C + self.C.T) #Ensure symmetry
                self.C = np.clip(self.C, 0, np.inf) #Handle numerical instability
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 19:31:32 INFO Full response text: **Analysis:**

Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveCovarianceDE` (last version), we see that the best uses a more sophisticated archive update strategy prioritizing both fitness and diversity, while the worst has a simpler update and lacks diversity consideration.  `EnhancedArchiveGuidedDE` also has an adaptive scaling factor (`F_scale`) that adds robustness.  (second best) `ArchiveGuidedAdaptiveDE` (first version) vs (second worst) `AdaptiveCovarianceMatrixDE`, the second best employs adaptive scaling factor (`F_scale`) based on convergence speed, enhancing its adaptability, unlike the second worst which uses a fixed `F_scale`. The archive management in the second best is better than the second worst, which lacks careful diversity preservation. Comparing (1st) `EnhancedArchiveGuidedDE` vs (2nd) `ArchiveGuidedAdaptiveDE` (first version), we see that the top-performing algorithm introduces a more advanced archive update mechanism using a threshold, ensuring only significantly better solutions replace existing archive members, which is missing in the second. Also, `EnhancedArchiveGuidedDE`'s parameter settings and adaptive strategy appears more carefully tuned. (3rd) `ArchiveGuidedGaussianDE` vs (4th) `ArchiveGuidedAdaptiveDE` (second version), both use archives but the former adds Gaussian mutation, making exploration more robust. The latter uses a less effective adaptive F.  Comparing (second worst) `AdaptiveCovarianceMatrixDE` vs (worst) `AdaptiveCovarianceDE` (last version), the second worst utilizes covariance matrix adaptation for guided mutation, directing the search towards promising regions. The worst implements covariance adaptation for pbest selection, a less direct and potentially less effective approach. The second worst also manages its archive better, prioritizing diversity.  Overall: The top performers heavily leverage adaptive archive management and parameter tuning, focusing on balancing exploration and exploitation effectively.  The lower-ranked algorithms exhibit less sophisticated archive handling and less effective parameter adaptation strategies.

**Experience:**

Effective heuristics necessitate careful archive management and adaptive parameter tuning, finely balancing exploration and exploitation.  Prioritizing diversity within the archive and implementing adaptive strategies significantly improve performance on complex, multimodal landscapes like f24.

2025-06-23 19:31:34 INFO Full response text: * **Keywords:**  Archive diversity, adaptive parameter tuning, exploration-exploitation balance, multimodal optimization.

* **Advice:** Focus on quantifiable metrics for archive diversity (e.g., coverage, distance metrics).  Develop adaptive parameter tuning strategies tied directly to observed performance (e.g., using performance indicators to adjust exploration/exploitation).  Rigorously test on diverse multimodal benchmarks (beyond just f24).  Employ clear separation of concerns in code for better maintainability and analysis.

* **Avoid:** Vague statements about "global exploration" and "local exploitation." Avoid subjective terms like "robust" without quantifiable support.  Do not simply reiterate existing methods without novel improvements.  Avoid overfitting to a single benchmark (f24).

* **Explanation:**  The goal is to move beyond general descriptions of effective heuristics to concrete, measurable improvements.  This involves specifying *how* archive diversity and parameter tuning are achieved and rigorously evaluating the impact on performance across multiple benchmarks.  The improved heuristics should be demonstrably superior to existing approaches with clear, quantifiable evidence.

2025-06-23 19:31:34 INFO Generating offspring via Crossover...
2025-06-23 19:34:14 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
AdaptiveCovarianceMatrixDE
import numpy as np
import random

# Name: AdaptiveCovarianceMatrixDE
# Description: Differential Evolution with adaptive covariance matrix and guided mutation for multimodal optimization.
# Code:
class AdaptiveCovarianceMatrixDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.Cr = 0.9  # Crossover rate
        self.covariance_matrix = np.eye(self.dim)  # Initialize covariance matrix
        self.learning_rate = 0.1  # Learning rate for covariance matrix adaptation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adapt_covariance_matrix()

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()

        for i in range(self.population_size):
            # Guided mutation using covariance matrix
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
                mutation = self.F_scale * np.random.multivariate_normal(pbest - population[i], self.covariance_matrix)
            else:
                pbest = population[np.argmin(fitness)]
                mutation = self.F_scale * (pbest - population[i])


            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            trial_vector = population[i] + mutation + population[a] - population[b]
            
            #Crossover
            jrand = np.random.randint(0,self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.Cr or j == jrand:
                    offspring[i,j] = trial_vector[j]
                else:
                    offspring[i,j] = population[i,j]


            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_covariance_matrix(self):
        if len(self.archive) > 0:
            # Simple covariance matrix adaptation (can be improved with more sophisticated methods)
            archive_solutions = np.array([x for x, _ in self.archive])
            mean = np.mean(archive_solutions, axis=0)
            cov = np.cov(archive_solutions, rowvar=False)
            self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov


### Worse code
ArchiveGuidedAdaptiveDE
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution (DE) with an adaptive archive to enhance exploration and exploitation in multimodal landscapes.  Uses an adaptive scaling factor and archive management for robustness.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 200 #Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor
        self.F_adaptation_rate = 0.1 #controls how quickly F adapts


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adaptive F scaling based on recent success
            if self.best_fitness_overall < np.mean(fitness):
              self.F_scale += self.F_adaptation_rate * (1-self.F_scale)
            else:
              self.F_scale -= self.F_adaptation_rate * self.F_scale
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9) #Keep F within reasonable bounds


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Select pbest from archive (if available)  Prioritize recent archive members
            if self.archive:
                pbest_index = np.random.choice(len(self.archive), p = [1/len(self.archive)] * len(self.archive) )
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]


            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity and fitness in archive using a weighted approach
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


### Analyze & experience
- Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveCovarianceDE` (last version), we see that the best uses a more sophisticated archive update strategy prioritizing both fitness and diversity, while the worst has a simpler update and lacks diversity consideration.  `EnhancedArchiveGuidedDE` also has an adaptive scaling factor (`F_scale`) that adds robustness.  (second best) `ArchiveGuidedAdaptiveDE` (first version) vs (second worst) `AdaptiveCovarianceMatrixDE`, the second best employs adaptive scaling factor (`F_scale`) based on convergence speed, enhancing its adaptability, unlike the second worst which uses a fixed `F_scale`. The archive management in the second best is better than the second worst, which lacks careful diversity preservation. Comparing (1st) `EnhancedArchiveGuidedDE` vs (2nd) `ArchiveGuidedAdaptiveDE` (first version), we see that the top-performing algorithm introduces a more advanced archive update mechanism using a threshold, ensuring only significantly better solutions replace existing archive members, which is missing in the second. Also, `EnhancedArchiveGuidedDE`'s parameter settings and adaptive strategy appears more carefully tuned. (3rd) `ArchiveGuidedGaussianDE` vs (4th) `ArchiveGuidedAdaptiveDE` (second version), both use archives but the former adds Gaussian mutation, making exploration more robust. The latter uses a less effective adaptive F.  Comparing (second worst) `AdaptiveCovarianceMatrixDE` vs (worst) `AdaptiveCovarianceDE` (last version), the second worst utilizes covariance matrix adaptation for guided mutation, directing the search towards promising regions. The worst implements covariance adaptation for pbest selection, a less direct and potentially less effective approach. The second worst also manages its archive better, prioritizing diversity.  Overall: The top performers heavily leverage adaptive archive management and parameter tuning, focusing on balancing exploration and exploitation effectively.  The lower-ranked algorithms exhibit less sophisticated archive handling and less effective parameter adaptation strategies.
- * **Keywords:**  Archive diversity, adaptive parameter tuning, exploration-exploitation balance, multimodal optimization.

* **Advice:** Focus on quantifiable metrics for archive diversity (e.g., coverage, distance metrics).  Develop adaptive parameter tuning strategies tied directly to observed performance (e.g., using performance indicators to adjust exploration/exploitation).  Rigorously test on diverse multimodal benchmarks (beyond just f24).  Employ clear separation of concerns in code for better maintainability and analysis.

* **Avoid:** Vague statements about "global exploration" and "local exploitation." Avoid subjective terms like "robust" without quantifiable support.  Do not simply reiterate existing methods without novel improvements.  Avoid overfitting to a single benchmark (f24).

* **Explanation:**  The goal is to move beyond general descriptions of effective heuristics to concrete, measurable improvements.  This involves specifying *how* archive diversity and parameter tuning are achieved and rigorously evaluating the impact on performance across multiple benchmarks.  The improved heuristics should be demonstrably superior to existing approaches with clear, quantifiable evidence.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 19:34:14 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Archive diversity, adaptive parameter tuning, exploration-exploitation balance, multimodal optimization.

* **Advice:** Focus on quantifiable metrics for archive diversity (e.g., coverage, distance metrics).  Develop adaptive parameter tuning strategies tied directly to observed performance (e.g., using performance indicators to adjust exploration/exploitation).  Rigorously test on diverse multimodal benchmarks (beyond just f24).  Employ clear separation of concerns in code for better maintainability and analysis.

* **Avoid:** Vague statements about "global exploration" and "local exploitation." Avoid subjective terms like "robust" without quantifiable support.  Do not simply reiterate existing methods without novel improvements.  Avoid overfitting to a single benchmark (f24).

* **Explanation:**  The goal is to move beyond general descriptions of effective heuristics to concrete, measurable improvements.  This involves specifying *how* archive diversity and parameter tuning are achieved and rigorously evaluating the impact on performance across multiple benchmarks.  The improved heuristics should be demonstrably superior to existing approaches with clear, quantifiable evidence.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 19:36:06 INFO Perform Harmony Search...
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:36:15 ERROR Can not run the algorithm
2025-06-23 19:36:15 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 19:36:15 INFO FeHistory: []
2025-06-23 19:36:15 INFO Expected Optimum FE: -100
2025-06-23 19:36:15 INFO Unimodal AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:36:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:36:15 INFO AOCC mean: 0.0000
2025-06-23 19:36:15 INFO Generation 2, best so far: 0.09189012611784185
2025-06-23 19:36:15 INFO Population length is: 10
2025-06-23 19:36:15 INFO --- Performing Long-Term Reflection at Generation 3 ---
2025-06-23 19:36:15 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution using an archive for enhanced exploration and exploitation in multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveArchiveDE:
    """
    Combines differential evolution with an adaptive archive to enhance exploration and exploitation in multimodal landscapes.  The archive manages diversity and guides the search.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic for population size
        self.archive_size = 200
        self.archive = []
        self.F = 0.8  # Differential weight (initial)
        self.CR = 0.9 # Crossover rate
        self.F_scale = 0.5 # Scaling factor for mutation (initial)

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self._update_archive(offspring, offspring_fitness)

            #Selection
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((self.fitness_values, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            self.fitness_values = combined_fitness[indices[:self.population_size]]
            
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)
            #Adaptive F
            self.F_scale = 0.5 + 0.3 * np.random.rand() #Add some randomness


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = self.population[np.argmin(self.fitness_values)]

            a, b, c = self._select_different(i)
            offspring[i] = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring


    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, offspring, offspring_fitness):
        combined = np.column_stack((offspring, offspring_fitness))
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                if len(self.archive) < self.archive_size:
                    self.archive.append(sol)
                else:  #Replace worst if better
                    worst_index = np.argmax([f for _, f in self.archive])
                    if sol[-1] < self.archive[worst_index][-1]:
                        self.archive[worst_index] = sol

        # Sort archive by fitness
        self.archive.sort(key=lambda x: x[-1])
        self.archive = self.archive[:self.archive_size] #Keep top

```

### Rank 2 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedAdaptiveDEwithGaussianMutation
# Description: Adaptive Differential Evolution with Gaussian mutation and archive guided pbest selection for multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDEwithGaussianMutation:
    """
    Combines Differential Evolution (DE) with an adaptive archive and Gaussian mutation to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 500  # Increased archive size
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.2 # Gaussian mutation parameter


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 3 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveDEwithGaussianMutation
# Description: Adaptive Differential Evolution using an archive and Gaussian mutation for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveArchiveDEwithGaussianMutation:
    """
    Combines Differential Evolution (DE) with an adaptive archive and Gaussian mutation to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.1 # Gaussian mutation standard deviation

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            self.adapt_parameters(fitness) # Adaptive parameter tuning

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            #Gaussian mutation for enhanced exploration
            offspring[i] += np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_parameters(self, fitness):
        #Adaptive F and sigma based on recent performance
        mean_fitness = np.mean(fitness)
        if self.best_fitness_overall < mean_fitness:
            self.F_scale += 0.1 * (1 - self.F_scale)
            self.sigma *= 0.9
        else:
            self.F_scale -= 0.1 * self.F_scale
            self.sigma *= 1.1
        self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
        self.sigma = np.clip(self.sigma, 0.01, 1.0)

```

### Rank 4 (Overall AOCC Score on function 24: 0.0000e+00# Name: EnhancedArchiveGuidedDE
# Description: Adaptive Differential Evolution with Gaussian mutation and an enhanced archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

class EnhancedArchiveGuidedDE:
    """
    Combines Differential Evolution (DE) with Gaussian mutation and an enhanced archive for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.2  # Initial Gaussian width (scaled later)
        self.sigma_decay = 0.99
        self.archive = []
        self.archive_threshold = 0.1 #Threshold for archive update

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)
        self.sigma = 0.2 * np.mean(self.upper_bounds - self.lower_bounds) #Scale sigma based on bounds

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._gaussian_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i or a == b or a == c or b == c:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[a] + self.F * (population[b] - population[c])
            jrand = random.randint(0, self.dim - 1)
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]

        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        if len(new_archive) > 0 : #Avoid error when archive is empty
          new_archive.sort(key=lambda x: x[-1])
          self.archive.extend(new_archive)
          
          #Keep only top solutions based on threshold
          self.archive.sort(key=lambda x: x[-1])
          
          avg_fitness = np.mean([x[-1] for x in self.archive])
          
          self.archive = [x for x in self.archive if x[-1] <= avg_fitness + (avg_fitness * self.archive_threshold)]
        
        return np.array(self.archive[:self.archive_size]) # Limit size



```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedAdaptiveDEwithGaussianMutation
# Description: Adaptive DE with archive and Gaussian mutation for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDEwithGaussianMutation
# Description: Adaptive DE with archive and Gaussian mutation for multimodal optimization.
# Code:

class ArchiveGuidedAdaptiveDEwithGaussianMutation:
    """
    Combines Differential Evolution with an adaptive archive and Gaussian mutation for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9
        self.sigma = 0.1 #Initial Gaussian mutation standard deviation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            self.adapt_parameters(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = self._select_different(i, population.shape[0])
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            #Gaussian Mutation
            trial += np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def _select_different(self, index: int, population_size:int) -> tuple:
        a, b, c = random.sample(range(population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c

    def adapt_parameters(self, fitness):
        std_dev = np.std(fitness)
        if std_dev < 0.1:
            self.F_scale *= 1.1
            self.sigma *= 1.1 #Increase Gaussian mutation if converging too fast
        elif std_dev > 5:
            self.F_scale *= 0.9
            self.sigma *= 0.9 #Reduce Gaussian mutation if too spread out

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: EnhancedArchiveGuidedDE
# Description: Differential Evolution with adaptive archive, prioritizing diversity and fitness for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: EnhancedArchiveGuidedDE
# Description: Differential Evolution with adaptive archive, prioritizing diversity and fitness for multimodal optimization.
# Code:
class EnhancedArchiveGuidedDE:
    """
    Combines Differential Evolution (DE) with an adaptive archive to enhance exploration and exploitation in multimodal landscapes.  Prioritizes both fitness and diversity in archive management. Uses an adaptive scaling factor.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.archive_diversity_threshold = 0.8 # Controls how aggressively the archive maintains diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adaptive F scaling
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Select pbest from archive (if available), weighted randomly
            if self.archive:
                pbest_index = np.random.choice(len(self.archive)) # Simple random choice for now.  Could be improved.
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and fitness using a threshold
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] * self.archive_diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDiversityDE
# Description: 
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class AdaptiveDiversityDE:
    """
    Adaptive Diversity Differential Evolution: Improves exploration-exploitation balance 
    by dynamically adjusting mutation parameters based on population and archive diversity.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = np.inf
        self.population_size = 10 * dim
        self.archive_size = 200  #Increased archive size for diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self.update_best(self.population, fitness)


        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population, fitness = self.select_next_generation(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self.update_best(self.population, fitness)
            self.adapt_parameters(fitness) # Adapt F and CR based on diversity and performance


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = self.select_indices(i, self.population_size)
            pbest = self.select_pbest(self.archive, fitness)
            offspring[i] = self.mutate(population[i], pbest, population[a], population[b], population[c])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring


    def mutate(self, x, pbest, a, b, c):
        mutant = x + self.F_scale * (pbest - x + a - b + c -x) #Modified mutation for better exploration
        return mutant


    def select_indices(self, i, pop_size):
        a, b, c = np.random.choice(pop_size, 3, replace=False)
        while a == i or b == i or c == i:
            a, b, c = np.random.choice(pop_size, 3, replace=False)
        return a, b, c


    def select_pbest(self, archive, fitness):
        if archive:
            # weighted selection using fitness and archive diversity measure
            archive_fitness = np.array([f for _, f in archive])
            weights = 1/(archive_fitness + 1e-9) #Avoid division by zero
            weights /= np.sum(weights) # Normalize weights
            pbest_index = np.random.choice(len(archive), p=weights)
            pbest = archive[pbest_index][0]
        else:
            pbest = self.population[np.argmin(fitness)]
        return pbest


    def crossover(self, x, mutant):
        mask = np.random.rand(self.dim) < self.CR
        offspring = np.where(mask, mutant, x)
        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def select_next_generation(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]


    def update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        best_solution = population[best_index]
        best_fitness = fitness[best_index]
        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution
        return best_solution, best_fitness


    def adapt_parameters(self, fitness):
        # Adaptive parameter control based on diversity and convergence rate
        archive_diversity = self.calculate_archive_diversity()
        if archive_diversity < 0.2 and np.std(fitness) < 0.01:
            self.F_scale *= 0.9 #Reduce exploration
            self.CR *= 0.9
        elif archive_diversity > 0.8 or np.std(fitness) > 10: #High diversity or high spread indicates need for more exploration
            self.F_scale *= 1.1 #Increase exploration
            self.CR *= 1.1
        self.F_scale = np.clip(self.F_scale, 0.1, 1.0) #Bound F_scale
        self.CR = np.clip(self.CR, 0.1, 1.0)


    def calculate_archive_diversity(self):
        if not self.archive:
            return 1.0  # Consider full diversity if archive is empty
        archive_solutions = np.array([sol for sol, _ in self.archive])
        if len(archive_solutions) < 2:
            return 1.0
        distances = pdist(archive_solutions)
        average_distance = np.mean(distances)
        max_possible_distance = np.linalg.norm(self.upper_bounds - self.lower_bounds)
        return average_distance / max_possible_distance


```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveMultimodalDE
# Description: 
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class AdaptiveMultimodalDE:
    """Adaptive Differential Evolution with archive diversity and adaptive parameter control for multimodal landscapes."""

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F = 0.5  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.adaptive_factor = 0.1 #controls the adaptation speed

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.pop_size
        
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self.update_archive(offspring, offspring_fitness)
            self.update_parameters()
            self.population = self.select_population(offspring, offspring_fitness)
            self.update_best(self.population, objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)
            while r1 == i or r2 == i or r3 == i:
                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)

            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])
            
            #Binomial crossover
            j_rand = np.random.randint(0, self.dim)
            u = np.copy(self.population[i])
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    u[j] = v[j]

            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Maintain diversity: replace worst solution based on distance to existing solutions
                distances = np.array([np.linalg.norm(offspring[i]-x) for x, _ in self.archive])
                worst_index = np.argmin(distances)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def update_parameters(self):
        #Adaptive parameter control based on archive diversity
        if len(self.archive)>1:
            distances = pdist([x for x,_ in self.archive])
            mean_distance = np.mean(distances)
            if mean_distance < 10: #If archive lacks diversity
                self.F += self.adaptive_factor * np.random.rand()
                self.CR -= self.adaptive_factor * np.random.rand()
            else:
                self.F -= self.adaptive_factor * np.random.rand()
                self.CR += self.adaptive_factor * np.random.rand()
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
    
    def select_population(self, offspring, offspring_fitness):
        combined_pop = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_pop[indices[:self.pop_size]]

    def update_best(self, population, objective_function):
        fitness = objective_function(population)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        if best_fitness < self.best_fitness_overall:
            self.best_solution_overall = best_solution
            self.best_fitness_overall = best_fitness
```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 56.66185705296313, archive_size: int = 908.9831751547036, initial_F_scale: float = 0.5477609044853405,
                 acceptance_threshold: float = 7.632039663549554e-05, archive_update_threshold: float = 0.8283989465348023):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold


    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 19:36:21 INFO Full response text: **Analysis:**

Comparing `AdaptiveArchiveDE` (best) vs `EnhancedArchiveGuidedDE` (worst), we see that the best-performing algorithm uses an adaptive archive that prioritizes both fitness and diversity, employing a more sophisticated archive update mechanism and adaptive parameter tuning.  The worst-performing algorithm uses simpler selection, archive update, and parameter handling, leading to less effective exploration and exploitation.

`AdaptiveArchiveDE` (best) vs `ArchiveGuidedAdaptiveDEwithGaussianMutation` (second worst): The top algorithm uses a more refined archive update strategy, efficiently managing diversity and focusing on high-quality solutions.  The second-worst algorithm, while including Gaussian mutation, lacks the adaptive archive management and sophisticated parameter tuning of the best algorithm.

Comparing `AdaptiveArchiveDE` (1st) vs `ArchiveGuidedAdaptiveDEwithGaussianMutation` (2nd), we see that the top performer utilizes a more strategic approach to archive management, combining fitness and diversity considerations, while the second-best algorithm primarily relies on fitness.  The top performer's adaptive parameter tuning further enhances its performance.

`AdaptiveArchiveDEwithGaussianMutation` (3rd) vs `EnhancedArchiveGuidedDE` (4th): The third-ranked algorithm incorporates Gaussian mutation and adaptive parameter adjustment, giving it an advantage over the fourth-ranked, which only adapts the sigma parameter in the Gaussian mutation. The 3rd algorithm's adaptive scheme for F_scale and sigma, coupled with the archive, results in better convergence.

Comparing `ArchiveGuidedAdaptiveDEwithGaussianMutation` (second worst) vs `EnhancedArchiveGuidedDE` (worst), we see that even though both utilize Gaussian mutation, the second-worst algorithm shows more sophisticated archive management and parameter adaptation, which improves exploration and exploitation of the search space.  The simpler archive update and parameter handling in the worst-performing algorithm hinder its ability to effectively navigate the complex search landscape.

Overall: The top-performing algorithms consistently utilize sophisticated adaptive archive management, incorporating measures of both fitness and diversity to efficiently explore and exploit the multimodal landscape. Adaptive parameter tuning, including F and CR adjustment, plays a crucial role in the algorithm's success. The less effective algorithms lack this adaptive nature, and their simpler update mechanisms limit their ability to find the global optimum.

**Experience:**

The key to superior performance lies in sophisticated adaptive archive management, balancing fitness and diversity, and incorporating robust adaptive parameter control.  Gaussian mutation can enhance exploration but is not sufficient without effective population and archive management.

2025-06-23 19:36:23 INFO Full response text: **Keywords:** Adaptive archive, fitness diversity, parameter control, Gaussian mutation, high-dimensional multimodal optimization.

**Advice:** Focus on novel archive management strategies that go beyond simple diversity metrics. Explore alternative mutation operators beyond Gaussian, potentially incorporating information from the archive to guide mutation.  Develop adaptive parameter control mechanisms that dynamically adjust based on the problem's characteristics and the archive's state. Quantify and compare the impact of different archive management techniques rigorously.

**Avoid:** Vague terms like "exploration" and "exploitation." Avoid generic statements about "adaptive parameter tuning" without specifying the adaptation mechanism.  Don't focus solely on benchmarks like f24; strive for generality.  Avoid simply restating known good practices without proposing novel improvements.

**Explanation:**  The current self-reflection lacks concrete, actionable steps.  To design better heuristics, we need to move beyond general principles and propose specific, testable improvements to archive management, mutation, and parameter control.  Rigorous experimentation and quantitative analysis are essential to justify the claimed superiority. The $999K justifies a detailed, specific, and rigorously testable proposal.

2025-06-23 19:36:23 INFO Generating offspring via Crossover...
2025-06-23 19:43:46 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
AdaptiveArchiveDEwithGaussianMutation
import numpy as np
import random

class AdaptiveArchiveDEwithGaussianMutation:
    """
    Combines Differential Evolution (DE) with an adaptive archive and Gaussian mutation to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.1 # Gaussian mutation standard deviation

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            self.adapt_parameters(fitness) # Adaptive parameter tuning

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            #Gaussian mutation for enhanced exploration
            offspring[i] += np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_parameters(self, fitness):
        #Adaptive F and sigma based on recent performance
        mean_fitness = np.mean(fitness)
        if self.best_fitness_overall < mean_fitness:
            self.F_scale += 0.1 * (1 - self.F_scale)
            self.sigma *= 0.9
        else:
            self.F_scale -= 0.1 * self.F_scale
            self.sigma *= 1.1
        self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
        self.sigma = np.clip(self.sigma, 0.01, 1.0)


### Worse code
EnhancedArchiveGuidedDE
import numpy as np
import random

# Name: EnhancedArchiveGuidedDE
# Description: Differential Evolution with adaptive archive, prioritizing diversity and fitness for multimodal optimization.
# Code:
class EnhancedArchiveGuidedDE:
    """
    Combines Differential Evolution (DE) with an adaptive archive to enhance exploration and exploitation in multimodal landscapes.  Prioritizes both fitness and diversity in archive management. Uses an adaptive scaling factor.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for multimodal problems
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.archive_diversity_threshold = 0.8 # Controls how aggressively the archive maintains diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adaptive F scaling
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Select pbest from archive (if available), weighted randomly
            if self.archive:
                pbest_index = np.random.choice(len(self.archive)) # Simple random choice for now.  Could be improved.
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and fitness using a threshold
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] * self.archive_diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


### Analyze & experience
- Comparing `AdaptiveArchiveDE` (best) vs `EnhancedArchiveGuidedDE` (worst), we see that the best-performing algorithm uses an adaptive archive that prioritizes both fitness and diversity, employing a more sophisticated archive update mechanism and adaptive parameter tuning.  The worst-performing algorithm uses simpler selection, archive update, and parameter handling, leading to less effective exploration and exploitation.

`AdaptiveArchiveDE` (best) vs `ArchiveGuidedAdaptiveDEwithGaussianMutation` (second worst): The top algorithm uses a more refined archive update strategy, efficiently managing diversity and focusing on high-quality solutions.  The second-worst algorithm, while including Gaussian mutation, lacks the adaptive archive management and sophisticated parameter tuning of the best algorithm.

Comparing `AdaptiveArchiveDE` (1st) vs `ArchiveGuidedAdaptiveDEwithGaussianMutation` (2nd), we see that the top performer utilizes a more strategic approach to archive management, combining fitness and diversity considerations, while the second-best algorithm primarily relies on fitness.  The top performer's adaptive parameter tuning further enhances its performance.

`AdaptiveArchiveDEwithGaussianMutation` (3rd) vs `EnhancedArchiveGuidedDE` (4th): The third-ranked algorithm incorporates Gaussian mutation and adaptive parameter adjustment, giving it an advantage over the fourth-ranked, which only adapts the sigma parameter in the Gaussian mutation. The 3rd algorithm's adaptive scheme for F_scale and sigma, coupled with the archive, results in better convergence.

Comparing `ArchiveGuidedAdaptiveDEwithGaussianMutation` (second worst) vs `EnhancedArchiveGuidedDE` (worst), we see that even though both utilize Gaussian mutation, the second-worst algorithm shows more sophisticated archive management and parameter adaptation, which improves exploration and exploitation of the search space.  The simpler archive update and parameter handling in the worst-performing algorithm hinder its ability to effectively navigate the complex search landscape.

Overall: The top-performing algorithms consistently utilize sophisticated adaptive archive management, incorporating measures of both fitness and diversity to efficiently explore and exploit the multimodal landscape. Adaptive parameter tuning, including F and CR adjustment, plays a crucial role in the algorithm's success. The less effective algorithms lack this adaptive nature, and their simpler update mechanisms limit their ability to find the global optimum.
- **Keywords:** Adaptive archive, fitness diversity, parameter control, Gaussian mutation, high-dimensional multimodal optimization.

**Advice:** Focus on novel archive management strategies that go beyond simple diversity metrics. Explore alternative mutation operators beyond Gaussian, potentially incorporating information from the archive to guide mutation.  Develop adaptive parameter control mechanisms that dynamically adjust based on the problem's characteristics and the archive's state. Quantify and compare the impact of different archive management techniques rigorously.

**Avoid:** Vague terms like "exploration" and "exploitation." Avoid generic statements about "adaptive parameter tuning" without specifying the adaptation mechanism.  Don't focus solely on benchmarks like f24; strive for generality.  Avoid simply restating known good practices without proposing novel improvements.

**Explanation:**  The current self-reflection lacks concrete, actionable steps.  To design better heuristics, we need to move beyond general principles and propose specific, testable improvements to archive management, mutation, and parameter control.  Rigorous experimentation and quantitative analysis are essential to justify the claimed superiority. The $999K justifies a detailed, specific, and rigorously testable proposal.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 19:43:46 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:** Adaptive archive, fitness diversity, parameter control, Gaussian mutation, high-dimensional multimodal optimization.

**Advice:** Focus on novel archive management strategies that go beyond simple diversity metrics. Explore alternative mutation operators beyond Gaussian, potentially incorporating information from the archive to guide mutation.  Develop adaptive parameter control mechanisms that dynamically adjust based on the problem's characteristics and the archive's state. Quantify and compare the impact of different archive management techniques rigorously.

**Avoid:** Vague terms like "exploration" and "exploitation." Avoid generic statements about "adaptive parameter tuning" without specifying the adaptation mechanism.  Don't focus solely on benchmarks like f24; strive for generality.  Avoid simply restating known good practices without proposing novel improvements.

**Explanation:**  The current self-reflection lacks concrete, actionable steps.  To design better heuristics, we need to move beyond general principles and propose specific, testable improvements to archive management, mutation, and parameter control.  Rigorous experimentation and quantitative analysis are essential to justify the claimed superiority. The $999K justifies a detailed, specific, and rigorously testable proposal.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 19:46:11 INFO Perform Harmony Search...
2025-06-23 19:46:21 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:21 ERROR Can not run the algorithm
2025-06-23 19:46:22 INFO Run function 24 complete. FEHistory len: 2373, AOCC: 0.0000
2025-06-23 19:46:22 INFO FeHistory: [218.45495905 199.07218112 204.0860399  ... 187.77967832 202.70284814
 172.58532171]
2025-06-23 19:46:22 INFO Expected Optimum FE: -100
2025-06-23 19:46:22 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:22 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:22 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:22 INFO AOCC mean: 0.0000
2025-06-23 19:46:22 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:22 ERROR Can not run the algorithm
2025-06-23 19:46:22 INFO Run function 24 complete. FEHistory len: 1083, AOCC: 0.0000
2025-06-23 19:46:22 INFO FeHistory: [180.02447186 217.28625346 167.94486914 ... 168.79893383 194.8113663
 162.54193786]
2025-06-23 19:46:22 INFO Expected Optimum FE: -100
2025-06-23 19:46:22 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:22 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:22 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:22 INFO AOCC mean: 0.0000
2025-06-23 19:46:22 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:23 ERROR Can not run the algorithm
2025-06-23 19:46:23 INFO Run function 24 complete. FEHistory len: 2101, AOCC: 0.0000
2025-06-23 19:46:23 INFO FeHistory: [183.21626835 191.26620517 198.85140459 ... 162.37451755 183.94873521
 191.51543433]
2025-06-23 19:46:23 INFO Expected Optimum FE: -100
2025-06-23 19:46:23 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:23 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:23 INFO AOCC mean: 0.0000
2025-06-23 19:46:23 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:24 ERROR Can not run the algorithm
2025-06-23 19:46:24 INFO Run function 24 complete. FEHistory len: 2137, AOCC: 0.0000
2025-06-23 19:46:24 INFO FeHistory: [193.08115754 197.25716481 225.17914926 ... 197.08950947 189.41942934
 172.58868244]
2025-06-23 19:46:24 INFO Expected Optimum FE: -100
2025-06-23 19:46:24 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:24 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:24 INFO AOCC mean: 0.0000
2025-06-23 19:46:24 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:25 ERROR Can not run the algorithm
2025-06-23 19:46:25 INFO Run function 24 complete. FEHistory len: 2115, AOCC: 0.0000
2025-06-23 19:46:25 INFO FeHistory: [198.30570539 153.64627525 223.58267518 ... 192.65291306 184.42161201
 183.65293122]
2025-06-23 19:46:25 INFO Expected Optimum FE: -100
2025-06-23 19:46:25 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:25 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:25 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:25 INFO AOCC mean: 0.0000
2025-06-23 19:46:25 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:25 ERROR Can not run the algorithm
2025-06-23 19:46:26 INFO Run function 24 complete. FEHistory len: 2288, AOCC: 0.0000
2025-06-23 19:46:26 INFO FeHistory: [172.04447909 184.66392368 167.40321036 ... 215.27243238 204.95834943
 192.30772961]
2025-06-23 19:46:26 INFO Expected Optimum FE: -100
2025-06-23 19:46:26 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:26 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:26 INFO AOCC mean: 0.0000
2025-06-23 19:46:26 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:26 ERROR Can not run the algorithm
2025-06-23 19:46:27 INFO Run function 24 complete. FEHistory len: 1999, AOCC: 0.0000
2025-06-23 19:46:27 INFO FeHistory: [167.19940531 149.44360752 197.71587417 ... 185.61619911 183.93083763
 167.63237709]
2025-06-23 19:46:27 INFO Expected Optimum FE: -100
2025-06-23 19:46:27 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:27 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:27 INFO AOCC mean: 0.0000
2025-06-23 19:46:27 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:27 ERROR Can not run the algorithm
2025-06-23 19:46:27 INFO Run function 24 complete. FEHistory len: 1547, AOCC: 0.0000
2025-06-23 19:46:27 INFO FeHistory: [169.50450238 152.83391377 181.33604974 ... 162.08250073 221.51115655
 206.62634698]
2025-06-23 19:46:27 INFO Expected Optimum FE: -100
2025-06-23 19:46:27 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:27 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:27 INFO AOCC mean: 0.0000
2025-06-23 19:46:27 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:28 ERROR Can not run the algorithm
2025-06-23 19:46:28 INFO Run function 24 complete. FEHistory len: 2115, AOCC: 0.0000
2025-06-23 19:46:28 INFO FeHistory: [163.84548979 181.84925852 174.06419268 ... 177.20843243 187.78185556
 158.68343435]
2025-06-23 19:46:28 INFO Expected Optimum FE: -100
2025-06-23 19:46:28 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:28 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:28 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:28 INFO AOCC mean: 0.0000
2025-06-23 19:46:28 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 19:46:28 ERROR Can not run the algorithm
2025-06-23 19:46:29 INFO Run function 24 complete. FEHistory len: 1012, AOCC: 0.0000
2025-06-23 19:46:29 INFO FeHistory: [208.87004452 173.0256745  183.91709837 ... 155.54320174 196.84966806
 173.32391714]
2025-06-23 19:46:29 INFO Expected Optimum FE: -100
2025-06-23 19:46:29 INFO Unimodal AOCC mean: nan
2025-06-23 19:46:29 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 19:46:29 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 19:46:29 INFO AOCC mean: 0.0000
2025-06-23 19:46:29 INFO Generation 3, best so far: 0.09189012611784185
2025-06-23 19:46:29 INFO Population length is: 10
2025-06-23 19:46:29 INFO --- Performing Long-Term Reflection at Generation 4 ---
2025-06-23 19:46:29 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 1.1964e-03# Name: AdaptiveArchiveDEwithGaussianMutation
# Description: Adaptive DE using an archive prioritizing diversity and fitness, enhanced with Gaussian mutation.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDEwithGaussianMutation
# Description: Adaptive DE using an archive prioritizing diversity and fitness, enhanced with Gaussian mutation.
# Code:
class AdaptiveArchiveDEwithGaussianMutation:
    """
    Combines Differential Evolution (DE) with an adaptive archive that prioritizes both fitness and diversity. 
    Includes Gaussian mutation for enhanced exploration. Adapts scaling factor (F) and mutation strength (sigma).
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.archive_diversity_threshold = 0.9


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adaptive parameter adjustments
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] * self.archive_diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 2 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDiversityDE
# Description: Adaptive Differential Evolution with enhanced archive diversity management for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class AdaptiveDiversityDE:
    """Adaptive Differential Evolution combining archive diversity and adaptive parameter control."""

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F = 0.5  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.adaptive_factor = 0.1 #controls the adaptation speed
        self.diversity_threshold = 10 #parameter to control diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.pop_size
        
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self.update_archive(offspring, offspring_fitness)
            self.update_parameters()
            self.population = self.select_population(offspring, offspring_fitness)
            self.update_best(self.population, objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)
            while r1 == i or r2 == i or r3 == i:
                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)

            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])
            
            #Binomial crossover
            j_rand = np.random.randint(0, self.dim)
            u = np.copy(self.population[i])
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    u[j] = v[j]

            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Maintain diversity: replace worst solution based on distance and fitness
                distances = np.array([np.linalg.norm(offspring[i]-x) for x, _ in self.archive])
                fitness_values = np.array([f for _, f in self.archive])
                combined_scores = distances + fitness_values #prioritize solutions that are both good and diverse
                worst_index = np.argmax(combined_scores)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def update_parameters(self):
        #Adaptive parameter control based on archive diversity
        if len(self.archive)>1:
            distances = pdist([x for x,_ in self.archive])
            mean_distance = np.mean(distances)
            if mean_distance < self.diversity_threshold: #If archive lacks diversity
                self.F += self.adaptive_factor * np.random.rand()
                self.CR -= self.adaptive_factor * np.random.rand()
            else:
                self.F -= self.adaptive_factor * np.random.rand()
                self.CR += self.adaptive_factor * np.random.rand()
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
    
    def select_population(self, offspring, offspring_fitness):
        combined_pop = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_pop[indices[:self.pop_size]]

    def update_best(self, population, objective_function):
        fitness = objective_function(population)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        if best_fitness < self.best_fitness_overall:
            self.best_solution_overall = best_solution
            self.best_fitness_overall = best_fitness

```

### Rank 3 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveDEwithEnhancedMutation
# Description: Adaptive Differential Evolution with enhanced mutation and archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveArchiveDEwithEnhancedMutation:
    """
    Combines Differential Evolution (DE) with an adaptive archive and enhanced mutation for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.2  # Initial Gaussian width
        self.archive = []
        self.archive_diversity_threshold = 0.1 # Threshold for archive diversity control
        self.F_scale = 0.9 # Scaling for F
        self.sigma_decay = 0.99
        

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)
        self.sigma = 0.2 * np.mean(self.upper_bounds - self.lower_bounds)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._enhanced_mutation(offspring)  # Enhanced mutation
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values) #Adapt parameters based on population performance
            self.sigma *= self.sigma_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i or a == b or a == c or b == c:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[a] + self.F * (population[b] - population[c])
            jrand = random.randint(0, self.dim - 1)
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]

        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _enhanced_mutation(self, offspring):
        # Incorporate archive information for enhanced mutation
        if len(self.archive) > 0:
            archive_sample = self.archive[np.random.choice(len(self.archive), size=int(0.1 * self.population_size))]
            for i in range(offspring.shape[0]):
                if random.random() < 0.2: # Probability of using archive information
                    archive_index = np.random.choice(len(archive_sample))
                    offspring[i] += 0.5 * (archive_sample[archive_index][:-1] - offspring[i]) # Blend with archive member

        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        if len(new_archive) > 0:
            new_archive.sort(key=lambda x: x[-1])
            self.archive.extend(new_archive)

            self.archive.sort(key=lambda x: x[-1])
            
            #Diversity control
            if len(self.archive) > self.archive_size:
                self.archive = self.archive[:self.archive_size]

        return np.array(self.archive)

    def _adapt_parameters(self, population, fitness_values):
        # Adapt F and sigma based on population performance

        avg_fitness = np.mean(fitness_values)
        if avg_fitness < self.best_fitness_overall * 0.9: #Check if improvements are significant
            self.F *= self.F_scale # Increase exploration if the improvement is significant
        else:
            self.F /= self.F_scale # Reduce exploration otherwise
        self.F = np.clip(self.F, 0.1, 1.0) # Keep F within bounds

```

### Rank 4 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveDEwithGaussianMutationAndEnhancedUpdate
# Description: Combines adaptive archive, Gaussian mutation, and enhanced archive update for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveArchiveDEwithGaussianMutationAndEnhancedUpdate:
    """
    Combines Differential Evolution (DE) with an adaptive archive and Gaussian mutation, 
    using an enhanced archive update strategy for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  #Larger population for higher dimensionality
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.1  # Gaussian mutation standard deviation
        self.archive_diversity_threshold = 0.1 # Threshold for diversity maintenance in archive

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            self.adapt_parameters(fitness)  # Adaptive parameter tuning

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            # Gaussian mutation for enhanced exploration
            offspring[i] += np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        # Enhanced archive update:  Considers both fitness and diversity
        for i in range(len(offspring)):
            #Check for duplicates before adding
            is_duplicate = False
            for sol, fit in self.archive:
                if np.allclose(offspring[i], sol, atol=1e-6):
                    is_duplicate = True
                    break
            if not is_duplicate:  
                if len(self.archive) < self.archive_size:
                    self.archive.append((offspring[i], offspring_fitness[i]))
                else:
                    #Remove worst solution while maintaining diversity
                    self.archive.sort(key=lambda x: x[1]) #Sort by fitness
                    worst_solution = self.archive[0]
                    self.archive.pop(0)
                    self.archive.append((offspring[i], offspring_fitness[i]))

        # Maintain diversity: Remove solutions that are too similar
        if len(self.archive) > self.archive_size/2: # Check only when archive is somewhat full
            self.archive = self._maintain_diversity(self.archive)

    def _maintain_diversity(self, archive):
        archive.sort(key=lambda x: x[1])  #Sort by fitness
        new_archive = [archive[0]] #Keep the best solution
        for i in range(1, len(archive)):
            is_similar = False
            for sol, _ in new_archive:
                if np.linalg.norm(archive[i][0] - sol) < self.archive_diversity_threshold:
                   is_similar = True
                   break
            if not is_similar:
                new_archive.append(archive[i])

        return new_archive[:self.archive_size] #Limit to archive size


    def adapt_parameters(self, fitness):
        # Adaptive F and sigma based on recent performance
        mean_fitness = np.mean(fitness)
        if self.best_fitness_overall < mean_fitness:
            self.F_scale += 0.1 * (1 - self.F_scale)
            self.sigma *= 0.9
        else:
            self.F_scale -= 0.1 * self.F_scale
            self.sigma *= 1.1
        self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
        self.sigma = np.clip(self.sigma, 0.01, 1.0)

```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDiversityDEwithGaussianMutation
# Description: Combines adaptive diversity DE with Gaussian mutation for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class AdaptiveDiversityDEwithGaussianMutation:
    """
    Combines adaptive diversity Differential Evolution (DE) with Gaussian mutation 
    to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = np.inf
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9
        self.sigma = 0.5 # Initial Gaussian mutation standard deviation

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self.update_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population, fitness = self.select_next_generation(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self.update_best(self.population, fitness)
            self.adapt_parameters(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = self.select_indices(i, self.population_size)
            pbest = self.select_pbest(self.archive, fitness)
            mutant = self.mutate(population[i], pbest, population[a], population[b], population[c])
            offspring[i] = self.crossover(population[i], mutant)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def mutate(self, x, pbest, a, b, c):
        mutant = x + self.F_scale * (pbest - x + a - b + c - x)
        #Gaussian perturbation
        mutant += np.random.normal(0, self.sigma, self.dim)
        return mutant

    def select_indices(self, i, pop_size):
        a, b, c = np.random.choice(pop_size, 3, replace=False)
        while a == i or b == i or c == i:
            a, b, c = np.random.choice(pop_size, 3, replace=False)
        return a, b, c

    def select_pbest(self, archive, fitness):
        if archive:
            archive_fitness = np.array([f for _, f in archive])
            weights = 1 / (archive_fitness + 1e-9)
            weights /= np.sum(weights)
            pbest_index = np.random.choice(len(archive), p=weights)
            pbest = archive[pbest_index][0]
        else:
            pbest = self.population[np.argmin(fitness)]
        return pbest

    def crossover(self, x, mutant):
        mask = np.random.rand(self.dim) < self.CR
        offspring = np.where(mask, mutant, x)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def select_next_generation(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        best_solution = population[best_index]
        best_fitness = fitness[best_index]
        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution
        return best_solution, best_fitness

    def adapt_parameters(self, fitness):
        archive_diversity = self.calculate_archive_diversity()
        if archive_diversity < 0.2 and np.std(fitness) < 0.01:
            self.F_scale *= 0.9
            self.CR *= 0.9
            self.sigma *= 0.9  #Reduce Gaussian exploration
        elif archive_diversity > 0.8 or np.std(fitness) > 10:
            self.F_scale *= 1.1
            self.CR *= 1.1
            self.sigma *= 1.1  #Increase Gaussian exploration
        self.F_scale = np.clip(self.F_scale, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
        self.sigma = np.clip(self.sigma, 0.1, 2.0) #Bound sigma

    def calculate_archive_diversity(self):
        if not self.archive:
            return 1.0
        archive_solutions = np.array([sol for sol, _ in self.archive])
        if len(archive_solutions) < 2:
            return 1.0
        distances = pdist(archive_solutions)
        average_distance = np.mean(distances)
        max_possible_distance = np.linalg.norm(self.upper_bounds - self.lower_bounds)
        return average_distance / max_possible_distance

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveDEwithGaussianMutationAndDiversity
# Description: Adaptive Differential Evolution with archive management prioritizing fitness and diversity, incorporating Gaussian mutation.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class AdaptiveArchiveDEwithGaussianMutationAndDiversity:
    """Adaptive Differential Evolution with archive management, Gaussian mutation, and diversity control for multimodal landscapes."""

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F = 0.5  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.2 # Gaussian mutation standard deviation
        self.adaptive_factor = 0.1 #controls the adaptation speed

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.pop_size
        
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self.update_archive(offspring, offspring_fitness)
            self.update_parameters()
            self.population = self.select_population(offspring, offspring_fitness)
            self.update_best(self.population, objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)
            while r1 == i or r2 == i or r3 == i:
                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)

            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])
            
            #Binomial crossover
            j_rand = np.random.randint(0, self.dim)
            u = np.copy(self.population[i])
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    u[j] = v[j]

            #Gaussian Mutation
            u += np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Maintain diversity: replace worst solution based on a combined fitness and diversity metric.
                distances = np.array([np.linalg.norm(offspring[i]-x) for x, _ in self.archive])
                fitness_values = np.array([f for _, f in self.archive])
                combined_metric = fitness_values + distances / np.mean(distances) #Normalize distances
                worst_index = np.argmax(combined_metric) #replace the worst solution based on combined metric
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def update_parameters(self):
        #Adaptive parameter control based on archive diversity and mean fitness improvement
        if len(self.archive)>1:
            distances = pdist([x for x,_ in self.archive])
            mean_distance = np.mean(distances)
            fitness_values = np.array([f for _, f in self.archive])
            mean_fitness = np.mean(fitness_values)

            if mean_distance < 10 or mean_fitness > self.best_fitness_overall * 0.9: #If archive lacks diversity or improvement stalled
                self.F += self.adaptive_factor * np.random.rand()
                self.CR -= self.adaptive_factor * np.random.rand()
                self.sigma += self.adaptive_factor * np.random.rand() *0.1 #adjusting sigma cautiously

            else:
                self.F -= self.adaptive_factor * np.random.rand()
                self.CR += self.adaptive_factor * np.random.rand()
                self.sigma -= self.adaptive_factor * np.random.rand() *0.1 #adjusting sigma cautiously
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
        self.sigma = np.clip(self.sigma, 0.01, 1.0)
    
    def select_population(self, offspring, offspring_fitness):
        combined_pop = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_pop[indices[:self.pop_size]]

    def update_best(self, population, objective_function):
        fitness = objective_function(population)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        if best_fitness < self.best_fitness_overall:
            self.best_solution_overall = best_solution
            self.best_fitness_overall = best_fitness

```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDiversityDE
# Description: Adaptive Differential Evolution balancing fitness and diversity in the archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class AdaptiveDiversityDE:
    """Adaptive Differential Evolution with archive diversity and adaptive parameter control for multimodal landscapes."""

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F = 0.5  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.adaptive_factor = 0.1 #controls the adaptation speed
        self.diversity_threshold = 10 # Threshold for archive diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.pop_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self.update_archive(offspring, offspring_fitness)
            self.update_parameters()
            self.population = self.select_population(offspring, offspring_fitness)
            self.update_best(self.population, objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)
            while r1 == i or r2 == i or r3 == i:
                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)

            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])

            j_rand = np.random.randint(0, self.dim)
            u = np.copy(self.population[i])
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    u[j] = v[j]

            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Replace based on combined fitness and diversity
                distances = np.array([np.linalg.norm(offspring[i] - x) for x, _ in self.archive])
                worst_index = np.argmax(self.archive_fitness + distances*0.1) #Weighted sum of fitness and distance
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def update_parameters(self):
        self.archive_fitness = np.array([f for _,f in self.archive])
        if len(self.archive) > 1:
            distances = pdist([x for x,_ in self.archive])
            mean_distance = np.mean(distances)
            if mean_distance < self.diversity_threshold:
                self.F += self.adaptive_factor * np.random.rand()
                self.CR -= self.adaptive_factor * np.random.rand()
            else:
                self.F -= self.adaptive_factor * np.random.rand()
                self.CR += self.adaptive_factor * np.random.rand()
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)

    def select_population(self, offspring, offspring_fitness):
        combined_pop = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_pop[indices[:self.pop_size]]

    def update_best(self, population, objective_function):
        fitness = objective_function(population)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        if best_fitness < self.best_fitness_overall:
            self.best_solution_overall = best_solution
            self.best_fitness_overall = best_fitness

```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveArchiveCovarianceMatrixAdaptationEvolutionStrategy
# Description: An evolution strategy that uses an adaptive archive and covariance matrix adaptation to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveCovarianceMatrixAdaptationEvolutionStrategy
# Description: An evolution strategy that uses an adaptive archive and covariance matrix adaptation to efficiently explore and exploit multimodal landscapes.
# Code:
class AdaptiveArchiveCovarianceMatrixAdaptationEvolutionStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.sigma = 0.5  # Initial step size
        self.c = 0.817 #Learning rate for covariance matrix
        self.mu = self.population_size // 2 #Number of parents

        self.covariance_matrix = np.eye(self.dim)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.normal(0, 1, size=(self.population_size, self.dim)) #Using normal for CMA-ES
        self.population = self.population @ np.linalg.cholesky(self.covariance_matrix) + np.mean(self.population, axis = 0) #Initial population from covariance matrix
        self.population = np.clip(self.population, self.lower_bounds, self.upper_bounds)
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        self.best_solution_overall = self.best_solution_overall + self.lower_bounds #Shift to original space
        

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self.update_archive(offspring, offspring_fitness)
            
            parents_indices = np.argsort(offspring_fitness)[:self.mu] #Select best mu offspring as parents
            parents = offspring[parents_indices]
            
            mean = np.mean(parents, axis = 0)

            #CMA-ES update
            self.update_covariance_matrix(parents, mean)
            self.update_sigma(mean)

            self.population = np.random.normal(0,1, size = (self.population_size, self.dim)) @ np.linalg.cholesky(self.covariance_matrix) + mean
            self.population = np.clip(self.population, self.lower_bounds, self.upper_bounds)

            #Update best solution
            fitness = objective_function(self.population)
            best_index = np.argmin(fitness)
            self.best_solution_overall = self.population[best_index] + self.lower_bounds #Shift back to original space
            self.best_fitness_overall = fitness[best_index]
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.random.normal(0, 1, size=(self.population_size, self.dim))
        offspring = offspring @ np.linalg.cholesky(self.covariance_matrix) + np.mean(self.population, axis = 0)
        offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i] + self.lower_bounds, offspring_fitness[i])) #Shift to original space before storing
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i] + self.lower_bounds, offspring_fitness[i])

    def update_covariance_matrix(self, parents, mean):
        ps = np.mean(parents - mean, axis = 0)
        self.covariance_matrix = (1-self.c) * self.covariance_matrix + self.c * (ps.reshape(-1,1) @ ps.reshape(1,-1))

    def update_sigma(self, mean):
        self.sigma = self.sigma * np.exp(0.1 * (np.linalg.norm(mean)/self.dim - 1))

```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 79.12588985065344, archive_size: int = 445.0942191276562,
                 initial_F_scale: float = 0.15032954729961243, F_scale_variation: float = 0.7548055439492717,
                 archive_update_threshold: float = 0.8170485560130908):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.F_scale_variation = F_scale_variation
        self.archive_update_threshold = archive_update_threshold


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 19:46:34 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveArchiveDEwithGaussianMutation vs (worst) AdaptiveArchiveCovarianceMatrixAdaptationEvolutionStrategy, we see that the best uses a simpler mutation strategy (Gaussian) combined with an adaptive archive and differential evolution, focusing on balancing exploration and exploitation. The worst employs a more complex covariance matrix adaptation evolution strategy (CMA-ES), which can be computationally expensive and less effective for high-dimensional, multimodal problems like f24.  (second best) AdaptiveDiversityDE vs (second worst) AdaptiveArchiveDEwithGaussianMutationAndDiversity show that explicit diversity management in the archive, as implemented in AdaptiveDiversityDE, outperforms a simpler archive update based only on fitness. Comparing (1st) AdaptiveArchiveDEwithGaussianMutation vs (2nd) AdaptiveDiversityDE, we see that Gaussian mutation provides a slight edge in exploration, compared to a purely adaptive DE approach with no explicit Gaussian component. (3rd) AdaptiveArchiveDEwithEnhancedMutation vs (4th) AdaptiveArchiveDEwithGaussianMutationAndEnhancedUpdate highlights that direct incorporation of archive information into the mutation step yields better results than simply using Gaussian mutation and an adaptive archive independently. Comparing (second worst) AdaptiveArchiveDEwithGaussianMutationAndDiversity vs (worst) AdaptiveArchiveCovarianceMatrixAdaptationEvolutionStrategy shows that the diversity management in the former results in improved performance compared to the complex CMA-ES. Overall: The top-performing algorithms effectively combine differential evolution with adaptive archives and incorporate mechanisms to balance exploration (Gaussian mutation) and exploitation (adaptive parameter control, fitness-based selection), and archive diversity management.  The lower-performing algorithms either lack these key components or rely on more computationally intensive strategies that are less suitable for high-dimensional, multimodal landscapes.

**Experience:**

Effective heuristics for high-dimensional multimodal optimization require a balance between exploration and exploitation, efficiently managed through adaptive parameter control, archive diversity, and mutation strategies like Gaussian.  Simpler, more robust methods often outperform computationally intensive approaches.

2025-06-23 19:46:35 INFO Full response text: * **Keywords:**  Simplicity, Robustness, Exploration-Exploitation Balance, Adaptive Parameter Control

* **Advice:** Focus on easily implementable, robust methods.  Prioritize a clear, well-defined balance between exploration and exploitation, avoiding over-engineered solutions.  Adaptive parameter control should be straightforward and computationally inexpensive.  Benchmark against simpler heuristics before adding complexity.

* **Avoid:**  Overly complex archive management, computationally expensive global exploration techniques,  fine-grained adaptive parameter tuning, explicit handling of non-separability as a primary design goal,  reliance on specific benchmark functions (like f24) for design decisions.

* **Explanation:**  The ineffective reflections focus too much on complex mechanisms and specific problem instances.  Superior heuristics prioritize simplicity and robustness, achieving a good balance between exploration and exploitation through relatively straightforward adaptive methods.  Avoid premature optimization; start simple and add complexity only when necessary.

2025-06-23 19:46:35 INFO Generating offspring via Crossover...
2025-06-23 20:13:41 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
AdaptiveArchiveDEwithGaussianMutation
import numpy as np
import random

# Name: AdaptiveArchiveDEwithGaussianMutation
# Description: Adaptive DE using an archive prioritizing diversity and fitness, enhanced with Gaussian mutation.
# Code:
class AdaptiveArchiveDEwithGaussianMutation:
    """
    Combines Differential Evolution (DE) with an adaptive archive that prioritizes both fitness and diversity. 
    Includes Gaussian mutation for enhanced exploration. Adapts scaling factor (F) and mutation strength (sigma).
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.archive_diversity_threshold = 0.9


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adaptive parameter adjustments
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] * self.archive_diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


### Worse code
AdaptiveArchiveDEwithGaussianMutation
import numpy as np
import random

# Name: AdaptiveArchiveDEwithGaussianMutation
# Description: Adaptive DE using an archive prioritizing diversity and fitness, enhanced with Gaussian mutation.
# Code:
class AdaptiveArchiveDEwithGaussianMutation:
    """
    Combines Differential Evolution (DE) with an adaptive archive that prioritizes both fitness and diversity. 
    Includes Gaussian mutation for enhanced exploration. Adapts scaling factor (F) and mutation strength (sigma).
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.archive_diversity_threshold = 0.9


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adaptive parameter adjustments
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] * self.archive_diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


### Analyze & experience
- Comparing (best) AdaptiveArchiveDEwithGaussianMutation vs (worst) AdaptiveArchiveCovarianceMatrixAdaptationEvolutionStrategy, we see that the best uses a simpler mutation strategy (Gaussian) combined with an adaptive archive and differential evolution, focusing on balancing exploration and exploitation. The worst employs a more complex covariance matrix adaptation evolution strategy (CMA-ES), which can be computationally expensive and less effective for high-dimensional, multimodal problems like f24.  (second best) AdaptiveDiversityDE vs (second worst) AdaptiveArchiveDEwithGaussianMutationAndDiversity show that explicit diversity management in the archive, as implemented in AdaptiveDiversityDE, outperforms a simpler archive update based only on fitness. Comparing (1st) AdaptiveArchiveDEwithGaussianMutation vs (2nd) AdaptiveDiversityDE, we see that Gaussian mutation provides a slight edge in exploration, compared to a purely adaptive DE approach with no explicit Gaussian component. (3rd) AdaptiveArchiveDEwithEnhancedMutation vs (4th) AdaptiveArchiveDEwithGaussianMutationAndEnhancedUpdate highlights that direct incorporation of archive information into the mutation step yields better results than simply using Gaussian mutation and an adaptive archive independently. Comparing (second worst) AdaptiveArchiveDEwithGaussianMutationAndDiversity vs (worst) AdaptiveArchiveCovarianceMatrixAdaptationEvolutionStrategy shows that the diversity management in the former results in improved performance compared to the complex CMA-ES. Overall: The top-performing algorithms effectively combine differential evolution with adaptive archives and incorporate mechanisms to balance exploration (Gaussian mutation) and exploitation (adaptive parameter control, fitness-based selection), and archive diversity management.  The lower-performing algorithms either lack these key components or rely on more computationally intensive strategies that are less suitable for high-dimensional, multimodal landscapes.
- * **Keywords:**  Simplicity, Robustness, Exploration-Exploitation Balance, Adaptive Parameter Control

* **Advice:** Focus on easily implementable, robust methods.  Prioritize a clear, well-defined balance between exploration and exploitation, avoiding over-engineered solutions.  Adaptive parameter control should be straightforward and computationally inexpensive.  Benchmark against simpler heuristics before adding complexity.

* **Avoid:**  Overly complex archive management, computationally expensive global exploration techniques,  fine-grained adaptive parameter tuning, explicit handling of non-separability as a primary design goal,  reliance on specific benchmark functions (like f24) for design decisions.

* **Explanation:**  The ineffective reflections focus too much on complex mechanisms and specific problem instances.  Superior heuristics prioritize simplicity and robustness, achieving a good balance between exploration and exploitation through relatively straightforward adaptive methods.  Avoid premature optimization; start simple and add complexity only when necessary.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 20:13:41 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Simplicity, Robustness, Exploration-Exploitation Balance, Adaptive Parameter Control

* **Advice:** Focus on easily implementable, robust methods.  Prioritize a clear, well-defined balance between exploration and exploitation, avoiding over-engineered solutions.  Adaptive parameter control should be straightforward and computationally inexpensive.  Benchmark against simpler heuristics before adding complexity.

* **Avoid:**  Overly complex archive management, computationally expensive global exploration techniques,  fine-grained adaptive parameter tuning, explicit handling of non-separability as a primary design goal,  reliance on specific benchmark functions (like f24) for design decisions.

* **Explanation:**  The ineffective reflections focus too much on complex mechanisms and specific problem instances.  Superior heuristics prioritize simplicity and robustness, achieving a good balance between exploration and exploitation through relatively straightforward adaptive methods.  Avoid premature optimization; start simple and add complexity only when necessary.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 20:15:05 INFO Perform Harmony Search...
2025-06-23 20:15:14 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:15:54 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0029
2025-06-23 20:15:54 INFO FeHistory: [199.65844111 196.03707913 181.42323488 ...  -0.38396786  -0.4497308
   9.93127414]
2025-06-23 20:15:54 INFO Expected Optimum FE: -100
2025-06-23 20:15:54 INFO Unimodal AOCC mean: nan
2025-06-23 20:15:54 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:15:54 INFO Multimodal (multiple components) AOCC mean: 0.0029
2025-06-23 20:15:54 INFO AOCC mean: 0.0029
2025-06-23 20:15:54 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:16:33 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0054
2025-06-23 20:16:33 INFO FeHistory: [180.38839091 232.1456078  179.08470761 ... -21.18090394 -22.21072894
 -12.33947952]
2025-06-23 20:16:33 INFO Expected Optimum FE: -100
2025-06-23 20:16:33 INFO Unimodal AOCC mean: nan
2025-06-23 20:16:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:16:33 INFO Multimodal (multiple components) AOCC mean: 0.0054
2025-06-23 20:16:33 INFO AOCC mean: 0.0054
2025-06-23 20:16:33 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:17:13 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0029
2025-06-23 20:17:13 INFO FeHistory: [175.50389011 198.49670273 189.80829563 ...   1.56585429  -4.66430887
  -8.14128881]
2025-06-23 20:17:13 INFO Expected Optimum FE: -100
2025-06-23 20:17:13 INFO Unimodal AOCC mean: nan
2025-06-23 20:17:13 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:17:13 INFO Multimodal (multiple components) AOCC mean: 0.0029
2025-06-23 20:17:13 INFO AOCC mean: 0.0029
2025-06-23 20:17:13 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:17:53 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0020
2025-06-23 20:17:53 INFO FeHistory: [158.50331654 184.30840841 217.38979917 ...  -0.2750057    2.72930266
  -2.39427707]
2025-06-23 20:17:53 INFO Expected Optimum FE: -100
2025-06-23 20:17:53 INFO Unimodal AOCC mean: nan
2025-06-23 20:17:53 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:17:53 INFO Multimodal (multiple components) AOCC mean: 0.0020
2025-06-23 20:17:53 INFO AOCC mean: 0.0020
2025-06-23 20:17:53 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:18:35 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0122
2025-06-23 20:18:35 INFO FeHistory: [191.81686988 203.08057265 191.28320342 ... -46.875288   -35.9941008
 -41.25302197]
2025-06-23 20:18:35 INFO Expected Optimum FE: -100
2025-06-23 20:18:35 INFO Unimodal AOCC mean: nan
2025-06-23 20:18:35 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:18:35 INFO Multimodal (multiple components) AOCC mean: 0.0122
2025-06-23 20:18:35 INFO AOCC mean: 0.0122
2025-06-23 20:18:35 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:19:14 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0050
2025-06-23 20:19:14 INFO FeHistory: [195.32112427 179.45642267 197.99434195 ... -19.77240283 -12.11972432
 -19.72453224]
2025-06-23 20:19:14 INFO Expected Optimum FE: -100
2025-06-23 20:19:14 INFO Unimodal AOCC mean: nan
2025-06-23 20:19:14 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:19:14 INFO Multimodal (multiple components) AOCC mean: 0.0050
2025-06-23 20:19:14 INFO AOCC mean: 0.0050
2025-06-23 20:19:14 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:19:56 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0005
2025-06-23 20:19:56 INFO FeHistory: [184.35154503 201.58540603 163.14038804 ...  60.90826216  49.61575664
  44.87056481]
2025-06-23 20:19:56 INFO Expected Optimum FE: -100
2025-06-23 20:19:56 INFO Unimodal AOCC mean: nan
2025-06-23 20:19:56 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:19:56 INFO Multimodal (multiple components) AOCC mean: 0.0005
2025-06-23 20:19:56 INFO AOCC mean: 0.0005
2025-06-23 20:19:56 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:20:38 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0133
2025-06-23 20:20:38 INFO FeHistory: [203.18877343 181.41864433 192.81324209 ... -47.68674067 -31.81395457
 -46.40374584]
2025-06-23 20:20:38 INFO Expected Optimum FE: -100
2025-06-23 20:20:38 INFO Unimodal AOCC mean: nan
2025-06-23 20:20:38 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:20:38 INFO Multimodal (multiple components) AOCC mean: 0.0133
2025-06-23 20:20:38 INFO AOCC mean: 0.0133
2025-06-23 20:20:38 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:21:18 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0099
2025-06-23 20:21:18 INFO FeHistory: [202.12146635 198.32166545 151.13454909 ... -25.02228008 -37.21857961
 -42.21242959]
2025-06-23 20:21:18 INFO Expected Optimum FE: -100
2025-06-23 20:21:18 INFO Unimodal AOCC mean: nan
2025-06-23 20:21:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:21:18 INFO Multimodal (multiple components) AOCC mean: 0.0099
2025-06-23 20:21:18 INFO AOCC mean: 0.0099
2025-06-23 20:21:18 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:21:58 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0059
2025-06-23 20:21:58 INFO FeHistory: [203.90158486 154.76047947 196.01008431 ... -13.34898436 -28.00877324
  -6.75019586]
2025-06-23 20:21:58 INFO Expected Optimum FE: -100
2025-06-23 20:21:58 INFO Unimodal AOCC mean: nan
2025-06-23 20:21:58 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:21:58 INFO Multimodal (multiple components) AOCC mean: 0.0059
2025-06-23 20:21:58 INFO AOCC mean: 0.0059
2025-06-23 20:21:58 INFO Generation 4, best so far: 0.09189012611784185
2025-06-23 20:21:58 INFO Population length is: 10
2025-06-23 20:21:58 INFO --- Performing Long-Term Reflection at Generation 5 ---
2025-06-23 20:21:58 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 1.3265e-02# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 34.696286477538784, archive_size: int = 1077.7941777008214, initial_F_scale: float = 0.2473716841208539):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 1.7208e-04# Name: AdaptiveDEwithGaussianMutationAndDiversity
# Description: Adaptive DE with Gaussian mutation and archive diversity management for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithGaussianMutationAndDiversity
# Description: Adaptive DE with Gaussian mutation and archive diversity management for multimodal optimization.
# Code:
class AdaptiveDEwithGaussianMutationAndDiversity:
    """
    Combines Differential Evolution (DE) with an adaptive archive that prioritizes both fitness and diversity. 
    Includes Gaussian mutation for enhanced exploration. Adapts scaling factor (F) and mutation strength (sigma).
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.diversity_threshold = 0.9  #parameter to control diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adaptive parameter adjustments
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                #Prioritize diversity in archive
                if offspring_fitness[i] < self.archive[worst_index][1] * self.diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 3 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDEwithGaussianMutationAndDiversity
# Description: Adaptive Differential Evolution with Gaussian mutation and archive diversity management for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class AdaptiveDEwithGaussianMutationAndDiversity:
    """Adaptive Differential Evolution with Gaussian mutation and archive diversity management."""

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F = 0.5  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.adaptive_factor = 0.1  # controls the adaptation speed
        self.diversity_threshold = 10  # parameter to control diversity
        self.sigma = 0.5 #initial standard deviation for Gaussian mutation

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.pop_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self.update_archive(offspring, offspring_fitness)
            self.update_parameters()
            self.population = self.select_population(offspring, offspring_fitness)
            self.update_best(self.population, objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)
            while r1 == i or r2 == i or r3 == i:
                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)

            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])
            
            #Binomial crossover
            j_rand = np.random.randint(0, self.dim)
            u = np.copy(self.population[i])
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    u[j] = v[j]

            #Gaussian mutation
            u = u + np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Maintain diversity: replace worst solution based on distance and fitness
                distances = np.array([np.linalg.norm(offspring[i]-x) for x, _ in self.archive])
                fitness_values = np.array([f for _, f in self.archive])
                combined_scores = distances + fitness_values #prioritize solutions that are both good and diverse
                worst_index = np.argmax(combined_scores)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def update_parameters(self):
        #Adaptive parameter control based on archive diversity
        if len(self.archive)>1:
            distances = pdist([x for x,_ in self.archive])
            mean_distance = np.mean(distances)
            if mean_distance < self.diversity_threshold: #If archive lacks diversity
                self.F += self.adaptive_factor * np.random.rand()
                self.CR -= self.adaptive_factor * np.random.rand()
                self.sigma *= 1.1 #increase mutation strength
            else:
                self.F -= self.adaptive_factor * np.random.rand()
                self.CR += self.adaptive_factor * np.random.rand()
                self.sigma *=0.9 #decrease mutation strength
        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
        self.sigma = np.clip(self.sigma, 0.1, 2.0) # keep sigma within reasonable bounds

    def select_population(self, offspring, offspring_fitness):
        combined_pop = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_pop[indices[:self.pop_size]]

    def update_best(self, population, objective_function):
        fitness = objective_function(population)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        if best_fitness < self.best_fitness_overall:
            self.best_solution_overall = best_solution
            self.best_fitness_overall = best_fitness

```

### Rank 4 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDEwithGaussianMutationAndDiversity
# Description: Differential Evolution with Gaussian mutation, adaptive parameters, and archive diversity management for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDEwithGaussianMutationAndDiversity
# Description: Differential Evolution with Gaussian mutation, adaptive parameters, and archive diversity management for multimodal optimization.
# Code:
class AdaptiveDEwithGaussianMutationAndDiversity:
    """Differential Evolution with Gaussian mutation, adaptive parameters, and archive diversity management."""

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F = 0.5  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.2 # Gaussian mutation standard deviation
        self.adaptive_factor = 0.1 #controls the adaptation speed
        self.diversity_threshold = 10 #parameter to control diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.pop_size
        
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self.update_archive(offspring, offspring_fitness)
            self.update_parameters()
            self.population = self.select_population(offspring, offspring_fitness)
            self.update_best(self.population, objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)
            while r1 == i or r2 == i or r3 == i:
                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)

            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])
            
            #Binomial crossover
            j_rand = np.random.randint(0, self.dim)
            u = np.copy(self.population[i])
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    u[j] = v[j]

            #Gaussian Mutation
            u = u + np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                distances = np.array([np.linalg.norm(offspring[i]-x) for x, _ in self.archive])
                fitness_values = np.array([f for _, f in self.archive])
                combined_scores = distances + fitness_values 
                worst_index = np.argmax(combined_scores)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def update_parameters(self):
        if len(self.archive)>1:
            distances = pdist([x for x,_ in self.archive])
            mean_distance = np.mean(distances)
            if mean_distance < self.diversity_threshold: 
                self.F += self.adaptive_factor * np.random.rand()
                self.CR -= self.adaptive_factor * np.random.rand()
                self.sigma *= (1 + self.adaptive_factor * np.random.rand()) #Increase exploration
            else:
                self.F -= self.adaptive_factor * np.random.rand()
                self.CR += self.adaptive_factor * np.random.rand()
                self.sigma *= (1 - self.adaptive_factor * np.random.rand()) #Reduce exploration

        self.F = np.clip(self.F, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
        self.sigma = np.clip(self.sigma, 0.01, 1.0) #Keep sigma within reasonable bounds

    def select_population(self, offspring, offspring_fitness):
        combined_pop = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_pop[indices[:self.pop_size]]

    def update_best(self, population, objective_function):
        fitness = objective_function(population)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        if best_fitness < self.best_fitness_overall:
            self.best_solution_overall = best_solution
            self.best_fitness_overall = best_fitness

def objective_function(X):
    # Placeholder - Replace with actual f24 function implementation
    return np.sum(X**2, axis=1) #Example: Sphere function


```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveGaussianDE
# Description: Differential Evolution with adaptive Gaussian mutation and archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianDE:
    """
    Differential Evolution algorithm with adaptive Gaussian mutation and archive 
    for efficiently exploring multimodal landscapes.
    """

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F = 0.5  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.5 #initial Gaussian mutation standard deviation
        self.adaptive_factor = 0.1 #controls the adaptation speed


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.pop_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self.update_archive(offspring, offspring_fitness)
            self.update_parameters()
            self.population = self.select_population(offspring, offspring_fitness)
            self.update_best(self.population, objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)
            while r1 == i or r2 == i or r3 == i:
                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)

            v = self.population[r1] + self.F * (self.population[r2] - self.population[r3])
            
            #Gaussian mutation
            v = v + np.random.normal(0, self.sigma, self.dim)

            #Binomial crossover
            j_rand = np.random.randint(0, self.dim)
            u = np.copy(self.population[i])
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    u[j] = v[j]

            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Replace worst solution based on fitness
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def update_parameters(self):
        #Adapt Gaussian mutation based on archive diversity and recent progress

        if len(self.archive) > 1 :
            improvement = (self.best_fitness_overall - self.archive[-1][1]) / self.best_fitness_overall if self.best_fitness_overall !=0 else 0
            if improvement > 0.1: # increase exploration
                self.sigma += self.adaptive_factor * np.random.rand()
            elif self.sigma > 0.1: #reduce exploration if no recent progress
                self.sigma -= self.adaptive_factor * np.random.rand()

        self.sigma = np.clip(self.sigma, 0.01, 1.0) #clamp sigma values


    def select_population(self, offspring, offspring_fitness):
        combined_pop = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((objective_function(self.population), offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_pop[indices[:self.pop_size]]

    def update_best(self, population, objective_function):
        fitness = objective_function(population)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        if best_fitness < self.best_fitness_overall:
            self.best_solution_overall = best_solution
            self.best_fitness_overall = best_fitness

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDiversityDEwithGaussianAndArchive
# Description: Adaptive DE with Gaussian mutation, archive diversity management, and fitness-based selection.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDiversityDEwithGaussianAndArchive
# Description: Adaptive DE with Gaussian mutation, archive diversity management, and fitness-based selection.
# Code:
class AdaptiveDiversityDEwithGaussianAndArchive:
    """
    Combines adaptive diversity Differential Evolution (DE) with Gaussian mutation and an archive 
    to enhance exploration and exploitation in multimodal landscapes.  Prioritizes both fitness and diversity.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = np.inf
        self.population_size = 10 * dim  #Larger population for higher dimensionality
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9
        self.sigma = 0.5  # Initial Gaussian mutation standard deviation
        self.diversity_threshold = 0.7 #Maintain at least 70% diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self.update_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population, fitness = self.select_next_generation(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self.update_best(self.population, fitness)
            self.adapt_parameters(self.archive) #Adapt based on archive diversity

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = self.select_indices(i, self.population_size)
            pbest = self.select_pbest(self.archive, fitness)
            mutant = self.mutate(population[i], pbest, population[a], population[b], population[c])
            offspring[i] = self.crossover(population[i], mutant)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def mutate(self, x, pbest, a, b, c):
        mutant = x + self.F_scale * (pbest - x + a - b + c - x)
        #Gaussian perturbation
        mutant += np.random.normal(0, self.sigma, self.dim)
        return mutant

    def select_indices(self, i, pop_size):
        a, b, c = np.random.choice(pop_size, 3, replace=False)
        while a == i or b == i or c == i:
            a, b, c = np.random.choice(pop_size, 3, replace=False)
        return a, b, c

    def select_pbest(self, archive, fitness):
        if archive:
            archive_fitness = np.array([f for _, f in archive])
            weights = 1 / (archive_fitness + 1e-9) #Avoid division by zero
            weights /= np.sum(weights)
            pbest_index = np.random.choice(len(archive), p=weights)
            pbest = archive[pbest_index][0]
        else:
            pbest = self.population[np.argmin(fitness)]
        return pbest

    def crossover(self, x, mutant):
        mask = np.random.rand(self.dim) < self.CR
        offspring = np.where(mask, mutant, x)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def select_next_generation(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        best_solution = population[best_index]
        best_fitness = fitness[best_index]
        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution
        return best_solution, best_fitness

    def adapt_parameters(self, archive):
        diversity = self.calculate_archive_diversity(archive)
        if diversity < self.diversity_threshold : #Increase exploration if low diversity
            self.F_scale *= 1.1
            self.CR *= 1.1
            self.sigma *= 1.1
        else: #Reduce exploration if high diversity
            self.F_scale *= 0.9
            self.CR *= 0.9
            self.sigma *= 0.9
        self.F_scale = np.clip(self.F_scale, 0.1, 1.0)
        self.CR = np.clip(self.CR, 0.1, 1.0)
        self.sigma = np.clip(self.sigma, 0.1, 2.0)

    def calculate_archive_diversity(self, archive):
        if not archive:
            return 1.0
        archive_solutions = np.array([sol for sol, _ in archive])
        if len(archive_solutions) < 2:
            return 1.0
        distances = pdist(archive_solutions)
        average_distance = np.mean(distances)
        max_possible_distance = np.linalg.norm(self.upper_bounds - self.lower_bounds)
        return average_distance / max_possible_distance

```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDEwithGaussianMutationAndArchive
# Description: Differential Evolution with Gaussian mutation, adaptive archive, and parameter control for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveDEwithGaussianMutationAndArchive:
    """
    Combines Differential Evolution (DE) with Gaussian mutation, an adaptive archive, and parameter control 
    for effectively exploring and exploiting multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim #Larger population for higher dimensionality
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.2  # Initial Gaussian width
        self.archive = []
        self.sigma_decay = 0.99
        self.F_scale = 0.9

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)
        self.sigma = 0.2 * np.mean(self.upper_bounds - self.lower_bounds)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population)
            offspring = self._gaussian_mutation(offspring)  # Gaussian mutation
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values) #Adapt parameters based on population performance
            self.sigma *= self.sigma_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i or a == b or a == c or b == c:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[a] + self.F * (population[b] - population[c])
            jrand = random.randint(0, self.dim - 1)
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]

        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _gaussian_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        if len(new_archive) > 0:
            new_archive.sort(key=lambda x: x[-1])
            self.archive.extend(new_archive)

            self.archive.sort(key=lambda x: x[-1])
            
            if len(self.archive) > self.archive_size:
                self.archive = self.archive[:self.archive_size]

        return np.array(self.archive)

    def _adapt_parameters(self, population, fitness_values):
        avg_fitness = np.mean(fitness_values)
        if avg_fitness < self.best_fitness_overall * 0.9: 
            self.F *= self.F_scale 
        else:
            self.F /= self.F_scale 
        self.F = np.clip(self.F, 0.1, 1.0) 
```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDifferentialEvolution
# Description: A differential evolution algorithm with adaptive mutation and crossover rates for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: A differential evolution algorithm with adaptive mutation and crossover rates for multimodal optimization.
# Code:

class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.population = None
        self.F = 0.5  # Initial mutation scale factor
        self.CR = 0.9  # Initial crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Adapt parameters
            self.adapt_parameters(fitness, offspring_fitness)

            # Selection
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_F': self.F,
            'final_CR': self.CR
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])

        return offspring

    def adapt_parameters(self, parent_fitness, offspring_fitness):
        #Simple adaptation: increase exploration if many offspring are better, increase exploitation otherwise.
        better_offspring_count = np.sum(offspring_fitness < parent_fitness)
        if better_offspring_count > self.population_size /2:
            self.F = min(1.0, self.F + 0.1) #Increase exploration
            self.CR = max(0.0, self.CR - 0.1) #Slightly reduce exploitation
        else:
            self.F = max(0.1, self.F - 0.1) #Reduce exploration
            self.CR = min(1.0, self.CR + 0.1) #Increase exploitation
```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDifferentialEvolution
# Description: A differential evolution algorithm with adaptive mutation and crossover rates for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: A differential evolution algorithm with adaptive mutation and crossover rates for multimodal optimization.
# Code:
class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.population = None
        self.F = 0.5  # Initial mutation scale factor
        self.CR = 0.9  # Initial crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection
            for i in range(self.population_size):
                if offspring_fitness[i] < fitness[i]:
                    self.population[i] = offspring[i]
                    fitness[i] = offspring_fitness[i]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adaptive parameter control (simple approach)
            if np.mean(fitness) < self.best_fitness_overall * 0.9: # if significant improvement, increase exploration
                self.F = min(1.0, self.F + 0.1)
                self.CR = min(1.0, self.CR + 0.1)
            else: # otherwise, increase exploitation
                self.F = max(0.1, self.F - 0.05)
                self.CR = max(0.0, self.CR - 0.05)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_F': self.F,
            'final_CR': self.CR
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])

        return offspring

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 20:22:03 INFO Full response text: **Analysis:**

Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveDifferentialEvolution`, we see that the best-performing algorithm uses an archive to store promising solutions and guides the search using these solutions. It also adapts its scaling factor for better exploration/exploitation balance. The worst-performing algorithm lacks an archive and has a simpler, less effective adaptation mechanism.  `(second best)` `AdaptiveDEwithGaussianMutationAndDiversity` uses an adaptive archive that prioritizes both fitness and diversity and incorporates Gaussian mutation for improved exploration in multimodal landscapes, which is lacking in the second-worst algorithm, `AdaptiveDEwithGaussianMutationAndArchive`. Comparing (1st) vs (2nd), we see that the top performer's archive management and pbest selection strategy are more sophisticated than the second-best, leading to a significant performance improvement. (3rd) `AdaptiveDEwithGaussianMutationAndDiversity` and (4th) `AdaptiveDEwithGaussianMutationAndDiversity` are both similar versions with slight variations and both performs poorly compared to the top two, likely due to the less effective adaptation strategies. Comparing (second worst) `AdaptiveDEwithGaussianMutationAndArchive` vs (worst) `AdaptiveDifferentialEvolution`, we see that the second-worst algorithm at least uses an adaptive archive to improve exploration and exploitation. The worst algorithm's simple adaptation method is less effective for the complex f24 landscape. Overall: The key differences lie in the use of an effective archive, sophisticated archive management,  adaptive parameter control strategies, and a better balance of exploration and exploitation through techniques like Gaussian mutation and pbest selection.

**Experience:**

Effective archive management and adaptive parameter control are crucial for handling complex, multimodal landscapes. Incorporating Gaussian mutation can significantly improve exploration, while a well-designed archive helps focus exploitation efforts.  A balance between exploration and exploitation is key.

2025-06-23 20:22:05 INFO Full response text: **Keywords:**  Adaptive parameter control, archive management, exploration-exploitation balance, Gaussian mutation, multimodal optimization.

**Advice:** Focus on specific, measurable improvements to archive management (e.g.,  novel diversity metrics,  dynamic archive sizing) and parameter adaptation (e.g.,  self-adjusting mutation rates based on landscape characteristics).  Quantify the impact of Gaussian mutation on exploration. Avoid vague claims of "balance."

**Avoid:**  Generic statements about exploration/exploitation,  unspecified "adaptive" strategies, references to specific benchmarks (like f24)  as primary justification,  claims of superiority without concrete evidence.

**Explanation:** The ineffective reflections lack concrete, measurable goals and methods.  The revised approach emphasizes specific design choices and quantifiable results, leading to more robust and better heuristics.  The $999K prize necessitates rigorous, evidence-based design rather than broad pronouncements.

2025-06-23 20:22:05 INFO Generating offspring via Crossover...
2025-06-23 20:36:08 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

### Better code
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

### Worse code
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

### Analyze & experience
- Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveDifferentialEvolution`, we see that the best-performing algorithm uses an archive to store promising solutions and guides the search using these solutions. It also adapts its scaling factor for better exploration/exploitation balance. The worst-performing algorithm lacks an archive and has a simpler, less effective adaptation mechanism.  `(second best)` `AdaptiveDEwithGaussianMutationAndDiversity` uses an adaptive archive that prioritizes both fitness and diversity and incorporates Gaussian mutation for improved exploration in multimodal landscapes, which is lacking in the second-worst algorithm, `AdaptiveDEwithGaussianMutationAndArchive`. Comparing (1st) vs (2nd), we see that the top performer's archive management and pbest selection strategy are more sophisticated than the second-best, leading to a significant performance improvement. (3rd) `AdaptiveDEwithGaussianMutationAndDiversity` and (4th) `AdaptiveDEwithGaussianMutationAndDiversity` are both similar versions with slight variations and both performs poorly compared to the top two, likely due to the less effective adaptation strategies. Comparing (second worst) `AdaptiveDEwithGaussianMutationAndArchive` vs (worst) `AdaptiveDifferentialEvolution`, we see that the second-worst algorithm at least uses an adaptive archive to improve exploration and exploitation. The worst algorithm's simple adaptation method is less effective for the complex f24 landscape. Overall: The key differences lie in the use of an effective archive, sophisticated archive management,  adaptive parameter control strategies, and a better balance of exploration and exploitation through techniques like Gaussian mutation and pbest selection.
- **Keywords:**  Adaptive parameter control, archive management, exploration-exploitation balance, Gaussian mutation, multimodal optimization.

**Advice:** Focus on specific, measurable improvements to archive management (e.g.,  novel diversity metrics,  dynamic archive sizing) and parameter adaptation (e.g.,  self-adjusting mutation rates based on landscape characteristics).  Quantify the impact of Gaussian mutation on exploration. Avoid vague claims of "balance."

**Avoid:**  Generic statements about exploration/exploitation,  unspecified "adaptive" strategies, references to specific benchmarks (like f24)  as primary justification,  claims of superiority without concrete evidence.

**Explanation:** The ineffective reflections lack concrete, measurable goals and methods.  The revised approach emphasizes specific design choices and quantifiable results, leading to more robust and better heuristics.  The $999K prize necessitates rigorous, evidence-based design rather than broad pronouncements.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 20:36:08 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Adaptive parameter control, archive management, exploration-exploitation balance, Gaussian mutation, multimodal optimization.

**Advice:** Focus on specific, measurable improvements to archive management (e.g.,  novel diversity metrics,  dynamic archive sizing) and parameter adaptation (e.g.,  self-adjusting mutation rates based on landscape characteristics).  Quantify the impact of Gaussian mutation on exploration. Avoid vague claims of "balance."

**Avoid:**  Generic statements about exploration/exploitation,  unspecified "adaptive" strategies, references to specific benchmarks (like f24)  as primary justification,  claims of superiority without concrete evidence.

**Explanation:** The ineffective reflections lack concrete, measurable goals and methods.  The revised approach emphasizes specific design choices and quantifiable results, leading to more robust and better heuristics.  The $999K prize necessitates rigorous, evidence-based design rather than broad pronouncements.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 20:37:33 INFO Perform Harmony Search...
2025-06-23 20:38:00 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:38:39 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0039
2025-06-23 20:38:39 INFO FeHistory: [205.52686297 198.62272947 193.31117231 ...  -2.5607329    6.64948196
  -6.82924745]
2025-06-23 20:38:39 INFO Expected Optimum FE: -100
2025-06-23 20:38:39 INFO Unimodal AOCC mean: nan
2025-06-23 20:38:39 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:38:39 INFO Multimodal (multiple components) AOCC mean: 0.0039
2025-06-23 20:38:39 INFO AOCC mean: 0.0039
2025-06-23 20:38:39 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:39:16 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.1100
2025-06-23 20:39:16 INFO FeHistory: [180.9364002  203.7479581  233.19617149 ... -98.64766575 -98.63689139
 -98.62125483]
2025-06-23 20:39:16 INFO Expected Optimum FE: -100
2025-06-23 20:39:16 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 180.6042288839484, initial_F_scale: float = 0.39942049822287795):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-23 20:39:16 INFO Unimodal AOCC mean: nan
2025-06-23 20:39:16 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:39:16 INFO Multimodal (multiple components) AOCC mean: 0.1100
2025-06-23 20:39:16 INFO AOCC mean: 0.1100
2025-06-23 20:39:16 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:39:56 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0198
2025-06-23 20:39:56 INFO FeHistory: [191.5765081  194.29261197 183.2441224  ... -60.9307996  -47.60018609
 -59.14756339]
2025-06-23 20:39:56 INFO Expected Optimum FE: -100
2025-06-23 20:39:56 INFO Unimodal AOCC mean: nan
2025-06-23 20:39:56 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:39:56 INFO Multimodal (multiple components) AOCC mean: 0.0198
2025-06-23 20:39:56 INFO AOCC mean: 0.0198
2025-06-23 20:39:56 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:40:38 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0039
2025-06-23 20:40:38 INFO FeHistory: [191.22440378 192.25762553 194.72680461 ...   6.3921231    5.07741329
 -12.78091934]
2025-06-23 20:40:38 INFO Expected Optimum FE: -100
2025-06-23 20:40:38 INFO Unimodal AOCC mean: nan
2025-06-23 20:40:38 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:40:38 INFO Multimodal (multiple components) AOCC mean: 0.0039
2025-06-23 20:40:38 INFO AOCC mean: 0.0039
2025-06-23 20:40:38 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:41:15 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.1084
2025-06-23 20:41:15 INFO FeHistory: [178.29576703 229.40733254 167.17799356 ... -98.69547557 -98.71723868
 -98.70621584]
2025-06-23 20:41:15 INFO Expected Optimum FE: -100
2025-06-23 20:41:15 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.86086410116114, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.44149416805587016):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-23 20:41:15 INFO Unimodal AOCC mean: nan
2025-06-23 20:41:15 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:41:15 INFO Multimodal (multiple components) AOCC mean: 0.1084
2025-06-23 20:41:15 INFO AOCC mean: 0.1084
2025-06-23 20:41:15 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:41:56 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0033
2025-06-23 20:41:56 INFO FeHistory: [204.38120644 218.11170033 202.03003121 ... -16.97400919 -11.43211924
 -13.43888568]
2025-06-23 20:41:56 INFO Expected Optimum FE: -100
2025-06-23 20:41:56 INFO Unimodal AOCC mean: nan
2025-06-23 20:41:56 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:41:56 INFO Multimodal (multiple components) AOCC mean: 0.0033
2025-06-23 20:41:56 INFO AOCC mean: 0.0033
2025-06-23 20:41:56 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:41:56 ERROR Can not run the algorithm
2025-06-23 20:41:56 INFO Run function 24 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 20:41:56 INFO FeHistory: []
2025-06-23 20:41:56 INFO Expected Optimum FE: -100
2025-06-23 20:41:56 INFO Unimodal AOCC mean: nan
2025-06-23 20:41:56 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:41:56 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 20:41:56 INFO AOCC mean: 0.0000
2025-06-23 20:41:57 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:42:35 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0870
2025-06-23 20:42:35 INFO FeHistory: [188.5737038  217.00572908 177.46392466 ... -98.08475161 -97.9017665
 -97.9620871 ]
2025-06-23 20:42:35 INFO Expected Optimum FE: -100
2025-06-23 20:42:35 INFO Unimodal AOCC mean: nan
2025-06-23 20:42:35 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:42:35 INFO Multimodal (multiple components) AOCC mean: 0.0870
2025-06-23 20:42:35 INFO AOCC mean: 0.0870
2025-06-23 20:42:35 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:43:14 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.0015
2025-06-23 20:43:14 INFO FeHistory: [215.52526729 172.27365674 176.47566672 ...  12.53449857   7.24527527
  15.76856504]
2025-06-23 20:43:14 INFO Expected Optimum FE: -100
2025-06-23 20:43:14 INFO Unimodal AOCC mean: nan
2025-06-23 20:43:14 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:43:14 INFO Multimodal (multiple components) AOCC mean: 0.0015
2025-06-23 20:43:14 INFO AOCC mean: 0.0015
2025-06-23 20:43:14 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 20:43:52 INFO Run function 24 complete. FEHistory len: 150000, AOCC: 0.1115
2025-06-23 20:43:52 INFO FeHistory: [191.17629609 150.28865871 184.57326314 ... -98.6291966  -98.65927373
 -98.66506264]
2025-06-23 20:43:52 INFO Expected Optimum FE: -100
2025-06-23 20:43:52 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-23 20:43:52 INFO Unimodal AOCC mean: nan
2025-06-23 20:43:52 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 20:43:52 INFO Multimodal (multiple components) AOCC mean: 0.1115
2025-06-23 20:43:52 INFO AOCC mean: 0.1115
2025-06-23 20:43:52 INFO Generation 5, best so far: 0.1114707164064747
2025-06-23 20:43:52 INFO Population length is: 9
2025-06-23 20:43:52 INFO --- Performing Long-Term Reflection at Generation 6 ---
2025-06-23 20:43:52 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 24, particularly:

f24 is a composite optimization problem that combines five heterogeneous components, each with distinct and challenging features. These components are designed to stress both the exploration and exploitation capabilities of algorithms. Each component has the following characteristics:

Each component is weighted equally (lambda = 0.25).
One component has a scale parameter sigma set to -100; the others have sigma values randomly sampled between -99 and -98.
The position of each component's minimum is randomly selected within the range [-80, 80] in each dimension.
Shape parameters mu1 and mu2 are randomly selected between 0.2 and 0.5.
Ruggedness is introduced via four omega parameters, each sampled between 5 and 50.
Ill-conditioning is enforced by randomly selecting diagonal values of a transformation matrix from a wide range (1 to 100,000).
Each component has strong non-separable interactions, with 75% of variables interacting.
Components are rotated using randomly generated angles between -pi and pi.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f24 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
  Component Sigma: [ -98.90165317  -98.57889237  -98.04211047  -98.46683472 -100.        ]
  Component H: [31552.24758498 98886.12002956 44789.90472406  1937.67642007
  5337.20114916 10234.34054835 53590.10469515 90340.28812687
 16536.2543575  88330.72581449 89588.72593339 11475.48254936
 23703.46099732 32665.16353231 62336.38821906 17234.87849402
 75546.54979719  1988.99350385 53883.5676031  58576.34138656
 23298.19440983 55624.46715881 10750.30541648  7198.35599467
 74382.84158166 23985.536067    1858.60164154 31736.92356981
 74533.69775622 62972.12098465 68650.40626723 74816.81727233
 90859.64171381 67883.87445846 57412.1864316  41406.18472597
 66379.80072733 13748.33293992 92750.93053102 62367.59703335
 42809.69089594 94948.97638145 90338.0486767  52706.28316766
  1583.10846341 13714.43782714 75387.86496994  2622.07247679
 55282.6450466  96959.60523622 80710.71245668 13646.38611084
 22571.70815145 96727.6657237  19543.75268145 49377.47765716
  7003.14434978 98861.62682509 66923.62011243 21018.19081747
 83462.73256407 28045.11876245 29362.12122322 21163.59997189
 14673.71076201 69440.32137262 51489.39631672 13928.49544873
 34777.23820869 75094.4924603  96484.03987479 44991.76343586
 57368.37498774 88594.32398898 92943.79393714 93259.61370825
 92302.53053011  2831.62049559 84203.24720507 56103.46089535
 38786.67654577  5992.70903353 71299.18504929 56810.47809153
 58136.3113684  61995.95188242 48635.02474859 57974.94217936
 26492.69084672 75275.80261833  1829.80944614 78928.14356582
 28778.2460833  26555.40039056 58930.96438479 41418.51277342
 94459.53100433 80739.32147966 75081.45950151 34890.48529944
 66344.48634035 57839.3830491    288.02983279 35727.61873049
 69090.00085477 69682.11933083 71152.76433809 24621.86054924
 12418.20733868  1865.71029    86354.32191409 12135.22423062
 55972.13848843 20330.12017286 97002.02888884 82898.26097412
 60633.33983587 38014.73712118  6634.41710801  6654.58159893
 75014.68135018 10323.49743176 13003.72718326 49157.82435487
 69976.13624373  4996.29594115 58655.91749516 39768.28602172
 72600.07253706 26993.51924861 62169.95032519 40814.27213933
 61714.87421716 90853.60655683 99732.2877223   6600.95127203
 12427.97192625 86002.93484034 27919.08871743 80063.46663539
 74712.41715208  4456.1433026   1256.58545993 25233.32213129
 84683.0333202  15679.98267321 56885.57485721 55095.27096357
 37009.04970721 26032.24954276]
  Omega: [46.93874311 47.75792537 26.86958002 22.76940258  5.62782078 30.04939347
 32.19397173 48.34681378 15.54629388 46.20228574 29.72965647 12.828005
 32.75502607 33.8704794  46.6781642  10.68482837 47.70573443 22.55034714
 46.3430046  11.07856211]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-13.27647925  35.25191895 -79.98170003 -31.62678838 -56.51905747
 -65.22582484 -50.19836618 -24.71028367 -16.51720412   6.21067744
 -12.9288777   29.63512006 -47.28764004  60.49878982 -75.61798509
  27.27480163 -13.23123162   9.39037255 -57.53808982 -48.30376175
  48.11913099  74.92185212 -29.85213149  30.77161851  60.22226437
  63.13706616 -66.39292618 -73.75123468 -52.82713287  60.50280055]
----------------------------------------

These settings create a complex, rugged, asymmetric, ill-conditioned, and highly non-separable landscape, making f24 one of the most difficult benchmark functions to optimize.
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 24 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 24: 1.1147e-01# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 24: 5.5425e-03# Name: ArchiveGuidedDEwithAdaptiveMutation
# Description: Differential Evolution enhanced with an adaptive archive and mutation strength.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedDEwithAdaptiveMutation:
    """
    Differential Evolution enhanced with an adaptive archive and mutation strength for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 34.696286477538784, archive_size: int = 1078, initial_F_scale: float = 0.5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = int(population_size_factor * self.dim)
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt F_scale based on progress
            if self.eval_count > self.budget * 0.2 and self.best_fitness_overall > -99.9 : #Check for stagnation
              self.F_scale = max(0.1, self.F_scale * 0.9) #Reduce if stagnation is detected.


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b]) + np.random.normal(0,0.1,self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 3 (Overall AOCC Score on function 24: 3.8453e-04# Name: AdaptiveDEwithGaussianMutationAndEnhancedArchive
# Description: Adaptive DE with Gaussian mutation and an enhanced archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithGaussianMutationAndEnhancedArchive
# Description: Adaptive DE with Gaussian mutation and an enhanced archive for multimodal optimization.
# Code:
class AdaptiveDEwithGaussianMutationAndEnhancedArchive:
    """
    Combines Differential Evolution (DE) with Gaussian mutation and an enhanced archive 
    that prioritizes both fitness and diversity for multimodal optimization.  Adapts 
    the scaling factor (F) and mutation strength (sigma).
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim  #Heuristic for population size
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.diversity_threshold = 0.9 #Parameter to control diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adaptive parameter adjustments based on performance
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            #Prioritize diverse pbest selection from archive
            if self.archive:
                #Weighted probability to favor both fitness and diversity
                probabilities = np.array([1/(1+f) for _,f in self.archive])
                probabilities /= np.sum(probabilities)
                pbest_index = np.random.choice(len(self.archive), p=probabilities)
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                #Prioritize diversity and fitness in archive update
                if offspring_fitness[i] < self.archive[worst_index][1] * self.diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 4 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDEwithGaussianMutationAndEnhancedArchive
# Description: Adaptive DE with Gaussian mutation and an enhanced archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithGaussianMutationAndEnhancedArchive
# Description: Adaptive DE with Gaussian mutation and an enhanced archive for multimodal optimization.
# Code:
class AdaptiveDEwithGaussianMutationAndEnhancedArchive:
    """
    Combines Differential Evolution (DE) with an adaptive archive that prioritizes both fitness and diversity. 
    Includes Gaussian mutation for enhanced exploration. Adapts scaling factor (F) and mutation strength (sigma).
    Improves archive management by using a distance-based diversity metric.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim  # Heuristic for population size
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.diversity_threshold = 0.9 #parameter to control diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adaptive parameter adjustments
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) #Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                #Prioritize diversity using Euclidean distance
                if offspring_fitness[i] < self.archive[worst_index][1] * self.diversity_threshold or self.diversity(offspring[i]) > self.diversity(self.archive[worst_index][0]):
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def diversity(self, solution):
        if not self.archive: return 0
        distances = np.linalg.norm(np.array(self.archive)[:,0] - solution, axis=1)
        return np.min(distances)

```

### Rank 5 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedAdaptiveDE
# Description: Adaptive Differential Evolution guided by a diversity-aware archive.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Adaptive Differential Evolution guided by a diversity-aware archive.
# Code:
class ArchiveGuidedAdaptiveDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.population = None
        self.F = 0.5  # Initial mutation scale factor
        self.CR = 0.9  # Initial crossover rate
        self.archive_size = 100  # Maximum archive size
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection and archive update
            self.update_population_and_archive(offspring, offspring_fitness)

            # Adaptive parameter control
            self.adapt_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_F': self.F,
            'final_CR': self.CR,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            # Use archive for pbest if available, otherwise use current best
            if self.archive:
                pbest = random.choice(self.archive)[0]
            else:
                pbest = self.best_solution_overall

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = self.population[a] + self.F * (pbest - self.population[a] + self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])

        return offspring

    def update_population_and_archive(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((self.get_fitness(self.population), offspring_fitness))

        #Sort by fitness
        sorted_indices = np.argsort(combined_fitness)
        
        #Update population
        self.population = combined_population[sorted_indices[:self.population_size]]
        
        #Update best solution
        self.best_solution_overall = self.population[0]
        self.best_fitness_overall = combined_fitness[sorted_indices[0]]

        #Update archive (add diverse solutions)
        for i in sorted_indices[:self.population_size]:
            self.add_to_archive(combined_population[i], combined_fitness[i])
            

    def add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            #Simple replacement strategy: replace the worst solution
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def adapt_parameters(self):
        # Simple adaptive strategy: increase exploration if stuck, otherwise exploit
        avg_fitness = np.mean(self.get_fitness(self.population))
        if avg_fitness > self.best_fitness_overall * 0.95:  # Adjust threshold as needed
            self.F = min(1.0, self.F + 0.1)
            self.CR = min(1.0, self.CR + 0.1)
        else:
            self.F = max(0.1, self.F - 0.05)
            self.CR = max(0.0, self.CR - 0.05)

    def get_fitness(self, population):
        if population is None:
            return np.array([])
        return np.array([self.best_fitness_overall] * len(population)) if len(population) == 0 else np.array([self.best_fitness_overall] * len(population)) # Placeholder - Needs objective function call

```

### Rank 6 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDEwithGaussianMutationAndDiversityPlusArchive
# Description: Adaptive DE with Gaussian mutation, archive diversity, and improved archive management.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithGaussianMutationAndDiversityPlusArchive
# Description: Adaptive DE with Gaussian mutation, archive diversity, and improved archive management.
# Code:
class AdaptiveDEwithGaussianMutationAndDiversityPlusArchive:
    """
    Combines Differential Evolution (DE) with an adaptive archive that prioritizes both fitness and diversity. 
    Includes Gaussian mutation for enhanced exploration. Adapts scaling factor (F) and mutation strength (sigma).
    Improves archive management by dynamically adjusting archive size and using a more sophisticated diversity metric.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.max_archive_size = 200  #Dynamically adjusted
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.diversity_threshold = 0.9


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adaptive parameter adjustments
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)
            self.adjust_archive_size() #Dynamic archive size

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim) 
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.max_archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] * self.diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
                

    def adjust_archive_size(self):
        #Dynamically adjust archive size based on exploration/exploitation phase
        if self.eval_count < self.budget * 0.5: # Exploration phase
          self.max_archive_size = max(self.max_archive_size , int(0.1 * self.budget)) #Expand archive to explore 
        else: # Exploitation phase
          self.max_archive_size = max(100, int(0.05 * self.budget)) #Shrink archive to exploit

```

### Rank 7 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveDEwithGaussianMutationAndEnhancedArchive
# Description: Adaptive DE with Gaussian mutation and an enhanced archive for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithGaussianMutationAndEnhancedArchive
# Description: Adaptive DE with Gaussian mutation and an enhanced archive for multimodal optimization.
# Code:
class AdaptiveDEwithGaussianMutationAndEnhancedArchive:
    """
    Combines Differential Evolution (DE) with an adaptive archive that prioritizes both fitness and diversity.
    Includes Gaussian mutation for enhanced exploration. Adapts scaling factor (F) and mutation strength (sigma).
    """

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim  # Heuristic
        self.archive_size = 200  # Adjust as needed
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.F_adaptation_rate = 0.1
        self.sigma = 0.5
        self.sigma_adaptation_rate = 0.05
        self.diversity_threshold = 0.9  # Parameter to control diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population = self.selection(self.population, fitness, offspring, offspring_fitness)
            
            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adaptive parameter adjustments
            if self.best_fitness_overall < np.mean(fitness):
                self.F_scale += self.F_adaptation_rate * (1 - self.F_scale)
                self.sigma += self.sigma_adaptation_rate * (1 - self.sigma)
            else:
                self.F_scale -= self.F_adaptation_rate * self.F_scale
                self.sigma -= self.sigma_adaptation_rate * self.sigma
            self.F_scale = np.clip(self.F_scale, 0.1, 0.9)
            self.sigma = np.clip(self.sigma, 0.01, 1.0)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim)  # Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] * self.diversity_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def selection(self, population, population_fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((population_fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

```

### Rank 8 (Overall AOCC Score on function 24: 0.0000e+00# Name: ArchiveGuidedDEwithAdaptiveMutation
# Description: Differential Evolution with an adaptive archive and mutation strategy for multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedDEwithAdaptiveMutation:
    """
    Differential Evolution enhanced with an adaptive archive and mutation strategy 
    to efficiently explore multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for better exploration
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 #Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt F and CR based on success rate
            self.adapt_parameters(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            #Adaptive Gaussian Mutation
            mutation = self.F_scale * (pbest - population[i] + population[a] - population[b]) + np.random.normal(0, 0.1, self.dim) #added Gaussian noise

            #Binomial Crossover
            jrand = random.randint(0, self.dim -1)
            offspring[i] = population[i].copy()
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i][j] = population[i][j] + mutation[j]
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_parameters(self, fitness):
        #Simple success rate based adaptation
        success_rate = np.mean(fitness[-self.population_size:] < fitness[:self.population_size])
        if success_rate > 0.2: #increase exploration
            self.F_scale = min(1.0, self.F_scale + 0.1)
            self.CR = min(1.0, self.CR + 0.1)
        elif success_rate < 0.1: #increase exploitation
            self.F_scale = max(0.1, self.F_scale - 0.1)
            self.CR = max(0.1, self.CR - 0.1)

```

### Rank 9 (Overall AOCC Score on function 24: 0.0000e+00# Name: AdaptiveGaussianDE
# Description: Differential Evolution with adaptive Gaussian mutation and dynamic archive management for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveGaussianDE
# Description: Differential Evolution with adaptive Gaussian mutation and dynamic archive management for multimodal optimization.
# Code:
class AdaptiveGaussianDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Dynamically adjusted
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.sigma = 0.2  # Initial Gaussian mutation standard deviation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)
            self.adapt_parameters(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = mutant + np.random.normal(0, self.sigma, self.dim)  # Gaussian mutation
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
        
        #Dynamic archive sizing
        self.archive_size = min(max(100, int(200*(1+self.eval_count/self.budget))), 500) #Adapt size based on progress
        if len(self.archive) > self.archive_size: #Maintain size, remove furthest
            distances = np.zeros(len(self.archive))
            for i in range(len(self.archive)):
                for j in range(i+1, len(self.archive)):
                    distances[i] += np.linalg.norm(self.archive[i][0] - self.archive[j][0])
                    distances[j] += np.linalg.norm(self.archive[i][0] - self.archive[j][0])
            
            to_remove = np.argmax(distances)
            self.archive.pop(to_remove)


    def adapt_parameters(self, offspring, offspring_fitness):
        # Adapt F based on success rate
        success_rate = np.mean(offspring_fitness < np.min(offspring_fitness))
        if success_rate > 0.2:
            self.F_scale = min(1, self.F_scale + 0.1)
        elif success_rate < 0.1:
            self.F_scale = max(0.1, self.F_scale - 0.1)
        
        # Adapt sigma based on fitness spread
        fitness_spread = np.std(offspring_fitness)
        if fitness_spread < 10: #Small spread, increase exploration
            self.sigma = min(1, self.sigma + 0.05)
        else: #Large spread, reduce exploration
            self.sigma = max(0.01, self.sigma - 0.05)

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 20:43:59 INFO Full response text: **Analysis:**

Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveGaussianDE`, we see that the best utilizes an adaptive scaling factor (`F_scale`) with slight variation, and its archive update prioritizes diversity alongside fitness. The worst uses simpler adaptation for both the scaling factor (`F_scale`) and the Gaussian mutation standard deviation (`sigma`), and its dynamic archive size adjustment lacks a clear strategy.  `EnhancedArchiveGuidedDE` shows more sophisticated archive management and parameter adaptation compared to `AdaptiveGaussianDE`.

`(second best)` `ArchiveGuidedDEwithAdaptiveMutation` vs `(second worst)` `AdaptiveDEwithGaussianMutationAndEnhancedArchive` (Rank 4): The second-best algorithm includes a Gaussian mutation term, adapting `F_scale` based on stagnation, and showing a simpler archive update than the second-worst. The second-worst, while also using Gaussian mutation and adaptive parameters, lacks clear diversity measures in its archive management, using a simpler diversity threshold.


Comparing (1st) `EnhancedArchiveGuidedDE` vs (2nd) `ArchiveGuidedDEwithAdaptiveMutation`, we see that the best algorithm incorporates a more refined archive update strategy that balances fitness and diversity, using a specific `archive_update_threshold`. The second-best has a simpler archive update, only replacing if the offspring fitness is strictly better.  The best also employs a more sophisticated adaptive scaling factor.

(3rd) `AdaptiveDEwithGaussianMutationAndEnhancedArchive` (Rank 3) vs (4th) `AdaptiveDEwithGaussianMutationAndEnhancedArchive` (Rank 4):  Both use adaptive parameters and Gaussian mutation. However, Rank 3 utilizes a weighted probability for pbest selection from the archive, promoting diversity. Rank 4 introduces a distance-based diversity metric for archive management which provides a more robust diversity mechanism compared to the simple fitness-based threshold of Rank 3. This explains why Rank 4 performed better than Rank 3.

Comparing (second worst) `AdaptiveDEwithGaussianMutationAndEnhancedArchive` (Rank 4) vs (worst) `AdaptiveGaussianDE`, we see that the former incorporates adaptive parameters and archive management techniques that are more refined than the latter.  The latter's dynamic archive sizing is less controlled and the parameter adaptation mechanisms are less effective.


Overall: The top-performing algorithms consistently incorporate adaptive parameter control, sophisticated archive management (prioritizing both fitness and diversity), and often Gaussian mutation for enhanced exploration in high-dimensional spaces.  Simpler adaptation mechanisms, less sophisticated archive management, and lack of explicit diversity measures lead to lower performance.  The use of distance metrics for diversity assessment also stands out in the better-performing algorithms.


**Experience:**

Effective heuristics for high-dimensional multimodal optimization require adaptive parameter control, strategic archive management that balances exploitation and exploration (including explicit diversity measures), and robust mutation strategies.  The choice of diversity metric significantly impacts performance.

2025-06-23 20:44:02 INFO Full response text: **Keywords:** High-Dimensional Multimodal Optimization, Heuristic Design, Adaptive Parameter Control, Archive Management, Diversity Metrics, Mutation Strategies, Exploration-Exploitation Balance.

**Advice:**  Focus on rigorously evaluating and comparing different diversity metrics.  Develop novel mutation strategies beyond Gaussian, considering their impact on both exploration and exploitation. Design archive management that explicitly incorporates a chosen diversity metric into selection and replacement policies.  Quantify the trade-off between exploration and exploitation for different heuristic components.

**Avoid:**  Vague terms like "robust" and "effective" without precise definitions or quantitative measures.  Generic statements about exploration/exploitation balance without specific mechanisms for achieving it.  Over-reliance on Gaussian mutation or a single diversity metric.  Benchmarking solely on a single problem (e.g., f24).

**Explanation:** The provided ineffective self-reflection examples suffer from a lack of concrete, measurable improvements.  The redefined self-reflection emphasizes specific design choices (diversity metrics, mutation strategies, archive management policies) and encourages a quantitative evaluation of their impact.  This allows for a systematic improvement of heuristics, enabling a data-driven approach to design superior algorithms.  Avoiding vague language ensures clarity and facilitates reproducible results.

2025-06-23 20:44:02 INFO Generating offspring via Crossover...
