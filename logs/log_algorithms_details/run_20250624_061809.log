2025-06-24 06:18:10 INFO Initializing first population
2025-06-24 06:18:10 INFO Initializing population from 9 seed files...
2025-06-24 06:41:27 INFO Started evolutionary loop, best so far: 0.019671809367479056
2025-06-24 06:41:27 INFO Population length is: 20
2025-06-24 06:41:27 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-24 06:41:27 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average weighted AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.9672e-02 |             AOCC Score on Unimodal instances: 1.9672e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 2 (Overall AOCC Score: 1.9025e-02 |             AOCC Score on Unimodal instances: 1.8376e-01 |             AOCC Score on Multimodal instances with a single component: 3.2403e-03 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 3 (Overall AOCC Score: 1.8791e-02 |             AOCC Score on Unimodal instances: 1.5395e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 4.8522e-03)
# Name: AdaptiveDifferentialEvolutionwithClustering
# Description: A Differential Evolution algorithm incorporating adaptive mutation and clustering to escape local optima and improve exploration in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np
from sklearn.cluster import KMeans

class AdaptiveDifferentialEvolutionwithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.F = 0.8 # scaling factor for mutation
        self.CR = 0.9 # crossover rate
        self.cluster_threshold = 0.8 # fraction of population for clustering
        
        self.population = np.random.uniform(low=self.lower_bounds, high=self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness_values = np.full(self.population_size, np.inf)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.fitness_values = np.full(self.population_size, np.inf) # reset fitness values
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        # Initial evaluation
        for i in range(self.population_size):
            self.fitness_values[i] = objective_function(self.population[i:i+1])[0]
            self.eval_count += 1
            if self.fitness_values[i] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness_values[i]
                self.best_solution_overall = self.population[i]

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Mutation
                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)
                while a == i or b == i or c == i:
                    a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Bounding

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])

                # Selection
                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    self.population[i] = trial
                    self.fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial

            #Adaptive Mutation and Clustering
            if self.eval_count/self.budget > self.cluster_threshold:
                kmeans = KMeans(n_clusters=int(0.2*self.population_size), random_state=0).fit(self.population)
                cluster_centers = kmeans.cluster_centers_
                self.F = 0.5 #reduce F for refined search within clusters
                for i in range(len(cluster_centers)):
                    self.population[i] = cluster_centers[i]
                    self.fitness_values[i] = objective_function(cluster_centers[i].reshape(1,-1))[0]
                    self.eval_count +=1
                    if self.fitness_values[i] < self.best_fitness_overall:
                        self.best_fitness_overall = self.fitness_values[i]
                        self.best_solution_overall = cluster_centers[i]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 4 (Overall AOCC Score: 1.8288e-02 |             AOCC Score on Unimodal instances: 1.8288e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 5 (Overall AOCC Score: 1.8168e-02 |             AOCC Score on Unimodal instances: 1.8168e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 6 (Overall AOCC Score: 1.8071e-02 |             AOCC Score on Unimodal instances: 1.8071e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 7 (Overall AOCC Score: 1.7653e-02 |             AOCC Score on Unimodal instances: 1.7653e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random

class EnhancedArchiveGuidedDE: #aocc 0.15
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale  # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 8 (Overall AOCC Score: 1.7571e-02 |             AOCC Score on Unimodal instances: 1.7571e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 9 (Overall AOCC Score: 1.6760e-02 |             AOCC Score on Unimodal instances: 1.6760e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 10 (Overall AOCC Score: 1.6691e-02 |             AOCC Score on Unimodal instances: 1.6691e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 11 (Overall AOCC Score: 1.5383e-02 |             AOCC Score on Unimodal instances: 1.5383e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a self-adaptive mutation strategy to efficiently explore and exploit multimodal landscapes.
# Code:
```python
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a self-adaptive mutation strategy to efficiently explore and exploit multimodal landscapes.

import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Differential Evolution crossover rate
        self.population = self.initialize_population()


    def initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def differential_evolution(self, population):
        new_population = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)  #Indices different from i
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            v = population[a] + self.F * (population[b] - population[c])
            
            # Adaptive Mutation: adjust F based on performance
            if self.eval_count > self.budget * 0.2: # Adjust trigger point as needed
                best_index = np.argmin(self.fitness_values)
                if np.linalg.norm(population[i] - population[best_index]) > 5: #adjust threshold
                   self.F *= 0.95 # Decrease F if far from the best

            #Boundary check with reflection
            v = np.clip(v, self.lower_bounds, self.upper_bounds)
            
            u = np.copy(population[i])
            j_rand = random.randint(0, self.dim - 1)
            for j in range(self.dim):
                if random.random() < self.CR or j == j_rand:
                    u[j] = v[j]
            new_population[i] = u
        return new_population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(self.fitness_values)
        self.best_solution_overall = self.population[best_index]
        self.best_fitness_overall = self.fitness_values[best_index]

        while self.eval_count < self.budget:
            new_population = self.differential_evolution(self.population)
            new_fitness_values = objective_function(new_population)
            self.eval_count += self.population_size

            combined_population = np.vstack((self.population, new_population))
            combined_fitness = np.concatenate((self.fitness_values, new_fitness_values))
            
            sorted_indices = np.argsort(combined_fitness)
            self.population = combined_population[sorted_indices[:self.population_size]]
            self.fitness_values = combined_fitness[sorted_indices[:self.population_size]]
            
            best_index = np.argmin(self.fitness_values)
            if self.fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness_values[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 12 (Overall AOCC Score: 1.5266e-02 |             AOCC Score on Unimodal instances: 1.5266e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalExploration
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive mutation strength and a local search mechanism to efficiently explore multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalExploration:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.mutation_strength = 0.5 # Initial mutation strength
        self.local_search_radius = 10 # Initial local search radius

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall, self.best_fitness_overall = self._get_best(self.population, fitness_values)

        while self.eval_count < self.budget:
            new_population = self._differential_evolution()
            new_fitness_values = objective_function(new_population)
            self.eval_count += self.population_size

            self.population = np.concatenate((self.population, new_population))
            fitness_values = np.concatenate((fitness_values, new_fitness_values))

            self.population, fitness_values = self._selection(self.population, fitness_values)

            best_solution, best_fitness = self._get_best(self.population, fitness_values)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness
            
            #Adaptive Mechanisms
            self._adapt_parameters(best_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            
            #Clamp values within bounds
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])

            #Add Mutation for exploration
            offspring[i] += np.random.normal(0, self.mutation_strength, self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def _selection(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_combined = combined[combined[:, -1].argsort()]
        return sorted_combined[:self.population_size, :-1], sorted_combined[:self.population_size, -1]


    def _get_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _adapt_parameters(self, best_fitness):
        # Adjust mutation strength based on progress
        if best_fitness < self.best_fitness_overall * 0.9 : #Significant improvement
            self.mutation_strength *= 0.9  # Reduce mutation for exploitation
            #self.local_search_radius *= 0.9
        elif self.eval_count > self.budget * 0.8: # Late stage, boost exploration
            self.mutation_strength *= 1.1 #Increase mutation for further exploration
            #self.local_search_radius *= 1.1

```

### Rank 13 (Overall AOCC Score: 1.5241e-02 |             AOCC Score on Unimodal instances: 1.5241e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a novel adaptive mutation strategy for efficient exploration of multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Differential Evolution crossover rate
        self.mutation_scale = 1.0  # Adaptive mutation scale

        self.population = np.random.uniform(low=self.lower_bounds, high=self.upper_bounds, size=(self.population_size, self.dim))

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        for i in range(self.population_size):
            if fitness_values[i] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[i]
                self.best_solution_overall = self.population[i].copy()


        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                # Differential Evolution
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)

                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Boundary handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.copy(self.population[i])
                jrand = random.randint(0, self.dim - 1)
                for j in range(self.dim):
                    if random.random() < self.CR or j == jrand:
                        trial[j] = mutant[j]


                # Adaptive Mutation (to escape local optima)
                if random.random() < 0.1 : #probability of adaptive mutation
                    adaptive_mutation = np.random.normal(0, self.mutation_scale, self.dim)
                    trial = np.clip(trial + adaptive_mutation, self.lower_bounds, self.upper_bounds)


                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1

                if trial_fitness[0] < fitness_values[i]:
                    offspring.append(trial)
                    fitness_values[i] = trial_fitness[0]
                    if trial_fitness[0] < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness[0]
                        self.best_solution_overall = trial.copy()
                else:
                    offspring.append(self.population[i])

            self.population = np.array(offspring)

            # Adjust mutation scale based on progress.  Reduce if stuck
            if self.eval_count % (self.budget//10) == 0: #check every 10% of budget
                recent_improvement = self.best_fitness_overall - np.min(fitness_values)
                if recent_improvement < 1e-4:
                    self.mutation_scale *= 1.2 #increase for more exploration
                else:
                    self.mutation_scale *= 0.9 # reduce for exploitation


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 14 (Overall AOCC Score: 1.5214e-02 |             AOCC Score on Unimodal instances: 1.5214e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: An evolutionary algorithm combining differential evolution with adaptive mutation and a niching strategy for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.niche_radius = 0.1 #Adaptive Niching Parameter


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)


        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)

                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.zeros(self.dim)
                for j in range(self.dim):
                    if random.random() < self.CR:
                        trial[j] = mutant[j]
                    else:
                        trial[j] = self.population[i][j]

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    self.fitness_values[i] = trial_fitness
                else:
                    new_population.append(self.population[i])

                if trial_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = trial_fitness
                    self.best_solution_overall = trial

            self.population = np.array(new_population)

            #Adaptive Niching: Adjust niche radius based on population diversity.
            distances = np.linalg.norm(self.population[:, np.newaxis, :] - self.population[np.newaxis, :, :], axis=2)
            min_distance = np.min(distances[distances > 0])
            self.niche_radius = min(self.niche_radius, min_distance*0.5) #Reduce radius if solutions are close


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'niche_radius_final':self.niche_radius
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 15 (Overall AOCC Score: 1.5210e-02 |             AOCC Score on Unimodal instances: 1.5210e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalExploration
# Description: A hybrid evolutionary algorithm combining Differential Evolution with adaptive Gaussian mutation for robust exploration of multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalExploration:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Differential Evolution crossover rate
        self.sigma = 0.5 # Initial Gaussian mutation standard deviation
        self.sigma_decay = 0.99 # Decay rate for sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        
        best_index = np.argmin(fitness)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness[best_index]

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Adaptive Gaussian Mutation to escape local optima
                mutant = np.clip(mutant + np.random.normal(0, self.sigma, self.dim), self.lower_bounds, self.upper_bounds)

                trial = np.copy(self.population[i])
                j_rand = random.randint(0, self.dim - 1)
                for j in range(self.dim):
                    if random.random() < self.CR or j == j_rand:
                        trial[j] = mutant[j]

                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial.copy()
                        self.best_fitness_overall = trial_fitness
                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)
            self.sigma *= self.sigma_decay #Reduce Mutation over time

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 16 (Overall AOCC Score: 1.5170e-02 |             AOCC Score on Unimodal instances: 1.5170e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive mutation and a niching strategy for multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.F = 0.8 # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate

        self.niche_radius = 0.1 #Initial niche radius, to be adapted.

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)

                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.copy(self.population[i])
                for j in range(self.dim):
                    if random.random() < self.CR:
                        trial[j] = mutant[j]

                trial_fitness = objective_function(trial[np.newaxis, :])[0]
                self.eval_count += 1

                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    self.fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial
                        self.best_fitness_overall = trial_fitness

                else:
                    new_population.append(self.population[i])


            self.population = np.array(new_population)
            # Adaptive Niche Radius and Mutation
            self.adapt_niche_radius()
            self.adapt_mutation()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def adapt_niche_radius(self):
        #Simple adaptation: reduce radius if convergence is slow.
        if self.eval_count > self.budget * 0.7 and self.best_fitness_overall > 1e-2:
            self.niche_radius *= 0.9


    def adapt_mutation(self):
        #Simple adaptation: increase F if stuck in local optima.
        if self.eval_count > self.budget * 0.5 and self.best_fitness_overall > 1e-2:
            self.F += 0.1
            self.F = min(self.F,1.5) #Bound F


```

### Rank 17 (Overall AOCC Score: 1.5168e-02 |             AOCC Score on Unimodal instances: 1.5168e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalExploration
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive Gaussian mutation for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalExploration:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness = None
        self.sigma = 0.5 #Initial Gaussian mutation scale
        self.sigma_decay = 0.99 #Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, np.inf)

        for i in range(self.population_size):
            self.fitness[i] = objective_function(self.population[i:i+1])[0]
            self.eval_count += 1
            if self.fitness[i] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness[i]
                self.best_solution_overall = self.population[i].copy()

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring_fitness)

            for i in range(len(offspring)):
                if offspring_fitness[i] < self.fitness[i]:
                    self.fitness[i] = offspring_fitness[i]
                    self.population[i] = offspring[i]
                    if self.fitness[i] < self.best_fitness_overall:
                        self.best_fitness_overall = self.fitness[i]
                        self.best_solution_overall = self.population[i].copy()

            #Adaptive sigma adjustment based on exploration success rate
            success_rate = np.sum(offspring_fitness < self.fitness[:len(offspring)]) / len(offspring)
            if success_rate > 0.7:
                self.sigma *= self.sigma_decay #Reduce Exploration for convergence
            elif success_rate < 0.3:
                self.sigma /= self.sigma_decay #increase exploration if local optima found

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'sigma': self.sigma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            #Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            offspring[i] = self.population[a] + 0.8*(self.population[b] - self.population[c])

            #Gaussian Mutation for exploration
            offspring[i] += np.random.normal(0, self.sigma, self.dim)

            #Clamp to bounds
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

```

### Rank 18 (Overall AOCC Score: 1.4768e-02 |             AOCC Score on Unimodal instances: 1.4768e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm using adaptive mutation and differential evolution to escape local optima and explore diverse regions of the search space.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.mutation_rate = 0.1  # Initial mutation rate
        self.crossover_rate = 0.9 # For Differential Evolution

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        fitness_values = objective_function(self.population)
        self.eval_count += len(self.population)

        self.best_solution_overall, self.best_fitness_overall = self._get_best(self.population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))
            
            self.population, fitness_values = self._selection(self.population, fitness_values)
            
            best_solution, best_fitness = self._get_best(self.population, fitness_values)
            
            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Adaptive Mutation Rate
            self.mutation_rate = max(0.01, self.mutation_rate * 0.95 + 0.05 * (1 - (best_fitness/self.best_fitness_overall) if self.best_fitness_overall !=0 else 1))


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'mutation_rate_final': self.mutation_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self):
        offspring = np.empty((self.population_size, self.dim))
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(len(self.population)), 3)
            v = self.population[a] + self.crossover_rate * (self.population[b] - self.population[c])

            # Bounding
            v = np.clip(v, self.lower_bounds, self.upper_bounds)

            # Mutation
            v = v + np.random.normal(0, self.mutation_rate, self.dim)
            v = np.clip(v, self.lower_bounds, self.upper_bounds)
            offspring[i] = v
        return offspring
    
    def _selection(self, population, fitness_values):
        # Tournament Selection
        selected_indices = np.random.choice(np.arange(len(population)), size=self.population_size, replace=False, p =  1/fitness_values)
        
        return population[selected_indices], fitness_values[selected_indices]


    def _get_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 19 (Overall AOCC Score: 1.4708e-02 |             AOCC Score on Unimodal instances: 1.4708e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a local search and adaptive mutation to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Differential Evolution crossover rate
        self.mutation_rate = 0.1 # Initial mutation rate
        self.population = None


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness_values)


        while self.eval_count < self.budget:
            new_population = self._differential_evolution()
            new_fitness_values = objective_function(new_population)
            self.eval_count += self.population_size
            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, new_population, new_fitness_values)
            fitness_values = np.concatenate((fitness_values, new_fitness_values))
            self._adaptive_mutation()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self):
        new_population = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            trial = np.clip(np.random.rand(self.dim) < self.CR, 0,1) * mutant + (1-np.clip(np.random.rand(self.dim) < self.CR, 0,1)) * self.population[i]
            new_population[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return new_population

    def _selection(self, population, fitness_values, new_population, new_fitness_values):
        combined_population = np.vstack((population, new_population))
        combined_fitness = np.concatenate((fitness_values, new_fitness_values))
        sorted_indices = np.argsort(combined_fitness)
        best_indices = sorted_indices[:self.population_size]
        selected_population = combined_population[best_indices]
        selected_fitness = combined_fitness[best_indices]

        best_solution, best_fitness = self._update_best(selected_population, selected_fitness)
        return selected_population, best_solution, best_fitness

    def _update_best(self, population, fitness_values):
      best_index = np.argmin(fitness_values)
      best_solution = population[best_index]
      best_fitness = fitness_values[best_index]
      if best_fitness < self.best_fitness_overall:
          self.best_fitness_overall = best_fitness
          self.best_solution_overall = best_solution
      return best_solution, best_fitness

    def _adaptive_mutation(self):
        # Adjust mutation rate based on progress
        if self.best_fitness_overall < 1e-2 : #Example Threshold, adjust this for your objective functions
            self.mutation_rate *= 0.9
        else:
            self.mutation_rate *= 1.1
        self.mutation_rate = np.clip(self.mutation_rate, 0.01, 0.5) #Keep mutation rate within bounds
```

### Rank 20 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: 
# Description: 
# Code:
```python

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 06:41:34 INFO Full response text: **Analysis:**

Comparing (best) `AdaptiveDifferentialEvolutionWithEnhancedInitialization` vs (worst), we see that the best utilizes a more sophisticated initialization strategy, incorporating knowledge of known optima to guide early exploration, and combines differential evolution with local search for efficient exploitation. The worst algorithm is empty and provides no optimization strategy.  `AdaptiveDifferentialEvolutionWithEnhancedInitialization` also adapts its parameters dynamically.

(second best) `AdaptiveGaussianSamplingEA` vs (second worst) `AdaptiveMultimodalOptimizer`: `AdaptiveGaussianSamplingEA` uses adaptive Gaussian sampling, which allows it to explore the search space more broadly than the simple DE approach of AdaptiveMultimodalOptimizer.  The adaptive mutation in `AdaptiveGaussianSamplingEA` is another advantage.


Comparing (1st) vs (2nd), we see that the top performer incorporates local search, which helps to refine solutions in promising areas identified by Differential Evolution. The second-best relies solely on Gaussian Sampling, which, while adaptive, may not be as efficient at exploiting local optima.

(3rd) `AdaptiveDifferentialEvolutionwithClustering` vs (4th) `AdaptiveGaussianSamplingEAwithArchive`: The third-ranked algorithm uses clustering to identify multiple promising regions within the search space, which helps it find better solutions in multimodal functions, while the fourth uses an archive for improved exploration but lacks the multi-region identification of clustering.

Comparing (second worst) `AdaptiveMultimodalOptimizer` vs (worst), we see that even the second-worst algorithm employs a basic differential evolution approach, showing that some kind of evolutionary strategy is helpful. The worst algorithm's lack of a defined optimization strategy leads to significantly worse performance.

Overall:  The top-performing algorithms combine sophisticated initialization strategies, adaptive parameter tuning, local search, clustering, and archiving to achieve better results.  These algorithms adapt their parameters based on the exploration and exploitation balance required at each stage of the process, dynamically modifying the search approach.  Simple DE or solely Gaussian sampling approaches underperform.


**Experience:**

Combining multiple strategies (e.g., DE, Gaussian sampling, local search, clustering, archiving) and employing adaptive parameter control significantly enhances the performance of evolutionary algorithms.  Prioritizing diversity through techniques like clustering and archiving is crucial for solving complex multimodal problems.

