2025-06-23 21:53:05 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:05 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:05 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:05 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:05 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:05 ERROR Can not run the algorithm
2025-06-23 21:53:05 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1470
2025-06-23 21:53:05 INFO FeHistory: [-183.29492633 -183.34925126 -183.35838631 -183.34441388 -183.28592995
 -183.28575877 -183.33502712 -183.37255039 -183.32551798 -183.41330888
 -183.37842114 -183.27986983 -183.43024942 -183.34358734 -183.38782268
 -183.38891031 -183.31072166 -183.27637417 -183.32854545 -183.38523574
 -183.33644569 -183.30482214 -183.27354611 -183.31804004 -183.29572833
 -183.29958191 -183.31387031 -183.36866466 -183.32594782 -183.35265909
 -183.34701167 -183.376642   -183.44827616 -183.29464555 -183.30212608
 -183.28073626 -183.3001434  -183.31555992 -183.34437714 -183.34268585
 -183.22861068 -183.38653932 -183.31738385 -183.30536473 -183.30718761
 -183.42797895 -183.38489351 -183.3552501  -183.41071574 -183.31930175
 -183.31709822 -183.37375481 -183.35645478 -183.35970313 -183.32859369
 -183.47182678 -183.34291785 -183.3271     -183.34359777 -183.30740469
 -183.37888196 -183.32657946 -183.30268109 -183.40441807 -183.45029318
 -183.38981962 -183.29669192 -183.39083844 -183.31892577 -183.32963592
 -183.38579742 -183.46543157 -183.34414051 -183.38409367 -183.30204123
 -183.30235181 -183.36467547 -183.43029884 -183.3281993  -183.34944968
 -183.33620647 -183.28295295 -183.34351417 -183.39888068 -183.3580689
 -183.35350904 -183.36646736 -183.33330684 -183.31075999 -183.29235054
 -183.37103802 -183.38427407 -183.42671577 -183.34730655 -183.2975443
 -183.36740464 -183.40376599 -183.35384281 -183.30282114 -183.38336857]
2025-06-23 21:53:05 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:05 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
from scipy.cluster.vq import kmeans2

class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100 # Example value - can be tuned
        self.F = 0.8 # Differential weight - can be tuned
        self.CR = 0.9 # Crossover rate - can be tuned
        self.cluster_k = 5 # Number of clusters - can be tuned


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness_values)


        while self.eval_count < self.budget:
            #Clustering
            centroids, labels = kmeans2(self.population, self.cluster_k)

            offspring = []
            offspring_fitness = []
            for i in range(self.population_size):
                cluster_indices = np.where(labels == labels[i])[0]
                cluster = self.population[cluster_indices]
                
                a, b, c = np.random.choice(cluster, size=3, replace=False)
                mutant = a + self.F * (b - c)
                
                trial = np.clip(np.random.rand(self.dim) < self.CR, 0, 1) * mutant + (1 - trial) * self.population[i]
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count +=1
                offspring.append(trial)
                offspring_fitness.append(trial_fitness[0])

            offspring = np.array(offspring)
            offspring_fitness = np.array(offspring_fitness)
            
            #Selection
            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size


            #Adaptive Mutation (adjust F based on success rate)
            #Implementation of Adaptive Mutation strategy is omitted for brevity.
            #A typical approach could be to increase F if many successful mutations are observed,
            #and decrease F if mutation frequently leads to worse solutions.

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
    
    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]

        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution

        return best_solution, best_fitness

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        indices = np.argsort(combined_fitness)
        selected_population = combined_population[indices[:self.population_size]]
        selected_fitness = combined_fitness[indices[:self.population_size]]

        best_solution, best_fitness = self._update_best(selected_population, selected_fitness)

        return selected_population, best_solution, best_fitness

2025-06-23 21:53:05 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:05 ERROR Can not run the algorithm
2025-06-23 21:53:05 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:53:05 INFO FeHistory: [3243483.21868803  876096.2087365  2599311.68490943 2085511.11815244
 2451000.1254489   478604.98372949 3634206.98358021 1365593.38842136
 3031425.4876966  1479738.23292201 1370941.89901696 1720979.01108077
 2422381.30053365 1453109.92496965 1299342.36008062 2752053.92667785
  617202.03338212 1142988.09384157 1256177.03077501  985238.16352642
 3030974.08555399 1292872.02068339 1189869.88962053 1197482.77310751
 3528571.86546085 3144611.05841549 2669359.60686471  980300.5561762
 1002983.68431805 1762585.51578086 2935021.64888172 2407630.52150918
 1235824.16015493 3744808.44411582 2872417.20814749 1537087.4825125
 2535910.66035051 3082586.57017555 2831041.35393926 2566900.03459911
 1873139.86996754 2122573.18514738 1981167.17769474 2642819.24914224
 1693302.1218848   939876.19802404 3066690.6583189  2077982.0956076
 5602820.83455537 1394717.0919408  1801640.00414079 1869443.48475387
  570920.53645971 1814439.49357051 1237301.83209094 1437901.11432036
 2252357.05901667 1347307.14620924 2029965.84536336 1670888.22204078
 1958747.56552944  561313.94679946 1276411.74139198 1378009.19183249
 3749047.65225046 1093539.3354583   784572.2308938  1684621.53441608
 3079403.54529382 3085426.64893279 1775996.32040634  593627.10469594
  955013.24229534 2648351.22750197  775777.30969137 1505644.70548018
 1623935.05481011 1700324.85797567 3540769.34957646  878437.67945145
 1939779.14999207 3270208.23592426 1560557.04251592  525614.41466611
 1598964.58097739 2243547.61905745 1157520.67063487 1259388.19711298
 2486377.62529274  735566.03433007 1044456.05241039 2833119.95353797
 4132176.38983255  907706.54160308 2133265.35062007 2761723.33791343
 1288891.21483185 1456893.40470853 2082640.88502065 1015932.71956441]
2025-06-23 21:53:05 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:53:05 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:53:05 ERROR Can not run the algorithm
2025-06-23 21:53:06 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:53:06 INFO FeHistory: [187300.79068455 179350.69997471 166513.51125521 191126.13849392
 133702.38950672 124764.74698257 142190.82347069 208496.00336734
 140199.9814917  173078.49770526 159006.79159436 135535.96852828
 107141.19123129 104188.99307556 140629.94680083 125045.11272517
 127340.5631748  160768.9232389  175114.95536267 188034.01774132
 169225.58780389 180367.52046432 171650.33415801 201804.94498257
 187913.1583497  201222.35953101 168454.41586494 142086.52374665
 120036.62202129 149175.89804148 143337.05618402 210117.27533553
 134423.64312216 141432.57265785 137652.71831216 117762.08774773
 159822.32874864 106789.85097781 177647.9283549  150465.31794065
 113334.73033961  94050.05998605  85321.5416035  124069.37024005
  96454.20370462 148055.39003144 165122.59848174 215899.11606742
 136620.99925859 109986.0020534  196048.77136861 151027.96135712
 207619.67193546 147382.79735218 131181.57828    139391.85665524
 156957.46264513 202398.368694    90467.82167248 101326.10557795
 155855.91823978 202301.57589328 162996.52253284 181512.52358385
 118098.82414213 107746.70744332 178472.78704289 150653.63083068
 174537.14522726  96311.82653094 181864.35064146 183327.1685841
 160092.33579668 182392.08544147 153635.68913704 134022.31450927
 209889.93421109 162618.05670681 157574.78952279 143118.83081385
  94692.78130388 136449.69772079  95924.17325284 176970.39154385
 159215.77979638 101286.07619576 168385.08971287 172795.72212675
 161570.90266628 127069.26513724  96009.89332172 155680.46352381
 110129.52263026 204749.67964618 130706.24014239 140817.96995138
 182532.35182197 185485.16776626 150202.97306792 132963.00968624]
2025-06-23 21:53:06 INFO Expected Optimum FE: -5000
2025-06-23 21:53:06 INFO Unimodal AOCC mean: 0.1470
2025-06-23 21:53:06 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:53:06 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:53:06 INFO AOCC mean: 0.0490
2025-06-23 21:53:06 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:06 ERROR Can not run the algorithm
2025-06-23 21:53:06 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1468
2025-06-23 21:53:06 INFO FeHistory: [-183.31998665 -183.30748987 -183.35382828 -183.41076893 -183.38124574
 -183.33293471 -183.36202196 -183.42771257 -183.37698989 -183.3019924
 -183.32398838 -183.34865849 -183.39263509 -183.26128791 -183.40303035
 -183.37904689 -183.29852003 -183.44834589 -183.28000028 -183.32060513
 -183.35772381 -183.35531935 -183.27974698 -183.3492923  -183.31827442
 -183.30764788 -183.46070375 -183.38634285 -183.32802081 -183.39633307
 -183.32577639 -183.3641311  -183.31972561 -183.32598292 -183.35773574
 -183.31889839 -183.34626567 -183.44041917 -183.33412708 -183.39400552
 -183.35431732 -183.38618221 -183.39318549 -183.38322815 -183.30049664
 -183.36343625 -183.33293277 -183.36358663 -183.36653219 -183.29367098
 -183.3267603  -183.34409225 -183.37194056 -183.35088233 -183.37368239
 -183.32924417 -183.26366739 -183.35653828 -183.39699897 -183.2783528
 -183.3210615  -183.39495754 -183.37301522 -183.39864144 -183.33007073
 -183.35823261 -183.40156934 -183.33126634 -183.26822422 -183.2756385
 -183.29377796 -183.28222406 -183.34874394 -183.31377837 -183.33174968
 -183.40342903 -183.32563459 -183.34317541 -183.40559846 -183.28955191
 -183.40275875 -183.42408551 -183.32990106 -183.35470678 -183.35509006
 -183.31913299 -183.30537092 -183.28889923 -183.31085021 -183.34015385
 -183.34959286 -183.33884397 -183.36940135 -183.35704269 -183.35232364
 -183.36152969 -183.38537067 -183.35815969 -183.36021995 -183.28415743]
2025-06-23 21:53:06 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:06 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.mutation_scale = 1.0 # Initial mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall, self.best_fitness_overall = self._get_best(self.population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, offspring, offspring_fitness)
            fitness_values = np.concatenate((fitness_values, offspring_fitness))
            #Adaptive Mutation: reduce mutation if stuck in local minima
            if self.eval_count > self.budget * 0.3 and self.best_fitness_overall > acceptance_threshold:
                self.mutation_scale *= 0.9


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            "final_mutation_scale": self.mutation_scale
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Keep within bounds

            #Add a local search step with a probability of 20%
            if random.random() < 0.2:
                mutant = self._local_search(mutant,objective_function)
                
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])
            
            #Add a small random perturbation to encourage exploration
            offspring[i] += np.random.normal(0,self.mutation_scale/10,self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def _local_search(self,x,objective_function):
        #Simple local search (replace with more sophisticated method if needed)
        step_size = 0.1
        for _ in range(10): #Number of steps to search
            for i in range(self.dim):
                neighbor = x.copy()
                neighbor[i] += random.uniform(-step_size,step_size)
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                fitness_neighbor = objective_function(np.array([neighbor]))[0]
                fitness_x = objective_function(np.array([x]))[0]
                if fitness_neighbor < fitness_x:
                  x = neighbor
        return x
    

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fitness)
        selected_population = combined_population[sorted_indices[:self.population_size]]
        best_solution, best_fitness = self._get_best(selected_population, combined_fitness[sorted_indices[:self.population_size]])
        return selected_population, best_solution, best_fitness

    def _get_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]
        return best_solution, best_fitness
2025-06-23 21:53:06 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:06 ERROR Can not run the algorithm
2025-06-23 21:53:06 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:53:06 INFO FeHistory: [3623014.70134708 2088609.82964069 2518329.48700526 2371265.37485796
 2204500.04483345 2093178.73022843 2197593.28999425 1182144.92801286
 1003439.66561383  670892.76576364 2657954.36124899 2736891.48001873
  397250.20102684  930671.04200666 1139592.07506688  866988.26554877
  974162.29177564 3146455.89388004 3637882.48453493 1310232.25674834
 3322039.79741731 1122874.20498093 2027884.98702541 3078811.04597568
 1864334.12665603 1191553.60089212 1230610.40333175  666454.10047681
  285352.71657093 1077949.99415208  513506.01528354 1591722.92878224
 2402822.72635963 1477637.10958555 1181545.65798989 2561257.45624615
 2750725.83960839  759750.63229656 2114955.62287302 2771873.27478183
 1536035.34581488 7670863.76802434  928901.34721109 2695572.8009745
 3885170.06118346 1582917.57447569 1163879.04531797 1384513.85788375
 1982745.47929023 2335804.01804446 1919919.27907898 1981346.09294293
 1173573.18893116 1292891.90047523 1498581.62849452 1894435.25665548
  802186.84925325 1874077.82822022 3086847.97443266  447261.74581064
 2016309.1163793   831040.94891302 1919000.8499829  1545772.24592691
 1915257.97878839 1809872.36357198 2409328.60654375 1466941.64399839
 3255016.02600078  606980.74219591 1120309.64497103 3156151.95870167
  502423.64664817  922472.32812451 1277951.87219122 1611038.96487249
  527451.65824082 1531738.66241941 1926636.28298641 2769197.08897242
 1323116.98063566 3153152.35348977  574861.5533387   561710.94775987
 3902971.40479139 2718242.56981857 4389718.87848684 1416797.19319242
 2424875.54662745 1258266.6920666  2984400.167418   1388123.86516907
 2530139.55878525 2134393.15625419 1147470.78173021 1348427.33198114
 2568744.57175784 2534628.18474089 2545288.31909372 1978785.42597213]
2025-06-23 21:53:06 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:53:06 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:53:06 ERROR Can not run the algorithm
2025-06-23 21:53:06 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:53:06 INFO FeHistory: [187994.59040793 180963.25427646 112241.86162069 133028.45143374
 158990.77990106 216201.72305604 170850.77109247 127880.49099624
 108087.48795379 104920.66762512 168628.48811641 189349.28725074
 178041.51499888 158618.13615577 118658.85072592 151002.21566473
 125989.27234365 146730.18295322  85690.79627037 119848.39609917
 113293.51310553 122496.12194382 171736.17593706 186437.8194347
 198367.64463746 160135.26357037 161469.5666077  166433.17678547
 127848.20763443 186231.77723247 138815.5074978  165460.66607859
 197193.32850507 154438.64738987 190882.17616597 157770.60632677
 128044.68394546  88105.57714154 147859.94561647 122502.82973727
 125436.69546452 149270.42273636 120400.29541934 215982.82246978
 161094.53898309 129867.01097479 145976.00131872 136453.29168027
 155645.10276524 180295.26825465 205588.85818474 167277.25593262
 173056.39092207 135006.02499207  82793.35030731 238890.75470901
 156559.81245943  99318.24282007 131141.8761903  122917.172551
 183040.46431935 127909.1383122  113409.7116228  176937.89638741
 152715.3335536  113440.8035051  125912.75362056 119691.62441063
 138414.32488725 170553.99684835 149523.07432079 163881.80029279
 155854.8794172  167002.30493735 140835.12235832 206043.58378343
 143098.22871735 100384.59446275 112576.3519052  115297.21451358
 132668.21070854 141281.99175698 153077.06274176 176693.50925956
 152268.77113721 169654.05173062 118144.59712109 211503.91582535
 131715.65918965 125872.92334953 137413.39065167 128104.45603106
 153170.81044175 130199.12051096 156442.45683633 165929.01660297
 106491.43637112 231225.11354706 149650.01276258 215681.39969799]
2025-06-23 21:53:06 INFO Expected Optimum FE: -5000
2025-06-23 21:53:06 INFO Unimodal AOCC mean: 0.1468
2025-06-23 21:53:06 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:53:06 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:53:06 INFO AOCC mean: 0.0489
2025-06-23 21:53:06 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:07 ERROR Can not run the algorithm
2025-06-23 21:53:07 INFO Run function 6 complete. FEHistory len: 300, AOCC: 0.1469
2025-06-23 21:53:07 INFO FeHistory: [-183.34060138 -183.32617798 -183.26042247 -183.33584164 -183.30451397
 -183.34052665 -183.35958139 -183.32984119 -183.32705309 -183.34980331
 -183.37828559 -183.33000394 -183.42621141 -183.37753502 -183.32726366
 -183.31567987 -183.37445411 -183.30917916 -183.40890695 -183.35080888
 -183.39644022 -183.36350472 -183.35162513 -183.31753789 -183.30574352
 -183.26769916 -183.33414771 -183.39708029 -183.300378   -183.34131991
 -183.3601605  -183.34970436 -183.33818828 -183.32778817 -183.33452888
 -183.36695332 -183.33639531 -183.30043809 -183.31986126 -183.39522948
 -183.36124258 -183.32552942 -183.35400027 -183.3730921  -183.39098978
 -183.33203359 -183.35124305 -183.37922379 -183.40258642 -183.27962188
 -183.45160055 -183.28067818 -183.32535687 -183.39342925 -183.26638365
 -183.32390434 -183.42995663 -183.45976082 -183.33739096 -183.33735003
 -183.36952966 -183.30977708 -183.31245952 -183.38643537 -183.38557107
 -183.34606558 -183.29338317 -183.296982   -183.29720298 -183.28995109
 -183.39876962 -183.31331174 -183.31235273 -183.33275571 -183.33299771
 -183.30004855 -183.40653315 -183.39617754 -183.34744514 -183.40713396
 -183.37634357 -183.3232122  -183.31887052 -183.33422253 -183.3716882
 -183.31914289 -183.38758328 -183.40647514 -183.42112209 -183.37764293
 -183.37775421 -183.27546327 -183.42601885 -183.36858907 -183.26477579
 -183.35204067 -183.37048675 -183.33960409 -183.38163827 -183.41105744
 -183.35005249 -183.31859323 -183.39236436 -183.3359014  -183.33582793
 -183.26572255 -183.26376479 -183.30298143 -183.31196975 -183.34031917
 -183.3071414  -183.34743484 -183.32782766 -183.2866997  -183.46546743
 -183.28091222 -183.21573116 -183.33264281 -183.41146042 -183.312352
 -183.29776542 -183.2579059  -183.31128052 -183.30515031 -183.38783887
 -183.2943576  -183.30952237 -183.31194251 -183.39337866 -183.23313365
 -183.30541249 -183.23904605 -183.31399964 -183.26183126 -183.36205959
 -183.28477028 -183.3435109  -183.39097995 -183.38261458 -183.36323223
 -183.27142815 -183.31712452 -183.33647806 -183.24124571 -183.29950259
 -183.37106221 -183.32942085 -183.34372086 -183.32311686 -183.34557916
 -183.36565189 -183.32821125 -183.25800411 -183.27435916 -183.34731031
 -183.22227592 -183.30591741 -183.28501175 -183.38535341 -183.25857413
 -183.32977051 -183.35219656 -183.32951941 -183.28411408 -183.31751029
 -183.33126675 -183.36059268 -183.27487134 -183.2710308  -183.315845
 -183.31002513 -183.3125017  -183.27058642 -183.37537417 -183.31006728
 -183.29531308 -183.20472328 -183.32052995 -183.41874444 -183.27230613
 -183.2753965  -183.29809003 -183.40186218 -183.29489237 -183.27299422
 -183.29654454 -183.34578371 -183.28053325 -183.35228998 -183.44191741
 -183.34972773 -183.33163513 -183.35436548 -183.23884943 -183.40024647
 -183.35310032 -183.25556344 -183.30155094 -183.41986583 -183.28612758
 -183.38407582 -183.29050006 -183.35385025 -183.31254637 -183.34891483
 -183.35279556 -183.27280635 -183.28484121 -183.37861163 -183.27700938
 -183.2904294  -183.29911564 -183.32456777 -183.46213021 -183.32322744
 -183.36917328 -183.31802174 -183.3213058  -183.32076739 -183.35336256
 -183.35167347 -183.33361944 -183.26195938 -183.35712141 -183.42603553
 -183.29061    -183.33789639 -183.34634754 -183.2457009  -183.28617932
 -183.30469972 -183.41335583 -183.31452904 -183.35560953 -183.37628457
 -183.28357829 -183.29919146 -183.40004539 -183.3659805  -183.33022368
 -183.33511395 -183.32979164 -183.29858834 -183.30800113 -183.29452746
 -183.33895179 -183.41055461 -183.32882135 -183.32274132 -183.43314092
 -183.31128394 -183.31364384 -183.30221771 -183.34130809 -183.26430251
 -183.4093334  -183.39270347 -183.30899974 -183.31058428 -183.2637783
 -183.33359317 -183.36418463 -183.34550955 -183.29029873 -183.27514186
 -183.38209146 -183.32269158 -183.37891579 -183.33908447 -183.30085003
 -183.34110483 -183.32843295 -183.34624416 -183.40127024 -183.39103417
 -183.39145841 -183.35703753 -183.32324168 -183.3016502  -183.29278379
 -183.29753538 -183.28758766 -183.37901905 -183.31713259 -183.39698903
 -183.34504933 -183.33315158 -183.31246835 -183.28575036 -183.33468908
 -183.27121909 -183.23699894 -183.35818943 -183.36219138 -183.35961809
 -183.35738651 -183.27946553 -183.32041389 -183.33520583 -183.33002028]
2025-06-23 21:53:07 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:07 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Differential Evolution crossover rate
        self.mutation_rate = 0.2 #Initial mutation rate
        self.population = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness_values)

        while self.eval_count < self.budget:
            new_population = self._differential_evolution()
            new_fitness_values = objective_function(new_population)
            self.eval_count += self.population_size

            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, new_population, new_fitness_values)
            fitness_values = np.concatenate((fitness_values,new_fitness_values))
            #Adaptive mutation rate adjustment: increase mutation rate if progress is slow
            if self.eval_count > self.budget * 0.1 and (self.best_fitness_overall > self.best_fitness_overall*0.999): #Check for lack of improvement
                self.mutation_rate += 0.02
                if self.mutation_rate > 0.5:
                    self.mutation_rate = 0.5

        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_mutation_rate' : self.mutation_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self):
        new_population = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

            #Clamp values to bounds
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            trial = np.zeros_like(self.population[i])
            for j in range(self.dim):
                if random.random() < self.CR:
                    trial[j] = mutant[j]
                else:
                    trial[j] = self.population[i][j]

            #Add adaptive mutation
            trial += np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
            new_population[i] = trial
        return new_population


    def _selection(self, pop1, fit1, pop2, fit2):
        combined_pop = np.concatenate((pop1, pop2))
        combined_fit = np.concatenate((fit1, fit2))
        sorted_indices = np.argsort(combined_fit)
        selected_pop = combined_pop[sorted_indices[:self.population_size]]
        selected_fit = combined_fit[sorted_indices[:self.population_size]]
        best_solution, best_fitness = self._update_best(selected_pop, selected_fit)
        return selected_pop, best_solution, best_fitness

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]
        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution
        return best_solution, best_fitness

2025-06-23 21:53:07 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:07 ERROR Can not run the algorithm
2025-06-23 21:53:07 INFO Run function 13 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-23 21:53:07 INFO FeHistory: [1680565.5806796  2525839.32414932  929368.7854418   422839.83442495
 1782569.43888277 2683342.33796264  943756.40656556 1519710.40471834
 2178259.59607336  763839.62704073  458285.79076992 1013552.58714981
 1576115.17571857 1626537.69383328  743847.52496036 1751563.14740012
 4410791.3151152  3234624.13219375 1851744.26584171 1020974.9618049
 2202588.08670007 1293070.96204516  981241.90062     469636.91311743
 2474766.64381007 1323627.86152927 1398886.04531015 2352302.39927927
 1392785.70198293  665923.82286674 2321063.49133412 1736125.84648537
 1546035.35817632 1072941.94345063 1130258.78130001  706336.87422293
 1264541.63003655 4325350.24096699  639234.12777609 2941648.4714174
  968800.75847803 2115181.47048583 2902715.59369473 4334264.10919529
 1028095.31599239  940117.77521703 1162082.76814437 3244905.6335398
 1222190.70851496 1382703.49246375 2378661.15400429 2500036.84279405
 2729570.20404243 3174906.98634575 3180712.35857899 2038693.98140135
  265692.60628413 2186087.05469192 3384866.27220345 1661766.848208
 2042312.87957679 1191655.78752532  877390.52918251 2802322.2199943
  696120.19849967 1074224.53665665 2004660.72965058  993736.49571947
 1839334.71647311 1785121.27101497 2393262.99122059  886035.11224543
 1740726.66099578 3577137.60786023  995965.96934095 1172013.59015206
 2875839.71964871 3542106.46880122 1190461.63610044 1663883.08746101
  726544.45486435 1759409.26410318 2731065.47106234 3514295.46988278
 3985269.3846819  2727002.74336699 2137949.16225168 2324909.29859797
 2570949.70957206 1712841.43419866 2272904.87425764 1418036.19480967
 1299663.15941211 1993700.77030545 4881861.80200321  777510.3222171
 2138965.41945166  786765.09634401 1268401.13186011 2010516.99009032
 1134861.31754725 4016966.90526969  918620.30462015 1617345.91822528
 1120493.94591921 2323227.29648331  749815.51346901 1113983.57969219
 1298419.90009018 1599192.59130445 3379698.97826602 2746690.10920944
 2892270.3744525  2752836.0309513  3309301.67000399 2222852.2602849
 2661065.99698375 3609336.76151551 1794558.94882555 2350998.79306247
 1569999.56606357 2211462.33679634 2301818.67730551 1690513.41179892
 2632770.10087681 2418754.03423724 1885660.7003407  4359946.05329431
 1937541.20623476 2033304.36718807 2858552.71054769 2364247.31679548
  738577.90376982 2391578.22926226 2290561.41824718 2228494.75232568
 2581886.0517131   490571.89572191 2356616.99685006  465601.23387353
 1675504.80814808  936252.19743385 1231125.26122007 1595947.114065
 4009014.39499919 3989195.0755832  1392088.08252616 4328116.30383556
 2595405.89094792 3412758.36473972 3976972.15011233 1433318.55607384
 1274786.10258639 2205085.11492401  642103.90653149 1632210.40291584
 1249519.30550965 2859704.53128481 1696387.74688886 1370802.80828272
 2336510.83889387 2195582.38895754 1723784.39505854 1817564.38679669
 3752278.82627482 1290068.50337705 1357770.00679584 3032190.39027935
 1642291.27442333 1524125.47280489 2001735.5926255  4594331.64749998
 2995831.79335005  983544.74778921 2080698.60129774 2343573.89623341
 3240467.8458528  2591487.4055546  3056950.30888473 1514962.43617036
 1347899.00305648 5578766.59692302  803975.37578118 1356388.59628512
 2779511.15347655 1219757.86110653  842663.97394102 3080689.42130889
 2996284.08940102 1468823.11438228 2047915.07620102 1878792.99467249
 3963603.20715085 1739376.22344276 1569599.98490913 2777109.07357028
 3682125.13944989  745493.51751162 1643039.27659451 3880983.06067509
 3988198.95787069  868822.3513117  4367289.19996081 3039420.94884252
 4929784.91359322 2496863.73853573 3628337.59345883 2738069.67156089
 1176367.08850689 2715587.93674568 1314155.13864081 2966292.17886569
 2052492.69681589 2062943.55926792 1962610.47755357 4259241.62397708
  749236.75368724 3651226.84649179 4943093.32706378 3980073.59607804
 2477634.07153096 3120075.87773517 3115071.88968231 2483844.83731949
 1052771.81854646 4550071.29646535 3821256.74916428 1849381.24941209
 1707596.53462158 2215736.09909467 1713193.88788075 2079058.28340705
  916628.3104551  2042815.32495169 3437073.72707641 3466342.38014084
 2453821.44905751 1700850.80246148 2631813.60942746 1888531.10466487
 2564362.93772041 2424492.25006205 2286924.91119948 2038349.05509449
 2353514.70813128 1983682.42073478 1446380.78297323 2074942.09923979
 2350846.04358205 2645764.73690727  688998.62418666  696182.36212979
 1033278.34519093 2193521.66157398 1526370.02299766 2693079.44481704
 2904916.65802935 1862332.95296335  978412.26376843  612719.78524991
 2461048.11194845 3792421.27902956 3159043.97608121 2344364.62235763
 5154365.53382505 3921073.59881255 1995147.2559266  8383312.97994313
 1822571.07042566  780864.84679046 1217198.99637376 4949530.71516015
 1587576.1441804  1687853.84526992 1800578.91628869 1714612.64497042
  611968.34822682 2156088.493182   3164432.13069771  628109.37333325
  824862.11937892 3434861.66423549  853710.78348873 1962667.47760609
 2414430.87630618 1007545.25679229 2236912.2548183   813264.21938535
 3905445.98156519  679232.19549452 3981339.91313411 2443818.90107444
 1178107.47093491 2579877.46917809 1744015.1259295  1575775.28858849
 1940733.22448562 2431117.11371021 3434422.38274256 2084129.4056632 ]
2025-06-23 21:53:07 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:53:07 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:53:07 ERROR Can not run the algorithm
2025-06-23 21:53:07 INFO Run function 18 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-23 21:53:07 INFO FeHistory: [123526.65535835 180890.72841752 122589.6500329  120547.78686797
 169492.20776328 186939.81625747 168586.85980847 207880.81039926
 158609.37663851  95177.28156262 112853.39560982 133820.43991438
 104760.7876057  227956.91710604 193691.58561996 166732.66767773
 145930.54221404 189571.13723019 176230.81276851 162392.42080608
 151102.93470403 166164.06925358 100937.47803237 144374.65872315
 134244.63521123 117266.34889189 149994.86846096 106102.33970882
 132202.56595885 159864.25823203 152934.59179047 152587.33289441
 119943.19337859 139015.82874037 173278.4869839  188015.83456564
 123913.4013997  124317.2326322  146118.83319822 193882.92706303
 239478.43005667 133016.90313044 123161.52613288  91619.03262813
 166276.24142756 118910.26725956 148170.90477381 170357.41004221
 181862.37578324 129527.7456931  151891.51731242 174011.32790745
 147928.69539906 209459.60251177 203260.88167534 120208.32266271
 241159.09363731 109218.92136395 194804.678986   101908.95403128
  84802.38232336 202161.39626409 182077.31987372 174214.84090987
 142629.39301404 158485.54258069 113815.52774162 220322.66589703
 128007.69148262 161828.140229   147452.41135766 119838.31923067
 142404.48597515 168722.47729945 160463.56396817 141682.53731129
 130768.25630183 160222.39149403 165995.10496257 240600.11781581
 223187.08365562 168551.57291071 167928.85651493 147845.32108162
 110772.77885514 106722.06593303 132902.19459495 130489.02820217
 162681.61580892 115241.74016172 111133.54730298 120413.49014731
 222738.13193676 131715.8492289  110788.10877036 119113.92495059
  99907.10133927 208884.43577997  93046.95392107 128665.79867787
 193942.74059822 184523.63892737 238737.47436495 157039.01242352
 140459.05976037 110048.5667958  206228.4370894  195005.95570874
 220361.23101864 224890.35290052 152164.16999347 159675.81310797
 116185.838863   191083.41848775 179983.07547234 227271.86229329
 276396.54066863 236673.12346741 146490.62399655 227419.41742431
 167285.68133569 192366.62313206 106946.25203755 152605.91694038
 211626.20292919 169749.46847348 143059.55870583 189558.65754848
 137803.48966114 183272.12748208 197825.96806048 189989.2118404
 164434.57223797 145205.92485192 264588.90746328 231860.02624108
 205394.23292746 222332.57426486 172999.96094494 145732.72010231
 208255.46534686 217519.53266668 153150.70711394 192778.00256555
 128461.14412726 149899.76162867 143587.82112549 163344.71616599
 195421.7763603  191966.1227078  159576.00778575 186498.74478417
 150611.98354855 193731.03373045 275298.44103966 112414.34628386
 172763.08894688 134354.93806306 169763.30896868 194107.76503371
 173173.27511962 186445.68545888 212122.00880597 157048.99582021
 162377.80298199 147577.5823951  176060.09748908 218468.6806152
 172565.91620063 178614.42461855 208562.66564339 177037.50030205
 188512.4147464  177869.97830917 252110.70871048 172691.55139505
 244043.91742613 197531.8537891  178717.10266896 189172.30489142
 207631.98101146 238656.0050034  131868.943494   191189.20830349
 158124.57519939 137775.19251875 175600.34889219 184759.39670796
 198245.87406347 188763.75019105 162482.17814964 166577.06074094
 134845.59839455 237405.88458954 185796.03116622 127995.39772165
 170853.90600076 142422.40085799 156148.36530845 174249.82586895
 104965.68962954 163862.75703303 205856.95492674 163113.00723938
 194971.52225132 148529.34386132 185780.76951601 236190.88705048
 203591.86691324 230821.86246417 192602.82234777 112047.95318009
 201417.73617719 277632.76045365 228899.04694685 173045.2197898
 168342.31157589 181814.92849914 162495.3252496  250732.31901612
 178201.32161651 270868.11739998 162117.36956601 141901.71595535
 153935.98169824 181088.18408124 155822.05908498 170661.32660572
 276996.44722638 165573.54473251 145825.8659109  273471.25994966
 115779.49517163 158488.31616947 153829.80900043 202828.06250405
 195994.77801613 170160.87796736 122392.73968723 158635.18557907
 205619.89891268 253864.17365465 227610.91120193 140964.5122129
 239553.76722683 146729.27544365 149248.89531636 276623.54609656
 268814.56431667 189450.89968801 192448.80817026 179878.22816466
 241948.08370379 156647.53679492 148903.35473949 217633.22327315
 185967.33814301 194245.23050513 185141.8517702  250396.51346589
 229204.63750307 158056.51368329 231560.31667553 209506.30647817
 157220.41271203 231490.96623204 165521.52783628 156619.82309901
 156522.00875876 293789.39550292 210340.91739107 193597.07144983
 155192.89029381 196358.18775693 244705.64749691 155143.12054358
 185506.81496473 171557.24567307 198493.3356937  176236.55494259
 166974.20613885 141028.0108336  251098.10640751 134327.48301245
 168872.02677795  99901.16923951 184238.02421112 174471.27476258
 185943.89676095 194219.07607368 222672.86865614 149791.37083371
 167399.70608693 168683.97441163  50256.17924701 224070.39148975
 187596.23463924 117960.09436985 300841.89497665 131581.0560568 ]
2025-06-23 21:53:07 INFO Expected Optimum FE: -5000
2025-06-23 21:53:07 INFO Unimodal AOCC mean: 0.1469
2025-06-23 21:53:07 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:53:07 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:53:07 INFO AOCC mean: 0.0490
2025-06-23 21:53:07 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:07 ERROR Can not run the algorithm
2025-06-23 21:53:08 INFO Run function 6 complete. FEHistory len: 300, AOCC: 0.1469
2025-06-23 21:53:08 INFO FeHistory: [-183.36632564 -183.28702764 -183.36798339 -183.33297014 -183.2869448
 -183.36833473 -183.36556123 -183.3701682  -183.34087993 -183.31841337
 -183.34329547 -183.28910771 -183.37378615 -183.2695367  -183.39731911
 -183.30378909 -183.42087342 -183.31530521 -183.34975051 -183.38198401
 -183.42160527 -183.37199629 -183.28091474 -183.34887978 -183.30467726
 -183.31911584 -183.32111022 -183.27646975 -183.30064337 -183.4380143
 -183.34060999 -183.34186226 -183.28041108 -183.37972989 -183.37551158
 -183.35309151 -183.43122003 -183.36784851 -183.32540591 -183.35962601
 -183.42971985 -183.30337563 -183.30813538 -183.25182223 -183.36831509
 -183.33516733 -183.43012997 -183.455626   -183.36259611 -183.37516105
 -183.38161295 -183.31798588 -183.37157241 -183.28241808 -183.30826755
 -183.32701586 -183.38751519 -183.33625052 -183.37509243 -183.32020937
 -183.37563246 -183.34713143 -183.38917626 -183.33547426 -183.34885327
 -183.32072149 -183.4391588  -183.33321008 -183.28981133 -183.33736846
 -183.33491751 -183.40751899 -183.35213786 -183.30362059 -183.37095399
 -183.32544246 -183.33599908 -183.3796352  -183.41893706 -183.40740732
 -183.40274263 -183.40063076 -183.38938594 -183.34466236 -183.29268466
 -183.38204847 -183.4241058  -183.38491444 -183.29642211 -183.38116273
 -183.42798058 -183.34754345 -183.43426298 -183.36171099 -183.42345124
 -183.30886547 -183.40068038 -183.3597352  -183.26972689 -183.34341584
 -183.32641072 -183.32664877 -183.27905735 -183.27454879 -183.29567324
 -183.37744515 -183.24336135 -183.31261715 -183.31831466 -183.31620122
 -183.30286753 -183.32500082 -183.28495152 -183.36530231 -183.34760258
 -183.35067615 -183.37096717 -183.32764046 -183.32678353 -183.36425678
 -183.29039695 -183.32822716 -183.31346924 -183.34745358 -183.3412215
 -183.313326   -183.39053794 -183.28790598 -183.28319257 -183.29099335
 -183.31386958 -183.3545086  -183.28941995 -183.30155837 -183.361262
 -183.35165355 -183.3377267  -183.40083283 -183.3332748  -183.26864707
 -183.31889207 -183.33754292 -183.27314751 -183.33866026 -183.37232601
 -183.33598972 -183.30287831 -183.29387856 -183.29286012 -183.31910835
 -183.28668563 -183.24865914 -183.26702079 -183.40061271 -183.33189297
 -183.28990034 -183.34189967 -183.32964595 -183.31315252 -183.30977544
 -183.36207941 -183.3176833  -183.31199453 -183.35519032 -183.29289464
 -183.25430678 -183.35542584 -183.3277261  -183.28025013 -183.31653223
 -183.32835373 -183.28061854 -183.36879915 -183.24493635 -183.35137173
 -183.28934669 -183.33741008 -183.28550089 -183.35434041 -183.28340273
 -183.33992187 -183.38479358 -183.31849165 -183.26862173 -183.29386691
 -183.31025174 -183.37132743 -183.35413179 -183.26940621 -183.39489573
 -183.24673109 -183.28692081 -183.37856685 -183.316591   -183.3216966
 -183.30185967 -183.31183502 -183.26813105 -183.33176924 -183.3212444
 -183.33918304 -183.28849234 -183.31330054 -183.34217537 -183.33525911
 -183.30676089 -183.38885017 -183.34419592 -183.291174   -183.39568258
 -183.29044656 -183.31348645 -183.44070351 -183.27962884 -183.38609057
 -183.33139778 -183.36754264 -183.33878757 -183.31052263 -183.30405841
 -183.25776247 -183.34127747 -183.46507914 -183.31241471 -183.32067361
 -183.35065413 -183.38246529 -183.34009249 -183.28859837 -183.34743468
 -183.36065866 -183.35206941 -183.29309921 -183.35299387 -183.387122
 -183.26378487 -183.36375872 -183.34973611 -183.31504277 -183.31964934
 -183.35692171 -183.34175228 -183.36074813 -183.30396349 -183.2655969
 -183.30928553 -183.37460324 -183.3189481  -183.40875987 -183.28852864
 -183.37558546 -183.33896095 -183.36239455 -183.34368677 -183.2580106
 -183.2769711  -183.33154517 -183.3003227  -183.34516322 -183.33345996
 -183.36877528 -183.22485762 -183.39235956 -183.31327566 -183.31801285
 -183.28731423 -183.33850938 -183.37450131 -183.36807958 -183.32979654
 -183.430436   -183.34737497 -183.303275   -183.28056178 -183.31561229
 -183.37944016 -183.35151948 -183.31477528 -183.39909678 -183.27608468
 -183.28461686 -183.31885291 -183.3251737  -183.34400898 -183.37279733
 -183.2956336  -183.34642    -183.30987944 -183.34353297 -183.28001746
 -183.27571443 -183.27269007 -183.32072715 -183.30229186 -183.32201067
 -183.26228465 -183.31832246 -183.31565806 -183.34491201 -183.25751675]
2025-06-23 21:53:08 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:08 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Differential Evolution crossover rate
        self.mutation_rate = 0.1 # Adaptive mutation rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, offspring, offspring_fitness)
            fitness_values = np.concatenate((fitness_values,offspring_fitness))
            self.mutation_rate = self._adapt_mutation_rate()
            
        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'mutation_rate_history': self._get_mutation_rate_history()
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
    
    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            v = self.population[a] + self.F * (self.population[b] - self.population[c])
            
            #Bound constraints
            v = np.clip(v, self.lower_bounds, self.upper_bounds)
            
            for j in range(self.dim):
                if random.random() < self.CR:
                    offspring[i, j] = v[j]
                else:
                    offspring[i, j] = self.population[i, j]
            
            #Adaptive Mutation
            if random.random() < self.mutation_rate:
                offspring[i] += np.random.normal(0, 0.1, self.dim) #Gaussian Mutation
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
                
        return offspring

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fitness)
        
        new_population = combined_population[sorted_indices[:self.population_size]]
        new_fitness = combined_fitness[sorted_indices[:self.population_size]]
        
        best_solution, best_fitness = self._update_best(new_population, new_fitness)
        
        return new_population, best_solution, best_fitness
        

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]

        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution

        return best_solution, best_fitness

    def _adapt_mutation_rate(self):
        #Example: Simple adaptation - increase mutation rate if not improving
        if self.eval_count % (self.population_size * 5) == 0: #Check every 5 generations
            if self.best_fitness_overall > self.best_fitness_overall:
                return min(self.mutation_rate + 0.01, 0.5) #Cap at 0.5
            else:
                return max(self.mutation_rate -0.005, 0.01) #Cap at 0.01
        return self.mutation_rate
    
    def _get_mutation_rate_history(self):
      # Placeholder for mutation rate history - implement a logging mechanism if needed.
      return []

2025-06-23 21:53:08 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:08 ERROR Can not run the algorithm
2025-06-23 21:53:08 INFO Run function 13 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-23 21:53:08 INFO FeHistory: [ 858718.33427348 2668949.38580251 1848011.92784056 1430924.44952685
 1648577.52110842 2331693.55289343 2268070.24472142  266967.90266083
 1500792.55868315 1136327.4310432   817854.90378892 1060783.28037624
 1933028.93143423 1111022.96004884  605931.3822464  1220676.34358077
  798967.30353694 2667157.64762682  921945.98665376  679800.23302405
  870491.4764972  1319475.38824294 2575830.01902777 1115434.60087287
 2673410.60145422 2844481.58645515 1710566.46265239 1316793.61188413
 2219275.40095241 1700290.65233039 1484592.45938     673496.41248966
  867923.59942892  659887.21168596 2578260.48363614 1795669.16350823
 2121260.35290637 2989453.02342409 2050991.92041981 2037530.38892213
 1690574.1965956  1676789.00347948 1830368.1364793  3273851.770936
  128917.06625192 1503900.45940257 1815768.96777147 1253045.50116387
 2854110.78646342 1015670.00112732 1583805.44153372 1150470.02121119
 1434870.4562419  2693489.74389988 1770626.72627798 2345236.57756001
 2807514.42370375 3041890.27342116 1353809.62625508  365591.73945832
  584167.97260292 2071664.00149083 2108100.26261915 2754885.05142187
  621224.21732382 1192047.05006917 4170353.96506499  550703.63522379
  952320.0042326   638361.87662577 2169887.00093118 1726552.95209973
 4146409.38992268 1108847.83285147 3296571.04521711 2114279.77834453
 2070112.32982898  424431.36660213 3398488.11699586  890604.85201946
 1556244.52713514 2691523.95191116 1166446.86730298 1611723.43611132
 3192265.95293638 2536928.81338803 1859435.66171098 2125134.32495159
 1259938.84750345 2609015.72965505 2367318.19459432 2375769.72818756
 2659027.18692775 3969772.58555698 2015963.86092016  884035.76654909
 1089344.21219148 1657883.80351703 1863334.93178522 1449763.64577156
 6819440.61584294 1224833.58620987 1912765.24382255  686283.2392006
 1488506.99956981 1958011.5351288  1185270.76381017 2211975.35223078
 1868766.74317482 1685736.99102489 1013090.64624577 1898221.79273692
 1929615.82550056 1032562.67740174 1992239.39761683 3139465.14605575
 2713817.71340267  652117.77659772 3151409.54712977 1292787.64831043
  426114.79540127 2438476.52166405 2349937.29675545  644978.88177375
 3423158.23766412  921365.73466484 4088437.49155027 2630088.0178713
 2670168.21057389 2716441.20714283 4688028.58962628 2767275.47343703
 2829264.04389643 2909611.34828557 1713221.17961928 1479188.42608096
 1515949.10423147 3176372.18648595 2731054.97086584 3601991.32359832
 2922404.90031696 3477235.07642712  424095.20835801 2957371.48931851
 2538295.15925813  699213.74017026 4259621.11127094 3865586.68882879
 1041208.95644185 2631364.96110633 1610947.06373719 1898769.11143809
 6676604.82736527  858161.52575473 1483550.48586488 2793485.44708806
 2158710.57252035 2533499.25526869 1283536.83238831 2980073.79754228
 4013289.30020222 1574835.24583054 2922043.77740077 1224960.29104385
 2431318.42654835  765527.05928855 2482216.93532416 3275445.15365082
 3505985.21008652 1304542.70218898  540384.58281637 2370067.72612661
 1575795.19891592 2784909.10778299 3490244.66941744 1542395.44182479
 3913266.19239261 2099660.5447359  2261057.6470479  1928646.1471635
 1308531.52239663 2957721.62255767 2103458.31498794 1591050.73119377
 2179882.4618202  2955998.81015374 2217565.73552117 1082572.08494405
 1750804.33981553 1609294.13023287 3277374.75832673 2186063.44052239
 4144251.76452024 1903413.14247854 1811361.57017385 2862037.4717194
 2620680.26905904 2427569.38399348 3906813.25842646 4207727.65136857
 2701287.12411918 1976829.73315177 3139075.37486092 1869817.12061
 2947489.64138909 1116125.4364671  1831700.56705471  849003.15341128
 1631339.99277066 5411955.76278163 2539038.54136987 1239512.5978766
 1676876.83745554 1489176.07522788 1591494.5348038  2300432.55104688
  763274.07975991 3299097.41254677 4005193.80676007 2544992.87358013
 2438907.69951232 3411619.33732681 1447787.31909171 1976008.2128494
 1727274.57016666 1321506.49071835 4454672.05433865 1315156.88046728
 4908893.00478174 1873388.08452693 4119120.17726177 1400309.30161496
 2139915.30412471 4638573.99100352 1457101.24450893 2049269.42735685
 3786316.52517647 1308324.17582953 4550271.58472771 2030373.65656551
 4613209.87761919 3021754.32276362 1377551.18712175 2034712.23861593
 1317386.04708532 1406836.24679436 2434680.25550461 1195849.04824558
 1864737.70622709  580229.2612238  1144394.28376816 1972841.64969169
 1477346.30135546 2922916.7272388  3759503.3477077  2993980.92124727
 3817602.44413178 2036517.44995123  753904.89822896 1165622.945218
 2487783.79084474 2280561.67991167 4385241.63050246 2637841.57121547
 1783554.3558401  2736366.42408751 1418222.63182343 2599416.34364121
 4052751.72179271 1998367.24780314 3795911.838675   3225451.1615171
 1695996.71206897 3823344.02951979 1674365.3508988  5103976.80107007
 1638261.06381326 2406085.19004475 1299946.83765071 1926648.24632629
 1637990.99945958 4791454.76359579 1282554.36268985 2619924.57640639
  857679.85007752 3136155.76067373 1188653.74292558 1789735.63990799
 1870799.1815152   977399.97004365 3270816.88749317 2752535.78793612
 2195975.57153996 2734924.35042937 4136735.63364428 1179906.75066265
 1494808.25701449 1990895.07352424 1775555.50174584 2527854.17333442]
2025-06-23 21:53:08 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:53:08 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:53:08 ERROR Can not run the algorithm
2025-06-23 21:53:08 INFO Run function 18 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-23 21:53:08 INFO FeHistory: [154211.68037879 134985.62757665 153391.79046478 150269.432088
 196754.85215072 184447.24931565 116210.82592723 124978.40033479
 124391.91750545 131644.04101186 137740.6173207   98136.53091547
 149819.61362176 141150.48431784 138844.01469745 133636.54498748
 136289.54874085 118736.33212413 186675.49280672  87743.40759018
 156722.71106305 171463.44144051 158445.72459354 114197.38446319
 176754.15840536 107963.86017592 207924.21534533 126156.14716676
 102017.53359711 188972.83236337 128045.38965519 132358.74799725
 125108.19134719 121878.85171794 109865.27827934 119760.98754419
  98507.65410373 135981.13844383 175525.3158791  174545.47829979
 200438.20216619 132229.86845668 190625.09975988 182110.44160689
  99051.10309865 135424.1987239  157726.6551055  158599.19127577
 167312.32344824 162558.31636527 101594.32416222  91476.40633489
 109260.35787802 221308.74083938 171906.27150779 118033.2452278
 129649.1426619  185989.21513371 127167.74896594 143465.16453372
 175404.31016719 191181.19461319 218055.05236833 146166.204893
  89687.20232103 155430.52257291 152433.79159599 129769.0659752
 120441.31437197 109722.02834777 153599.18836986 200317.2124432
 116070.92333362 158627.23322293 132893.38194174  84162.94193742
 100644.31779607 139218.34636441 189218.19419877 166709.76421253
 115695.91744918 170630.93608109 156918.70797887 151976.84082261
 199837.36412028 153718.42104955 128570.99022291 204293.41422478
 175515.14833029 132706.53019986 222480.55275302 160182.28407982
 157009.39921665 224236.23425533 123265.0139513  179456.44105145
 162080.14729316 200771.03504581 187130.19732649 119179.99868465
 181983.89631005 229107.00415746 166774.45567429 259608.59682819
 153438.62968276 177382.35520343  93333.71353633 221074.19932452
 177778.10082493 312802.90789033 313960.14034245 134519.74346648
 181197.47550529 194162.11694164 135850.22636876 169858.54520036
 202331.19540907 189813.15387656 207535.24204094 204786.68422031
 159300.83123543 183800.00771023 214227.90127394 137917.74321246
 131963.86880885 176771.93639506 167612.84680051 157325.05212639
 236141.45660928 235910.678998   139674.47588212 192944.76672569
 100373.71756947 160780.86134253 213903.41638862 264621.78077142
 189302.77260406 185669.26503009 296487.97869487 209859.09081947
 185512.66087381 199627.96452618 182178.43193943 184206.17654112
 181321.63621926 126360.93473725 160231.0512131  134367.27795168
 257132.10441982 222650.56949134 183489.42598816 264392.57629662
 163111.15695694 270905.30708813 132252.28831607 210585.4957826
 253575.58634439 151866.884462   220963.34558021 230890.94500411
 200505.144738   179430.78646749 355644.68331447 213814.1612629
 190045.09584643 189851.57439216 197885.54845392 149080.28910865
 101019.0987152  157995.71024144 270006.6374509  194741.43845482
 163976.14505502 187026.86493732 190266.21488547 287624.27876138
 202681.81147503 139504.09213446 268348.01996807 218550.26223263
 205575.15176675 211018.43468593 175907.86521172 237952.21949898
 142105.2890958  279755.94580499 135964.1949963  199843.90937332
 160481.95045123 170928.36042142 184050.32411195 192396.30029491
 167850.43365202 217596.19354127 148970.60852785 175466.73470943
 125538.8858164  134769.56873932 307663.32651451 227641.87915179
 233006.24289789 229944.18030497 236667.35457479 261211.77296916
 216219.1695677  133031.23591541 191056.93775192 129777.90565539
 139797.48204366 255290.31384291 230414.95310773  82663.1471637
 196952.63159523 148736.02372201 171267.29813874 170861.31561926
 121399.72536919 206821.91859946 168910.68854044 216447.78162825
 180433.0228187  220607.35495932 182599.75560139 181265.1463122
 163633.22882979 163022.65317167 162552.4467568  140046.37909532
 174312.94109131 255415.2812556  196174.86521649 198841.92637684
 158635.91694971 142557.08718259 292229.82159461 138361.82283746
 215574.43798577 161051.67901922 254742.40554747 237706.97333435
 182397.78396057 233865.90312806 172024.10928865 188710.7452026
 141697.70957735 211669.54330114 212279.29830941 232138.75009165
 205801.55796701 156698.25270864 124390.82356927 138919.72937564
 103386.20041861 137447.03854528 210224.51943171 252200.08839275
 106977.75609564 243608.30617214 192975.23380016 225846.46564499
 144034.61043938 221317.8451091  143231.61004168 179189.85305287
 119809.20690146 243159.90637474 233481.00176724 208392.34078323
 208876.75629774 150935.58497882 163851.49201675 140739.93625071
 229682.57725512 270244.50503041 193632.70262031 163415.44098892
 226914.54314094 131826.34848149 231452.57430959 126075.13119923
 180877.91118609 300416.58279334 246684.86812227 218565.07432668
 175061.36763142 187449.16335543 236773.07674838 154614.01527704
 191181.12788787 193566.46445555 148598.23184686 144997.54339524
 167148.44938093 254401.80063322 213121.25365824 195962.56708469
 156039.25722917 160136.33647849 167789.27177458 175440.23739288]
2025-06-23 21:53:08 INFO Expected Optimum FE: -5000
2025-06-23 21:53:08 INFO Unimodal AOCC mean: 0.1469
2025-06-23 21:53:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:53:08 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:53:08 INFO AOCC mean: 0.0490
2025-06-23 21:53:08 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:12 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1473
2025-06-23 21:53:12 INFO FeHistory: [-183.3518245  -183.29993598 -183.35706488 ... -183.50939955 -183.50941018
 -183.50937556]
2025-06-23 21:53:12 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:12 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalEvolutionaryStrategy
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.mutation_rate = 0.1 # initial mutation rate
        self.mutation_strength = 5.0 # initial mutation strength
        self.niche_radius = 20.0 # for niching

        self.population = self.initialize_population()


    def initialize_population(self):
        # Create a diverse initial population using latin hypercube sampling
        population = np.zeros((self.population_size, self.dim))
        for i in range(self.dim):
            values = np.linspace(self.lower_bounds[i], self.upper_bounds[i], self.population_size)
            random.shuffle(values)
            population[:, i] = values
        return population


    def mutate(self, individual):
        # Adaptive mutation based on recent success
        mutation = np.random.normal(0, self.mutation_strength, self.dim)
        return np.clip(individual + mutation, self.lower_bounds, self.upper_bounds)

    def select(self, fitness_values):
       #Tournament Selection
       selected_indices = np.random.choice(range(self.population_size), size=self.population_size, replace=True)
       return selected_indices


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population = self.initialize_population()


        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]


        while self.eval_count < self.budget:
            # Selection (Tournament)
            selected_indices = self.select(fitness_values)
            offspring = self.population[selected_indices].copy()

            # Mutation with Adaptive Mutation Strength
            for i in range(self.population_size):
                offspring[i] = self.mutate(offspring[i])


            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Merge and replace (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))

            sorted_indices = np.argsort(combined_fitness)
            self.population = combined_population[sorted_indices[:self.population_size]]
            fitness_values = combined_fitness[sorted_indices[:self.population_size]]


            #Update best solution
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index].copy()
                self.best_fitness_overall = fitness_values[best_index]


            # Adapt mutation strength (crude example, can be more sophisticated)
            improvement = (self.best_fitness_overall - np.mean(fitness_values))
            if improvement > 0:
                self.mutation_strength *= 1.1  #Increase on success
            else:
                self.mutation_strength *= 0.9 #Decrease on failure
            self.mutation_strength = max(0.01, min(10, self.mutation_strength)) #keep within bounds


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            "mutation_strength": self.mutation_strength
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

2025-06-23 21:53:12 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:14 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1519
2025-06-23 21:53:14 INFO FeHistory: [-183.42090463 -183.46669458 -183.33631169 ... -183.79549742 -183.77687941
 -183.88374304]
2025-06-23 21:53:14 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:14 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100 # Adjust as needed
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.mutation_rate = 0.5 # Initial mutation rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall, self.best_fitness_overall = self.get_best(self.population, fitness_values)
        
        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self.select_three_different(i)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                trial = self.crossover(self.population[i], mutant)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds) # Boundary handling

                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                
                if trial_fitness[0] < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness[0]
                    if trial_fitness[0] < self.best_fitness_overall:
                        self.best_solution_overall = trial
                        self.best_fitness_overall = trial_fitness[0]
                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)
            self.mutation_rate = max(0.01, self.mutation_rate * 0.95) # Adaptive mutation rate decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def select_three_different(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
        return u

    def get_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]


2025-06-23 21:53:14 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:20 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:53:20 INFO FeHistory: [1.29782916e+06 1.41778586e+06 1.95153809e+06 ... 1.75610597e+03
 1.75628346e+03 1.75614219e+03]
2025-06-23 21:53:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:53:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:53:23 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:53:23 INFO FeHistory: [1526255.30140554 1079998.51437596 1354697.17444298 ... 2110677.02131037
 1180598.14502212 1536690.63140612]
2025-06-23 21:53:23 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:53:23 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:53:26 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1520
2025-06-23 21:53:26 INFO FeHistory: [-183.45922225 -183.40452105 -183.3715893  ... -183.74083429 -183.87428388
 -183.73495348]
2025-06-23 21:53:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:26 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.mutation_strength = 0.5 # Initial mutation strength
        self.niche_radius = 5 # Radius for niching

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = np.full(self.population_size, np.inf)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.fitness_values = np.full(self.population_size, np.inf)


        # Initial evaluation
        self.evaluate_population(objective_function)

        while self.eval_count < self.budget:
            new_population = np.copy(self.population)
            for i in range(self.population_size):
                a, b, c = self.select_different_individuals(i)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                trial = self.crossover(self.population[i], mutant)
                trial = self.bound_solution(trial) # Ensure solution stays within bounds

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self.fitness_values[i]:
                    new_population[i] = trial
                    self.fitness_values[i] = trial_fitness


            self.population = new_population
            self.adapt_mutation_strength() # Adapt mutation strength based on convergence
            self.apply_niching() # Apply niching to maintain diversity

            # Update overall best solution
            best_index = np.argmin(self.fitness_values)
            if self.fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness_values[best_index]
                self.best_solution_overall = self.population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def evaluate_population(self, objective_function):
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size


    def select_different_individuals(self, i):
        while True:
            a, b, c = random.sample(range(self.population_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c


    def crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u


    def bound_solution(self, solution):
        solution = np.clip(solution, self.lower_bounds, self.upper_bounds)
        return solution


    def adapt_mutation_strength(self):
        # Simple adaptation: Reduce mutation strength if population is converging, increase otherwise
        avg_fitness_diff = np.mean(np.abs(np.diff(np.sort(self.fitness_values))))
        if avg_fitness_diff < 1e-2: #Example threshold. Adjust as needed
            self.mutation_strength *= 0.9
        else:
            self.mutation_strength *= 1.1
        self.mutation_strength = np.clip(self.mutation_strength, 0.1, 2)  # Keep within reasonable bounds


    def apply_niching(self):
        # Simple niching: Remove solutions that are too close to each other
        for i in range(self.population_size):
            for j in range(i + 1, self.population_size):
                distance = np.linalg.norm(self.population[i] - self.population[j])
                if distance < self.niche_radius and self.fitness_values[i] > self.fitness_values[j]:
                    self.population[i] = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                    self.fitness_values[i] = objective_function(self.population[i].reshape(1,-1))[0] # Re-evaluate
                    self.eval_count +=1

                elif distance < self.niche_radius and self.fitness_values[j] > self.fitness_values[i]:
                    self.population[j] = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                    self.fitness_values[j] = objective_function(self.population[j].reshape(1,-1))[0] # Re-evaluate
                    self.eval_count +=1

2025-06-23 21:53:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:39 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1483
2025-06-23 21:53:39 INFO FeHistory: [-183.33917884 -183.32984231 -183.29908973 ... -183.38162953 -183.38162953
 -183.38162953]
2025-06-23 21:53:39 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:39 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalEvolutionaryStrategy
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness = None
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial mutation standard deviation
        self.niche_radius = 0.2 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Initial niche radius

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        self.fitness = np.full(self.population_size, float('inf'))

        while self.eval_count < self.budget:
            self.fitness = self._evaluate_population(self.population, objective_function)

            # Update best solution
            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness[best_index]
                self.best_solution_overall = self.population[best_index]


            # Selection and Reproduction with Adaptive Mutation and Niching
            offspring = self._create_offspring(self.population, self.sigma)
            offspring_fitness = self._evaluate_population(offspring, objective_function)


            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((self.fitness, offspring_fitness))

            # Niching: Select individuals based on fitness and distance from existing solutions
            selected_indices = self._niching_selection(combined_population, combined_fitness, self.niche_radius)
            self.population = combined_population[selected_indices]
            self.fitness = combined_fitness[selected_indices]
            
            # Adaptive Sigma: Adjust mutation strength based on success rate
            self.sigma = self._adaptive_sigma(self.sigma)


        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _evaluate_population(self, population, objective_function):
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        return fitness

    def _create_offspring(self, population, sigma):
        offspring = population + np.random.normal(0, sigma, population.shape)
        offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)  #Handle boundary constraints
        return offspring

    def _niching_selection(self, population, fitness, niche_radius):
        selected = []
        for i, (individual, fit) in enumerate(zip(population, fitness)):
            is_unique = True
            for j, (other_individual, other_fit) in enumerate(zip(population, fitness)):
                if i != j and np.linalg.norm(individual - other_individual) < niche_radius and fit > other_fit :
                    is_unique = False
                    break
            if is_unique:
                selected.append(i)

        #Ensure Population Size 
        selected = random.sample(selected, min(len(selected),self.population_size))
        return selected

    def _adaptive_sigma(self, sigma):
        #Simple adaptive mechanism.  More sophisticated methods exist.
        improvement_rate = np.mean(self.fitness < self.best_fitness_overall)
        if improvement_rate > 0.2:
            sigma *= 1.1  # Increase sigma if many improvements
        elif improvement_rate < 0.1 :
            sigma *= 0.9  # Decrease sigma if few improvements
        return sigma
2025-06-23 21:53:39 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:42 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1529
2025-06-23 21:53:42 INFO FeHistory: [-183.32009869 -183.34277654 -183.31038746 ... -183.9150251  -183.91563315
 -183.92564958]
2025-06-23 21:53:42 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:42 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalEvolutionaryStrategy
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.mutation_rate = 0.1  # Initial mutation rate
        self.mutation_decay = 0.99 #Decay rate for mutation
        self.local_search_radius = 10.0 # Radius for local search
        self.population = self.initialize_population()

    def initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def mutate(self, solution):
        mutated_solution = solution + np.random.normal(0, self.mutation_rate * (self.upper_bounds-self.lower_bounds), self.dim)
        mutated_solution = np.clip(mutated_solution, self.lower_bounds, self.upper_bounds)
        return mutated_solution


    def local_search(self, solution, objective_function):
        best_local_solution = solution.copy()
        best_local_fitness = objective_function(best_local_solution.reshape(1,-1))[0]

        for _ in range(10):  # Limited local search iterations
            neighbor = best_local_solution + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)
            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
            neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
            if neighbor_fitness < best_local_fitness:
                best_local_solution = neighbor
                best_local_fitness = neighbor_fitness

        return best_local_solution, best_local_fitness

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')


        while self.eval_count < self.budget:
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size


            for i, fitness in enumerate(fitness_values):
                if fitness < self.best_fitness_overall:
                    self.best_fitness_overall = fitness
                    self.best_solution_overall = self.population[i].copy()

            # Selection (Tournament Selection)
            parents = []
            for _ in range(self.population_size):
                tournament = random.sample(range(self.population_size), 5)
                winner = min(tournament, key=lambda i: fitness_values[i])
                parents.append(self.population[winner])

            # Reproduction (Mutation & Local Search)
            offspring = []
            for parent in parents:
                mutated_solution = self.mutate(parent)
                local_solution, local_fitness = self.local_search(mutated_solution, objective_function)
                offspring.append(local_solution)
                self.eval_count += 1 # Account for local search evaluations

            self.population = np.array(offspring)
            self.mutation_rate *= self.mutation_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
2025-06-23 21:53:42 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:53:43 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:53:43 INFO FeHistory: [ 910376.92909963 2441149.50198069 2380864.78330356 ... 2395967.60686633
  879914.96163017 1949701.02568797]
2025-06-23 21:53:43 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:53:43 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:53:45 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:53:45 INFO FeHistory: [145860.14841548 191314.8432255  125124.75739134 ...  37646.02146636
  37646.7586342   37646.60169224]
2025-06-23 21:53:45 INFO Expected Optimum FE: -5000
2025-06-23 21:53:45 INFO Unimodal AOCC mean: 0.1473
2025-06-23 21:53:45 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:53:45 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:53:45 INFO AOCC mean: 0.0491
2025-06-23 21:53:45 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:51 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:53:51 INFO FeHistory: [162242.38540068 203720.23791945 160559.43471082 ...  53376.78506651
  44277.86581897  82796.25003355]
2025-06-23 21:53:51 INFO Expected Optimum FE: -5000
2025-06-23 21:53:51 INFO Unimodal AOCC mean: 0.1519
2025-06-23 21:53:51 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:53:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:53:51 INFO AOCC mean: 0.0506
2025-06-23 21:53:51 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:53:53 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1472
2025-06-23 21:53:53 INFO FeHistory: [-183.3756955  -183.42475162 -183.27074395 ... -183.34048502 -183.34047762
 -183.34049862]
2025-06-23 21:53:53 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:53:53 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.mutation_strength = 0.5 # Initial mutation strength, adaptive later


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]

        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(self.population)
            for i in range(self.population_size):
                # Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Boundary handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                
                # Crossover
                trial = np.zeros_like(self.population[i])
                j_rand = random.randint(0, self.dim -1)
                for j in range(self.dim):
                    if random.random() < self.CR or j == j_rand:
                        trial[j] = mutant[j]
                    else:
                        trial[j] = self.population[i][j]
                
                # Local Search (Simple hill climbing)
                for _ in range(5): # Limited local search iterations
                    neighbor = trial + np.random.normal(0, self.mutation_strength, self.dim)
                    neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                    neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                    self.eval_count += 1
                    if neighbor_fitness < fitness_values[i]:
                        trial = neighbor
                        fitness_values[i] = neighbor_fitness
                
                new_population[i] = trial

            self.population = new_population
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size
            
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index].copy()
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Mutation Strength
            self.mutation_strength *= 0.98 # Gradually decrease to focus exploitation
            if self.mutation_strength < 0.01: # Avoid getting stuck
                self.mutation_strength = 0.1
            
        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

2025-06-23 21:53:53 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:54:00 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1524
2025-06-23 21:54:00 INFO FeHistory: [-183.35704237 -183.30074879 -183.34631975 ... -183.80726855 -183.79143936
 -183.87571101]
2025-06-23 21:54:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:54:00 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.5 # Initial standard deviation for Gaussian mutation
        self.mutation_factor = 0.8 # Factor for differential evolution mutation
        self.crossover_rate = 0.9 # Crossover rate for differential evolution

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])

                # Adaptive Gaussian Mutation
                mutant = np.clip(mutant + np.random.normal(0, self.sigma, self.dim), self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.population[i])

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial.copy()
                        self.best_fitness_overall = trial_fitness
                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)

            #Adaptive Sigma Adjustment (reduce sigma if convergence is detected)
            fitness_std = np.std(fitness_values)
            if fitness_std < 0.1 : # Adjust threshold as needed
                self.sigma *= 0.9


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

2025-06-23 21:54:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:54:01 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:54:01 INFO FeHistory: [ 692867.38953185 1959346.63785056 3783884.58893867 ... 1341760.53944387
 1337310.2958297  1340303.52478297]
2025-06-23 21:54:01 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:54:01 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:54:09 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:54:09 INFO FeHistory: [2026536.37729851 1035336.5508973  2449091.04839601 ... 1382032.29601243
 1725060.12316181 2481172.79003427]
2025-06-23 21:54:09 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:54:09 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:54:13 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:54:13 INFO FeHistory: [3229037.60812724 2243071.94268053 2187968.19104603 ...   17858.61883065
   17858.61883065   17858.61883065]
2025-06-23 21:54:13 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:54:13 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:54:19 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:54:19 INFO FeHistory: [201721.61765935 141367.66604107 120282.48437319 ...  34775.27112205
  42670.09798541  19509.21702491]
2025-06-23 21:54:19 INFO Expected Optimum FE: -5000
2025-06-23 21:54:19 INFO Unimodal AOCC mean: 0.1520
2025-06-23 21:54:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:54:19 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:54:19 INFO AOCC mean: 0.0507
2025-06-23 21:54:20 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:54:20 INFO FeHistory: [ 751634.35255095 4210477.96135961 4569636.05738095 ...  450621.07947719
  198106.32523603  290609.73686912]
2025-06-23 21:54:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:54:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:54:28 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:54:28 INFO FeHistory: [186876.41562019 169292.02772371 153252.91902117 ... 246727.82962485
 246735.04994985 246811.61692665]
2025-06-23 21:54:28 INFO Expected Optimum FE: -5000
2025-06-23 21:54:28 INFO Unimodal AOCC mean: 0.1472
2025-06-23 21:54:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:54:28 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:54:28 INFO AOCC mean: 0.0491
2025-06-23 21:54:36 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:54:36 INFO FeHistory: [163667.62126106 142850.27950491 112258.16988547 ...  18092.53896363
  22005.81862946  36418.50900544]
2025-06-23 21:54:36 INFO Expected Optimum FE: -5000
2025-06-23 21:54:36 INFO Unimodal AOCC mean: 0.1524
2025-06-23 21:54:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:54:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:54:36 INFO AOCC mean: 0.0508
2025-06-23 21:55:02 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:55:02 INFO FeHistory: [189567.57686451  98991.19366243 142595.53791016 ...  91577.34992834
  91577.34992834 104980.87345561]
2025-06-23 21:55:02 INFO Expected Optimum FE: -5000
2025-06-23 21:55:02 INFO Unimodal AOCC mean: 0.1483
2025-06-23 21:55:02 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:55:02 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:55:02 INFO AOCC mean: 0.0494
2025-06-23 21:56:32 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:56:32 INFO FeHistory: [126541.55312422 151028.74310669 198967.42875707 ...   8297.55860505
   6269.4622413    4868.85666766]
2025-06-23 21:56:32 INFO Expected Optimum FE: -5000
2025-06-23 21:56:32 INFO Unimodal AOCC mean: 0.1529
2025-06-23 21:56:32 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:56:32 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:56:32 INFO AOCC mean: 0.0510
2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:23 ERROR Can not run the algorithm
2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:23 ERROR Can not run the algorithm
2025-06-23 21:58:23 INFO Run function 6 complete. FEHistory len: 110, AOCC: 0.1468
2025-06-23 21:58:23 INFO FeHistory: [-183.33091709 -183.36476353 -183.38811976 -183.34146829 -183.32798545
 -183.37791946 -183.39688493 -183.35018068 -183.41367424 -183.28466446
 -183.29841831 -183.34084439 -183.32012714 -183.38214208 -183.32916405
 -183.34775737 -183.35196564 -183.30116461 -183.32421607 -183.37684996
 -183.39371477 -183.32246961 -183.36214574 -183.36524093 -183.32982294
 -183.39761414 -183.30793799 -183.33578577 -183.38617261 -183.33780846
 -183.37029343 -183.39204418 -183.42685399 -183.3937324  -183.32618458
 -183.34185834 -183.36546902 -183.31610932 -183.3586055  -183.37024952
 -183.29901583 -183.33978845 -183.33685464 -183.37202882 -183.361642
 -183.40589176 -183.37423682 -183.31566178 -183.28450786 -183.31246578
 -183.33025206 -183.32398179 -183.42365523 -183.37753997 -183.38983757
 -183.33363369 -183.43169598 -183.32666899 -183.44574347 -183.38913161
 -183.35973653 -183.29643904 -183.3298887  -183.37008745 -183.34945562
 -183.36293072 -183.33693227 -183.45673355 -183.3305816  -183.41551929
 -183.3017541  -183.33385968 -183.36823864 -183.43082635 -183.28941927
 -183.37408859 -183.39398727 -183.30592111 -183.27942125 -183.36966601
 -183.30833469 -183.37414023 -183.36696643 -183.3153959  -183.3962121
 -183.27016352 -183.37738581 -183.29622215 -183.27669183 -183.36129011
 -183.39242687 -183.29067158 -183.32522581 -183.33986644 -183.37234125
 -183.39627191 -183.39445469 -183.34476247 -183.41256238 -183.38646213
 -183.32189841 -183.29675545 -183.32550658 -183.350038   -183.39705178
 -183.23307359 -183.31663488 -183.28283923 -183.40938501 -183.25790337]
2025-06-23 21:58:23 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:58:23 INFO Good algorithm:
Algorithm Name: ArchiveGuidedGaussianMutationDE
import numpy as np
import random

class ArchiveGuidedGaussianMutationDE:
    """
    Combines Differential Evolution, Gaussian mutation, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99
        self.archive_diversity_threshold = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation with Archive Guidance
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])
                
                #add archive element with some prob
                if random.random()<0.2 and len(self.archive)>0:
                  archive_index = random.randint(0, len(self.archive)-1)
                  mutant += self.mutation_scale * (self.archive[archive_index] - self.population[i])

                #Adaptive Gaussian perturbation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                    self._update_archive(trial, trial_fitness) #add to archive
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                self.best_solution_overall, self.best_fitness_overall = self._find_best(np.array(new_population), np.array(new_fitness_values))

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

        #maintain diversity
        if len(self.archive)>1:
          self._maintain_archive_diversity()


    def _maintain_archive_diversity(self):
      archive_solutions = np.array([sol for sol,_ in self.archive])
      distances = np.linalg.norm(archive_solutions[:,None,:] - archive_solutions[None,:,:], axis=2)
      
      for i in range(len(distances)):
        if np.sum(distances[i]<self.archive_diversity_threshold)>1:
          #remove the worst solution
          worst_index = np.argmax([f for _,f in self.archive])
          self.archive.pop(worst_index)
          break #only remove one in each iteration
          

2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:58:23 ERROR Can not run the algorithm
2025-06-23 21:58:23 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1474
2025-06-23 21:58:23 INFO FeHistory: [-183.34392409 -183.31855756 -183.33255886 -183.30000304 -183.36220877
 -183.34421583 -183.45635411 -183.31515107 -183.33049489 -183.34651395
 -183.36021639 -183.38452862 -183.37625015 -183.27486447 -183.28162899
 -183.37319902 -183.35360345 -183.30213427 -183.3559445  -183.35968133
 -183.40756586 -183.34231379 -183.30936231 -183.28741414 -183.27227287
 -183.40220625 -183.39583838 -183.42332033 -183.31878374 -183.3175429
 -183.36891124 -183.3332109  -183.30989612 -183.38386116 -183.3324904
 -183.2706597  -183.5031329  -183.42059404 -183.3303398  -183.29208171
 -183.34953701 -183.36152207 -183.40285353 -183.30762078 -183.26774244
 -183.34756845 -183.32764694 -183.35198631 -183.41752967 -183.31433418
 -183.36209589 -183.33569674 -183.35803726 -183.29891332 -183.32933461
 -183.27784636 -183.3265764  -183.34302006 -183.38562182 -183.32429235
 -183.41632058 -183.42254295 -183.33739868 -183.26237979 -183.3056156
 -183.33757932 -183.39192135 -183.42350955 -183.27748603 -183.43622043
 -183.25912686 -183.35625646 -183.50370157 -183.48104057 -183.41252851
 -183.38738979 -183.37678784 -183.44452386 -183.32177768 -183.35866042
 -183.30476355 -183.34481613 -183.37620902 -183.33251183 -183.33794797
 -183.43266635 -183.322216   -183.34351164 -183.35121496 -183.39786614
 -183.37224863 -183.37913342 -183.37340586 -183.38184841 -183.36347966
 -183.30463259 -183.39455526 -183.28216634 -183.37786807 -183.36373075]
2025-06-23 21:58:23 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:58:23 INFO Good algorithm:
Algorithm Name: ArchiveGuidedGaussianMutationDE
import numpy as np
import random

class ArchiveGuidedGaussianMutationDE:
    """
    Combines Differential Evolution, Gaussian mutation, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Mutation with Archive Augmentation
                a, b, c = self._select_different(i, population)
                mutant = self._differential_mutation(population[a], population[b], population[c])

                # Adaptive Gaussian perturbation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    self._update_archive(trial, trial_fitness) #add to archive
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(fitness[:len(new_population)]))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.mutation_scale *= self.mutation_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        #Select from population and archive
        candidates = list(range(len(population))) + [i for i in range(len(self.archive))]
        a, b, c = random.sample(candidates, 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(candidates, 3)
        
        if a >= len(population):
            a_val = self.archive[a - len(population)][0]
        else:
            a_val = population[a]
        if b >= len(population):
            b_val = self.archive[b - len(population)][0]
        else:
            b_val = population[b]
        if c >= len(population):
            c_val = self.archive[c - len(population)][0]
        else:
            c_val = population[c]

        return a_val, b_val, c_val


    def _differential_mutation(self, a, b, c):
        return a + self.mutation_scale * (b - c)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:58:23 ERROR Can not run the algorithm
2025-06-23 21:58:23 INFO Run function 13 complete. FEHistory len: 102, AOCC: 0.0000
2025-06-23 21:58:23 INFO FeHistory: [ 779272.39649079 1901291.79861826 3139558.37418232 1015975.2343375
 2318671.06324437 1846733.3670936  2777142.5269839  3511270.63471432
 3195813.47226375 2640945.32985382 2573061.80525334 1200886.62889984
 3752588.02767294 2314152.5154493  2421475.55988432 1429920.06794021
 1734170.51008939 1390516.84233443 2347942.47639185 1053931.71367398
 1728937.34233504 1869805.6824487  1918771.40270646  834601.610504
 1417764.77446939 1402570.72897716 1828118.16625643 1190781.85185752
  717581.01276543  451610.68105012 1655068.95132468  104720.08891676
 2065156.36624917 2026823.75597942 2373007.73040151 1892606.1445103
 1509674.83311832  830412.62424023 3074335.01887435 3608696.80341809
 4489562.9270665  2209206.42524106  555589.20590552 2077297.7663451
 2448804.89603959 1567588.63694245 1102370.78531827 1520190.2505089
 4218029.12502485 2773233.33870877 3381040.65856118 2932052.83583283
 1361587.45237427  653180.48059491 1459633.41587395  675035.31600276
 1450008.78541106 3574166.25127347 3361265.61073146 1426291.48268309
 1996607.75325406 1937271.46562801 2380369.53408787 1401114.52254567
 3607102.70050743 1412270.8814779  1798859.03214622 4137944.57185099
 1705958.98076527 1519330.03496146  761093.0961103  2482777.86024774
 1873167.13950873 2040165.15133177 1386885.30075114 2680540.15020367
 1998456.82138933 3395296.57681117  715771.88078419 2061204.9998351
 3701194.6127923  3587318.9272526   921488.56880475 3310962.61318362
 1998395.39389454 1805299.71532773 1513875.96578198 4103159.51970227
 1883384.76241161 2538977.07219986  878686.65946389 2569155.38387367
  759196.53768949 2067182.83686158 1385177.96793409  497676.65915487
 1112694.48949482 1982905.25994173 1036661.39000553  507269.0817575
 1498060.25160381 1668009.85394433]
2025-06-23 21:58:23 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:58:23 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:58:23 INFO FeHistory: [2881069.96298411 2626824.36679545  700620.16194445 1592569.81137587
  813700.56504272 3166664.99948715 4271752.1184988  3047948.37713351
 2241605.32414578 2664897.36881116 2639475.15710869 1379856.39681822
  704507.48146423  991992.38920889 1044765.4261389  1290176.15597598
  961653.65064491 2816265.67790379 2849245.43266497 2325149.69656221
 2812152.83131302  641040.71401554 2646645.358546    952984.37566687
 2284783.46920298 1257542.83483722 5422792.7079865  1463942.88131014
 1527174.47472011  938590.68328604 1710431.9621807  1258060.06964672
 2620042.42847423 2025413.39227026 2373763.10411712 1450286.91424319
 1321809.24357335  384547.61896783 1916533.02959234 2356815.68178846
 1121721.13337312 1361319.36631488 2389863.60923566 1140861.39134502
 3186235.96926997 1983861.46635524 3261837.11456986 1419912.8249052
  692611.52612156 1232989.9999662   782732.33252171 1457255.11103963
 1548834.64424715 1426282.87845019 1699457.79251539 2312612.56646313
 3641011.51765032 2169657.16558808 3521087.93673435 2389978.12102414
  382676.10108532 2191285.95234568 3507820.93107129 1836141.25148882
 2651816.0611734  1592931.64243764 1522768.33772576 3434725.81769856
 1472328.00417892 1727270.24801598 1673670.77392881 1210249.52113509
 3308567.49385301 1683218.07427622  861069.78946668 1319888.60235401
 1790499.82913417 1214250.17809189  350510.15913201  916778.53718814
 4758932.28528916  994125.23788427 1665980.6335506  1767058.18016601
 1239366.00214156 3394248.12937523 3787243.01388832  716357.48880565
 1449574.37459271 1354927.20321874 3406086.31257065 1197701.68303183
 1522499.68068301  815388.90380215 1144661.08326394 1250956.79415914
 4953304.01023013 1089555.02436837 1339006.4672605  2346700.22176867]
2025-06-23 21:58:23 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:58:23 ERROR Can not run the algorithm
2025-06-23 21:58:23 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:58:23 ERROR Can not run the algorithm
2025-06-23 21:58:24 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 21:58:24 INFO FeHistory: [167293.33395268 286775.56757711 143232.57038045 166667.56529023
 133816.65094693 146793.6798853  148110.90806706 142315.13914672
 169617.95064997 145274.6642691  201121.85375834 150712.49678104
  89360.71057712  66831.99723961 181960.44871918 127264.14143388
 149537.63992067  73687.83305907 206987.70763506 149312.33012124
 190697.64171517 133116.75375775 139115.78862525 175926.81904259
 152019.78909605 213725.25134689 150225.65724594 115454.78036433
 230875.08541519 151783.10619527 140357.97117501 110933.15383974
 170855.59030387 164687.7205731  158153.41311784 195390.94472539
 155458.13700943 136080.42607029 199968.35985795 134171.63433686
 170292.66876344 216472.84603401 168368.92565205 180738.45935328
 137137.15936165 111484.4353032  176127.96321154 173224.09648117
 174003.60433603 141283.36195845 102581.31285406 189839.99570006
 151544.83311078 140171.16950963 142472.85658709 152206.45263722
  94695.19406109 105420.96137035 183310.83082214 120464.68998238
 128503.09713583 106781.92187195 155052.21389284 190328.65094675
 162897.12257584 168598.97522444 154323.61457753 147435.56935797
 119570.61854171 165178.04758752 161614.44159506 114045.62026133
 180217.96977692 201127.53292844 172408.66734936 101334.65253397
 148504.39548547 172923.15272808 124240.57511248 101195.18715291
 128903.05704746 183163.14553939 164409.52205057 137024.65563586
  90487.08586653 155426.26855186  77583.79019074 144545.92501417
 135406.30850411 120223.18383055 188883.87195279 177638.56368226
 165158.54319709 112164.99795681 176199.43467443 194001.30024603
 192648.87212453 148326.17039086 142225.13122218 128417.29274337
 150064.48538021]
2025-06-23 21:58:24 INFO Expected Optimum FE: -5000
2025-06-23 21:58:24 INFO Unimodal AOCC mean: 0.1468
2025-06-23 21:58:24 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:58:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:58:24 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:58:24 INFO FeHistory: [140969.12760092 128729.52423703 112921.59181942 224936.00489035
 105938.51957871 162132.56126698 137664.98860663 128902.45136112
 188592.57807617 122178.3687933  160774.93558914 164442.08702628
 159426.33172633 117846.4603669  146647.37496081 125624.91134337
 175223.65395388  94525.25765748 130286.76674813 177976.01235298
 172214.73782099 112002.36086469 211623.74684188 136422.72478431
 125850.14780905 183651.50878701 154698.97235464 141262.50049747
 100792.87895823  97184.30936387 122333.35777222 157399.79431486
 144796.79995236 208963.92115643 114943.87704511 229194.61926353
 210677.36669628 150862.43292721 196419.44759896 210666.63401576
 146117.35457507 158217.63943663 229244.53780486 205474.08492141
 185317.13961214  85337.68926401  86385.54256087 122164.43900504
 105464.52202684 141963.24742492 198804.27246768 167193.9570403
 152357.18629809 192696.80313238 143418.66534111 141323.10124485
 142541.14869953 137903.24891394 125117.89584182 124005.78096023
 195379.23371269 148137.80457193 139825.9555623  138105.84660051
 160221.42105598 145172.47574838 126599.28839611 103745.89091053
 135285.81690435 169261.65164609 114667.7117238   85919.04753811
 188757.31548642 178374.89260497 174584.09980509 180291.70369773
 152637.98579266 110933.86703072 146094.30867509 118855.10944076
  69816.27817289 158871.32095118 220945.9254288  163651.93529054
 136070.11800946 208190.34297106 135599.93509279 122767.36735199
 150047.834777   118283.62231039 126934.70299512 215440.18922576
 112599.91810212 131392.44259794 136126.82718321 199871.13225447
 136363.77017128 147662.26350653 270602.19114588 128336.26039027]
2025-06-23 21:58:24 INFO Expected Optimum FE: -5000
2025-06-23 21:58:24 INFO Unimodal AOCC mean: 0.1474
2025-06-23 21:58:24 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:58:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:58:45 INFO AOCC mean: 0.0489
2025-06-23 21:58:45 INFO AOCC mean: 0.0491
2025-06-23 21:58:45 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:45 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:45 ERROR Can not run the algorithm
2025-06-23 21:58:45 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1470
2025-06-23 21:58:45 INFO FeHistory: [-183.37250861 -183.39460435 -183.26781091 -183.41055245 -183.37708535
 -183.43367867 -183.27086977 -183.28432639 -183.28574488 -183.33534612
 -183.38749425 -183.25971533 -183.33976226 -183.3676243  -183.3767911
 -183.30099854 -183.32749542 -183.34093846 -183.38594595 -183.31648446
 -183.42320402 -183.43296298 -183.31154114 -183.28489112 -183.38418891
 -183.42341852 -183.31797048 -183.31491129 -183.35765077 -183.27237013
 -183.33357691 -183.40659144 -183.30117807 -183.42639871 -183.3386425
 -183.31903517 -183.47598923 -183.31916949 -183.29532354 -183.39847021
 -183.33294163 -183.37624729 -183.35461734 -183.36810897 -183.36987721
 -183.31784301 -183.32947069 -183.37550897 -183.40825117 -183.40905274
 -183.31013276 -183.32717371 -183.31807955 -183.40211391 -183.40682009
 -183.3112334  -183.35303061 -183.39138063 -183.36021043 -183.29266454
 -183.31951018 -183.31276186 -183.42159125 -183.341781   -183.36285761
 -183.35626576 -183.37295447 -183.36237205 -183.38911915 -183.39476857
 -183.29316602 -183.31425046 -183.40078295 -183.39306698 -183.41190125
 -183.4216682  -183.32057666 -183.33644881 -183.34615237 -183.35600179
 -183.44593627 -183.30271381 -183.37228646 -183.46915338 -183.43022159
 -183.3601341  -183.34973356 -183.31032565 -183.36391049 -183.2715224
 -183.40697386 -183.32152571 -183.30479865 -183.38144539 -183.3013467
 -183.35413153 -183.37595017 -183.37791545 -183.41369949 -183.37348163]
2025-06-23 21:58:45 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:58:45 INFO Good algorithm:
Algorithm Name: ArchiveGuidedGaussianMutationDE
import numpy as np
import random

class ArchiveGuidedGaussianMutationDE:
    """
    Combines Differential Evolution with adaptive Gaussian mutation and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50  # Size of the archive
        self.archive = []
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99
        self.population = None
        self.fitness_values = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)
        
        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation with Archive Integration
                a, b, c = self._select_different(i, self.population, self.archive)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                # Adaptive Gaussian Mutation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                # Selection and Archive Update
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population, archive):
        candidates = np.concatenate((population, np.array(archive)))
        a, b, c = random.sample(range(len(candidates)), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(len(candidates)), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_solution, worst_fitness = max(self.archive, key=lambda item: item[1])
            if fitness < worst_fitness:
                self.archive.remove((worst_solution, worst_fitness))
                self.archive.append((solution, fitness))
2025-06-23 21:58:45 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:58:45 ERROR Can not run the algorithm
2025-06-23 21:58:46 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:58:46 INFO FeHistory: [3094475.72669072 2540316.89004487 1203749.76183834 1396171.27665837
 2419979.99968897 1876462.29973251  824521.76065057 1097109.11992592
 2042962.93057741  891705.13370673 2928688.916357    441461.22492286
 3995237.00471337 2094918.26838439  897797.43058874  564729.26563157
  824270.61131963 1772692.98351488 2039783.81426087 3014267.92548757
 2605247.97724285 3448761.86255788 2785262.89382505 2296701.90891149
 3697178.20949289  281611.71774908 3286140.69992108 1370805.19128592
 1371209.49830137 2757645.62948921 2436146.2733072  1530890.32594449
  492556.34037761 2338862.38008639 5764828.80960587 1244098.32518458
 2227307.00927888 1255909.53056612 2703742.47955346 3496740.34027068
 2152049.31611905  646806.87070777 2603040.29471237 1197514.28339941
 1649086.00705044 2363454.35593199 1693571.22144187 1910147.21736869
 1104378.94293474 1636890.73834438 1031960.7771884  1343178.25633864
  509005.98765806 1959760.91307895 1500684.41251841 5745093.6211976
 1791634.24784001 1970882.23698006 2538323.69651197 1535206.03457502
 1404682.72313639 2062140.44955675 1184513.684841   2381397.79276561
  855878.18892922 1635078.65903747 1484096.92982618 2302867.73199701
  677226.06096623 1531319.81561982 1327599.8510372  4185954.5436885
 1577420.56387775 1539349.04602822 4000732.23523723 1635315.74794842
 1574197.69195436 2969036.13060535 1407330.71689127 2055983.65711135
 2649982.07090431 1731570.38993129  450591.59964476  668076.22985952
 3391269.56133598  894009.61016598 3345126.97423133  889872.65468766
 1909394.65610799 2586311.4871161  3241509.58181538 2614655.73791734
 1641319.69152597 1860016.32584597 3395258.73089924 1143510.62229591
 1279807.92507718 1578663.16438034 3004030.14358107 3150876.04351781]
2025-06-23 21:58:46 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:58:46 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:58:46 ERROR Can not run the algorithm
2025-06-23 21:58:46 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 21:58:46 INFO FeHistory: [117428.7177284  107506.88245896 145321.8272194  155906.10134246
 146486.33235892 141977.69513069 166480.90754425 129351.75088631
 115686.22791635 146777.72353817 173359.89297269 198342.01398128
 143636.97869593 155849.90844647 137588.30946681 159088.12174593
 181387.97927434 178955.7922     182251.13494006 191234.22632995
 143042.91372531 158240.01286874 166595.41797103 185108.42091404
 185367.16130335 110706.34624062  87931.04165961 120538.65666624
 151960.23699396 153137.00881862 172482.55165196 148211.28735529
 153216.42354617 190663.43998792  84830.8344378  167442.82508788
 169149.4878374  149262.54078992 162062.82410894 129425.63718964
 103614.27501065 168599.85293579 183073.96653201 120880.15759458
 141185.45354157 142101.86083014 128323.15716087 130579.48463062
 128539.28355841 127125.34492289 209097.15844396 158499.58530901
 131257.01216383 135465.0990045  150982.39863389 129247.82180896
 123210.34443255 124996.38007535 138171.92820735 154731.5907484
 163679.40178935 165927.19795959 209339.50720338 154550.2861878
 138875.07290082  72964.80493273 119815.67659872 180700.47209562
 163699.35551327 167803.62339711 144142.47009131 122030.20156847
 137026.93919725 103127.08403949 174072.44216692  91637.88912305
 157471.48770559 162236.79935475 143306.9143733  160935.42529974
 158431.40625658 174202.44170998 117563.7329982  175644.88979521
 172100.72648939 181983.36339125 169024.31226405 174810.14793803
 155980.04702365 166762.76480076 152030.2128432  142919.33159231
  88458.51997219 151130.25476941 210325.10109961 149577.38113452
 106512.97387158 172399.45341099 163667.38109826 153408.34912825]
2025-06-23 21:58:46 INFO Expected Optimum FE: -5000
2025-06-23 21:58:46 INFO Unimodal AOCC mean: 0.1470
2025-06-23 21:58:46 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:58:46 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:58:46 INFO AOCC mean: 0.0490
2025-06-23 21:58:46 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:58:54 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1521
2025-06-23 21:58:54 INFO FeHistory: [-183.36695005 -183.30968643 -183.32761285 ... -183.69502555 -183.67789214
 -183.66629917]
2025-06-23 21:58:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:58:54 INFO Good algorithm:
Algorithm Name: ArchiveGuidedAdaptiveGaussianDE
import numpy as np
import random

class ArchiveGuidedAdaptiveGaussianDE:
    """
    Combines Differential Evolution (DE) with an archive and adaptive Gaussian mutation for efficient multimodal optimization.  The archive helps maintain diversity and guide exploration, while adaptive Gaussian mutation allows for fine-tuned exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.mutation_strength = 0.1 #initial mutation strength

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt mutation strength based on progress
            self.mutation_strength = max(0.01, self.mutation_strength * (1 + 0.1 * (self.best_fitness_overall > 0.01) ) )  # Reduce if close to 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_strength': self.mutation_strength
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            
            #Gaussian Mutation
            gaussian_noise = np.random.normal(0, self.mutation_strength * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring[i] = mutant + gaussian_noise

            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

2025-06-23 21:58:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:58:54 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1515
2025-06-23 21:58:54 INFO FeHistory: [-183.27024504 -183.25538869 -183.33188549 ... -183.77852402 -183.7361757
 -183.79972387]
2025-06-23 21:58:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:58:54 INFO Good algorithm:
Algorithm Name: ArchiveGuidedGaussianDE
import numpy as np
import random

class ArchiveGuidedGaussianDE:
    """
    Combines Differential Evolution with Gaussian mutation and an archive for enhanced exploration in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian width
        self.sigma_decay = 0.99
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(population, i)
                trial = self._crossover(population[i], mutant)
                trial = self._gaussian_mutation(trial) #Gaussian mutation added
                trial = self._bound_solution(trial)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                
                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    offspring.append(population[i])

            population = np.array(offspring)
            self._update_archive(population, fitness_values) #Update archive
            self.sigma *= self.sigma_decay
            
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[best_index]
                self.best_solution_overall = population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _generate_mutant(self, population, i):
        a, b, c = self._select_different_individuals(i, self.population_size)
        mutant = population[a] + self.F * (population[b] - population[c])
        return mutant

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _gaussian_mutation(self, solution):
        solution += np.random.normal(0, self.sigma, self.dim)
        return solution

    def _bound_solution(self, solution):
        return np.clip(solution, self.lower_bounds, self.upper_bounds)

    def _select_different_individuals(self, i, pop_size):
        while True:
            a, b, c = random.sample(range(pop_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        combined = sorted(combined, key=lambda x: x[-1])
        
        if len(self.archive) < self.archive_size:
            self.archive.extend(combined[:self.archive_size-len(self.archive)])
        else:
            self.archive[:self.archive_size - len(combined)] = combined

2025-06-23 21:58:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:58:54 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1520
2025-06-23 21:58:54 INFO FeHistory: [-183.32298681 -183.37231606 -183.2584226  ... -183.84839235 -183.75162383
 -183.75254595]
2025-06-23 21:58:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:58:54 INFO Good algorithm:
Algorithm Name: ArchiveGuidedGaussianDE
import numpy as np
import random

class ArchiveGuidedGaussianDE:
    """
    Combines Differential Evolution with Gaussian mutation and an archive to enhance exploration and exploitation in multimodal optimization problems.  The archive stores promising solutions encountered so far, promoting diversity and preventing premature convergence.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian width
        self.sigma_decay = 0.99 # Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += len(fitness)

        self.best_solution_overall = population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        self.update_archive(population, fitness)

        while self.eval_count < self.budget:
            # Differential Evolution with Gaussian Mutation
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                
                #Gaussian Mutation
                mutant += np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    offspring[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    offspring[i] = population[i]

            population = offspring
            self.sigma *= self.sigma_decay
            
            self.update_archive(population, fitness)
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def update_archive(self, population, fitness):
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))
        self.archive.sort(key=lambda x: x[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] #Keep only the best

2025-06-23 21:58:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:59:03 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:59:03 INFO FeHistory: [1866949.24424346 2724802.58323813  519134.96246187 ... 4403639.18774541
 5019172.8723894  2026090.58536794]
2025-06-23 21:59:03 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:59:03 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:59:04 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:59:04 INFO FeHistory: [2016986.70118599  494463.05996896 1008347.68923308 ... 1497198.93503346
 1496516.62810982 1552576.40669754]
2025-06-23 21:59:04 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:59:04 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:59:05 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:59:05 INFO FeHistory: [2658949.29092956 1207881.41421037  931783.39391203 ... 1867512.86545602
 2228667.5370933  3741187.06449181]
2025-06-23 21:59:05 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:59:05 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 21:59:30 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:59:30 INFO FeHistory: [139534.4994167  123564.78142142 170449.96419713 ... 283831.68713025
 445801.9666279  272443.83707689]
2025-06-23 21:59:30 INFO Expected Optimum FE: -5000
2025-06-23 21:59:30 INFO Unimodal AOCC mean: 0.1521
2025-06-23 21:59:30 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:59:30 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:59:30 INFO AOCC mean: 0.0507
2025-06-23 21:59:30 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:59:32 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:59:32 INFO FeHistory: [187575.15594934 144945.58374053 117257.01500135 ...  13555.49143882
  18246.55993053  37160.7468556 ]
2025-06-23 21:59:32 INFO Expected Optimum FE: -5000
2025-06-23 21:59:32 INFO Unimodal AOCC mean: 0.1515
2025-06-23 21:59:32 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:59:32 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:59:32 INFO AOCC mean: 0.0505
2025-06-23 21:59:32 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 21:59:33 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:59:33 INFO FeHistory: [ 82223.77957134 143912.35479795 145349.47779927 ...  21798.95508587
  18135.09019523  37445.88730072]
2025-06-23 21:59:33 INFO Expected Optimum FE: -5000
2025-06-23 21:59:33 INFO Unimodal AOCC mean: 0.1520
2025-06-23 21:59:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 21:59:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 21:59:33 INFO AOCC mean: 0.0507
2025-06-23 21:59:40 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1515
2025-06-23 21:59:40 INFO FeHistory: [-183.3760637  -183.32548094 -183.34493319 ... -183.74069883 -183.84353909
 -183.80417225]
2025-06-23 21:59:40 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 21:59:40 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianDEwithArchive
import numpy as np
import random

class AdaptiveGaussianDEwithArchive:
    """Combines adaptive Gaussian mutation with differential evolution and an archive."""
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50  # Size of the archive
        self.archive = []
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = np.full(self.population_size, np.inf)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.fitness_values = np.full(self.population_size, np.inf)
        self.evaluate_population(objective_function)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self.select_different_individuals(i)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                trial = self.crossover(self.population[i], mutant)
                trial = self.gaussian_mutation(trial) #Add Gaussian Mutation
                trial = self.bound_solution(trial)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    self.fitness_values[i] = trial_fitness
                else:
                    new_population.append(self.population[i]) #Keep the old solution

            self.population = np.array(new_population)
            self.update_archive()
            self.sigma *= self.sigma_decay #Adapt Gaussian Mutation

            best_index = np.argmin(self.fitness_values)
            if self.fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness_values[best_index]
                self.best_solution_overall = self.population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def evaluate_population(self, objective_function):
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

    def select_different_individuals(self, i):
        while True:
            a, b, c = random.sample(range(self.population_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c

    def crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u

    def bound_solution(self, solution):
        solution = np.clip(solution, self.lower_bounds, self.upper_bounds)
        return solution

    def gaussian_mutation(self, solution):
        solution += np.random.normal(0, self.sigma, size=solution.shape)
        return solution

    def update_archive(self):
        # Add new solutions to archive, keeping only best
        for i in range(self.population_size):
            self.archive.append((self.population[i], self.fitness_values[i]))
        self.archive.sort(key=lambda item: item[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] # Keep only top solutions

2025-06-23 21:59:40 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 21:59:49 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 21:59:49 INFO FeHistory: [ 726915.00156032  916693.56272314 1490201.13243268 ... 1026131.4422197
 1085295.60442158 3129843.14124954]
2025-06-23 21:59:49 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 21:59:49 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:00:17 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:00:17 INFO FeHistory: [141846.97004627 158531.76615937 157272.67808282 ...  21445.89569834
  27035.38649245  16197.71110864]
2025-06-23 22:00:17 INFO Expected Optimum FE: -5000
2025-06-23 22:00:17 INFO Unimodal AOCC mean: 0.1515
2025-06-23 22:00:17 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:00:17 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:00:17 INFO AOCC mean: 0.0505
2025-06-23 22:01:56 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1781
2025-06-23 22:01:56 INFO FeHistory: [-183.32557713 -183.25600719 -183.2660086  ... -185.49437915 -185.49437915
 -185.49437915]
2025-06-23 22:01:56 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:01:56 INFO Good algorithm:
Algorithm Name: ArchiveGuidedAdaptiveGaussianEA
import numpy as np
import random

class ArchiveGuidedAdaptiveGaussianEA:
    """
    Combines adaptive Gaussian mutation with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial sigma
        self.sigma_decay = 0.99
        self.archive = []
        self.archive_threshold = 1e-6 #Threshold for archive uniqueness

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay  # Adaptive sigma decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

2025-06-23 22:01:56 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:03:04 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1658
2025-06-23 22:03:04 INFO FeHistory: [-183.3458689  -183.34695187 -183.3304382  ... -184.90551091 -184.90551092
 -184.90551089]
2025-06-23 22:03:04 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:03:04 INFO Good algorithm:
Algorithm Name: ArchiveGuidedAdaptiveDEMutationEA
import numpy as np
import random

class ArchiveGuidedAdaptiveDEMutationEA:
    """
    Combines Differential Evolution (DE) with adaptive Gaussian mutation and an archive 
    to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.98

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)
        self.archive = self._update_archive(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(i)
                trial = self._crossover(self.population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count +=1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)
            self.archive = self._update_archive(np.vstack((self.population,self.population)), np.concatenate((self.fitness_values,self.fitness_values))) #Adding whole population for archive update.
            self.mutation_scale *= self.mutation_scale_decay
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _generate_mutant(self, index):
        a, b, c = self._select_different(index)
        mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])
        mutant += np.random.normal(0, self.sigma, self.dim)
        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < 0.5, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-23 22:03:04 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:03:39 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1695
2025-06-23 22:03:39 INFO FeHistory: [-183.40891997 -183.50266171 -183.4407455  ... -185.54712037 -185.55147923
 -185.55599049]
2025-06-23 22:03:39 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:03:39 INFO Good algorithm:
Algorithm Name: AdaptiveArchiveGuidedGaussianEA
import numpy as np
import random

class AdaptiveArchiveGuidedGaussianEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial step size
        self.sigma_decay = 0.99  # Decay factor for sigma
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_mutation(parents) #Direct mutation, no recombination
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        # Initialize population around the center of the search space
        center = (self.upper_bounds + self.lower_bounds) / 2
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)


    def _gaussian_mutation(self, parents):
        offspring = parents + np.random.normal(0, self.sigma, size=parents.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

2025-06-23 22:03:39 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:05:37 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:05:37 INFO FeHistory: [2.62434221e+06 3.59006320e+06 3.70691200e+06 ... 6.07410715e+02
 6.07410715e+02 6.07410715e+02]
2025-06-23 22:05:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:05:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:06:12 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:06:12 INFO FeHistory: [2670882.98055881 1425296.74380109 1748536.22679652 ...  633109.856076
 2565986.93824096 2521630.35025108]
2025-06-23 22:06:12 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:06:12 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:08:39 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:08:39 INFO FeHistory: [1.42795179e+06 1.04978859e+06 2.42386084e+06 ... 7.58549111e+02
 7.58529827e+02 7.58529980e+02]
2025-06-23 22:08:39 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:08:39 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:09:21 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:09:21 INFO FeHistory: [172150.88523989 110766.96032571 117991.52116476 ...  -4419.9
  -4419.9         -4419.9       ]
2025-06-23 22:09:21 INFO Expected Optimum FE: -5000
2025-06-23 22:09:21 INFO Unimodal AOCC mean: 0.1781
2025-06-23 22:09:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:09:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:09:21 INFO AOCC mean: 0.0594
2025-06-23 22:09:51 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:09:51 INFO FeHistory: [162711.24716656 134257.57768421 167590.14222211 ...  -4399.53653935
  53152.80989878  -4399.23260191]
2025-06-23 22:09:51 INFO Expected Optimum FE: -5000
2025-06-23 22:09:51 INFO Unimodal AOCC mean: 0.1658
2025-06-23 22:09:51 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:09:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:09:51 INFO AOCC mean: 0.0553
2025-06-23 22:14:01 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:14:01 INFO FeHistory: [112469.13149623 104516.33765311  60915.98922175 ...  -4317.8993102
  -4317.89969485  -4317.89847683]
2025-06-23 22:14:01 INFO Expected Optimum FE: -5000
2025-06-23 22:14:01 INFO Unimodal AOCC mean: 0.1695
2025-06-23 22:14:01 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:14:01 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:14:01 INFO AOCC mean: 0.0565
2025-06-23 22:14:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:14:53 ERROR Can not run the algorithm
2025-06-23 22:14:54 INFO Run function 6 complete. FEHistory len: 151, AOCC: 0.1461
2025-06-23 22:14:54 INFO FeHistory: [-183.40518489 -183.39097992 -183.3920647  -183.39050801 -183.3916685
 -183.39041069 -183.39248822 -183.39466654 -183.39334455 -183.38966605
 -183.39076238 -183.39098264 -183.3891939  -183.39057993 -183.39180715
 -183.39028014 -183.39083323 -183.39077739 -183.39099531 -183.39277649
 -183.38893993 -183.38967415 -183.39067717 -183.39165676 -183.39066868
 -183.39264598 -183.38956497 -183.3905703  -183.39014019 -183.38995073
 -183.39008322 -183.38921005 -183.38933723 -183.38929418 -183.38961738
 -183.39206876 -183.39084123 -183.39006276 -183.39132137 -183.39095762
 -183.39098793 -183.39227049 -183.3910693  -183.38946111 -183.39174744
 -183.39022098 -183.3900296  -183.39123189 -183.38906681 -183.39134701
 -183.39220838 -183.39172468 -183.39271203 -183.39134012 -183.39118413
 -183.39089554 -183.38866973 -183.39100205 -183.39257572 -183.39317622
 -183.39185226 -183.39087612 -183.39113226 -183.38970323 -183.39038309
 -183.39145897 -183.38858313 -183.39161021 -183.39112882 -183.38979162
 -183.39132906 -183.38990962 -183.39204562 -183.39113928 -183.39045162
 -183.39202273 -183.39119873 -183.39054104 -183.38933614 -183.39051148
 -183.38917899 -183.39255487 -183.39059734 -183.39172237 -183.39239396
 -183.39014151 -183.39085057 -183.3907273  -183.39246106 -183.38980469
 -183.3900208  -183.39144925 -183.39276729 -183.38950875 -183.39088234
 -183.39037252 -183.39277357 -183.3912363  -183.39108637 -183.39315892
 -183.39119165 -183.39688177 -183.3956271  -183.38722841 -183.39361507
 -183.38412462 -183.38664133 -183.38565381 -183.38083845 -183.37065311
 -183.39585559 -183.38909708 -183.39302678 -183.38861894 -183.39229131
 -183.39960599 -183.38775716 -183.39250466 -183.37050419 -183.39430886
 -183.39282966 -183.39244865 -183.37854914 -183.38794426 -183.36828731
 -183.39642551 -183.38779157 -183.39005849 -183.3926309  -183.38422748
 -183.39608126 -183.38709547 -183.39035454 -183.39675668 -183.39404309
 -183.38811059 -183.39914767 -183.38905917 -183.37319106 -183.38042719
 -183.39567366 -183.3881367  -183.39635961 -183.38637911 -183.38919808
 -183.39333433 -183.39100394 -183.33985349 -183.38787145 -183.38819864
 -183.39300422]
2025-06-23 22:14:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:14:54 INFO Good algorithm:
Algorithm Name: AdaptiveCauchySamplingWithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchySamplingWithArchive
# Description: An evolutionary algorithm using adaptive Cauchy sampling and an archive to escape local optima in multimodal landscapes.
# Code:
class AdaptiveCauchySamplingWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.exploration_rate = 0.2

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        for _ in range(int(self.budget / self.population_size)):
            
            #Selection (Tournament Selection)
            parents = self._tournament_selection(population, fitness_values)

            #Recombination (Cauchy Mutation)
            offspring = self._cauchy_recombination(parents)

            #Archive Management
            self._update_archive(offspring, objective_function)

            #Adaptive Exploration
            self._adaptive_exploration(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            #Update best solution
            self._update_best(offspring, offspring_fitness)

            self.gamma *= self.gamma_decay


        if self.best_solution_overall is None and self.dim > 0:  # Fallback
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.gamma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, objective_function):
        offspring_fitness = objective_function(offspring)
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]


    def _adaptive_exploration(self, offspring):
        num_explore = int(self.exploration_rate * len(offspring))
        for i in range(num_explore):
            if len(self.archive) > 0:
                random_solution = np.random.choice(len(self.archive))[0]
                offspring[i] = self.archive[random_solution][0] + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:14:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:14:54 ERROR Can not run the algorithm
2025-06-23 22:14:54 INFO Run function 13 complete. FEHistory len: 151, AOCC: 0.0000
2025-06-23 22:14:54 INFO FeHistory: [1206642.6350106   407264.76764066  725725.85026184  573755.83766759
  973692.42841973 1077199.09523585  970763.30258753  985758.47311991
 1067811.6092756  1149376.28114223 1066216.36985988 1077550.26725844
 1348285.07389965  846519.25681573 1051596.71018554 1280050.00318611
 1162118.0525637  1042855.89507792  835387.22722145  899615.23817811
 1230749.32235031 1061069.97155814 1190343.52148251 1167941.54211792
  992437.73409165  855603.18796541 1056520.18442849 1225396.92614014
  326805.40387993  995710.82702369 1004799.75970891 1100100.42653214
  772750.64980914  775326.47357288  902774.44921495 1313707.40593815
 1098085.82148224  646058.20915857 1251445.59289098  636827.48150027
 1106389.17141621  639795.69336027 1068632.22553507 1330615.51704709
  699016.88556926 1174951.68232323  604948.46866255 1111854.34276384
  937210.78962573  623875.03294802  613795.54601633  850817.50423078
  713305.0635404  1217721.96650801 1282619.19613375 1010174.77105036
  544418.50226483 1537884.6624603   882099.02907706 1259289.16090443
  654367.1937656  1845961.75233891 1273947.75495694 1280331.22946354
  916941.60966303 1054627.8719242   445083.67472773  952604.80971917
  319910.26273446  810571.54019517  929803.03213246  519948.862285
  683647.61638207 1132944.85744166  972961.89381788 1026344.67541164
  965740.15141047 1080313.85598149  683512.52902225  440299.1259162
 1035613.35048385 1147869.42428023 1268963.88618     753709.03658444
  610038.32094083  855514.68033831 1599402.34001987  636272.73033787
  499952.65365267 1484736.04388778  913012.12338997 1120705.78815023
  809929.34538007  917657.66344251  867182.30734759 1144698.53230136
 1216200.33372716  947926.65758572 1049125.5811714  1042766.79268974
  680686.78138907 5914040.83036793  338849.4166038  2636124.1239655
  753213.41316512 1793089.23402844  706026.80239165 1326140.45457989
 2569697.68501358 1786739.68961097 1588570.50403457 1171160.69882763
  714143.75225959 1441276.23238363  415312.64330272 1534692.8944408
 2245609.66348692 1407801.86102079 1800819.38939438  998763.95485053
  775920.74257956 1551983.77240173 1224957.1012362  2949460.99872142
  568393.76560277 3024727.43407571 1269276.86733531 3609591.61072371
 3693960.28221237 1975702.33885954 4115969.92099475  271609.32949488
 2876365.91837447  681112.17834836 1919849.80426837  842178.35806925
 1343182.1745688   995159.62050832 1885982.54716618  582368.67062791
  881034.83606094 2581026.86925612  387993.79191905  826627.65670031
 2824606.95058818 1770893.12680976  752822.64797302 1431360.63438249
 1964255.33914214  602064.18345617 2362412.85440009]
2025-06-23 22:14:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:14:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:14:54 ERROR Can not run the algorithm
2025-06-23 22:14:54 INFO Run function 18 complete. FEHistory len: 151, AOCC: 0.0000
2025-06-23 22:14:54 INFO FeHistory: [255064.34389681 142840.62327657 148321.39261182 136543.62995397
 138466.93066721 152095.98276914 157748.43301567 135596.98756017
 148578.11883008 148811.53046619 144466.25771102 154397.83664619
 129700.25466935 155981.61478247 157785.65743231 154211.56360335
 145835.61407947 139406.76479225 128925.17368337 133364.22718237
 131513.65333083 160131.2655025  144536.72707838 154545.06277314
 146573.06705269 157133.50700188 139454.48237582 134678.01094472
 150688.74239249 156269.903178   144488.57306691 157973.67536498
 149358.58632498 158610.47402034 142925.82733636 126587.42602052
 144162.21723415 155515.10127315 162376.59151662 142493.03170293
 143862.09682893 151429.38330863 158106.83214948 149629.00149405
 136851.20682344 129508.23012873 161460.30388165 156899.86743487
 148499.61143248 154029.63110467 139252.13263688 146975.71404204
 161330.33330086 142752.37488606 152292.80036896 153476.87479731
 174622.38796574 147128.74305334 150998.55774623 151195.20880596
 144520.33999828 146735.13954135 146115.40016126 170856.40091606
 149309.64580656 142505.64011348 163982.39098701 144328.46072485
 160937.96550192 150560.3171863  162013.48365474 141826.94046548
 150437.54080671 159534.80895877 161553.21762168 150204.12343645
 160796.78627673 159207.43193179 176677.17730493 148235.0460657
 157481.27678263 152386.52284443 145627.36489373 141032.02842705
 136539.1248831  145151.32293839 141755.73976041 150335.34826388
 159366.12657392 144863.54404672 148623.89450996 149765.77985817
 138712.8617582  151417.88211227 143380.98980824 151072.37220461
 141720.22655755 149577.49575054 145033.19141219 132513.4945503
 155273.65418273 150817.35261151 113171.30822487 146575.88730865
 116099.07324692 141515.13693647 123014.24784048 177803.19126036
 126201.64318589 159526.61166045 201842.55824861 179620.70262521
 159411.26011835 156674.76676182 171165.208218   140568.98814002
 165756.4042937  177299.44876798 140453.07126061 145484.07289832
 152573.24732101 165202.4466478  139053.17207923 146618.38365768
 146862.98783988 103759.14778055 220545.77117902 187910.70601071
 120898.52268834 139455.64806809 140701.14026638 135153.32729699
 139498.88924879 160832.07375614 129397.94263466 121965.33405783
 161259.66190026 145139.64241328 140875.69394304 111258.52433285
 169977.5672051  155625.15752062 122788.32657323 127935.20329758
 181673.76743075 118461.70632605 128431.0395359  148839.94784409
 147503.75887272 150286.44061036 136306.24558809]
2025-06-23 22:14:54 INFO Expected Optimum FE: -5000
2025-06-23 22:14:54 INFO Unimodal AOCC mean: 0.1461
2025-06-23 22:14:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:14:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:14:54 INFO AOCC mean: 0.0487
2025-06-23 22:17:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:20:55 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1521
2025-06-23 22:20:55 INFO FeHistory: [-183.29665591 -183.39879434 -183.39315003 ... -183.76586504 -183.69496908
 -183.7749747 ]
2025-06-23 22:20:55 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:20:55 INFO Good algorithm:
Algorithm Name: ArchiveGuidedCauchyDE
import numpy as np
from scipy.stats import cauchy
import random

# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.99
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(population, i)
                trial = self._crossover(population[i], mutant)
                trial = self._cauchy_mutation(trial)  # Cauchy mutation
                trial = self._bound_solution(trial)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    offspring.append(population[i])

            population = np.array(offspring)
            self._update_archive(population, fitness_values)
            self.gamma *= self.gamma_decay

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[best_index]
                self.best_solution_overall = population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _generate_mutant(self, population, i):
        a, b, c = self._select_different_individuals(i, self.population_size)
        mutant = population[a] + self.F * (population[b] - population[c])
        return mutant

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _cauchy_mutation(self, solution):
        solution += cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
        return solution

    def _bound_solution(self, solution):
        return np.clip(solution, self.lower_bounds, self.upper_bounds)

    def _select_different_individuals(self, i, pop_size):
        while True:
            a, b, c = random.sample(range(pop_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        combined = sorted(combined, key=lambda x: x[-1])

        if len(self.archive) < self.archive_size:
            self.archive.extend(combined[:self.archive_size - len(self.archive)])
        else:
            self.archive = combined[:self.archive_size] #Efficiently replace the whole archive
2025-06-23 22:20:55 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:21:08 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:08 INFO FeHistory: [2930641.13307255 2734682.15327689 1063204.19047542 ... 2611215.25756933
 4498776.043295   2480312.1811797 ]
2025-06-23 22:21:08 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:08 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:21:42 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:42 INFO FeHistory: [163386.62613758 130537.38313857 137522.80291079 ...  34814.85547251
  59493.4679758   45544.62394316]
2025-06-23 22:21:42 INFO Expected Optimum FE: -5000
2025-06-23 22:21:42 INFO Unimodal AOCC mean: 0.1521
2025-06-23 22:21:42 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:21:42 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:21:42 INFO AOCC mean: 0.0507
2025-06-23 22:23:27 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:23:40 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1614
2025-06-23 22:23:40 INFO FeHistory: [-183.40536679 -183.36953263 -183.29499723 ... -184.49445063 -184.49445063
 -184.49445063]
2025-06-23 22:23:40 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:23:40 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyArchiveEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to maintain solution diversity for efficiently navigating multimodal landscapes.
# Code:

class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 0.1  #Initial Cauchy scale parameter
        self.gamma_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        for i in range(self.population_size):
            self._update_archive(population[i], fitness_values[i])

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._cauchy_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            for i in range(len(offspring)):
                self._update_archive(offspring[i], offspring_fitness[i])
            
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        offspring += cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

2025-06-23 22:23:40 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:23:53 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:23:53 INFO FeHistory: [3.44348076e+05 1.97649709e+06 2.92046223e+06 ... 6.34239649e+02
 6.34239649e+02 6.34239649e+02]
2025-06-23 22:23:53 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:23:53 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:26 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:24:26 INFO FeHistory: [144930.57042962 182445.94839902  80644.82598398 ...  20113.85205655
  20113.85205655  20113.85205655]
2025-06-23 22:24:26 INFO Expected Optimum FE: -5000
2025-06-23 22:24:26 INFO Unimodal AOCC mean: 0.1614
2025-06-23 22:24:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:26 INFO AOCC mean: 0.0538
2025-06-23 22:26:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:26:38 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1648
2025-06-23 22:26:38 INFO FeHistory: [-183.32669066 -183.33780073 -183.37294096 ... -184.67183549 -184.67183549
 -184.67183549]
2025-06-23 22:26:38 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:26:38 INFO Good algorithm:
Algorithm Name: ArchiveGuidedCauchyDEwithTournamentSelection
import numpy as np
from scipy.stats import cauchy

class ArchiveGuidedCauchyDEwithTournamentSelection:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection 
    for robust multimodal optimization in high-dimensional spaces.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._tournament_selection(population, fitness)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness[:len(new_population)])
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _tournament_selection(self, population, fitness):
        tournament = np.random.choice(len(population), self.tournament_size, replace=False)
        winner_index = tournament[np.argmin(fitness[tournament])]
        return population[winner_index], population[np.random.choice(len(population),1,replace=False)[0]], population[np.random.choice(len(population),1,replace=False)[0]]


    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < 0.5, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

2025-06-23 22:26:38 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:26:54 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:26:54 INFO FeHistory: [ 817721.5724529   935850.4266045  2081467.59746435 ...  397991.84199467
    4947.21935187    4947.21935187]
2025-06-23 22:26:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:26:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:27:31 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:31 INFO FeHistory: [105353.85790876 132854.74101066 175577.6212017  ...  -3289.35590629
  -3289.35590629  -3289.35590629]
2025-06-23 22:27:31 INFO Expected Optimum FE: -5000
2025-06-23 22:27:31 INFO Unimodal AOCC mean: 0.1648
2025-06-23 22:27:31 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:27:31 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:27:31 INFO AOCC mean: 0.0549
2025-06-23 22:27:31 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:27:44 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1627
2025-06-23 22:27:44 INFO FeHistory: [-183.43565072 -183.30114399 -183.34829821 ... -184.63890879 -184.63890863
 -184.63890966]
2025-06-23 22:27:44 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:27:44 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Combines Differential Evolution, adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])

            # Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
2025-06-23 22:27:44 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:27:57 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:57 INFO FeHistory: [2.43992121e+06 2.73038332e+06 1.62009683e+06 ... 2.44141617e+03
 2.44141618e+03 2.44141617e+03]
2025-06-23 22:27:57 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:27:57 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:28:30 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:28:30 INFO FeHistory: [111533.11019147 128303.893716   155162.3626073  ...   2478.63528515
   2478.63528114   2478.63542217]
2025-06-23 22:28:30 INFO Expected Optimum FE: -5000
2025-06-23 22:28:30 INFO Unimodal AOCC mean: 0.1627
2025-06-23 22:28:30 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:28:30 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:28:30 INFO AOCC mean: 0.0542
2025-06-23 22:29:28 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:29:28 ERROR Can not run the algorithm
2025-06-23 22:29:29 INFO Run function 6 complete. FEHistory len: 301, AOCC: 0.1473
2025-06-23 22:29:29 INFO FeHistory: [-183.37710569 -183.35626503 -183.37343406 -183.35208007 -183.3072701
 -183.28142612 -183.35459648 -183.3990117  -183.27072028 -183.32742639
 -183.34641274 -183.3774268  -183.40599056 -183.34845652 -183.3094985
 -183.36449265 -183.30257556 -183.29374431 -183.42533514 -183.29446924
 -183.39931897 -183.3428812  -183.38413755 -183.28610117 -183.3757001
 -183.29908283 -183.3533885  -183.2515038  -183.34651289 -183.37702587
 -183.36252628 -183.35226023 -183.38644464 -183.34213351 -183.4698732
 -183.38511232 -183.47551728 -183.35440016 -183.42849143 -183.26818262
 -183.29416699 -183.35024544 -183.35758296 -183.34466779 -183.26517544
 -183.36443449 -183.2947607  -183.28117632 -183.31405778 -183.41987946
 -183.29392985 -183.34532701 -183.33909793 -183.33019516 -183.36884908
 -183.33547075 -183.41716718 -183.29314934 -183.3562877  -183.36836122
 -183.29885837 -183.37418674 -183.35017075 -183.28253716 -183.44492103
 -183.29498111 -183.37389856 -183.49934504 -183.26314655 -183.46079971
 -183.33642236 -183.3501577  -183.36659433 -183.40610717 -183.31937993
 -183.29909533 -183.30059364 -183.35770471 -183.3485087  -183.29164462
 -183.44080123 -183.32577884 -183.40292392 -183.39344138 -183.37931512
 -183.35544358 -183.33047768 -183.36697634 -183.34221446 -183.34765758
 -183.45290424 -183.3715414  -183.32139415 -183.43678924 -183.34870077
 -183.38870927 -183.36599731 -183.39417718 -183.39964888 -183.3648072
 -183.35917765 -183.43405017 -183.39260995 -183.27823945 -183.39904844
 -183.34255485 -183.31734418 -183.39854131 -183.30602351 -183.38562538
 -183.38185918 -183.38250218 -183.26266763 -183.34676469 -183.26394079
 -183.33978133 -183.23057792 -183.32657209 -183.31781655 -183.33605758
 -183.34895537 -183.34957038 -183.28637643 -183.32960382 -183.3847373
 -183.31133907 -183.29181453 -183.25240458 -183.34138104 -183.27938918
 -183.41347919 -183.30095852 -183.4298041  -183.48355651 -183.38068255
 -183.3269807  -183.454643   -183.46214488 -183.35069836 -183.37182968
 -183.35879595 -183.29443865 -183.28394044 -183.24147123 -183.29261251
 -183.32268429 -183.41107111 -183.35771726 -183.31977812 -183.29585138
 -183.37080021 -183.28000247 -183.2788974  -183.34279185 -183.28928552
 -183.35233018 -183.33324441 -183.36184802 -183.32911662 -183.27360503
 -183.31038496 -183.28776263 -183.32682247 -183.33368835 -183.29610062
 -183.29830541 -183.35495857 -183.312884   -183.29312232 -183.39653901
 -183.28293046 -183.37842877 -183.37387088 -183.33971613 -183.27978739
 -183.25395628 -183.34003955 -183.33543088 -183.39480986 -183.24077628
 -183.26927204 -183.409486   -183.37948614 -183.22655693 -183.34088033
 -183.40997281 -183.33313811 -183.35522828 -183.2803737  -183.42004449
 -183.24641713 -183.34482306 -183.3166051  -183.32613643 -183.36428728
 -183.43388202 -183.29065857 -183.36003649 -183.40784731 -183.31928391
 -183.37253154 -183.40034836 -183.31967004 -183.36532228 -183.37834681
 -183.35832782 -183.37583945 -183.37136726 -183.340189   -183.35203299
 -183.35165505 -183.38804254 -183.35176665 -183.28881772 -183.421114
 -183.43838583 -183.33203183 -183.3343549  -183.37245207 -183.38594352
 -183.38267177 -183.35551226 -183.37038653 -183.32817866 -183.35883635
 -183.31917611 -183.34515953 -183.44132612 -183.33785344 -183.3867068
 -183.3284962  -183.36308237 -183.30300021 -183.29758858 -183.37197504
 -183.33470333 -183.45455585 -183.39136064 -183.42915009 -183.42169245
 -183.31238418 -183.41170634 -183.338424   -183.36283306 -183.39496545
 -183.33624169 -183.32891694 -183.2904223  -183.35521819 -183.40157294
 -183.30895392 -183.32716189 -183.37775826 -183.32400212 -183.36018479
 -183.41696304 -183.35122343 -183.33902843 -183.3594938  -183.37225308
 -183.33465488 -183.41296148 -183.30935533 -183.37954707 -183.42178808
 -183.34012971 -183.32240589 -183.29572482 -183.34550815 -183.45700703
 -183.32879811 -183.3560945  -183.4410096  -183.36773998 -183.43098907
 -183.39490189 -183.30469495 -183.3409535  -183.35264537 -183.43741832
 -183.41062796 -183.3933722  -183.36169176 -183.34644251 -183.4028679
 -183.33784903 -183.37620205 -183.39395032 -183.38929185 -183.34710646
 -183.35177804 -183.36435709 -183.31860273 -183.29706685 -183.3394255
 -183.34702019 -183.35849632 -183.36908422 -183.34560313 -183.30735193
 -183.47804423]
2025-06-23 22:29:29 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:29:29 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential evolution with adaptive mutation and an archive to escape local optima.
# Code:
class AdaptiveDifferentialEvolutionWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.5  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.F_scale = 1.1 # Scaling factor for F

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutation(a, b, c)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _mutation(self, a, b, c):
        mutant = a + self.F * (b - c)
        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        child = np.where(crosspoints, mutant, parent)
        return child

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.concatenate((self.archive, population)) if self.archive else population
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness_values)) if self.archive else fitness_values
        sorted_indices = np.argsort(combined_fitness)
        self.archive = [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]
    

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Simple Adaptive F based on average fitness improvement
        if len(self.archive) > 0:
            avg_archive_fitness = np.mean([x[1] for x in self.archive])
            avg_pop_fitness = np.mean(fitness_values)
            improvement = avg_archive_fitness - avg_pop_fitness
            self.F = max(0.1, min(1.0, self.F + 0.01*improvement))  # Keep F within reasonable bounds
            self.F = min(self.F * self.F_scale,1.0) #Cap the value of F for better exploration, otherwise the algorithm might over-exploit
            

2025-06-23 22:29:29 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:29:29 ERROR Can not run the algorithm
2025-06-23 22:29:29 INFO Run function 13 complete. FEHistory len: 301, AOCC: 0.0000
2025-06-23 22:29:29 INFO FeHistory: [1346914.97598968 1686594.30719036 2226020.44506149 2717989.07324461
 2338561.22634098 1763111.7121591  2823568.57948886  832457.69029358
 1343957.80627842 1428832.57498154 1935788.25415018 1657941.70404592
 1826024.54523188 2065740.73776896 4034526.64400271 2515688.88879766
 2164752.38128726 7679954.15316226  978837.0327438   933406.86901758
 1268604.18743486  780913.51212841 1598993.88385312 2077334.53024611
 5349053.11372151 1621721.63380388 4329145.69803974 1856234.10646508
 1844174.47764148 2779306.26581717 2349108.30469899  822427.74211679
 1362158.95602289 1831835.4741072  1313051.79851978 1353051.12835035
 1093273.33210253  692538.92326488 2616655.54078987  162198.8402784
 1160962.63155222 1340984.80670362 3020109.81288255 1965562.92426587
 3525875.77518628 1293001.20410831 3028233.1763495   747221.06318807
  979602.92667027 1057280.91471024 1407009.27867942 3982509.20468761
 1127624.59623177 1229067.73402605 1701379.72587672 2732525.91017119
 1435480.78857799 2264139.06157984 2080211.61282728 2095464.37164643
 1276342.87782807 1140605.12430922 3546711.41214264 1574247.82041139
 1468647.37271985 2376966.23539186  337096.91374261 1928045.02451714
 4743076.62089362 1803446.88901019 3009991.68045589 3226490.23991686
 2612572.17949817 1008160.83994516 1660745.30681547 1591812.70714259
  987831.68840361 1976739.81726161 3521721.98662158 1456089.47788341
 2575709.75334202 2389846.72041779 3075425.20540892 2671370.7823755
 2141286.8708087  1102124.81607327 1194250.53956076 3506250.07360436
 2615819.51817871 2000394.57589614 2606790.67924219  984366.3709127
 2854575.03045603 1610888.63227924 2267648.95531429 1520631.41167797
  874354.63626333 1999607.76287842 2231542.80431335 4008955.17722844
 1185587.18550816 3563421.50155044 1801297.36894162 2323297.57667082
 1304785.12778098  471473.18655273 1567979.53520896 2390271.31813602
 1917587.61646974 1453766.80504252 1470633.06224519 2868850.7198678
 1416631.79181286 2421982.74179462 3261531.46523187 3092106.87794398
 1616240.83268244 5588154.01434891 1171712.79430607 2205280.82748551
 2801825.89933397 1211428.44802153 1978736.75989235 2179311.93462167
 1587021.88909356 2103744.93118504 5109524.78623698 1493825.71563604
  816664.06525803 2011646.24945349 2264831.19870078 4546430.46906644
 1589932.1940339  2262640.91203464 2389474.76860794 1762710.39384248
 2194584.54305604 2071722.42140572 3672529.88256451 1462146.3077595
  809565.75754154 4108055.27817389 4111201.79422602 2094776.77932958
 1345652.24740909 2048932.8903563  1757609.65737119 4102845.76502265
 1848941.0346407  1681494.15536208 2304502.30712818 2147767.75923799
 2157502.31188772 1929583.2116027  1805145.35881628 2175200.11440215
 1134376.1019693  1585497.33889767 1006247.88811852 1581293.89304624
 1548670.20737081  796968.63568523 4148532.84193928 2417378.53790066
 2042819.78683626 1283828.09471138  630268.42098411 1423338.16556053
 1438137.25320161 3457959.06508805  896092.44720146 1711206.13132133
 2741650.1149053  2107107.10304447 4416888.39629939 1594823.99590349
  698862.54624988 1179037.9025717   728099.06834635  952706.0711716
  943708.75660021 2661099.2178683  1474415.41524494  646845.01661914
  992950.49229979 1004526.53598748 2774370.41181221  928350.43026428
 1548259.73674114 2169631.78896481 2153949.94919593 1000644.96110957
 1273466.64039308 3061287.46956581 2606300.68154769  830325.44699017
 1303498.0521625  1311720.11159521  807177.60604557 2048343.46219779
 1770943.59706548 3383007.21394381 1729467.74809354 1055827.99493675
 1972881.01344417 1266137.97922251 1694091.5134471   919969.73096276
 1208781.63580526 2323882.20307118  698818.67805182  863877.52638189
  846415.45387696 2617739.34547892  831327.06581251 2482995.58607226
 2909654.39072817 2749796.48456535 2232372.09188041 2899121.39701288
 2270168.04282824 1268794.38144167  648666.56437831 3735031.09307741
  284942.88241619 3075176.41004458 2079538.0920931  1188017.82492029
 1025377.68662084 1777316.19484267  935383.4018997  1902073.865863
 1662784.04865541 1958079.51595419 3401098.2527817  2142123.37479254
 2686002.36763792 3897109.76008622  780229.88734882  437880.71125781
 1473962.57877487 2070760.46489665 2491136.9506668  1442323.13146539
 2258522.18590276 1949231.89498115 1487359.82189282  680632.86642492
 2035683.86272642 2332666.84421671  812461.65783289 1472951.87163595
 1942326.7284476  1797880.17075678 2930484.15170708 2142586.84835003
 2083094.43094017 1614173.59093852 2396334.82718664 1720754.99396927
 2713783.1298696  1725695.46749594 3110420.87393242 1117059.55240729
 3262737.48219885 4002938.51833982 2217591.29079674 2725267.26088732
 2176813.56692752 1661810.2438831  1671457.27927096 1835719.96924267
  440126.61804245 3075669.62965711 2013117.47061066 1725821.03637115
 2205799.27642718 2725473.23772194 1351558.0119753  2406919.56033404
 1135611.1969717  1912986.51978456 4688158.39051139 3375383.66849743
 3263316.99283763  725948.75935533 1992200.15916399 2093820.39281619
 1733997.91855001 1053242.86486572 1605525.46505035 1900890.17951973
  512496.16442443  256763.9491436   763359.17736617 2538379.0199476
  924051.88319344 1455374.32700709  720891.74078684 2819301.23819695
 2296091.54161919]
2025-06-23 22:29:29 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:29:29 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:29:29 ERROR Can not run the algorithm
2025-06-23 22:29:29 INFO Run function 18 complete. FEHistory len: 301, AOCC: 0.0000
2025-06-23 22:29:29 INFO FeHistory: [ 93391.52299089 119064.44478927 145966.4594422  109282.78018436
 156926.84111249 191380.33443793 130434.70504832 153238.4908106
 102370.76483766 159590.39469499 134198.84930635 133152.86794039
 104974.12894102 147170.88728538 192427.28449341 137370.82773188
 142926.43440307 112258.30086859 142158.83612124 111127.14539249
 227592.88799208 158301.30953011 178997.73133431 155956.27796314
 153439.32752918 204892.16809913 172624.33149572 132903.72944492
 156938.78543094 195530.28755766 166576.31154021  76069.00016901
 100521.15018962 144708.71616871 158675.87098246 147446.6803005
 186124.87618677 160772.55918868 153370.6927027  178779.04572243
  75520.01948183 165928.36169072 178566.40644129 157107.21228365
 148167.02229099 164883.91829732  82842.49446031 215481.87252901
 206392.9459109  139720.57433865 170011.93625269 146195.30690644
 177832.13427496 194139.59843113 193591.38961304 229825.62214558
 162824.58244568 165835.5089067  159806.63402239 203012.77534953
 150381.8948465  127513.58382907 127403.20444553 128496.94882561
 182864.59480058 132519.42407874 147834.08890462 164417.079401
 203016.53134155 116616.34171681 224163.34912119 129595.89155175
 140163.6656019  169010.19732797 120191.66659561 123066.86510552
 214710.96708345 144342.25051985 153083.95284794 217984.86391402
  89484.37044794 122109.59166339 137579.91366228 153708.50995431
 174980.0389724  178980.36829258 164205.87352671 144782.31713013
 173149.44663529 133736.67180978 168404.79931287 168684.01678626
 188545.79353534 156813.79763083 232398.60751567 212070.761667
 184002.4674901  153827.81368442 168416.01536987 235090.8834015
 149892.79878797 155386.3488706  192141.02916417 160087.29270044
 204675.66030713 138454.09936615 142912.38075764 185537.79914788
 124451.61022322  96472.54869397 128296.54823252 172706.33808868
 169692.60587305 165576.81753803 178146.1597986  150530.46136929
 244545.28188784 118642.13733102 160398.69906843 198105.89465502
 147675.3342118  194581.51050499 208999.3217817  158060.81646786
 208581.46716577 171040.80840697 193155.985202   132316.15477558
 233338.82404106 259787.66916755 208905.87105273 172734.50709973
 156946.54611252  92295.55492015 182723.04572656 158970.52380706
 178229.99403099 204976.7178341  107557.56991232 209135.10055118
 168142.55737948 107697.17872282 195675.38004473 191140.59497285
 150049.7879906  147653.00448857 132017.03106627 180433.85961997
 166500.37887794 223427.73618215 184971.38746233 144086.54267569
 145465.26223566 154383.69749146 184651.53502463 141187.78330224
 223529.6887823  158031.34709841 131762.05562267 264025.13264465
 113286.18471738 142843.220039   144050.23024756 199174.50505059
 132616.52442458 181015.68343982 153376.32502954 187938.87265482
 149475.97146142 134163.01675662 215298.52542835 168406.72515903
 144086.16785246 157144.86516818 189777.3382946  171021.40904077
 106773.2921957  125602.45756646 164526.34731417 173844.66454993
 274899.4000869  182501.90617643 167869.51337894 150175.59516973
 133996.0841787  162761.69936127 289589.06300761 161360.27676309
 123670.07815578 138939.75940547 170379.00281493 168791.1730082
 175580.22326386 273119.91735214 159253.74883981 149675.33822293
 137196.42276893 138255.03437851 221445.39548295 100284.50649379
 167281.52689093 157826.9107643  114143.76508529 111851.1642367
 185766.69399397 211488.88468069 171619.95153846 139368.23006861
 183209.9475042  157576.14627692 103493.09052209 201668.85788445
 144418.68936127 177604.0469821  122840.47115042 131479.53991452
 136539.81068615 106040.42366692 167942.55008156 153519.86288811
 162578.319005   144978.19119074 233010.31440193 163594.48151773
 165101.57540574 135457.32725735 171494.55413684 124914.34428704
 209178.41854054 183915.32186132 172121.66081073 142408.94199162
 133775.75348573 155567.63125124 117806.55760941 143085.60235078
 107829.9630616   99204.50177598 122608.4983532  106336.7150032
  75656.49671641 179989.70834962 214682.79210748 172504.11980575
 142698.02976395 106429.23957441 134627.06196911 111406.78881798
 152175.15526354  88002.58987074 152595.65912212 158980.90684459
  92683.58523872 147019.42364928  96289.47120662 125566.46102745
  86522.48644514 209327.226598   147637.52024551 123537.84162922
 134397.53008979 131680.77034018  98172.44659083 223994.35772739
 179616.94785702 146056.74947627 143055.1541139  119450.1392682
 204482.47559197 220826.58079433 196422.66117417 106882.81353376
 174373.24305676 132498.00057153 135440.78951198 161921.31338703
 137908.81045577 163752.61932088 212610.34366499 129489.0358353
 120361.16765827 127289.72994058 169261.89004809 179681.57269945
 142079.17378271 235317.67002297 108009.71063414 216997.48539367
 189379.8921735   98857.11847408 152545.63441474 121476.81917557
 138816.24828017 196222.35458582 123000.79710614 229186.2699038
 129726.83573099 176250.91494325 140035.25429315 159145.72364521
 191924.82444328]
2025-06-23 22:29:29 INFO Expected Optimum FE: -5000
2025-06-23 22:29:29 INFO Unimodal AOCC mean: 0.1473
2025-06-23 22:29:29 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:29:29 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:29:29 INFO AOCC mean: 0.0491
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:32 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1636
2025-06-23 22:32:32 INFO FeHistory: [-183.38441407 -183.34467684 -183.37403303 ... -184.73224488 -184.73224461
 -184.73224389]
2025-06-23 22:32:32 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:32 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentSelectionAndArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelectionAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive to maintain diversity for multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelectionAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5 #tournament size
        self.archive_size = 100 #Archive size
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter
            self._update_archive(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _update_archive(self, population, fitness):
        #add to archive, maintaining diversity
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))
        
        #Maintain archive size
        self.archive.sort(key=lambda item:item[1])
        self.archive = self.archive[:self.archive_size]
2025-06-23 22:32:32 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:45 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:32:45 INFO FeHistory: [ 364334.23031703 1258678.57911796 1765284.42455274 ...    2278.83374903
    2278.8339203     2278.83193784]
2025-06-23 22:32:45 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:45 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:33:17 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:33:17 INFO FeHistory: [168886.20914873 191919.10379939 157460.56738645 ...   6218.98331605
   6218.9832554    6218.98333038]
2025-06-23 22:33:17 INFO Expected Optimum FE: -5000
2025-06-23 22:33:17 INFO Unimodal AOCC mean: 0.1636
2025-06-23 22:33:17 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:33:17 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:33:17 INFO AOCC mean: 0.0545
2025-06-23 22:34:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:02 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1753
2025-06-23 22:35:02 INFO FeHistory: [-183.29452877 -183.38642125 -183.39524026 ... -185.67776716 -185.67452659
 -185.67579841]
2025-06-23 22:35:02 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:02 INFO Good algorithm:
Algorithm Name: ArchiveEnhancedCauchyEA
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Tournament Selection
            parents = self._tournament_selection(population, fitness_values)

            # Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            # Evaluate offspring
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Next Generation Selection
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            #Update Best
            self._update_best(offspring, offspring_fitness)

            #Adapt Cauchy parameter
            self.gamma *= 0.99 #Decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + np.random.standard_cauchy(size=parents.shape) * self.gamma
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)


    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive.sort(key=lambda x: x[1])
        self.archive = self.archive[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:35:02 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:11 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:35:11 INFO FeHistory: [2335750.6716327  2368735.70296116 1864469.52751645 ...    2433.12988435
    2433.12989059    2433.12981632]
2025-06-23 22:35:11 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:11 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:40 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:35:40 INFO FeHistory: [ 76250.69677246 153732.88740133 115748.75918758 ...  13797.00958633
  13797.00903609  13797.00862653]
2025-06-23 22:35:40 INFO Expected Optimum FE: -5000
2025-06-23 22:35:40 INFO Unimodal AOCC mean: 0.1753
2025-06-23 22:35:40 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:40 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:40 INFO AOCC mean: 0.0584
2025-06-23 22:37:41 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:54 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1642
2025-06-23 22:37:54 INFO FeHistory: [-183.32847477 -183.36186182 -183.38231889 ... -184.75317389 -184.75316163
 -184.75316652]
2025-06-23 22:37:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:37:54 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithTournamentSelectionAndAdaptiveArchive
# Name: AdaptiveDEwithTournamentSelectionAndAdaptiveArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an adaptive archive for enhanced multimodal optimization.
# Code:
import numpy as np
from scipy.stats import cauchy

class AdaptiveDEwithTournamentSelectionAndAdaptiveArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5 #tournament size
        self.archive_size = 100 #Archive size
        self.archive = []
        self.archive_diversity_threshold = 0.1 # Threshold to trigger archive adaptation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter
            self._update_archive(population, fitness)
            self._adapt_archive()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _update_archive(self, population, fitness):
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))

    def _adapt_archive(self):
        if len(self.archive) > self.archive_size:
            # Adaptive archive size control based on diversity
            self.archive.sort(key=lambda item: item[1])
            self.archive = self.archive[:int(self.archive_size * (1 + self.archive_diversity_threshold))]
            

2025-06-23 22:37:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:38:06 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:06 INFO FeHistory: [2.13186247e+06 1.22541236e+06 2.98017960e+06 ... 2.74173513e+03
 2.74173505e+03 2.74173446e+03]
2025-06-23 22:38:06 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:38:06 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:38:39 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:39 INFO FeHistory: [141808.38092144 150239.6737471  119767.54764071 ...   6538.67472657
   6538.67475796   6538.6747408 ]
2025-06-23 22:38:39 INFO Expected Optimum FE: -5000
2025-06-23 22:38:39 INFO Unimodal AOCC mean: 0.1642
2025-06-23 22:38:39 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:38:39 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:38:39 INFO AOCC mean: 0.0547
2025-06-23 22:38:39 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:38:51 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1666
2025-06-23 22:38:51 INFO FeHistory: [-183.2986425  -183.40567268 -183.29148036 ... -185.01930975 -185.01696792
 -185.01448781]
2025-06-23 22:38:51 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:38:51 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithEnhancedTournamentAndArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithEnhancedTournamentAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, enhanced tournament selection, and a refined archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithEnhancedTournamentAndArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an enhanced tournament selection 
    with adaptive scaling, and an archive for robust multimodal optimization in high dimensions.  
    The algorithm incorporates a refined archive management strategy and adaptive tournament size.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, 
                 tournament_size_init=5, tournament_size_decay=0.98):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size_init
        self.tournament_size_decay = tournament_size_decay
        self.F = 0.5 #Differential Evolution scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._enhanced_tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.gamma *= self.gamma_decay
            self.tournament_size = int(max(2, self.tournament_size * self.tournament_size_decay)) #Adaptive tournament size

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            #Crossover with parent
            offspring[i] = np.where(np.random.rand(self.dim) < self.cr, offspring[i], population[i])
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _enhanced_tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

2025-06-23 22:38:51 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:39:04 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:39:04 INFO FeHistory: [2052364.78917283 1994062.61165515 3297556.71259128 ...  688092.65256006
   53066.07034953  607668.18608378]
2025-06-23 22:39:04 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:39:04 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:39:37 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:39:37 INFO FeHistory: [145360.33393394 189125.01676546 198335.86477288 ...  -4452.43623454
  -4452.43638875  -4452.43689885]
2025-06-23 22:39:37 INFO Expected Optimum FE: -5000
2025-06-23 22:39:37 INFO Unimodal AOCC mean: 0.1666
2025-06-23 22:39:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:39:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:39:37 INFO AOCC mean: 0.0555
2025-06-23 22:40:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:40:33 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1517
2025-06-23 22:40:33 INFO FeHistory: [-183.32215493 -183.36980072 -183.43478295 ... -183.66624146 -183.6791162
 -183.63987904]
2025-06-23 22:40:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:40:33 INFO Good algorithm:
Algorithm Name: AdaptiveLevyFlightWithDifferentialEvolution
import numpy as np
import random

# Name: AdaptiveLevyFlightWithDifferentialEvolution
# Description: Combines adaptive Levy flights for global exploration with differential evolution for local exploitation and utilizes a niching strategy to maintain diversity.
# Code:
class AdaptiveLevyFlightWithDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.levy_alpha = 1.5  # Levy flight exponent
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._niching_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Levy Flight Exploration
            levy_step = self._levy_flight(self.levy_alpha, self.dim)
            new_solution = population[i] + 0.1*levy_step * (self.upper_bounds - self.lower_bounds)  #scale levy step
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)

            # Differential Evolution Exploitation
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, new_solution)
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _levy_flight(self, alpha, dim):
        # Generates a Levy flight step using Mantegna's algorithm.
        u = np.random.normal(0, 1, dim)
        v = np.random.normal(0, 1, dim)
        step = u / (np.abs(v)**(1/alpha))
        return step

    def _niching_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        selected_population = []
        selected_fitness = []
        
        while len(selected_population) < self.population_size:
            best_index = np.argmin(combined_fitness)
            best_solution = combined_population[best_index]
            best_fitness = combined_fitness[best_index]
            
            selected_population.append(best_solution)
            selected_fitness.append(best_fitness)
            
            combined_population = np.delete(combined_population, best_index, axis=0)
            combined_fitness = np.delete(combined_fitness, best_index)

        return np.array(selected_population), np.array(selected_fitness)


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

2025-06-23 22:40:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:40:46 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:40:46 INFO FeHistory: [ 799172.26668637 1994739.97136203 2082520.68923737 ...  973314.30113199
 1953445.27272821 4639068.49649994]
2025-06-23 22:40:46 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:40:46 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:18 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:41:18 INFO FeHistory: [174124.16015938 147378.49010911 138214.36622422 ...  31624.73137746
  53670.08353955  57514.24414741]
2025-06-23 22:41:18 INFO Expected Optimum FE: -5000
2025-06-23 22:41:18 INFO Unimodal AOCC mean: 0.1517
2025-06-23 22:41:18 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:18 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:18 INFO AOCC mean: 0.0506
2025-06-23 22:43:24 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:43:34 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1608
2025-06-23 22:43:34 INFO FeHistory: [-183.24496175 -183.28599509 -183.43468654 ... -184.4562979  -184.4562979
 -184.4562979 ]
2025-06-23 22:43:34 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:43:34 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Combines DE, adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = 5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
2025-06-23 22:43:34 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:43:45 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:43:45 INFO FeHistory: [1.57881366e+06 2.27158473e+06 8.08903455e+05 ... 1.93173145e+03
 1.93173145e+03 1.93173145e+03]
2025-06-23 22:43:45 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:43:45 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:44:16 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:16 INFO FeHistory: [223022.39215554 108611.00635395 133373.76220476 ...   5995.00231412
   5995.00231411   5995.00231411]
2025-06-23 22:44:16 INFO Expected Optimum FE: -5000
2025-06-23 22:44:16 INFO Unimodal AOCC mean: 0.1608
2025-06-23 22:44:16 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:44:16 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:44:16 INFO AOCC mean: 0.0536
2025-06-23 22:44:16 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:44:26 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1588
2025-06-23 22:44:26 INFO FeHistory: [-183.45179769 -183.27043359 -183.3135749  ... -184.34800308 -184.34800308
 -184.34800308]
2025-06-23 22:44:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:44:26 INFO Good algorithm:
Algorithm Name: AdaptiveDECauchyWithArchiveTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDECauchyWithArchiveTournament
# Description: Combines DE, adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDECauchyWithArchiveTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
2025-06-23 22:44:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:44:37 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:37 INFO FeHistory: [2.70687164e+06 1.27477988e+06 1.20998678e+06 ... 1.21295038e+03
 1.21295038e+03 1.21295038e+03]
2025-06-23 22:44:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:44:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:45:07 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:45:07 INFO FeHistory: [133319.32681645 170292.23626343 159847.30231355 ...   1105.7706223
   1105.7706223    1105.7706223 ]
2025-06-23 22:45:07 INFO Expected Optimum FE: -5000
2025-06-23 22:45:07 INFO Unimodal AOCC mean: 0.1588
2025-06-23 22:45:07 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:45:07 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:45:07 INFO AOCC mean: 0.0529
2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:46:20 ERROR Can not run the algorithm
2025-06-23 22:46:20 INFO Run function 6 complete. FEHistory len: 201, AOCC: 0.1466
2025-06-23 22:46:20 INFO FeHistory: [-183.36119904 -183.32637512 -183.34864326 -183.34950349 -183.33055677
 -183.36849809 -183.31312048 -183.2883333  -183.27583912 -183.39062071
 -183.28642027 -183.27174552 -183.2755029  -183.36177535 -183.31019729
 -183.35800506 -183.26794005 -183.31833618 -183.30681877 -183.30654971
 -183.30582668 -183.27581672 -183.36723978 -183.31034836 -183.32984349
 -183.30134507 -183.36971375 -183.25486524 -183.31333039 -183.35093252
 -183.28621291 -183.29830652 -183.29880816 -183.34585232 -183.29817158
 -183.32924191 -183.32647666 -183.28487916 -183.33111731 -183.25849178
 -183.34578744 -183.34891248 -183.27003828 -183.2755872  -183.34497245
 -183.30333767 -183.3264816  -183.32544155 -183.32105362 -183.35259807
 -183.33923413 -183.35838891 -183.35029677 -183.32579158 -183.34060455
 -183.34860466 -183.27888025 -183.37671084 -183.26905321 -183.36266017
 -183.27878956 -183.30472345 -183.30817042 -183.30894179 -183.35103469
 -183.33588819 -183.33771869 -183.28049975 -183.31332035 -183.30064143
 -183.29861758 -183.32102718 -183.33209599 -183.3426969  -183.38733179
 -183.278644   -183.27706471 -183.32597567 -183.33940911 -183.32634562
 -183.2998024  -183.31618241 -183.27866097 -183.30940947 -183.28821766
 -183.32843864 -183.29043671 -183.38167161 -183.37839433 -183.29581746
 -183.35881567 -183.31340156 -183.33418132 -183.30909334 -183.27168952
 -183.34170226 -183.35733958 -183.31612504 -183.26984594 -183.36428093
 -183.30071409 -183.28535131 -183.44416329 -183.38772957 -183.34715014
 -183.30195936 -183.30946904 -183.31421342 -183.34983854 -183.32085283
 -183.31121205 -183.35494358 -183.26996895 -183.32808632 -183.37633862
 -183.32204358 -183.35690504 -183.35517451 -183.32828412 -183.34480311
 -183.36449567 -183.28820527 -183.3716477  -183.26010476 -183.33875321
 -183.29584385 -183.29618368 -183.27989753 -183.34774105 -183.25610959
 -183.33018682 -183.33222768 -183.31173768 -183.27373153 -183.30681958
 -183.41454426 -183.30346368 -183.35194304 -183.31608616 -183.32311387
 -183.37216721 -183.3636561  -183.29938409 -183.29500061 -183.38731987
 -183.34567152 -183.22244405 -183.30699285 -183.27578394 -183.38780914
 -183.35089815 -183.34024971 -183.35318123 -183.31949419 -183.34738083
 -183.34655494 -183.3050821  -183.33574392 -183.30023116 -183.29442229
 -183.35258426 -183.36401867 -183.4170344  -183.32266115 -183.32103323
 -183.36457364 -183.32207114 -183.36976086 -183.29401825 -183.34336762
 -183.37600953 -183.32448763 -183.3267342  -183.36960563 -183.34094101
 -183.33851417 -183.35376103 -183.34869427 -183.31688565 -183.3831218
 -183.42664678 -183.34070644 -183.39285251 -183.33701137 -183.39642107
 -183.39116368 -183.32183523 -183.38450087 -183.30542244 -183.28661692
 -183.38058751 -183.36486955 -183.32096137 -183.33569853 -183.39427825
 -183.33225373 -183.36888662 -183.35932934 -183.39181026 -183.31136301
 -183.35589156]
2025-06-23 22:46:20 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:46:20 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveMultimodalOptimizer
# Description: An evolutionary algorithm combining adaptive Gaussian and Cauchy mutations with dynamic population sizing and niching for multimodal optimization.
# Code:
class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.cauchy_scale = 0.1 * (self.upper_bounds - self.lower_bounds)  # Cauchy mutation scale
        self.niche_radius = 0.5 * np.mean(self.upper_bounds - self.lower_bounds) # initial niche radius
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._update_population(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _generate_offspring(self, population, fitness_values):
        parents = self._tournament_selection(population, fitness_values)
        offspring = self._gaussian_recombination(parents)
        offspring = self._mutate(offspring)
        return offspring

    def _mutate(self, offspring):
        mutation_choice = np.random.rand(len(offspring)) < 0.5 #Half Gaussian, half Cauchy
        offspring[mutation_choice] += np.random.normal(0, self.sigma, size=(np.sum(mutation_choice), self.dim))
        offspring[~mutation_choice] += cauchy.rvs(loc=0, scale=self.cauchy_scale, size=(np.sum(~mutation_choice), self.dim))
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.array(offspring)


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _update_population(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            is_new = True
            for j, archived_sol in enumerate(self.archive):
                if np.linalg.norm(sol - archived_sol[0]) < self.niche_radius:
                    is_new = False
                    if offspring_fitness[i] < archived_sol[1]:
                        self.archive[j] = (sol, offspring_fitness[i])
                    break
            if is_new:
                self.archive.append((sol, offspring_fitness[i]))

    def _adapt_parameters(self, population, fitness_values):
        self.sigma *= self.sigma_decay
        # Adjust niche radius based on population spread
        spread = np.max(np.linalg.norm(population - np.mean(population, axis=0), axis=1))
        self.niche_radius = 0.5 * spread
        # Dynamic population sizing (simple example):
        average_fitness = np.mean(fitness_values)
        if average_fitness < self.best_fitness_overall * 0.8: #increase pop if doing good
            self.population_size = min(self.population_size * 1.1, 500) # limit to 500
        else: #decrease pop if doing bad
            self.population_size = max(int(self.population_size * 0.9), 50) # limit to 50

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:46:20 ERROR Can not run the algorithm
2025-06-23 22:46:20 INFO Run function 13 complete. FEHistory len: 201, AOCC: 0.0000
2025-06-23 22:46:20 INFO FeHistory: [1918293.88661092 2833999.50219739 1047365.3996287  1390799.88901011
 2547010.62597487 2028451.85077997 2287655.60877997 4050749.2065268
  551599.18099608 2324368.37891053  893840.54464665 1548287.77671106
 1278046.36421692 1691614.70026886 1400753.74096629 1098470.88795201
 1797501.08790306 2047235.63739936 2787025.50277651 2558879.05628805
 1418266.81948436 2548321.24746241 4750951.02865133  831650.62442688
 1819345.20232235 1109165.01094593  999527.37939053 1549293.61225763
 2311179.90784887  450328.76768196  904197.2825428  1178046.0505109
 1712039.84984029 2552656.87760867 2239709.88826882 2298714.1902402
 2896039.42334867  866239.78808797 2134543.34821291 3299681.88476853
 1497909.93073334  901773.01224956 1292075.39655997 1053744.05916398
 2391924.88156361 1420022.20984033 1862703.40443854 1726742.22422063
  608251.65727847 2575097.03305076 3347582.49920115 1795446.58751353
 2616989.94530625  377445.15083373 1276278.78418845 1395394.09438086
  803111.0767142  2964995.54299587 1446093.69341604  885637.43778853
  981666.49465099 1215572.07440768 3029593.155573   1791921.86094941
 2141413.12015875 2972848.97921764 3281800.2369059  1706131.58393366
 2980627.91715005 2826588.49139254 1195264.16987206 3364408.32186817
 2180923.75414483 1506489.24874836 1960715.37103269 2845828.64976032
 1609999.32669556  694843.93492689 2551272.55839533  964795.29076489
 1300544.36570186 2201234.25759273  656939.30341279 1537601.67687273
 1819295.14475474 2913904.59820043 2011957.33783838 1261973.73360455
 2905679.52959524 1522643.85534028  451107.71196016  801758.6482406
 1699796.46214852 3023122.00399314 1657872.66001647 1383021.29497536
  680935.62497594 1061367.04273404 2049943.36458055 3334349.00818054
 2534324.15793778 2155430.91138822 1995967.97384983 3116754.70429073
 4017636.44429838  463363.46367511 1243757.58594092 1110701.81843161
 1204653.26886727  714405.75246037 1318915.27287591 2641579.38243671
 1192955.86868526 2292087.24758514 3223593.63632797 1985435.16430738
 1328317.29649241 2969632.84652392 3367644.25226978 2098958.87803393
 1073188.23563442 4160836.46387303  510324.16034694 3811345.81987865
 2591475.54966789 2382824.36916896 1514287.74529235  475957.17540628
 3687986.75178622 1011573.0664325  1913765.28130275 1450174.64517926
 1574036.61609629 1300694.15936866 1707357.83794423  562096.86469695
 1201045.33849913 3250035.4133125  2506282.90288651 2269503.28751121
 3184009.53269697 1668257.4850463  3830215.33835805 2733725.11257256
 1897113.9679924  1098784.62108797 3256718.31314776  530494.5541064
 2701924.22025375 1815811.21703979 1504339.08242769 1293510.31185508
 2256752.31866209 3644236.15482546 1970901.98839401 2467341.64018508
 2163041.67825685 2004505.93958584 1302124.61568504 1254541.16926738
 2661435.74587822  362195.16621687 1518034.57243988 1690475.04021313
 3153701.19773113 1322567.17270392 1112754.3963966   607293.32564159
  605087.17395873  628316.28376526 4648500.65240114 2122147.67181683
  824332.36687808 1321830.08284508  970271.24478092 2308060.27934013
  689891.38708881 1784754.77517354 4794697.68539308  934225.78997497
 3541607.97685035 4805222.29536902 3024494.68673935 1791389.85367303
 1355061.78349174 2122076.91484074  569736.685099   4773412.59014023
  704847.21816996  923334.02773997 3359514.61617567 1083225.35597083
  948983.41051381 1120584.00267791 1957308.11748883 1257483.10455388
 2945404.81523764 1161889.57549141 1728563.48955223 2922505.26268271
 1817109.5251781 ]
2025-06-23 22:46:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:46:20 ERROR Can not run the algorithm
2025-06-23 22:46:21 INFO Run function 18 complete. FEHistory len: 291, AOCC: 0.0000
2025-06-23 22:46:21 INFO FeHistory: [104870.61833819 115314.39555213 173174.54097989 102020.26534927
 188062.04410142  71241.86154681 109545.57784159 112720.05668246
 142144.79630825 108331.41640443 128647.37998652 153576.42557801
 126169.51043627 107576.8190455  141700.28366413 101357.12830419
 162331.53858955 115014.55380926 156566.99960187 134358.17047806
 169451.42732548 186616.76839255 144376.05374971  98857.59534562
 144685.20909687  99847.55825959 108878.14563087 148085.28025173
 120807.80390188 154696.14272942  83202.150358   100835.85763334
 131703.78104509 124699.92606823 128192.74574568 122066.41772764
 131052.71600947 147007.67869036 137808.41606976 216445.71391504
 243910.44318584 137262.42304985  98492.23600128 156218.42134242
 107631.03280384 133460.77658073  99494.18308331 132215.45437685
 148460.53032077 120950.78874294 151784.85485985 180850.60356195
 154608.65544174 127181.35311978 126290.55184213 118142.6747564
 120551.48520772 111022.34196089 140254.88265936 172706.983031
 113503.93690851 147290.11507309 115000.03133323 186527.42922281
 167021.50678672 153031.62339904 156688.53817607  99387.46018439
 101298.44065888 107104.11747816  84500.79266386 142458.42248966
 139433.78863502 127745.15319324 103438.04938243 141045.71841166
 166162.52322751 107266.25875769 168921.893771   150792.14859014
 156941.65986008 145613.3742328  137191.48214876 155189.00391782
 132524.19511664 103739.32461952 160953.49023552 139823.28851354
 163929.257458   137646.3280001  144857.59928343 196037.00642935
 131497.28610522 172758.49263668 103700.29649887 120385.68215124
 112607.80001069 101593.94244167 127376.39367879 145427.58654676
 131789.99009704 159076.0497377  106312.42659545 131931.16733609
  97402.15619526 166478.25618375 122951.44940548 113752.59696107
 118131.59207685 160657.91495317 162651.14562579 130524.83106482
 106300.77123296 132730.45394974 115990.91665825 117872.08368844
 122594.13040956 151374.94891842 105595.24251792 138771.83688783
 150950.27825437 172008.53831485 177902.24246403 144518.48132233
 105633.63859454  86942.46776089 120489.47572047 187098.32439818
 173015.67427992 189118.4649307  118607.94589406 142522.9891313
 176851.00622245 177563.53424881 253021.44824235 102516.16232619
 125301.87198364 145482.79319335 173112.63352679 160800.73992619
 120722.60801157 174756.96360362 159176.1809389  107116.03051398
  92664.47590673 172306.10188281 134984.36678344 138068.28567455
 156403.96861501 103837.7708431  158512.95986621 125541.45263735
 111269.17004037 174920.67685191 168045.47902402  97647.74535075
  86368.97520924 145086.1961184  105915.24872259  83075.21796849
 145500.33548923 130152.24144948 142302.82553439 182520.95576104
 139189.57058521 164010.68896626 145156.28228322 125967.36077924
 106151.76185452 124915.47287206 134524.20833188 192130.93880473
 121824.08300279 127251.92246483 148181.78177024  94439.85314642
 143555.70974968  87910.42247352 158403.38275424 124500.58370143
 113459.45252163 205574.4883648  177268.75237408 188362.07616391
 144031.58778855 148434.49807892 174211.93949116 157132.96814185
  64343.57123596 125405.44075105 110637.40940218 200700.6399134
 174871.51711186 179563.30981256 156223.53242086 136859.47830272
 149736.18577306 157506.68045346 113265.50153205 141192.11941308
 181806.68575281  77809.98377011  84357.63818292 117092.39398812
 143903.95529056 141746.23551923 112807.29648594  89105.85188036
 129623.23638558 149344.91984006 120593.67419044 129741.2291718
 157951.13565686 138984.17114602 165759.49189729 153240.81468431
 134313.48475147 115383.73893695 124367.05243617 293867.25576068
 145931.4787084   56644.29273782 102099.80024679 112233.76133045
 156110.09225955  91640.70847239 106522.09949136 132322.64496488
 186434.94892606 235626.9114253  177853.30487137 168205.09667759
 132263.42436459 124463.65315587 146500.53804901 144672.15150207
 113251.63081385 122443.61115757 174393.85787839 114006.32013461
 119431.85692508 101777.68278278 153144.05167624 156048.39075406
 188494.88059966 192588.35693078 181303.5968506  167931.03170245
 127774.21236004 111187.54013347 172821.59344548  79779.10716796
 107316.4860961  172225.60460911 114954.45246023 117704.73925423
 152577.89457178 124835.55032    227617.57287035 180967.05477895
 106956.88027105 175433.97843086 192490.8194912  140131.56129297
 102242.93686522 189027.64497274 129668.5640932  155417.37569649
 120096.00839182 112652.60720953 107884.97597894 133045.49218626
 120510.38552033 110988.06292645 160474.7404633  166966.62525562
 135613.88236473 124725.06297479 126275.75986828 124875.18542521
 117631.8072129  138177.49541803 140818.42233953 191103.44334556
 142204.84300918 169225.46335567 128474.24904364 157037.3741902
 150112.09888433 101117.81663684 165053.23949125]
2025-06-23 22:46:21 INFO Expected Optimum FE: -5000
2025-06-23 22:46:21 INFO Unimodal AOCC mean: 0.1466
2025-06-23 22:46:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:46:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:46:21 INFO AOCC mean: 0.0489
2025-06-23 22:50:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:53 ERROR Can not run the algorithm
2025-06-23 22:50:54 INFO Run function 6 complete. FEHistory len: 250, AOCC: 0.1478
2025-06-23 22:50:54 INFO FeHistory: [-183.33418059 -183.35803219 -183.34402179 -183.37917077 -183.34550437
 -183.30698215 -183.39629206 -183.33278199 -183.34202602 -183.37848848
 -183.41713043 -183.31407784 -183.35587633 -183.35982257 -183.23646008
 -183.31323089 -183.3527735  -183.37968926 -183.24690382 -183.3305204
 -183.3615095  -183.34316587 -183.43258273 -183.38413248 -183.28465926
 -183.36955339 -183.31070784 -183.32338534 -183.29239708 -183.32063785
 -183.39440623 -183.40550781 -183.34499027 -183.32477958 -183.38657977
 -183.31724904 -183.32380393 -183.3404208  -183.32716703 -183.27596424
 -183.35324416 -183.39557536 -183.39001304 -183.337327   -183.32643925
 -183.32556099 -183.36487976 -183.42025284 -183.39293305 -183.35919298
 -183.39236794 -183.34562946 -183.26258154 -183.35492861 -183.31482091
 -183.37070272 -183.3696324  -183.30516719 -183.33833846 -183.36064454
 -183.32642582 -183.35695708 -183.36447498 -183.37659983 -183.35908838
 -183.31580381 -183.38680286 -183.3959347  -183.29552597 -183.53611466
 -183.37589977 -183.38900796 -183.37246208 -183.32892863 -183.33445996
 -183.40407264 -183.38138104 -183.39197275 -183.31096657 -183.33308914
 -183.30202957 -183.36007677 -183.29877677 -183.37740576 -183.3615927
 -183.41308885 -183.36610589 -183.3054534  -183.2992649  -183.30836654
 -183.35963143 -183.36342198 -183.41690414 -183.34957015 -183.3276601
 -183.30326916 -183.38775137 -183.36783773 -183.40146671 -183.36611922
 -183.20302549 -183.21101488 -183.35025139 -183.255693   -183.20941052
 -183.13441051 -183.2701577  -183.29589704 -183.27479073 -183.27500481
 -183.21803225 -183.18314208 -183.3111956  -183.29561507 -183.20605526
 -183.21710829 -183.26529837 -183.23608123 -183.13649029 -183.19913805
 -183.17258351 -183.27256997 -183.21738548 -183.27592436 -183.21533513
 -183.26035657 -183.2198451  -183.211032   -183.18540505 -183.23386137
 -183.20235926 -183.20761808 -183.29668832 -183.14218094 -183.17317654
 -183.27946636 -183.12952394 -183.16469587 -183.19316776 -183.16016505
 -183.22361451 -183.25094357 -183.12541903 -183.22494414 -183.24777735
 -183.19315389 -183.24134296 -183.21153883 -183.20830638 -183.22256184
 -183.17658152 -183.1609549  -183.30023157 -183.11489678 -183.15348541
 -183.15449221 -183.27745322 -183.19245255 -183.17980555 -183.2198767
 -183.35148033 -183.23153525 -183.25875815 -183.24857407 -183.30941241
 -183.24298547 -183.18536833 -182.87146214 -183.2231196  -183.18821486
 -183.25716887 -183.2422382  -183.17718168 -183.23143022 -183.33411212
 -183.23786073 -183.15237958 -183.14417747 -183.10461201 -183.16593624
 -183.23100427 -183.11776341 -183.24003337 -183.30434975 -183.22324263
 -183.28965879 -183.20294916 -183.30685787 -183.20134558 -183.23351128
 -183.16341318 -183.25244972 -183.16068045 -183.26706132 -183.24992809
 -183.26068416 -183.2179165  -183.25025459 -183.18168389 -183.22089867
 -183.28184184 -183.19668434 -183.22534784 -183.24758037 -183.27341871
 -183.16837959 -183.34816672 -183.21785994 -183.31699161 -183.21742479
 -183.20301826 -183.05719371 -183.44200799 -183.22294709 -183.25575962
 -183.29304191 -183.25006424 -183.1870547  -183.22582597 -183.24645
 -183.19911867 -183.25944501 -183.24836884 -183.36055116 -183.27034235
 -183.25608166 -183.02606064 -183.28632627 -183.26476779 -183.24474951
 -183.24729913 -183.18379395 -183.18794471 -183.22670374 -183.21906457
 -183.24694606 -183.27655495 -183.20128418 -183.13460703 -183.19537498
 -183.26510176 -183.3012522  -183.20963271 -183.17028999 -183.13905711
 -183.18738069 -183.21984137 -183.27847722 -183.26111296 -183.33526425]
2025-06-23 22:50:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:50:54 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyAndClustering
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyAndClustering
# Description: Combines DE, adaptive Cauchy mutation, and clustering for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyAndClustering:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and clustering 
    to handle multimodal landscapes effectively.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, cluster_threshold=0.5, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.cluster_threshold = cluster_threshold
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population, fitness = self._clustering(population, fitness) # Apply clustering
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _clustering(self, population, fitness_values):
        # Simple distance-based clustering (can be replaced with more sophisticated methods)
        
        #This is a placeholder; a real clustering algorithm should be implemented here.  This example just removes some solutions.
        
        if len(population) > self.population_size //2:
            indices_to_keep = np.argsort(fitness_values)[:self.population_size //2]
            return population[indices_to_keep], fitness_values[indices_to_keep]
        else:
            return population, fitness_values
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 INFO Run function 13 complete. FEHistory len: 250, AOCC: 0.0000
2025-06-23 22:50:54 INFO FeHistory: [8.90374157e+05 3.66270316e+06 1.68902308e+06 4.19465078e+05
 3.20494140e+06 1.53598882e+06 1.08696186e+06 1.27652454e+06
 1.80710274e+06 3.09275316e+06 4.60242698e+05 1.07560376e+06
 1.97232042e+06 1.41872317e+06 1.00190618e+06 2.43879641e+06
 1.55294459e+06 1.31410767e+06 4.66445472e+06 4.42308464e+06
 5.83664887e+05 2.21280934e+06 1.86317582e+06 1.54748207e+06
 2.27576239e+06 2.22335038e+06 9.28596750e+05 3.74951825e+06
 1.63685310e+06 4.19563073e+06 9.83098714e+05 1.93799547e+06
 2.86425675e+06 3.73101255e+05 2.35982169e+06 1.47401829e+06
 2.43008185e+06 3.03538346e+06 9.96740033e+05 5.63580709e+05
 1.13699690e+06 1.50594259e+06 7.27592016e+05 7.26058375e+05
 5.36342179e+05 2.33609631e+06 4.02032017e+05 8.46340700e+05
 2.47506008e+06 9.55188363e+05 1.49787529e+06 1.84228270e+06
 1.89124690e+06 2.76348203e+06 1.62625276e+06 3.85305146e+06
 2.46997617e+06 9.47701299e+05 9.50594953e+05 2.14302906e+06
 7.01328294e+05 9.26028337e+05 1.32972867e+06 4.75260094e+05
 2.13732958e+06 7.63050768e+05 2.15595791e+06 1.81449667e+06
 2.21825539e+06 3.18008811e+06 3.32490567e+06 1.48311771e+06
 1.50685278e+06 5.41657166e+05 3.56253711e+06 6.86850097e+05
 2.29607719e+06 1.03707901e+06 2.90077959e+06 5.20686345e+05
 3.08666280e+06 3.36313195e+06 1.40273183e+06 1.35886215e+06
 1.84885529e+06 4.86267784e+05 2.44956430e+06 4.14788350e+06
 2.42619599e+06 4.45842130e+05 3.68655681e+06 1.77099932e+06
 1.59705634e+06 1.89244198e+06 1.88713943e+06 1.66595975e+06
 2.16753329e+06 2.77784900e+06 6.07574383e+05 1.77724214e+06
 7.93643919e+06 7.81032674e+06 8.55647311e+06 5.41213784e+06
 3.08426554e+06 4.78633651e+06 3.22448083e+06 2.65691229e+06
 5.73618945e+06 6.94813453e+05 4.96043778e+06 1.52557429e+06
 7.85889793e+06 2.73499691e+06 3.60815933e+06 6.09021404e+06
 1.91607537e+06 5.08841203e+06 6.20611202e+06 1.44190116e+06
 2.49735427e+06 8.45365741e+06 6.39822953e+06 7.98482652e+06
 3.83984567e+06 5.43027951e+06 3.45496262e+06 3.50605084e+06
 1.77673079e+06 2.20958440e+06 6.30056647e+06 8.52671793e+06
 1.78922313e+06 3.86610137e+06 1.48579271e+06 5.46034846e+06
 2.64855191e+06 3.64476223e+06 3.65034485e+06 1.99479253e+06
 1.57674196e+06 3.75289584e+06 5.72389474e+06 3.67365399e+06
 4.92169459e+06 4.47128309e+06 2.59792372e+07 2.17966482e+06
 1.08152363e+07 2.81257342e+06 3.64909027e+06 9.57026083e+06
 2.20790540e+06 3.77326387e+06 3.33633115e+06 4.92294831e+06
 3.36834594e+06 2.56039685e+06 5.98023595e+06 3.14307785e+06
 1.57233656e+06 1.44585930e+09 3.25671043e+07 7.91340217e+06
 6.17736299e+05 1.86464605e+06 6.45121703e+06 2.91985974e+06
 7.94591983e+06 2.23658150e+06 4.64157936e+06 4.25171747e+06
 8.54124651e+06 2.83033151e+06 3.91081608e+06 6.31094950e+06
 8.57452527e+06 5.99250743e+06 2.13048066e+06 4.37086357e+06
 2.16701538e+06 1.33477477e+06 5.75668673e+06 1.21432836e+06
 2.23964531e+06 2.81754974e+06 4.14940568e+06 3.53280685e+06
 8.22711130e+05 3.18209118e+06 1.35137023e+06 8.40538869e+06
 4.41898915e+06 8.45442109e+06 2.63204992e+06 5.38957104e+06
 4.67659270e+06 2.33419496e+06 7.21785574e+06 4.48112728e+06
 3.58658917e+06 3.03928221e+06 2.48394348e+06 4.04255541e+06
 4.56128843e+06 1.02894277e+06 8.43396633e+06 4.96107493e+06
 3.96846290e+06 5.65283428e+06 2.61161711e+06 4.49824481e+06
 2.94581353e+06 4.15424656e+06 1.14067483e+07 3.95944547e+06
 2.14715042e+07 3.14989210e+06 1.20828932e+07 6.52653862e+06
 6.41342710e+06 8.39897024e+06 5.59718808e+06 6.94481805e+06
 4.21518293e+06 3.23239216e+06 1.17369605e+07 5.96098771e+06
 7.98337542e+06 9.85671658e+06 1.51818649e+07 3.51280064e+06
 7.44797825e+06 5.71045283e+06 2.30445310e+06 3.30190829e+06
 5.57076419e+06 1.20777614e+06 2.51131957e+06 3.90180077e+06
 4.64393017e+06 2.10712121e+06 4.59228822e+06 4.43120614e+06
 9.57444045e+06 2.21066729e+06 3.29531349e+06 2.80628968e+06
 3.52350625e+06 6.05974089e+06]
2025-06-23 22:50:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 INFO Run function 18 complete. FEHistory len: 250, AOCC: 0.0000
2025-06-23 22:50:54 INFO FeHistory: [1.88702526e+05 1.21578066e+05 1.52191871e+05 1.76505472e+05
 2.46913791e+05 1.56554665e+05 1.13284491e+05 1.27345823e+05
 1.36444339e+05 1.53580677e+05 9.47900395e+04 1.33624105e+05
 1.75870961e+05 1.67698031e+05 1.32280633e+05 1.98327141e+05
 1.15005902e+05 1.27639625e+05 1.22373033e+05 1.35863449e+05
 1.38526760e+05 1.93687061e+05 1.36940080e+05 1.44882408e+05
 1.42117315e+05 1.36736332e+05 2.85528117e+05 1.21614941e+05
 1.68494566e+05 1.30246590e+05 1.14357398e+05 1.22249317e+05
 1.59348532e+05 1.48618795e+05 1.26297948e+05 1.42830558e+05
 1.43889598e+05 1.19889041e+05 1.51843012e+05 1.57070350e+05
 1.72177601e+05 1.41137426e+05 1.40195043e+05 1.74819556e+05
 9.71792561e+04 8.80484530e+04 1.39705942e+05 1.31285200e+05
 1.42212721e+05 1.42464795e+05 1.77000089e+05 8.77761278e+04
 1.76405127e+05 1.16051870e+05 1.12789228e+05 1.48641010e+05
 9.35818579e+04 1.33255582e+05 1.75376662e+05 1.36552568e+05
 1.40389933e+05 1.64406460e+05 1.74173972e+05 1.84738778e+05
 2.10542523e+05 1.46344733e+05 1.45054236e+05 1.14995357e+05
 1.00447339e+05 1.79733094e+05 1.16598297e+05 1.59789706e+05
 1.49566865e+05 1.67595165e+05 1.64167290e+05 1.30779541e+05
 1.25002862e+05 2.35086630e+05 1.97438056e+05 1.55607982e+05
 1.73414494e+05 1.61251935e+05 2.34889356e+05 1.48389652e+05
 1.37659437e+05 1.55170543e+05 1.57472597e+05 1.25784109e+05
 1.70797788e+05 1.42172336e+05 1.75156391e+05 1.44578720e+05
 1.57769558e+05 1.06384876e+05 1.41328801e+05 1.00413816e+05
 2.09810999e+05 7.76321245e+04 1.33659276e+05 1.55013213e+05
 2.89257936e+05 2.14773962e+05 3.74066280e+05 2.93457273e+05
 3.72542607e+05 2.29021097e+05 2.68305908e+05 5.74824873e+05
 2.59797105e+05 3.57786798e+05 2.79482907e+05 4.95461540e+05
 4.16851781e+05 3.15080607e+05 4.47341673e+05 4.01959824e+05
 2.64756905e+05 4.44945217e+05 2.04212665e+05 3.31341108e+05
 3.28474756e+05 3.18075945e+05 5.11070280e+05 3.37672696e+05
 3.63346622e+05 2.68834015e+05 3.11800690e+05 3.38251179e+05
 2.44244597e+05 1.85165296e+05 2.43162458e+05 4.42048988e+05
 5.42256488e+05 2.35545260e+05 1.44350423e+05 2.72169492e+05
 2.42370984e+05 2.18269229e+05 4.07666971e+05 2.50784886e+05
 3.63440745e+05 2.94129499e+05 2.47612137e+05 3.48360660e+05
 4.22320077e+05 3.77662148e+05 2.93613708e+05 5.54624512e+05
 3.85324555e+05 3.54710826e+05 2.44527846e+05 3.95870601e+05
 2.24831203e+05 1.14596061e+08 3.81392023e+05 2.58153943e+05
 2.96335740e+06 3.43837771e+05 2.41240758e+05 2.69832922e+05
 2.62276261e+05 2.50189798e+05 2.91470353e+05 4.39029218e+05
 4.05998299e+05 3.63114015e+05 2.92472444e+05 7.98860364e+08
 3.81936966e+05 5.91194359e+05 3.54469504e+05 3.38179329e+05
 3.15336304e+05 2.84438125e+05 4.43994228e+05 1.92463952e+05
 2.97203368e+05 3.13488609e+05 2.73634864e+05 2.69986541e+05
 2.66187699e+05 6.85328388e+05 3.53425968e+05 4.46594031e+05
 3.70241411e+05 3.51584385e+05 2.78767121e+05 2.90599789e+05
 3.05692544e+05 5.42271385e+05 1.54452799e+05 3.99413719e+05
 3.68735316e+05 8.50739219e+05 3.28040276e+05 3.43126628e+05
 2.19358341e+05 4.06677866e+05 3.77662702e+05 2.20902101e+05
 2.81346677e+05 3.03215369e+05 4.05762872e+05 3.15184610e+05
 3.37597470e+05 2.98462234e+05 2.47123266e+05 3.63122962e+05
 4.17123024e+05 2.48493569e+05 2.38195264e+05 2.91910585e+05
 2.47187179e+05 1.78176628e+05 4.02980354e+05 3.71531382e+05
 2.07480975e+05 2.87811512e+05 2.65506105e+05 2.68164709e+05
 4.41338571e+05 2.24387107e+05 2.05323364e+05 3.54599948e+05
 3.45087688e+05 2.81238757e+05 3.95380911e+05 1.92440458e+05
 3.76771196e+05 3.14431415e+05 3.66977322e+05 3.57909775e+05
 2.71777267e+05 1.73594474e+05 2.12990340e+05 3.10024651e+05
 3.71753022e+05 1.91370913e+05 2.65555396e+05 2.88060104e+05
 3.12178933e+05 3.78831200e+05 3.43615944e+05 3.48030453e+05
 2.58090910e+05 2.99732323e+05 2.65102420e+05 2.94728297e+05
 2.77041948e+05 2.77855411e+05]
2025-06-23 22:50:54 INFO Expected Optimum FE: -5000
2025-06-23 22:50:54 INFO Unimodal AOCC mean: 0.1478
2025-06-23 22:50:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:50:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:50:54 INFO AOCC mean: 0.0493
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:55 ERROR Can not run the algorithm
2025-06-23 22:50:56 INFO Run function 6 complete. FEHistory len: 7800, AOCC: 0.1545
2025-06-23 22:50:56 INFO FeHistory: [-183.38862794 -183.3008395  -183.32553822 ... -183.98531113 -184.00802095
 -184.01311551]
2025-06-23 22:50:56 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:50:56 INFO Good algorithm:
Algorithm Name: AdaptiveDEWithCauchyAndClustering
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEWithCauchyAndClustering
# Description: Combines DE, adaptive Cauchy mutation, and clustering for robust multimodal optimization.
# Code:
class AdaptiveDEWithCauchyAndClustering:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, and clustering to escape local optima and explore multimodal landscapes effectively.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, cluster_threshold=0.5, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.cluster_threshold = cluster_threshold
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population, fitness = self._clustering(population, fitness) #Added clustering step
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _clustering(self, population, fitness):
        #Simple distance based clustering.  Replace with a more sophisticated method if needed.
        from scipy.spatial.distance import cdist
        distances = cdist(population, population, 'euclidean')
        np.fill_diagonal(distances, np.inf) #Avoid self-similarity

        clusters = []
        assigned = [False] * len(population)
        for i in range(len(population)):
            if not assigned[i]:
                cluster = [i]
                assigned[i] = True
                for j in range(i+1, len(population)):
                    if not assigned[j] and distances[i,j] < self.cluster_threshold:
                        cluster.append(j)
                        assigned[j] = True
                clusters.append(cluster)

        #Maintain Diversity: Select a representative from each cluster
        new_population = []
        new_fitness = []
        for cluster in clusters:
            best_index_in_cluster = cluster[np.argmin(fitness[cluster])]
            new_population.append(population[best_index_in_cluster])
            new_fitness.append(fitness[best_index_in_cluster])
        
        #Pad with random solutions if clustering reduced population size
        while len(new_population) < self.population_size:
            new_solution = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
            new_fitness_value = objective_function(new_solution.reshape(1,-1))[0]
            self.eval_count +=1
            new_population.append(new_solution)
            new_fitness.append(new_fitness_value)
        return np.array(new_population), np.array(new_fitness)

2025-06-23 22:50:56 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:50:57 ERROR Can not run the algorithm
2025-06-23 22:50:57 INFO Run function 13 complete. FEHistory len: 12000, AOCC: 0.0000
2025-06-23 22:50:57 INFO FeHistory: [1794454.60168253 1689085.80728126 2860427.45014371 ...   88628.27159462
  727779.9243277  1318785.91584246]
2025-06-23 22:50:57 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:50:57 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:51:00 ERROR Can not run the algorithm
2025-06-23 22:51:01 INFO Run function 18 complete. FEHistory len: 9300, AOCC: 0.0000
2025-06-23 22:51:01 INFO FeHistory: [ 74311.32603029  90916.14297753 199743.1068511  ...  11826.82123856
  13887.7407893   36000.04759899]
2025-06-23 22:51:01 INFO Expected Optimum FE: -5000
2025-06-23 22:51:01 INFO Unimodal AOCC mean: 0.1545
2025-06-23 22:51:01 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:51:01 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:51:01 INFO AOCC mean: 0.0515
2025-06-23 22:51:01 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:51:01 ERROR Can not run the algorithm
2025-06-23 22:51:01 INFO Run function 6 complete. FEHistory len: 200, AOCC: 0.1474
2025-06-23 22:51:01 INFO FeHistory: [-183.31361317 -183.31158732 -183.27190004 -183.41024958 -183.30576616
 -183.31519087 -183.3286042  -183.51035929 -183.30293649 -183.2852618
 -183.32518279 -183.34701156 -183.32291017 -183.31229288 -183.37479558
 -183.32094208 -183.3695691  -183.43752227 -183.31659465 -183.36917474
 -183.28893777 -183.35208071 -183.3546907  -183.3369044  -183.44393783
 -183.34513535 -183.32739359 -183.32572424 -183.32286977 -183.3535678
 -183.34942646 -183.42162843 -183.32635687 -183.31107248 -183.34003267
 -183.4503264  -183.35071139 -183.39517818 -183.46149946 -183.33816774
 -183.44117449 -183.31916558 -183.35219678 -183.3436548  -183.38018418
 -183.35961195 -183.25845552 -183.33030108 -183.27336663 -183.2976814
 -183.22990086 -183.42753626 -183.34261475 -183.34012912 -183.3489545
 -183.40436335 -183.39736519 -183.41523789 -183.37132279 -183.38834782
 -183.42767347 -183.33023872 -183.36549991 -183.4475591  -183.34262982
 -183.36740256 -183.36347341 -183.319256   -183.3172138  -183.31273609
 -183.35164688 -183.34941013 -183.29194635 -183.31556662 -183.36476194
 -183.35699755 -183.32245805 -183.41422771 -183.38120531 -183.32088894
 -183.34808617 -183.42274466 -183.36467038 -183.31159638 -183.32206507
 -183.27212383 -183.33673979 -183.35760202 -183.34161796 -183.30024948
 -183.37053644 -183.3259341  -183.30558109 -183.48214304 -183.39597687
 -183.27335834 -183.31175974 -183.50902224 -183.3715129  -183.28135762
 -183.3442009  -183.35607781 -183.34685834 -183.30234048 -183.34165702
 -183.31717322 -183.39265489 -183.29440021 -183.34715572 -183.31977215
 -183.33025311 -183.34336419 -183.3317829  -183.29381302 -183.31772986
 -183.25267064 -183.26306948 -183.37116921 -183.34226414 -183.25618624
 -183.34167871 -183.29204296 -183.36308769 -183.3465641  -183.281449
 -183.29469366 -183.32241414 -183.31457338 -183.38985167 -183.2942026
 -183.26431097 -183.32041416 -183.389239   -183.29050193 -183.24820333
 -183.40819877 -183.30850693 -183.37827465 -183.24825182 -183.26253964
 -183.31759644 -183.30844325 -183.31665752 -183.27893941 -183.33146601
 -183.34573804 -183.42600658 -183.29639121 -183.22105524 -183.2839925
 -183.34457708 -183.23983498 -183.31944284 -183.31114893 -183.37510251
 -183.30244631 -183.30279021 -183.29844777 -183.35308404 -183.29858922
 -183.18452986 -183.37833181 -183.29095167 -183.294279   -183.29961068
 -183.28184272 -183.26379586 -183.2702934  -183.29777693 -183.30017944
 -183.32384375 -183.3341739  -183.31869187 -183.33249817 -183.29062045
 -183.28137001 -183.24852955 -183.2845206  -183.33369692 -183.38955182
 -183.33860695 -183.31919085 -183.25027912 -183.27793001 -183.34922731
 -183.28463563 -183.31350791 -183.35228049 -183.35367321 -183.32669009
 -183.28624327 -183.27780498 -183.25786536 -183.33222533 -183.31352536
 -183.30878005 -183.21520536 -183.27495799 -183.22341454 -183.3689035 ]
2025-06-23 22:51:01 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:51:01 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveTournament
import numpy as np
from scipy.stats import cauchy
import random

# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Adaptive Differential Evolution with Cauchy mutation, archive, and tournament selection for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.archive = [] # Archive of good solutions
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._archive_tournament_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_step = np.random.standard_cauchy(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _archive_tournament_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        #Tournament Selection with Archive
        tournament_size = 5
        next_gen = []
        next_fit = []
        for i in range(self.population_size):
            tournament_indices = np.random.choice(len(combined_population), tournament_size, replace=False)
            winner_index = tournament_indices[np.argmin(combined_fitness[tournament_indices])]
            winner = combined_population[winner_index]
            winner_fit = combined_fitness[winner_index]

            # Check Archive for Niching
            is_unique = True
            for sol in self.archive:
                if np.linalg.norm(winner - sol) < self.niche_radius:
                    is_unique = False
                    break

            if is_unique :
                next_gen.append(winner)
                next_fit.append(winner_fit)
                self.archive.append(winner) # Add to archive

        return np.array(next_gen), np.array(next_fit)



    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self):
        self.gamma *= 0.99 # Adapt Cauchy scale
        self.niche_radius *= 0.99 #Gradually reduce niche radius for finer local search

2025-06-23 22:51:01 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:51:01 ERROR Can not run the algorithm
2025-06-23 22:51:01 INFO Run function 13 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 22:51:01 INFO FeHistory: [1891403.7921375  2101352.87046591 2323812.84847433 3506475.97455075
 3386496.03782216 3038857.0266882  1538190.50258638 2302067.56370356
  416136.81627798 1818884.56773713 2609361.76127071 1843810.40079298
 2168478.5392853  1166846.08088064 2687857.41750789  992445.67095976
  822376.05280948 2291374.38307321  864557.55170518  672090.36164
 1739129.1071216  3185263.95793114 1926523.29384823 1377158.53877981
 1012633.2561656  2280281.89185741 3287061.71286524 1460358.577292
 2480666.07667594 1028554.14925519 2453316.33522363 3098829.72544729
 1505017.93567402 2399006.26707254 1125712.61438708 1668551.14729569
 2332835.85533865 1788186.44606367 2024256.67097788 2071480.21376555
 1339172.77895543  945601.72488608 2994557.93437499  484349.74061568
 3157225.04421198  654485.06783513 1503688.4018091   845285.05173362
 1662522.32393544 1735684.02420487 3095401.59003838 2060148.66860246
 3083126.01594265 1500748.2349659  1677564.39626191 2258841.68135886
 1031545.99600464 1237930.44187314 1546248.11660066 2965498.7671796
 1884953.16180729 1135427.34914266 5248271.86497815 3337183.82731373
 1882091.44581819 2772903.86238084 2370845.16491942  820388.04799322
 2448792.18926914 1578058.3744734  5783961.62488741 1967891.34219811
 3125771.59729312 2277940.09072503 1028616.12989162  959895.58081663
 1158299.22353145 1960236.17684793 1476456.06597208 1650945.36090359
 1449209.32460271 4602785.5174577  1319001.07119514 4165372.69918728
 1741479.76130548 2094887.88920922 2209625.80967763 4824996.62792314
 1176124.14147498 1740639.97600188 1539602.18942946 1558223.85801931
 1171261.66661543 1610054.23836585 1922408.11004146 1327956.84295702
 1201855.80824688 2072799.11838938 3648853.77474943 1017645.54183329
  928945.37224705 4246162.17289837  998254.93051868 3140029.22869491
 1686917.92914946 1073448.12898719 1956748.47374796 4615805.27077483
 1643766.66576642 1676681.52933232 1001032.52915853  911731.79320288
 1977818.14138323 2876176.46752265 3893308.53165964 1190924.45545734
 2689548.12977215  992593.40548781 1699751.41918457 3189796.84154814
 2157165.42622929 1592205.43294544 1760519.29127126 1200595.39148273
  942116.40585005 3628105.7054894  3001183.55784566 1734796.35147046
 5524787.6141754  2230121.19949473 5447263.62041124  457688.48858819
  814812.86867686 1583219.25024708  959651.61856356 2819010.5680895
 2872989.33302263 2450602.14108771 1322099.23359417  708451.099352
 1462321.01025021 2618366.92726654 2895014.50350489 1779277.13267941
 3255624.93921607  729311.19286316 2106664.35433881 2472416.16954551
 1254210.71347494 4721277.55563722 1694253.35199387 2794424.26643963
 1599637.01910904 2979837.84644373  625917.60406597 1059997.43476875
 4258040.04964699 3591593.45821675 2964710.41136649 2843560.82132475
 1012872.54858406 1478997.85949771 3776851.42515922 2298752.24222776
 1307408.09879827 2693941.32112138 2413983.26364627 2966840.03053898
 1118450.5561106  2278126.07698418 2163403.74599177 1580652.33951533
 4536745.08426227 1444960.27759744 2325845.98347553 2272479.04826563
 4211079.41484932 1890893.95362573  825378.80824843 3613986.58196004
 4888295.10432158  775290.39796967 3167884.99557539 3684697.7607872
 1660998.36971174 1040982.90132531 2398000.41762753 2622540.47002816
  599392.98143698 2948145.94902195 2591464.47441309 4637323.48882971
 3064884.55783149 3383101.88550664 3690946.00954172 2822774.81725567
  922654.91207791 2611106.70431865 1897439.26356837 1881171.6104234 ]
2025-06-23 22:51:01 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:51:01 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:51:01 ERROR Can not run the algorithm
2025-06-23 22:51:02 INFO Run function 18 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 22:51:02 INFO FeHistory: [138606.53023048 193879.89555053 221763.17962241 188659.05992638
 144653.52137796 160452.5232127  115423.32887829 108751.6844189
 206010.23896331 144700.34349605  82288.86353361 125352.6283792
 237225.24360265 141104.23969976 122334.94727922 154169.68216544
 131488.2043059  155470.15980023 196442.95539721 141893.73045115
 139205.90643319 105871.56231112 162149.16910302 125104.83988114
 152664.70648031 127993.92868074 173322.91611554 212504.82161795
 169832.56829749 136859.94358571 120271.84092122 153977.95889005
 187800.67893088 205044.73768418 133449.94343732 171838.13421261
  69581.5025092  152572.56527658 226978.92496315 134429.57404144
 104764.15740571 221416.95479862 117588.31908961 116839.64807243
 168231.9742806  110464.20677748 178739.6353515  139983.38602359
 130406.26196504 168323.41566387 236041.1140045  169432.15982846
 136198.25755337 147483.58170897 100247.91211138 194100.0330119
 160801.66988584 231215.25674015 137195.94461952 111579.58979322
 145373.06776461 154259.1890551  163807.97312206 163905.29891452
 118045.02522637 154675.6130479  135776.70772462 166820.72637376
 155005.51712434 216910.7496661  181229.79231657 192527.65258405
 133242.80993161  95580.03687121 153834.04149763 137182.68017393
 197445.82672856 155861.38872164 188916.79542894 114451.71622264
 101399.31023075 188907.26933683 116809.17187559 119276.22810439
 117902.92666264 202743.40326708 160036.723309   158460.54390831
  97570.25520153 216878.56101593 151385.57514559  82132.0834638
 143381.83355353 168456.5681852  117189.2052336  161619.62687867
 115913.70541517 168285.0428163  188686.78761075 116477.73267882
 131101.06287441 196930.06220143 207296.17679984 171918.50211715
 191598.36743283 199861.92196889 150982.21260198  84404.01082015
 117176.00234461 208922.01365855 177403.80042349 255608.81215478
 113683.47986022 186670.98596091 157861.23897206 159544.00016723
 180184.75052257 115000.70952095 176790.67797257 129119.95132654
 127591.39250742 330932.92247601 181446.27483634 125076.12828519
 160084.74509008 228669.9680936  178374.9966731  159550.80816752
 236507.16017147 160513.3398848  109643.80360482 172102.42917952
 228639.79952215 130461.82473118 159827.27559624 139039.75987007
 199207.06936152 170006.19273887 162288.99058895 180027.47529402
  74576.85512598 299530.56768147 231203.88441991 163339.61083698
 190568.75107432 121788.39368174 146436.40759076 221842.66127874
 155580.82141164 202324.50812187 176379.18394746 248103.98266413
 167885.27683566 163601.93533997 186691.35400956 182597.64780423
 227355.03180119 187723.2030089  149586.62008877 201213.99992475
 199161.05429189 288936.53712323 162241.43613021 264976.22007051
 228269.47301507 254576.12325931 281371.35007073 238897.30722148
 216949.88676376 193710.1658202  137539.26499862 241364.48942861
 125006.42915704 213556.52139255 220920.31800259 205549.48686027
 209289.64497557 190440.59801281 185326.70791303 175841.10432365
 121944.6627003  182870.15215652 220248.20200862  87462.07564749
 165109.94044868 224606.55500352 145920.81822139 217820.70821364
 174877.64365193 264316.56470723 169441.79455579 205554.97815093
 157392.01353514 159116.25933906 176422.05131554 186077.88017092
 171575.78689424 147816.55921157 229056.737988   226171.95821253]
2025-06-23 22:51:02 INFO Expected Optimum FE: -5000
2025-06-23 22:51:02 INFO Unimodal AOCC mean: 0.1474
2025-06-23 22:51:02 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:51:02 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:51:02 INFO AOCC mean: 0.0491
2025-06-23 22:52:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:52:56 ERROR Can not run the algorithm
2025-06-23 22:52:56 INFO Run function 6 complete. FEHistory len: 201, AOCC: 0.1471
2025-06-23 22:52:56 INFO FeHistory: [-183.43504503 -183.39693532 -183.41412994 -183.28340989 -183.33657969
 -183.37157009 -183.35833861 -183.30975186 -183.30308261 -183.31815948
 -183.28849144 -183.47039915 -183.31504179 -183.35396081 -183.43142078
 -183.37056338 -183.36029318 -183.284483   -183.34313439 -183.32714272
 -183.34352593 -183.35595111 -183.42561453 -183.34302658 -183.39211071
 -183.37918698 -183.33416784 -183.38245556 -183.28261717 -183.39558612
 -183.34235346 -183.2994846  -183.2897932  -183.40850946 -183.34032008
 -183.3400914  -183.30920193 -183.38137102 -183.3578384  -183.28507424
 -183.41556231 -183.40215735 -183.33825077 -183.34410163 -183.35999405
 -183.35389696 -183.38674068 -183.35866181 -183.37095242 -183.39090619
 -183.31530029 -183.33083877 -183.39021366 -183.31323332 -183.30532688
 -183.40798442 -183.33174443 -183.30764648 -183.32764596 -183.37295449
 -183.33380138 -183.33612061 -183.27578229 -183.34996726 -183.40084724
 -183.36451966 -183.3517012  -183.31005567 -183.36003293 -183.29081845
 -183.34239816 -183.29968711 -183.35342509 -183.33583478 -183.45415705
 -183.34811824 -183.29450018 -183.31556331 -183.26887566 -183.32176611
 -183.31273926 -183.27566679 -183.38360154 -183.31567198 -183.41002877
 -183.3679184  -183.36948951 -183.28900252 -183.31095254 -183.483086
 -183.34386388 -183.40168691 -183.37615473 -183.27494577 -183.36587679
 -183.40201358 -183.43018819 -183.34627038 -183.41465783 -183.29260791
 -183.34996336 -183.24066881 -183.39885221 -183.35674105 -183.31442433
 -183.33906084 -183.30158613 -183.35374413 -183.32401613 -183.3110007
 -183.27693514 -183.27798345 -183.27244413 -183.41466754 -183.27606464
 -183.28179548 -183.27285471 -183.26441993 -183.27975538 -183.37921085
 -183.26549574 -183.33276582 -183.3608869  -183.28290731 -183.3217713
 -183.38524708 -183.39603802 -183.30151955 -183.33229951 -183.25624233
 -183.30488899 -183.29869719 -183.28417484 -183.37002993 -183.31335887
 -183.22559357 -183.34925821 -183.28560169 -183.41144161 -183.33890896
 -183.30153125 -183.30782423 -183.27471681 -183.26985605 -183.2865086
 -183.3402535  -183.30425693 -183.24312007 -183.45424199 -183.27125149
 -183.27229621 -183.34623196 -183.32816623 -183.34105337 -183.31882174
 -183.33357916 -183.40322383 -183.26902798 -183.27432879 -183.38334877
 -183.29602668 -183.27761678 -183.23775342 -183.32448471 -183.29005861
 -183.42026978 -183.38438488 -183.2252201  -183.30988118 -183.2564958
 -183.30643139 -183.27708719 -183.39062185 -183.22313691 -183.35678162
 -183.29957482 -183.34063271 -183.29434741 -183.31270919 -183.29195775
 -183.31348572 -183.32386951 -183.33614254 -183.30430867 -183.32807708
 -183.34687382 -183.28529137 -183.36551456 -183.28839328 -183.3468969
 -183.31746126 -183.34176249 -183.37212769 -183.29266921 -183.38649863
 -183.30892463 -183.37621532 -183.2871697  -183.29753484 -183.28615955
 -183.39102906]
2025-06-23 22:52:56 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:52:56 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyMutation
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: Differential evolution with adaptive scaling and Cauchy mutation for escaping local optima in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.scale_factor = 1.0 # Initial scaling factor for mutation
        self.scale_decay = 0.98 # Decay rate for scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = np.copy(population)
            for i in range(self.population_size):
                #Differential Evolution Mutation
                a, b, c = self._select_different(population, i)
                mutant = a + self.F * (b - c)
                
                #Cauchy Mutation for Exploration
                cauchy_mutation = cauchy.rvs(loc=0, scale=self.scale_factor, size=self.dim)
                mutant += cauchy_mutation

                #Crossover
                j_rand = np.random.randint(self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == j_rand:
                        offspring[i, j] = mutant[j]

                #Bound handling
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection
            population = np.where(offspring_fitness < fitness_values[:,None], offspring, population)
            fitness_values = np.where(offspring_fitness < fitness_values, offspring_fitness, fitness_values)


            # Update best solution
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[best_index]
                self.best_solution_overall = population[best_index]

            self.scale_factor *= self.scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _select_different(self, population, i):
        a, b, c = np.random.choice(range(self.population_size), size=3, replace=False)
        while a == i:
            a = np.random.randint(self.population_size)
        while b == i or b == a:
            b = np.random.randint(self.population_size)
        while c == i or c == a or c == b:
            c = np.random.randint(self.population_size)
        return population[a], population[b], population[c]

2025-06-23 22:52:56 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:52:56 ERROR Can not run the algorithm
2025-06-23 22:52:57 INFO Run function 13 complete. FEHistory len: 201, AOCC: 0.0000
2025-06-23 22:52:57 INFO FeHistory: [2024609.2760946  3938196.0385358  2258320.06754845 2303857.43662129
 1459517.70277013 1653062.6913117  1777207.99605405 1377300.61110275
 3896021.12685134  483420.53980876 1689163.76096645 2168889.84242502
 3690342.60474964 2088541.21833917 2952994.32361577  919342.72272145
 1869657.58624502 2398174.07272759 1840544.03257554  359199.23192235
 4390939.91479492 2399741.86500208 2402289.73463127 3337746.58151411
 1972791.78391107 3961001.90573053 1614283.80944039 1253551.40699396
 1710969.99915462 1962916.09435316  210104.33355631 2448363.04312022
 1168747.76330519 3182179.28706522  873732.96413563 4286099.42932765
  808210.7808079  5001844.4313648  1928144.39749288 1264675.71558578
 2527622.51151695 2103694.91584142  543973.91161156 1432455.15150932
 2179639.11586595  977885.0827278  1633820.3801017   861183.29330906
 1690856.54105859 1929585.26028139 1552179.55675026 1451533.10939456
 1826344.23944066 2711650.56696251  479955.7655575   719327.61238452
 3819291.78639457 1878805.24086939 2242105.05448392 1059019.8739976
 1102684.13974106  899460.21174194 1824054.78620768 1390569.54497337
 1858224.75803722 2620901.91197622 1188859.98592133  961375.72688179
 2980859.7651256   948738.728296   1635187.72493971 1884753.5829327
 1462869.05234247 1433989.80699977 1598515.90497904 1323899.95581139
 2151908.6252204  1460462.97448695 3883376.19280151 2825327.69720804
 3246275.95169539 1046924.20475974 1949927.75295364 4946475.78587609
 1647945.98015227 2700430.96508488 1881775.72942539 1323659.90969852
 1234553.80066388 2275960.32800111 1785090.44288213  938366.99240579
 1083001.34876242 3448432.54262436 2518327.28046508 2470403.95226073
  760130.87293605 2387150.44563064 1168707.47561712 1661839.17772904
  985561.36406773 2739106.70792537 1106792.82578599 1824284.85409543
  908049.66473499 2538467.71665821 2121097.00552644 1238610.85921515
 1597985.18594028 4114807.83079224 5772595.66796696 3181104.90796975
 2274252.23371602 1582481.90228857 4129923.99453868 1301949.65026647
  724525.7574463  1536242.39821091 2308059.38693742 1731349.20523545
 3423174.93017279 4116182.48631882 4111232.59241586 1236776.63493928
 2351601.34694204 1585278.82004263 2270290.02510212 1999694.76077551
  471165.22312331  815415.58046662 2252235.28447274 3771108.50056582
 2236936.03426624 2499541.99591827 1299627.04822565 2415160.57194739
 2156218.09065514 2169273.93609448 2086078.77677287  857473.52152785
 1628394.11937386 2211562.27416074 1194044.4075083  3855117.45162435
 1511999.35587111 1017931.19792316 1961138.8306836  4149326.77321601
 2229555.01467606 2189957.03979538 3015945.08354713 5180904.81651206
 3922863.26411139 1650987.04154769  774882.69223524 2154754.46561393
  905802.56898249 2704795.25807742 1348718.95671177 1935525.37948091
 4086271.33743246 2186080.99517205 2523549.92722911  301683.91512911
  715683.63223226 1645825.26520073 3168480.05200139 4174501.53882527
  950097.54857828 2099219.47131438 2964462.99049341 1879191.56299164
 2622422.6826525  3365275.85511756 2618467.57536749 1982668.85335844
 1550956.30826179 2055913.18909016 1306622.09580016 3644934.56538248
 1616041.60245306 1476627.85902558 3073158.34089896 1966339.88150757
 3192219.58260914 4230415.12055029 2054083.06364707 2137150.11180589
 3023774.99299224 1134733.91580916 4236916.12429892 1205980.97920979
 2000278.74400432 1409005.34562686 3012036.89761003 2764363.8760544
 4013708.00032489 2881111.74121443  680600.76599332 1345692.40333625
 1126296.87000781]
2025-06-23 22:52:57 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:52:57 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:52:57 ERROR Can not run the algorithm
2025-06-23 22:52:57 INFO Run function 18 complete. FEHistory len: 201, AOCC: 0.0000
2025-06-23 22:52:57 INFO FeHistory: [147439.61903734 193470.98906705 182318.79045195 201701.64989504
 146891.81801772 128157.50082377 162874.35083787  91252.42309723
 268307.17598306 146452.93084896 141112.23942737 105239.45619138
 182825.03248227 185394.75225609 144964.36073481 162626.89011815
 189433.54909631 136769.48900048 144752.71343675 107201.45155931
 156427.85707356 154030.79475115 131247.08062499 115195.89289424
 108060.9934658  198821.12514744 163725.24688687 138955.46510141
 151807.47847778 122412.14833202 166893.6060162  123190.85313112
 105786.80682256 207938.85895685 176750.27802461 185575.61238992
 164990.93895193 165015.6127087  191422.06432014 193455.78478979
 115190.88692517 177262.17145008 120108.35791503 112963.55332007
 176141.81054503 232504.88199492 178753.82706438 136250.36718289
 115603.73058868 183030.6319345   76015.99300631 188827.21747931
 140878.13506387 191899.58761315 143310.4923939  122432.28410977
 123880.4016896  139773.17868841 167619.75727952 208626.17195025
 173523.90277164 204559.38373527 182297.83613506 177831.4933231
 209794.78479304 141539.81566845 158825.35752738 119950.96813121
 118198.35227261 164349.11984591 164916.13425618 131509.8071786
 161057.07080387 153390.73283532 154958.74596433 150807.40989725
 181718.76793388 174848.14356475 130307.36563281 151799.15412751
 153598.35115965 156659.13046614 161816.96686074 176765.38004061
 121611.20817876 138110.60517949  75039.75496672 175833.07671111
 192569.28026397 166290.23278051 163923.6533369  131055.26251261
 141882.11906321 110037.50610805 126317.1348027  161411.91695902
 174746.25543874 166481.39120978 114500.49565642 191916.1880798
 111360.1461604  235497.35280495 251753.5240955  142222.04588035
 245577.30296811 173661.89909763 207376.6634964  161083.28061412
 202718.28314043 160320.5061444  255630.70538244 279181.84584263
 124169.32236392 221202.79048914 133831.28677263 134619.75060815
 111681.44757783 180343.07075011 231017.46373724 163060.56778261
 180896.91411053 169643.74217111 205215.14415421 246586.10844136
 182117.01685184 194195.7472861  168845.29345921 264434.65199489
 155153.10990717 180143.27256082 200054.97262509 153439.64176746
 275090.53165037 199938.3886142  178876.30535818 194891.5991282
 146376.67584602 181546.39596226 166846.62990772 217979.83509929
 250480.97801376 106858.02643773 244388.40041017 224919.90169937
 231325.43287057 195699.33574901 175323.72235862 171204.80281477
 223798.77067259 203007.15952371 167247.85013504 191569.42991488
 201880.79409403 158047.81019918 248274.58634865 138220.80902043
 166273.56869466 152909.91227906 166539.13204597 216685.83762199
 341233.66983749 207847.98279917 182089.97688423 203614.38246622
 196703.1525858  123990.87301394 261463.5115474  186328.67499325
 182839.32583002 132204.21407075 186566.97672305 133144.5795449
 203897.09951869 228591.7826914  149242.31806113 178846.33532984
 239322.33038436 304259.56581698 212226.39721334 147760.26257623
 210127.77019838 202202.22010809 292104.4767871  184767.72585291
 242451.62544281 170378.27621385 152451.09639693 192538.86797894
 250148.60071197 176186.08583374 180004.59457346 163248.39225591
 134717.33617608 263863.96908799 161567.18416513 221330.4674597
 174717.96160148 222881.34673986 162246.80855534 255337.51061419
 171060.31088177]
2025-06-23 22:52:57 INFO Expected Optimum FE: -5000
2025-06-23 22:52:57 INFO Unimodal AOCC mean: 0.1471
2025-06-23 22:52:57 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:52:57 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:52:57 INFO AOCC mean: 0.0490
2025-06-23 22:55:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:56:19 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1664
2025-06-23 22:56:19 INFO FeHistory: [-183.33293178 -183.34946145 -183.39901971 ... -184.9775597  -184.9786618
 -184.97917773]
2025-06-23 22:56:19 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:56:19 INFO Good algorithm:
Algorithm Name: AdaptiveDEWithCauchyAndClusteringTournament
import numpy as np
from scipy.stats import cauchy
import random

# Name: AdaptiveDEWithCauchyAndClusteringTournament
# Description:Combines DE, adaptive Cauchy mutation, clustering, and tournament selection for multimodal optimization.
# Code:
class AdaptiveDEWithCauchyAndClusteringTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.gamma = 0.95  # Cauchy scale factor decay
        self.k = 5  # Number of clusters
        self.tournament_size = 5


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        cauchy_scale = 0.1 * (self.upper_bounds - self.lower_bounds)

        while self.eval_count < self.budget:
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                # Differential Evolution
                a, b, c = self._select_different(population, i)
                mutant = a + self.F * (b - c)

                # Cauchy Mutation
                mutant += cauchy.rvs(loc=0, scale=cauchy_scale, size=self.dim)

                # Crossover
                jrand = np.random.randint(self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == jrand:
                        offspring[i, j] = mutant[j]
                    else:
                        offspring[i, j] = population[i, j]

                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Tournament Selection with Clustering
            combined_pop = np.vstack((population, offspring))
            combined_fit = np.concatenate((fitness_values, offspring_fitness))
            
            next_gen, next_fit = self._tournament_selection_with_clustering(combined_pop, combined_fit)
            population = next_gen
            fitness_values = next_fit


            self._update_best(offspring, offspring_fitness)
            cauchy_scale *= self.gamma

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _tournament_selection_with_clustering(self, population, fitness_values):
        centroids = self._kmeans_clustering(population, self.k)
        next_generation = []
        next_generation_fitness = []

        for _ in range(self.population_size):
            tournament = random.sample(range(len(population)), self.tournament_size)
            tournament_individuals = population[tournament]
            tournament_fitness = fitness_values[tournament]

            best_index = np.argmin(tournament_fitness)
            winner = tournament_individuals[best_index]
            winner_fitness = tournament_fitness[best_index]
            next_generation.append(winner)
            next_generation_fitness.append(winner_fitness)
        return np.array(next_generation), np.array(next_generation_fitness)

    def _kmeans_clustering(self, population, k):
        #Simplified k-means++ for brevity.  Could be replaced with a more robust version
        centroids = random.sample(list(population), k)
        for _ in range(10): #Limit iterations for efficiency
            clusters = [[] for _ in range(k)]
            for point in population:
                distances = np.linalg.norm(point - np.array(centroids), axis=1)
                closest_centroid_index = np.argmin(distances)
                clusters[closest_centroid_index].append(point)
            centroids = np.array([np.mean(cluster, axis=0) if cluster else centroid for cluster, centroid in zip(clusters, centroids)])
        return centroids

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:56:19 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:56:43 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:56:43 INFO FeHistory: [ 681073.99822332 1268943.18397884 1941422.17427775 ...    2929.12939424
    2929.12939498    2929.12939496]
2025-06-23 22:56:43 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:56:43 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:57:27 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:57:27 INFO FeHistory: [ 84170.16501702 206610.99757894 149318.92641504 ...   1884.14399595
   1884.14399595   1884.14399595]
2025-06-23 22:57:27 INFO Expected Optimum FE: -5000
2025-06-23 22:57:27 INFO Unimodal AOCC mean: 0.1664
2025-06-23 22:57:27 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:57:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:57:27 INFO AOCC mean: 0.0555
