2025-06-23 22:14:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:14:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:14:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:14:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:14:56 ERROR Can not run the algorithm
2025-06-23 22:14:56 INFO Run function 6 complete. FEHistory len: 201, AOCC: 0.1467
2025-06-23 22:14:56 INFO FeHistory: [-183.35769503 -183.32875913 -183.37267331 -183.34267586 -183.37961035
 -183.23128779 -183.37306959 -183.39076884 -183.4079133  -183.28621526
 -183.41281918 -183.30291249 -183.2723605  -183.32046579 -183.38947439
 -183.3377914  -183.29778801 -183.33430083 -183.4198075  -183.37475393
 -183.31348067 -183.39877584 -183.33829157 -183.3178722  -183.31736157
 -183.33625799 -183.42370166 -183.35023809 -183.33985307 -183.35530336
 -183.271671   -183.33167608 -183.37700562 -183.33315542 -183.37392206
 -183.3387961  -183.39349086 -183.36170786 -183.39397801 -183.35167771
 -183.25608784 -183.3203057  -183.33670323 -183.309506   -183.27682191
 -183.36932988 -183.35002114 -183.44166522 -183.31752844 -183.33138658
 -183.27945991 -183.34733465 -183.30719208 -183.33917942 -183.27764244
 -183.38539261 -183.3597701  -183.28143933 -183.35175309 -183.33642418
 -183.38076511 -183.36260574 -183.31644096 -183.32908239 -183.40888395
 -183.37274662 -183.3196124  -183.35035964 -183.37094536 -183.40110213
 -183.45318254 -183.3623315  -183.29711772 -183.38508424 -183.28599704
 -183.34179121 -183.32061755 -183.40892568 -183.32896033 -183.37851909
 -183.3346148  -183.3655617  -183.36281105 -183.34230573 -183.28103834
 -183.34931841 -183.31431369 -183.35229564 -183.32258171 -183.4073856
 -183.31797787 -183.38379705 -183.41025632 -183.32593798 -183.33075992
 -183.30680458 -183.34278107 -183.31132336 -183.29322634 -183.38222302
 -183.36960878 -183.37105134 -183.39710675 -183.33088804 -183.43678617
 -183.37050424 -183.36970085 -183.40374475 -183.33104987 -183.33150043
 -183.41985176 -183.3442437  -183.38442912 -183.38477368 -183.38482436
 -183.36778791 -183.33212843 -183.39982014 -183.41883815 -183.40555507
 -183.38562089 -183.41030965 -183.42248469 -183.38743034 -183.33618751
 -183.42477299 -183.42747539 -183.40995583 -183.34538075 -183.41286961
 -183.44869094 -183.4091636  -183.40580663 -183.44199718 -183.34149498
 -183.37205716 -183.33178901 -183.37180039 -183.37728606 -183.39112366
 -183.39665142 -183.39774011 -183.36957785 -183.38773651 -183.37190496
 -183.38142751 -183.383531   -183.35672273 -183.39400492 -183.42052318
 -183.45227345 -183.38550532 -183.39504238 -183.43945071 -183.39435099
 -183.39802498 -183.41186518 -183.39452147 -183.37977    -183.43670459
 -183.40803673 -183.38769253 -183.4384419  -183.42357615 -183.38829529
 -183.41320188 -183.41770353 -183.36399632 -183.39128408 -183.3213073
 -183.37417485 -183.40614375 -183.34474627 -183.37848056 -183.37925369
 -183.36557264 -183.38898147 -183.40806021 -183.35903815 -183.38478519
 -183.35937381 -183.37721678 -183.37662478 -183.42659398 -183.34690466
 -183.37877189 -183.42273728 -183.4063246  -183.42695829 -183.4091711
 -183.37346992 -183.41028441 -183.34680776 -183.3612292  -183.37041534
 -183.40741582 -183.3739335  -183.37159724 -183.42482542 -183.37010718
 -183.41608968]
2025-06-23 22:14:56 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:14:56 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyArchiveEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to escape local optima in multimodal landscapes.
# Code:
class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (adaptive)
        self.gamma_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._cauchy_mutation(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._update_population(population, fitness_values)
            self.gamma *= self.gamma_decay  # Adaptive Cauchy scale decay
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + cauchy.rvs(loc=0, scale=self.gamma, size=parents.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, solutions, fitness_values):
        combined = np.column_stack((solutions, fitness_values))
        self.archive.extend(combined)
        self.archive.sort(key=lambda x: x[-1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size]


    def _update_population(self, population, fitness_values):
        combined_pop = np.vstack((population, self._sample_archive()))
        combined_fit = np.concatenate((fitness_values, self._get_archive_fitness()))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _sample_archive(self):
        num_samples = self.population_size // 2
        if len(self.archive) > 0 :
            return np.array([x[:-1] for x in np.random.choice(self.archive, num_samples, replace=False)])
        else:
            return np.empty((0, self.dim))

    def _get_archive_fitness(self):
        if len(self.archive) > 0:
            return np.array([x[-1] for x in self.archive])
        else:
            return np.array([])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:14:56 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:14:56 ERROR Can not run the algorithm
2025-06-23 22:14:56 INFO Run function 13 complete. FEHistory len: 201, AOCC: 0.0000
2025-06-23 22:14:56 INFO FeHistory: [1853700.84616119  495689.05449229  738642.08660617 3968320.4204218
  943508.74851    1638979.45875367 1784196.95060978 1689485.75176717
  615572.69157215 1576855.39437495 2823403.6362306  2941336.14458661
 2265885.48049509  555727.49121261 1194807.8379932   815343.12795296
 1457235.67239618 1553147.52319898  855152.2832461  1765651.13488367
  808094.70405112 2479100.78875672 1111245.32539151 1934880.17777922
 1848199.62882036 1821112.92041987 2667002.31981198 3208747.12297514
 1417166.94310174  969508.08191049 2882760.04071212 2527497.40134203
 1964923.15984215  747353.04219423 2262282.97535049 1377080.80949886
  267579.26170089 3539913.89720885 1149602.26788356 3563787.05889952
 1239251.81552273 2604403.67725777 2663213.96688376 1935436.61488336
 2177909.21870587 1175543.55723543 1282764.80714654 1588713.1779561
  862917.24171165  855818.00328271 1289308.26473913 2401050.35858135
 1594358.96001079 2245112.17478202 2696637.29210553 1436287.39544292
 2490418.77624588 1870655.43460587 1212276.35056182 1857102.60329161
 1376747.3856463   799545.04117757 2282623.73564803 1120627.67254845
 2641134.81810492 1478838.99490762 2188823.20597611 3138436.42575483
  661560.59503097  645310.69583852 1738812.02887974 3134537.26885329
 3409921.91060079  431523.46641145 2348223.68188606 1898731.43560279
 1427010.96620565 1459962.6564908  1136178.12251267 1842695.94540811
  548414.5891255  3692338.92895357 1780295.1422742  1095549.32562426
 1559851.5259892  1992734.42309459 2082153.8849553  1707002.91531051
  735128.12151416 3552987.10461213 1023075.69218517 2114643.76182821
 2021458.13685176 1409942.90276135  367644.09417694  675715.42257271
 2180130.86841124 1584415.51273895 2022719.97101991 1328316.60151947
 2282650.67634729  186403.20257056 1493673.99149114 2091820.39928258
 2575154.35713751  793357.44417003 3609774.75406399 1143278.01827205
  172812.99097354 2023911.86795356 1601367.93333468  692924.62553883
 2298677.26402088 1273566.85784212  850292.24722363 2868653.06842314
  846545.10345114 1307676.89384726  864197.18006861 2172600.98590287
 2988166.95071845 1809521.59173076 1210736.25823562 1559816.59944471
 1814625.89900836 1334495.52968435  680137.40384017 1080647.51092662
 1294667.74423113  610201.74790053  750543.66465149 1736980.65700705
 1263858.03938388 1104026.44916322 2152927.88811306 3206600.51856112
 2557244.04143389  802873.35930133 1158283.44236718 2674659.34049872
 2390619.76772511 1010474.87610188 1326200.93595553  854731.59733937
  662040.53037737 1029276.20839049 2273350.5648079  2308668.99359802
 1245840.15789474 1371124.34184433 1009253.53692252 1841981.04735374
 2678500.47076717 1214333.81471903 1269380.80226778  983650.81949149
 2520132.50925666 1098075.62214962 2184028.8571787  2019593.34805328
 1701449.16348098 2619295.74205911  913108.34380317  163807.09672393
  808774.51013925 1039555.96144749 1546481.49868445  461762.51563105
  531920.23240134 2077843.53299244  814778.16242212 1344668.14530321
 1546389.60755187 1306692.89167769 1815282.66325624  929328.80429986
  914315.29217443  938333.50727777 1016106.99128189  834796.57873382
  984598.42278711 1188010.68353777 1501010.46568308 2057803.19016225
  497184.53338414  677021.68832797  959322.92304034 2860561.50839091
 1465752.48534241 1015562.5778659  1313033.29935719 1734334.01064704
 1832631.70488716 1305732.2793331   701565.96162211 1688319.55499421
 1036500.83236639 1179696.98233137  676094.34552843  557020.98852963
 1184520.68794768]
2025-06-23 22:14:56 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:14:56 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:14:56 ERROR Can not run the algorithm
2025-06-23 22:14:57 INFO Run function 18 complete. FEHistory len: 201, AOCC: 0.0000
2025-06-23 22:14:57 INFO FeHistory: [148298.3179635  115488.84415145 162958.26990727 107214.21107786
 154338.09704361 137404.42018467 200772.92724108 172045.71977993
 108988.51400843 117506.85899262 193189.68776455 110003.467685
 198866.9512906  194012.55026712 123939.95317472 145392.0172988
 166818.18062313 158087.23693639 137443.75947293 165002.22039505
 151172.91897057 114312.35849628 203942.42302287 119110.34858584
 181393.31749308 155281.4919533  210531.50359079 103899.96885251
 117085.21500809 169949.5907377  159900.27953285 146810.50077606
 122918.61742296 138474.27742333 191009.57211939 115296.38598307
 165973.89628238 198671.78032252 198936.29778961 168280.8688451
  83030.81186659  77047.21251643 134135.43261546 165133.32232523
 149159.41361064 124595.84293249 186798.39998304 185738.6892834
 154611.70772157 143344.17150046 165359.2924186  152698.06176529
 117377.75975082 183028.60732577 129101.69016779 213415.57740931
 155026.80601632 190946.99848246 157731.24153526 156720.28883423
  84977.54180249 182065.82197566 193867.69047091 132639.65613278
 121454.97131017 152269.05420171 128214.64467031 133859.93158882
 146298.02393145 223024.42345302 183391.33029568  99237.43037565
 156455.18646172 116834.32297022 147935.83585886 155383.04575415
 136385.90075204 143878.80133164 197690.16638076 116187.20374071
 123670.99366585 131983.36040847 153961.90597701 167071.33338589
 133369.03525035 136842.63424901 190487.61020834 108197.33937632
 120877.32196292 177267.77799527 214150.0439255  151559.42785448
 145543.78424318 134126.962365   161487.48587637 200712.6176155
 117986.849415   122389.73992032 108613.10485768 146346.59710917
 124062.90252567 162795.43056278 134458.630664    99613.05561947
 115094.64637267 118798.28776505  91019.64715703 138125.72330504
 122151.72260224 126188.40375466 122007.00124251 109530.32318553
 120002.24607076 154476.82535495 135535.89647502 122765.09352934
 107008.88937402 145841.99884073  92634.95963753  86315.17224724
 135013.00428521 156595.03489765 123413.02035869 156079.56826108
 133058.99195412 117970.60364787 152504.93251783 161750.31906882
 111710.77746137 144866.92370578 162275.2418883   98319.18282648
 122492.07098376 142762.98699978  98763.48214442 142264.76866055
 113080.26351597 106107.93711899  97080.39520194 131221.19165403
 125157.32872015 100329.50707966 129755.39559134 144822.96345065
 121705.31734747 111040.93593444 133894.81741679 175904.94646579
 106077.25430779 135000.17680834 120285.12472152 153882.37678534
 114926.93386489  97518.16887218 171775.5628671  133854.30795141
 130703.12783834  69114.97160862 101851.38068493 130713.23580396
 126495.14674116 126022.69703241 102735.10812735 124766.19148837
 126094.47646123 135588.57878943 129458.04914171  82460.22126633
 104999.40039687 156552.58149711 128549.66822105  82205.48633466
  79170.42886859 112878.31903706 130509.57096675 130478.32000732
  87591.00613926 207321.82239446 120499.23465328 126445.15647855
 117003.25098535 115470.79651317 117122.81921693 136479.94327475
 110216.30854349  95968.76085135 102748.18521752 152451.69830631
 115531.71784582  92602.13323543 114507.44991909 144753.30048895
 150327.81346218 125352.49499643 159293.40919963 131638.25006863
 119989.72317862 128323.68864048 160443.92302467 158612.77224216
 111531.63565243]
2025-06-23 22:14:57 INFO Expected Optimum FE: -5000
2025-06-23 22:14:57 INFO Unimodal AOCC mean: 0.1467
2025-06-23 22:14:57 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:14:57 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:14:57 INFO AOCC mean: 0.0489
2025-06-23 22:15:05 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1565
2025-06-23 22:15:05 INFO FeHistory: [-183.35703953 -183.35312646 -183.39895327 ... -184.15453826 -184.15453826
 -184.15453826]
2025-06-23 22:15:05 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:15:05 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyExplorationEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyExplorationEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation for efficient exploration of multimodal landscapes.
# Code:
class AdaptiveCauchyExplorationEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.gamma = 1.0  # Cauchy scale parameter (initially broad exploration)
        self.gamma_decay = 0.95 #Decay rate of gamma
        self.archive = [] #To store good solutions
        self.archive_size = 100


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._cauchy_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        if self.best_solution_overall is None and self.dim > 0:  #Fallback
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            child1 = (parent1 + parent2) / 2
            child2 = (parent1 + parent2) / 2
            offspring.extend([child1, child2])
        return np.array(offspring)

    def _adaptive_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        offspring = offspring + mutation
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            if len(self.archive) < self.archive_size:
                self.archive.append((sol, offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (sol, offspring_fitness[i])
2025-06-23 22:15:05 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:15:05 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1616
2025-06-23 22:15:05 INFO FeHistory: [-183.38774548 -183.34886854 -183.27849902 ... -184.91116258 -184.86380211
 -184.90202053]
2025-06-23 22:15:05 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:15:05 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithArchive
import numpy as np
import random

# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential Evolution with an archive to escape local optima and adaptive mutation strength.
# Code:
class AdaptiveDifferentialEvolutionWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.sigma_mult = 0.1 # Initial mutation strength multiplier

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.F = max(0.1, self.F * 0.99) #Slowly decay F to focus on exploitation
            self.sigma_mult *= 0.995 # Slowly reduce mutation strength

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_individuals(i, population)
            mutant = a + self.F * (b - c) + np.random.normal(0, self.sigma_mult * (self.upper_bounds - self.lower_bounds), size=self.dim)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _select_individuals(self, i, population):
        indices = list(range(self.population_size))
        indices.remove(i)
        a = population[i]
        b = population[random.choice(indices)]
        c = population[random.choice(indices)]
        return a, b, c

    def _crossover(self, parent, mutant):
        child = np.copy(parent)
        for j in range(self.dim):
            if random.random() < self.CR:
                child[j] = mutant[j]
        return child

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:15:05 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:15:06 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1527
2025-06-23 22:15:06 INFO FeHistory: [-183.43082501 -183.4182188  -183.41827805 ... -183.90033958 -183.90033958
 -183.90033958]
2025-06-23 22:15:06 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:15:06 INFO Good algorithm:
Algorithm Name: AdaptiveCauchySamplingWithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchySamplingWithArchive
# Description: An evolutionary algorithm using adaptive Cauchy sampling and an archive to escape local optima in multimodal landscapes.
# Code:
class AdaptiveCauchySamplingWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.mutation_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Cauchy mutation)
            offspring = self._cauchy_recombination(parents)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self._update_archive(offspring, offspring_fitness)

            # Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)

            # Adapt Cauchy scale parameter
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.gamma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:15:06 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:15:14 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:15:14 INFO FeHistory: [3.26306714e+06 1.32281642e+06 1.01684692e+06 ... 1.33498062e+03
 1.33498062e+03 1.33498062e+03]
2025-06-23 22:15:14 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:15:14 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:15:15 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:15:15 INFO FeHistory: [3637461.21614485  988363.60667467 1402176.42881367 ...    9544.03334612
   61020.7123172    49981.16060724]
2025-06-23 22:15:15 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:15:15 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:15:16 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:15:16 INFO FeHistory: [1.79872211e+06 2.07585516e+06 4.84330617e+06 ... 3.07994823e+03
 3.07994823e+03 3.07994823e+03]
2025-06-23 22:15:16 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:15:16 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:15:44 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:15:44 INFO FeHistory: [169668.17724787  89528.85767089 149395.01900336 ...   5788.48537525
   5788.48537525   5788.48537525]
2025-06-23 22:15:44 INFO Expected Optimum FE: -5000
2025-06-23 22:15:44 INFO Unimodal AOCC mean: 0.1565
2025-06-23 22:15:44 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:15:44 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:15:44 INFO AOCC mean: 0.0522
2025-06-23 22:15:45 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0502
2025-06-23 22:15:45 INFO FeHistory: [ 98508.857587   116896.60383055 168546.78313952 ...  -4996.56320547
  -4998.41253669  -4997.80678494]
2025-06-23 22:15:45 INFO Expected Optimum FE: -5000
2025-06-23 22:15:45 INFO Unimodal AOCC mean: 0.1616
2025-06-23 22:15:45 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:15:45 INFO Multimodal (multiple components) AOCC mean: 0.0502
2025-06-23 22:15:45 INFO AOCC mean: 0.0706
2025-06-23 22:15:47 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:15:47 INFO FeHistory: [142176.2004163  143121.88453809 145326.48846981 ...  38093.29924382
  38093.29924382  38093.29924382]
2025-06-23 22:15:47 INFO Expected Optimum FE: -5000
2025-06-23 22:15:47 INFO Unimodal AOCC mean: 0.1527
2025-06-23 22:15:47 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:15:47 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:15:47 INFO AOCC mean: 0.0509
2025-06-23 22:17:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:17:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:17:53 ERROR Can not run the algorithm
2025-06-23 22:17:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:17:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:17:53 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1473
2025-06-23 22:17:53 INFO FeHistory: [-183.29971989 -183.30399185 -183.25708112 -183.31387584 -183.40699333
 -183.30024869 -183.42546188 -183.28698201 -183.33532806 -183.3712027
 -183.37920843 -183.35532562 -183.34413334 -183.31965162 -183.40723307
 -183.37614865 -183.3946667  -183.37890513 -183.3161715  -183.30355091
 -183.35813508 -183.45222296 -183.41671812 -183.34420477 -183.32240353
 -183.28476584 -183.31317224 -183.26541259 -183.39851794 -183.3390871
 -183.35513834 -183.42488699 -183.37796438 -183.41497651 -183.35446582
 -183.2721142  -183.44037236 -183.31917391 -183.38319657 -183.34819468
 -183.38479884 -183.35508706 -183.32237807 -183.29409798 -183.34270255
 -183.32982561 -183.33950891 -183.40755379 -183.45791489 -183.24663846
 -183.31731219 -183.35842309 -183.33709893 -183.41093367 -183.32575671
 -183.37352835 -183.3425861  -183.33221247 -183.35324269 -183.31067419
 -183.33328568 -183.28448055 -183.33547532 -183.38359819 -183.38168524
 -183.34776241 -183.4381349  -183.40549935 -183.34657758 -183.35195954
 -183.34036889 -183.36236773 -183.42784767 -183.29017731 -183.35261933
 -183.31955082 -183.41202596 -183.36779544 -183.33926144 -183.35782705
 -183.3395676  -183.4094817  -183.44719211 -183.33364466 -183.38051239
 -183.37309751 -183.38260014 -183.34871596 -183.39813566 -183.31020036
 -183.49664857 -183.32689756 -183.31947968 -183.36884575 -183.31340902
 -183.3574648  -183.33154604 -183.44814253 -183.32224585 -183.38475051]
2025-06-23 22:17:53 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:17:53 INFO Good algorithm:
Algorithm Name: ArchiveGuidedAdaptiveCauchyDE
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
class ArchiveGuidedAdaptiveCauchyDE:
    """
    Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100, population_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []
        self.population_size = population_size

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.gamma = 1.0 #Initial Cauchy scale parameter
        self.gamma_decay = 0.99 #Decay rate for gamma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Mutation with Archive Augmentation
                a, b, c = self._select_different(i, population)
                mutant = self._differential_mutation(population[a], population[b], population[c])

                # Adaptive Cauchy perturbation
                mutant += self._cauchy_mutation(self.gamma)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover (Binomial)
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    self._update_archive(trial, trial_fitness)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(fitness[:len(new_population)]))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        candidates = list(range(len(population))) + [i for i in range(len(self.archive))]
        a, b, c = random.sample(candidates, 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(candidates, 3)

        if a >= len(population):
            a_val = self.archive[a - len(population)][0]
        else:
            a_val = population[a]
        if b >= len(population):
            b_val = self.archive[b - len(population)][0]
        else:
            b_val = population[b]
        if c >= len(population):
            c_val = self.archive[c - len(population)][0]
        else:
            c_val = population[c]

        return a_val, b_val, c_val

    def _differential_mutation(self, a, b, c):
        return a + 0.8 * (b - c) #fixed mutation scale

    def _cauchy_mutation(self, gamma):
        return gamma * np.random.standard_cauchy(self.dim)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

2025-06-23 22:17:53 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:17:53 ERROR Can not run the algorithm
2025-06-23 22:17:54 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:17:54 INFO FeHistory: [1663302.296891   1307744.06194838 2043755.05741749 2039825.18501924
 1006594.68752432 2000246.63246566 2285791.36066324 2703502.92164089
 1593342.16709229 2422407.56374801  962764.49054382 1032439.8079158
 1108591.09054014  528047.6458043  2808057.79268426 2358712.1296519
 1036670.89466816 2823572.71852285  570773.20206336 3111644.91546916
 3295265.90338804 1405866.49899938 1791444.6446101  1579302.06043209
 1325279.59110698 2606100.84069335  847432.57249677 2482768.51478505
 2543324.81441578 2439288.80579044 2935158.72433048 2050850.07902064
 3412141.27354662 3328899.30441305  857311.01725329  587404.31490956
 2163459.27035302 1420244.15269686 1459322.18271869 1661387.36450757
 1572792.09852086 1167679.99420025 1345491.8365934  1013811.7838127
 3404381.14165031 2126436.1705643  4789588.08702424 1388267.88366783
 2331600.23448306 1760908.70939953 1794256.09894746 1233422.51431387
 1272584.55401083 1134553.41081909 2412759.20670876 1254247.48580799
 2519192.60252404 1583267.76640113 3318469.11792849 3009705.51190772
 1393251.22175629 1034636.90382689 2745806.58548645 3102927.94831445
 1379553.33834869 5491449.27599394  378517.00770965 1084129.31678948
 3087979.08203976 3133097.13042426 3088342.09972151 1861469.22742275
 1712772.80883209 1795038.44268382  967920.9332759  1556446.62388831
  430948.14459113 2157835.20509509 3033237.62200597 1472621.07568879
 3396026.90327371  422391.47751731 4561782.68106699 1601731.95825488
 1620229.52333221 3033208.36703568 2498539.88498425  595018.85296257
  937999.27664774  399312.85582799  766759.7322009  2059785.00111706
 1077809.62972562 2913089.21885467 3447794.78177242 1850334.47876566
 4385395.23157    2066104.26930111 1301543.48733586 1297051.98785578]
2025-06-23 22:17:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:17:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:17:54 ERROR Can not run the algorithm
2025-06-23 22:17:54 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:17:54 INFO FeHistory: [106931.4575344  227733.88162879 131400.91758235 176515.24824588
 160237.47808107 147582.17314977  95130.00131067 190929.07782464
  98213.96663604 159605.21935887 170174.35358539 147242.28039015
 129185.99482384 119990.9954466  137071.00675518  79460.5238575
 199699.14863278 104447.48901243 177570.59354809 133411.35829216
 104866.87321772 184236.45707906 152677.17991126 169022.24127291
 179644.71801289 148228.55436555 187558.30440482 151853.49582931
 166720.17906248 169131.22313605 133260.08906999 206908.92489851
 134950.42192477 193528.05255187 159231.64545153 128953.94002553
 179419.45805904 113080.42456921 112489.79063468 118694.41112801
 171543.50335642 206132.72396163 135047.46501834 128848.32318005
 136363.89619614 153975.96373393 180756.0594399  150440.56445355
 130323.09163012 115512.91054253 135536.68834577 166556.68078362
 192328.9737969  124028.4200866  188244.51983298 224042.95624001
 212605.04141567 148998.07060466 162948.03945893 158956.5136034
 182103.26582457 135720.15691641 106880.38697981 173847.64648947
 154296.08496613 171824.98252192 164503.92967247 119675.89123203
 173241.99239139 199638.0758513  149922.73079636 158966.94367601
 149580.55156137 151650.48768243 229328.64961491 176405.54531705
 119617.68423081 169169.69361017 206311.17158508 119899.51471892
 150459.41438413  99111.33960936 146490.27413315 151938.03824779
 162009.14875739 148096.01841828 140959.06807511 146728.6759778
 131562.69997741 164863.67749502 119681.0744594  148700.85557049
 232288.07229249  95209.59943344 159348.58332012 127274.24357026
 124793.22852798 129172.9166593  157190.00391648 213904.49157645]
2025-06-23 22:17:54 INFO Expected Optimum FE: -5000
2025-06-23 22:17:54 INFO Unimodal AOCC mean: 0.1473
2025-06-23 22:17:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:17:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:17:54 INFO AOCC mean: 0.0491
2025-06-23 22:17:54 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:20:52 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1771
2025-06-23 22:20:52 INFO FeHistory: [-183.3245386  -183.32310929 -183.40117288 ... -185.96818334 -185.97029872
 -185.96307941]
2025-06-23 22:20:52 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:20:52 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEWithArchive
import numpy as np
import random

class AdaptiveCauchyDEWithArchive:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and an archive to enhance exploration and exploitation in multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0 #Cauchy scale parameter, initialized to 1
        self.gamma_decay = 0.95 #Decay rate for gamma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt Cauchy scale parameter
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        F = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + F * (pbest - population[i] + population[a] - population[b])
            
            #Cauchy Mutation
            cauchy_noise = self.gamma * np.random.standard_cauchy(self.dim)
            offspring[i] = mutant + cauchy_noise

            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

2025-06-23 22:20:52 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:20:54 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1534
2025-06-23 22:20:54 INFO FeHistory: [-183.36953312 -183.34243951 -183.34381249 ... -183.95363953 -183.95363953
 -183.95363953]
2025-06-23 22:20:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:20:54 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyArchiveEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: Combines Cauchy mutation with an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.mutation_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Cauchy mutation)
            offspring = self._cauchy_recombination(parents)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self._update_archive(offspring, offspring_fitness)

            # Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)

            # Adapt Cauchy scale parameter
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.gamma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:20:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:20:54 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1537
2025-06-23 22:20:54 INFO FeHistory: [-183.32557054 -183.41446699 -183.3161796  ... -183.9652811  -183.9652811
 -183.9652811 ]
2025-06-23 22:20:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:20:54 INFO Good algorithm:
Algorithm Name: ArchiveGuidedAdaptiveCauchyEA
import numpy as np

class ArchiveGuidedAdaptiveCauchyEA:
    """
    Combines Cauchy mutation for robust exploration with an archive for diversity preservation in high-dimensional multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (initially large for exploration)
        self.gamma_decay = 0.95 #Decay rate of gamma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._cauchy_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + self._cauchy_sample(self.gamma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + self._cauchy_sample(self.gamma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _cauchy_sample(self, scale, dim):
        return scale * np.tan(np.pi * (np.random.rand(dim) - 0.5))

    def _adaptive_mutation(self, offspring):
        return np.clip(offspring + self._cauchy_sample(self.gamma, self.dim), self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            self._add_to_archive(population[i], fitness_values[i])

    def _add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:20:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:20:54 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1590
2025-06-23 22:20:54 INFO FeHistory: [-183.26395996 -183.37034652 -183.2630978  ... -184.75489356 -184.73507915
 -184.71158357]
2025-06-23 22:20:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:20:54 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95 #Decay rate for Cauchy scale parameter
        self.F = 0.5 #Differential Evolution scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)

            population, fitness = self._select_next_generation(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay #Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            
            #Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _select_next_generation(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
2025-06-23 22:20:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:21:03 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:03 INFO FeHistory: [ 491295.7801859  2655053.34429585 4803046.75345566 ...  526268.35790208
  362416.32673999  141333.91538101]
2025-06-23 22:21:03 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:03 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:21:05 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:05 INFO FeHistory: [1496088.10665662 2542120.94342631 2020615.76928218 ...    2873.02459479
    2873.02459479    2873.02459479]
2025-06-23 22:21:05 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:05 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:21:06 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:06 INFO FeHistory: [2.36728322e+06 2.17618228e+06 2.19328984e+06 ... 1.88495505e+03
 1.88495505e+03 1.88495505e+03]
2025-06-23 22:21:06 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:06 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:21:07 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:07 INFO FeHistory: [1249321.50491042 2471790.2258969  1939921.23678642 ... 1043029.1573858
  542373.64728875  863006.81003923]
2025-06-23 22:21:07 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:07 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:21:33 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.1588
2025-06-23 22:21:33 INFO FeHistory: [162268.18738684 139255.48802027  60301.10581948 ...  -4999.99265794
  -4999.99690926  -4999.99543497]
2025-06-23 22:21:33 INFO Expected Optimum FE: -5000
2025-06-23 22:21:33 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEWithArchive
import numpy as np
import random

class AdaptiveCauchyDEWithArchive:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and an archive to enhance exploration and exploitation in multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0 #Cauchy scale parameter, initialized to 1
        self.gamma_decay = 0.95 #Decay rate for gamma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt Cauchy scale parameter
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        F = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + F * (pbest - population[i] + population[a] - population[b])
            
            #Cauchy Mutation
            cauchy_noise = self.gamma * np.random.standard_cauchy(self.dim)
            offspring[i] = mutant + cauchy_noise

            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

2025-06-23 22:21:33 INFO Unimodal AOCC mean: 0.1771
2025-06-23 22:21:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:21:33 INFO Multimodal (multiple components) AOCC mean: 0.1588
2025-06-23 22:21:33 INFO AOCC mean: 0.1120
2025-06-23 22:21:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:21:36 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:36 INFO FeHistory: [180963.89703176 145092.29662358 142737.0927739  ...  47992.3147286
  47992.3147286   47992.3147286 ]
2025-06-23 22:21:36 INFO Expected Optimum FE: -5000
2025-06-23 22:21:36 INFO Unimodal AOCC mean: 0.1534
2025-06-23 22:21:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:21:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:21:36 INFO AOCC mean: 0.0511
2025-06-23 22:21:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:21:38 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:38 INFO FeHistory: [210959.33427087 142273.88949291 166469.03296285 ...  22626.88929181
  22626.88929181  22626.88929181]
2025-06-23 22:21:38 INFO Expected Optimum FE: -5000
2025-06-23 22:21:38 INFO Unimodal AOCC mean: 0.1537
2025-06-23 22:21:38 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:21:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:21:38 INFO AOCC mean: 0.0512
2025-06-23 22:21:38 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:21:40 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:40 INFO FeHistory: [166695.51691148 164780.49247756 131227.88206029 ...  -4353.89643629
  -4323.33929223  -4305.12314189]
2025-06-23 22:21:40 INFO Expected Optimum FE: -5000
2025-06-23 22:21:40 INFO Unimodal AOCC mean: 0.1590
2025-06-23 22:21:40 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:21:40 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:21:40 INFO AOCC mean: 0.0530
2025-06-23 22:21:40 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:21:44 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1511
2025-06-23 22:21:44 INFO FeHistory: [-183.31239791 -183.31807795 -183.48346976 ... -183.70613325 -183.68681865
 -183.65185346]
2025-06-23 22:21:44 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:21:44 INFO Good algorithm:
Algorithm Name: ArchiveGuidedCauchyDE
import numpy as np
import random

class ArchiveGuidedCauchyDE:
    """
    Combines Differential Evolution with Cauchy mutation and an archive to enhance exploration and exploitation in multimodal optimization problems. The archive stores promising solutions, promoting diversity and preventing premature convergence.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100, population_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []
        self.population_size = population_size

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.gamma = 1.0 #Cauchy scale parameter


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += len(fitness)

        self.best_solution_overall = population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        self.update_archive(population, fitness)

        while self.eval_count < self.budget:
            # Differential Evolution with Cauchy Mutation
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                
                #Cauchy Mutation
                mutant += np.random.standard_cauchy(self.dim) * self.gamma
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    offspring[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    offspring[i] = population[i]

            population = offspring
            
            self.update_archive(population, fitness)
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def update_archive(self, population, fitness):
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))
        self.archive.sort(key=lambda x: x[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] #Keep only the best

2025-06-23 22:21:44 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:21:47 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1524
2025-06-23 22:21:47 INFO FeHistory: [-183.3215556  -183.32018761 -183.36693589 ... -183.84322688 -183.82804139
 -183.8610971 ]
2025-06-23 22:21:47 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:21:47 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEWithArchive
import numpy as np
from scipy.stats import cauchy, norm

# Name: AdaptiveCauchyDEWithArchive
# Description: Combines Cauchy mutation with Differential Evolution and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            trial = self._crossover(population[i], mutant)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_parents(self, i, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:21:47 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:21:48 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1500
2025-06-23 22:21:48 INFO FeHistory: [-183.37514689 -183.36677514 -183.33294212 ... -183.4659198  -183.42673158
 -183.43240688]
2025-06-23 22:21:48 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:21:48 INFO Good algorithm:
Algorithm Name: ArchiveGuidedAdaptiveCauchyDE
import numpy as np
import random

class ArchiveGuidedAdaptiveCauchyDE:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and an archive for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.gamma = 1.0 #initial Cauchy scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt Cauchy scale parameter based on progress. Reduce gamma if close to optimum.
            self.gamma = max(0.1, self.gamma * (1 - 0.1 * (self.best_fitness_overall < 1.0)))


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            
            #Cauchy Mutation
            cauchy_noise = np.random.standard_cauchy(self.dim) * self.gamma * (self.upper_bounds - self.lower_bounds)
            offspring[i] = mutant + cauchy_noise
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

2025-06-23 22:21:48 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:21:53 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1595
2025-06-23 22:21:53 INFO FeHistory: [-183.40431443 -183.38589358 -183.29459284 ... -184.37784526 -184.37784526
 -184.37784526]
2025-06-23 22:21:53 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:21:53 INFO Good algorithm:
Algorithm Name: ArchiveGuidedCauchyDE
import numpy as np
from scipy.stats import cauchy

# Name: ArchiveGuidedCauchyDE
# Description: Differential Evolution with adaptive Cauchy mutation and archive for multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    """
    Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.  
    Employs Cauchy's heavy tails for enhanced exploration in high-dimensional spaces.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness[:len(new_population)])
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < 0.5, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)
2025-06-23 22:21:53 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:21:54 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:54 INFO FeHistory: [1560858.45335808 1698806.48763961 1385637.20453265 ... 2098851.88974521
 3736499.8951084  2325864.18779522]
2025-06-23 22:21:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:21:57 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:57 INFO FeHistory: [3238848.05778967 2749634.22350344 1290225.26697878 ... 1196316.26895037
 1025976.89690946  599615.95541583]
2025-06-23 22:21:57 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:57 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:21:58 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:21:58 INFO FeHistory: [2392117.59607308 1170676.43013504 1596821.48156205 ... 5369981.61295759
 5326774.80503404 2545043.71451267]
2025-06-23 22:21:58 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:21:58 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:22:06 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:22:06 INFO FeHistory: [1029688.24826889 2552149.76936618 1907649.79754171 ...  727878.75360692
  570601.92141176  700612.73315793]
2025-06-23 22:22:06 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:22:06 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:22:26 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:22:26 INFO FeHistory: [218123.05607405 236249.47535003 127339.91789953 ...  44475.20119899
  40461.83292359  19342.80815229]
2025-06-23 22:22:26 INFO Expected Optimum FE: -5000
2025-06-23 22:22:26 INFO Unimodal AOCC mean: 0.1511
2025-06-23 22:22:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:22:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:22:26 INFO AOCC mean: 0.0504
2025-06-23 22:22:28 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:22:28 INFO FeHistory: [121994.55643519  94620.33624056  95347.5945621  ...  29085.8946639
  23840.77019929  16227.86786443]
2025-06-23 22:22:28 INFO Expected Optimum FE: -5000
2025-06-23 22:22:28 INFO Unimodal AOCC mean: 0.1524
2025-06-23 22:22:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:22:28 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:22:28 INFO AOCC mean: 0.0508
2025-06-23 22:22:29 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:22:29 INFO FeHistory: [190844.71889453 160152.9742083  146468.83266931 ... 286435.59716917
 281891.46785782 216332.86192291]
2025-06-23 22:22:29 INFO Expected Optimum FE: -5000
2025-06-23 22:22:29 INFO Unimodal AOCC mean: 0.1500
2025-06-23 22:22:29 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:22:29 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:22:29 INFO AOCC mean: 0.0500
2025-06-23 22:22:41 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:22:41 INFO FeHistory: [222004.95168857 175197.18938472 115812.03253609 ...  -4013.3307528
  -4013.3307528   79959.62109283]
2025-06-23 22:22:41 INFO Expected Optimum FE: -5000
2025-06-23 22:22:41 INFO Unimodal AOCC mean: 0.1595
2025-06-23 22:22:41 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:22:41 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:22:41 INFO AOCC mean: 0.0532
2025-06-23 22:23:27 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:23:27 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:23:27 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:23:27 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:23:37 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1594
2025-06-23 22:23:37 INFO FeHistory: [-183.32042464 -183.35513061 -183.37887415 ... -184.32968829 -184.32968829
 -184.32968829]
2025-06-23 22:23:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:23:37 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyArchiveEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to maintain solution diversity for high-dimensional multimodal optimization.
# Code:

class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (adaptive)
        self.gamma_decay = 0.95

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (intermediate recombination)
            offspring = self._intermediate_recombination(parents)

            # Mutation (adaptive Cauchy mutation)
            offspring = self._cauchy_mutation(offspring)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _intermediate_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            child1 = (parent1 + parent2) / 2
            child2 = (parent1 + parent2) / 2
            offspring.extend([child1, child2])
        return np.array(offspring)

    def _cauchy_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        mutated_offspring = offspring + mutation
        return np.clip(mutated_offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:23:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:23:38 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1692
2025-06-23 22:23:38 INFO FeHistory: [-183.35307771 -183.3151465  -183.35127145 ... -184.9993557  -184.9993559
 -184.99935571]
2025-06-23 22:23:38 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:23:38 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyArchiveEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to maintain solution diversity for high-dimensional multimodal optimization.
# Code:

class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (initially broad)
        self.gamma_decay = 0.98

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._update_population(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay  # Adaptive decay of Cauchy scale
            self._update_best(offspring, offspring_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        parents = self._tournament_selection(population, fitness_values, tournament_size=5)
        offspring = parents + cauchy.rvs(loc=0, scale=self.gamma, size=parents.shape)
        offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)
        return offspring

    def _tournament_selection(self, population, fitness_values, tournament_size):
        num_parents = len(population)
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _update_population(self, population, fitness_values, offspring, offspring_fitness):
      combined_pop = np.vstack((population, offspring))
      combined_fit = np.concatenate((fitness_values, offspring_fitness))
      sorted_indices = np.argsort(combined_fit)
      next_gen = combined_pop[sorted_indices[:self.population_size]]
      next_fit = combined_fit[sorted_indices[:self.population_size]]
      return next_gen, next_fit

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            if len(self.archive) < self.archive_size:
                self.archive.append((sol, offspring_fitness[i]))
            else:
                worst_index = np.argmax([fit for _, fit in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (sol, offspring_fitness[i])


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:23:38 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:23:38 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1664
2025-06-23 22:23:38 INFO FeHistory: [-183.30816072 -183.44883625 -183.41842249 ... -185.05439143 -185.05430744
 -185.05435758]
2025-06-23 22:23:38 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:23:38 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyArchiveEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to maintain solution diversity for high-dimensional multimodal optimization.
# Code:
class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 500  # Size of the archive
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._cauchy_mutation(population, self.gamma)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self.gamma *= self.gamma_decay
            self._update_best(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _cauchy_mutation(self, population, gamma):
        mutation = cauchy.rvs(loc=0, scale=gamma, size=population.shape)
        offspring = population + mutation
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            solution = population[i]
            fitness = fitness_values[i]
            if len(self.archive) < self.archive_size:
                self.archive.append((solution, fitness))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if fitness < self.archive[worst_index][1]:
                    self.archive[worst_index] = (solution, fitness)

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]
2025-06-23 22:23:38 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:23:39 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1737
2025-06-23 22:23:39 INFO FeHistory: [-183.25451331 -183.35262074 -183.36341737 ... -185.22620838 -185.22620838
 -185.22620839]
2025-06-23 22:23:39 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:23:39 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyArchiveEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to maintain diversity for high-dimensional multimodal optimization.
# Code:
class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.99 #Decay rate of gamma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._cauchy_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(population, fitness_values)
            self.gamma *= self.gamma_decay
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        #Adaptive Cauchy Mutation
        offspring += cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    
    def _update_archive(self, population, fitness_values):
        #Maintain diversity using archive
        for i in range(len(population)):
             self.archive.append((population[i], fitness_values[i]))
        if len(self.archive) > self.archive_size:
             self.archive.sort(key=lambda x: x[1])
             self.archive = self.archive[:self.archive_size]

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]
2025-06-23 22:23:39 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:23:46 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:23:46 INFO FeHistory: [8.38039338e+05 1.25003361e+06 3.69210448e+06 ... 7.54919851e+02
 7.54919851e+02 7.54919851e+02]
2025-06-23 22:23:46 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:23:46 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:23:48 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:23:48 INFO FeHistory: [ 492801.49228517 1274927.45256572 1285950.24508201 ...    2332.63038519
    2332.63038519    2332.63038519]
2025-06-23 22:23:48 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:23:48 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:23:49 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:23:49 INFO FeHistory: [1.74838579e+06 1.12344259e+06 2.00509754e+06 ... 1.83160174e+03
 1.83160468e+03 1.83160187e+03]
2025-06-23 22:23:49 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:23:49 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:23:50 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:23:50 INFO FeHistory: [2.64953316e+06 1.74324224e+06 1.25332314e+06 ... 7.41374571e+02
 7.41374571e+02 7.41374571e+02]
2025-06-23 22:23:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:23:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:16 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:24:16 INFO FeHistory: [149268.06264308 140015.82357204 130622.66882438 ...   7709.27719461
   7709.27719461   7709.27719461]
2025-06-23 22:24:16 INFO Expected Optimum FE: -5000
2025-06-23 22:24:16 INFO Unimodal AOCC mean: 0.1594
2025-06-23 22:24:16 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:16 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:16 INFO AOCC mean: 0.0531
2025-06-23 22:24:19 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:24:19 INFO FeHistory: [145703.95130922 138682.49800806 146142.07762824 ...  21725.32643382
  21725.32643362  21725.32643365]
2025-06-23 22:24:19 INFO Expected Optimum FE: -5000
2025-06-23 22:24:19 INFO Unimodal AOCC mean: 0.1692
2025-06-23 22:24:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:19 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:19 INFO AOCC mean: 0.0564
2025-06-23 22:24:21 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:24:21 INFO FeHistory: [ 98415.57146539 126470.46620255 191426.34714563 ...   8700.09617576
   8700.09656672   8700.10628836]
2025-06-23 22:24:21 INFO Expected Optimum FE: -5000
2025-06-23 22:24:21 INFO Unimodal AOCC mean: 0.1664
2025-06-23 22:24:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:21 INFO AOCC mean: 0.0555
2025-06-23 22:24:22 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:24:22 INFO FeHistory: [120403.32905116 158228.98535603 114756.58491789 ...  -1886.84938469
  -1886.84938469  -1886.84938469]
2025-06-23 22:24:22 INFO Expected Optimum FE: -5000
2025-06-23 22:24:22 INFO Unimodal AOCC mean: 0.1737
2025-06-23 22:24:22 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:22 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:22 INFO AOCC mean: 0.0579
2025-06-23 22:26:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:26:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:26:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:26:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:26:32 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1504
2025-06-23 22:26:32 INFO FeHistory: [-183.23617333 -183.34754371 -183.32721939 ... -183.73329656 -183.65192104
 -183.60346757]
2025-06-23 22:26:32 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:26:32 INFO Good algorithm:
Algorithm Name: ArchiveGuidedCauchyDE
import numpy as np
from scipy.stats import cauchy

# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic population sizing
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._cauchy_mutation(offspring) # Apply Cauchy mutation after DE
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Choose 3 distinct vectors (excluding the current one)
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)
            a, b, c = population[indices]
            mutant = a + self.F * (b - c)
            
            # Binomial crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crossover_mask, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _cauchy_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        mutated_offspring = offspring + mutation
        return np.clip(mutated_offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:26:32 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:26:33 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1506
2025-06-23 22:26:33 INFO FeHistory: [-183.33859324 -183.40045425 -183.32087733 ... -183.64567547 -183.59955754
 -183.61809259]
2025-06-23 22:26:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:26:33 INFO Good algorithm:
Algorithm Name: ArchiveGuidedCauchyDE
import numpy as np
from scipy.stats import cauchy

# Name: ArchiveGuidedCauchyDE
# Description:  Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim # Heuristic population sizing
        self.archive_size = 2 * self.population_size
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (adaptive)
        self.gamma_decay = 0.95
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._cauchy_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_different_individuals(i,len(population))
            mutant = population[a] + self.F * (population[b] - population[c])
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different_individuals(self, i, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(i)
        np.random.shuffle(candidates)
        return candidates[0], candidates[1], candidates[2]
    
    def _crossover(self,x,v):
        jrand = np.random.randint(self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _cauchy_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        mutated_offspring = offspring + mutation
        return np.clip(mutated_offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:26:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:26:36 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1591
2025-06-23 22:26:36 INFO FeHistory: [-183.35375579 -183.33011473 -183.36217812 ... -184.35078197 -184.35078197
 -184.35078197]
2025-06-23 22:26:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:26:36 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, and an archive for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness[:len(new_population)])
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)
2025-06-23 22:26:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:26:39 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1629
2025-06-23 22:26:39 INFO FeHistory: [-183.34237966 -183.40542941 -183.35009318 ... -184.84102892 -184.84104486
 -184.84167743]
2025-06-23 22:26:39 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:26:39 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchive
# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and archive for multimodal optimization.
# Code:
import numpy as np
from scipy.stats import cauchy

class AdaptiveCauchyDEwithArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, and an archive for robust multimodal optimization.
    Uses Cauchy distribution for exploration and DE for exploitation, dynamically adjusting mutation scale.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=None, archive_size=100, gamma_init=1.0, gamma_decay=0.95):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.population_size = population_size if population_size is not None else 10 * dim #Heuristic
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness[:len(new_population)])
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay #Adaptive Mutation Scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < 0.5, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)
2025-06-23 22:26:39 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:26:43 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:26:43 INFO FeHistory: [ 866273.59064387 1725663.12766257 1869793.81932597 ... 2095987.38436872
 1216909.08825291 1427301.45214399]
2025-06-23 22:26:43 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:26:43 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:26:43 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:26:43 INFO FeHistory: [1524514.26588548 3425330.43744564  975926.41450624 ... 1756812.05330393
 1469831.76355154 2700398.52408782]
2025-06-23 22:26:43 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:26:43 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:26:51 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:26:51 INFO FeHistory: [1925723.30091881 1235694.47691369 1369432.38302956 ...    2624.15243195
    2624.15243195    2624.15243195]
2025-06-23 22:26:51 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:26:51 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:26:56 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:26:56 INFO FeHistory: [2197324.2578631   619523.22646505 1644199.96402123 ...  553660.28854375
  439152.62071884  919217.44310629]
2025-06-23 22:26:56 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:26:56 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:27:14 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:14 INFO FeHistory: [139129.17511312 130954.74762705 130034.62625446 ...  59216.78862835
  58063.96770929  47903.00097623]
2025-06-23 22:27:14 INFO Expected Optimum FE: -5000
2025-06-23 22:27:14 INFO Unimodal AOCC mean: 0.1504
2025-06-23 22:27:14 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:27:14 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:27:14 INFO AOCC mean: 0.0501
2025-06-23 22:27:14 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:27:15 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:15 INFO FeHistory: [162671.28918392 127384.15399554  94164.5175482  ...  29524.46274393
  55652.9073139   64850.18496731]
2025-06-23 22:27:15 INFO Expected Optimum FE: -5000
2025-06-23 22:27:15 INFO Unimodal AOCC mean: 0.1506
2025-06-23 22:27:15 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:27:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:27:15 INFO AOCC mean: 0.0502
2025-06-23 22:27:15 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:27:26 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:26 INFO FeHistory: [183728.32905096 149251.50810117 113460.78122116 ...   -414.72361093
   -414.72361093   -414.72361093]
2025-06-23 22:27:26 INFO Expected Optimum FE: -5000
2025-06-23 22:27:26 INFO Unimodal AOCC mean: 0.1591
2025-06-23 22:27:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:27:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:27:26 INFO AOCC mean: 0.0530
2025-06-23 22:27:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:27:27 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1665
2025-06-23 22:27:27 INFO FeHistory: [-183.36627091 -183.40523572 -183.35788588 ... -185.00765146 -185.00835433
 -185.00744188]
2025-06-23 22:27:27 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:27:27 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEWithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEWithArchiveAndTournament
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive with tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEWithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, and an archive, 
    enhanced with tournament selection for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100  #Heuristic population size
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.F = 0.8
        self.CR = 0.9
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._tournament_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c]) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = self._crossover(population[i], mutant)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_parents(self, i, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]

    def _tournament_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        next_gen = np.zeros_like(population)
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]

        return next_gen, next_fit
            

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:27:27 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:27:28 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1597
2025-06-23 22:27:28 INFO FeHistory: [-183.33857397 -183.39241955 -183.32853136 ... -184.45884828 -184.45881458
 -184.45881452]
2025-06-23 22:27:28 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:27:28 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelection
# Description: Combines Differential Evolution with adaptive Cauchy mutation and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95 #Decay rate for Cauchy scale parameter
        self.F = 0.5 #Differential Evolution scaling factor
        self.tournament_size = 5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay #Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            
            #Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

2025-06-23 22:27:28 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:27:36 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:36 INFO FeHistory: [111098.27199398 201183.34310871 130161.86490906 ...  -4246.657513
  -4247.89395159  -4254.33673744]
2025-06-23 22:27:36 INFO Expected Optimum FE: -5000
2025-06-23 22:27:36 INFO Unimodal AOCC mean: 0.1629
2025-06-23 22:27:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:27:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:27:36 INFO AOCC mean: 0.0543
2025-06-23 22:27:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:27:38 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1602
2025-06-23 22:27:38 INFO FeHistory: [-183.3448698  -183.3589495  -183.32825813 ... -184.4862276  -184.48622752
 -184.48622732]
2025-06-23 22:27:38 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:27:38 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelection
# Description: Differential Evolution with adaptive Cauchy mutation and tournament selection for multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5 #tournament size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
2025-06-23 22:27:38 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:27:40 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:40 INFO FeHistory: [2.04614881e+06 1.06425267e+06 2.15723716e+06 ... 1.36161261e+03
 1.36161261e+03 1.36161261e+03]
2025-06-23 22:27:40 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:27:40 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:27:40 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:40 INFO FeHistory: [2.20452105e+06 1.49467504e+06 9.30681319e+05 ... 2.01166000e+03
 2.01166000e+03 2.01166000e+03]
2025-06-23 22:27:40 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:27:40 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:27:49 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1661
2025-06-23 22:27:49 INFO FeHistory: [-183.37590943 -183.36182024 -183.30018407 ... -184.99985932 -184.99905146
 -185.00115114]
2025-06-23 22:27:49 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:27:49 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveImprovements
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveImprovements
# Description: Combines Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveImprovements:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Fixed population size
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95
        self.F = 0.8 #DE scaling factor
        self.CR = 0.9 # Crossover rate
        self.tournament_size = 5 # for tournament selection

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._tournament_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(self._crossover(population[i], trial), self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros_like(population)
        next_fit = np.zeros_like(fitness)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:27:49 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:27:50 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:27:50 INFO FeHistory: [1.42551628e+06 2.91951645e+06 5.82128474e+05 ... 2.68977349e+03
 2.68977334e+03 2.68977344e+03]
2025-06-23 22:27:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:27:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:28:02 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:28:02 INFO FeHistory: [2026020.64698806 2132534.8444711  2642830.1301479  ...    4963.35084068
    4963.35084068    4963.35084068]
2025-06-23 22:28:02 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:28:02 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:28:12 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:28:12 INFO FeHistory: [196738.72288417 116903.49352297 127646.38264798 ...   1040.31238402
   1040.31212418   1040.31215301]
2025-06-23 22:28:12 INFO Expected Optimum FE: -5000
2025-06-23 22:28:12 INFO Unimodal AOCC mean: 0.1597
2025-06-23 22:28:12 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:28:12 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:28:12 INFO AOCC mean: 0.0532
2025-06-23 22:28:13 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:28:13 INFO FeHistory: [143243.24954514 223374.97060904 143393.37935486 ...   8764.66130233
   8764.66130233   8764.66130233]
2025-06-23 22:28:13 INFO Expected Optimum FE: -5000
2025-06-23 22:28:13 INFO Unimodal AOCC mean: 0.1665
2025-06-23 22:28:13 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:28:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:28:13 INFO AOCC mean: 0.0555
2025-06-23 22:28:22 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:28:22 INFO FeHistory: [146165.45677544 155887.3062993   95531.05094639 ...   3103.23921289
   3103.23921286   3103.23921288]
2025-06-23 22:28:22 INFO Expected Optimum FE: -5000
2025-06-23 22:28:22 INFO Unimodal AOCC mean: 0.1602
2025-06-23 22:28:22 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:28:22 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:28:22 INFO AOCC mean: 0.0534
2025-06-23 22:28:36 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:28:36 INFO FeHistory: [138896.26092356 212378.53942682 168600.77518233 ...   5159.65478003
   5159.65478003   5159.65478003]
2025-06-23 22:28:36 INFO Expected Optimum FE: -5000
2025-06-23 22:28:36 INFO Unimodal AOCC mean: 0.1661
2025-06-23 22:28:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:28:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:28:36 INFO AOCC mean: 0.0554
2025-06-23 22:29:28 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:29:28 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:29:28 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:29:28 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:29:38 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1530
2025-06-23 22:29:38 INFO FeHistory: [-183.34255541 -183.34709423 -183.34109621 ... -183.93535301 -183.98700077
 -183.90841283]
2025-06-23 22:29:38 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:29:38 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithArchive
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential Evolution with adaptive mutation and an archive to maintain diversity and escape local optima.
# Code:
class AdaptiveDifferentialEvolutionWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.adaptation_rate = 0.1 #Rate at which F and CR adapt


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._adapt_parameters(population, fitness_values)
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutate(a, b, c)
            child = self._crossover(population[i], mutant)
            offspring.append(child)
        return np.array(offspring)
    
    def _select_parents(self, i, population):
      indices = np.random.choice(self.population_size, 3, replace=False)
      while i in indices:
        indices = np.random.choice(self.population_size, 3, replace=False)
      return population[indices[0]], population[indices[1]], population[indices[2]]
    

    def _mutate(self, a, b, c):
        return np.clip(a + self.F * (b - c), self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, mutant, parent)

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.hstack((population, fitness_values.reshape(-1, 1)))
        self.archive.extend(combined)
        self.archive.sort(key=lambda x: x[-1])
        self.archive = self.archive[:self.archive_size]


    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptation based on diversity and convergence.
        diversity = np.mean(pdist(population))
        convergence = np.std(fitness_values)
        
        if diversity < np.mean(self.upper_bounds - self.lower_bounds) / 4 : #Low Diversity, Increase exploration.
          self.F = min(1, self.F + self.adaptation_rate)
          self.CR = max(0, self.CR - self.adaptation_rate/2)

        if convergence < 0.1 * np.mean(fitness_values): #Rapid Convergence, Increase Exploitation
          self.F = max(0, self.F - self.adaptation_rate/2)
          self.CR = min(1, self.CR + self.adaptation_rate)

        self.F = np.clip(self.F, 0, 1)
        self.CR = np.clip(self.CR, 0, 1)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:29:38 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:29:38 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1527
2025-06-23 22:29:38 INFO FeHistory: [-183.30029329 -183.32109202 -183.32702301 ... -183.8709406  -183.86530982
 -183.93355633]
2025-06-23 22:29:38 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:29:38 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and an archive for escaping local optima.
# Code:
class AdaptiveCauchyDEwithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50  # Size of the archive to store diverse solutions
        self.archive = []
        self.F = 0.8  # Differential weight (scale factor)
        self.CR = 0.9  # Crossover rate
        self.scale = 1.0 # Initial Cauchy scale


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            
            self._adapt_scale(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutate(a, b, c)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring


    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _mutate(self, a, b, c):
        mutant = a + self.F * (b - c)
        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        child = np.where(crosspoints, mutant, parent)
        return child

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        # simple archive update, replace worst with best if better
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness_values[i]))
            else:
                worst_idx = np.argmax([f for _, f in self.archive])
                if fitness_values[i] < self.archive[worst_idx][1]:
                    self.archive[worst_idx] = (population[i], fitness_values[i])
                    
    def _adapt_scale(self, population, fitness_values):
        # Adapt Cauchy scale based on population diversity
        diversity = np.std(population)
        if diversity < 0.1 * np.ptp(self.upper_bounds - self.lower_bounds): # ptp is peak-to-peak
            self.scale *= 1.1  # Increase scale for low diversity
        else:
            self.scale *= 0.9  # Reduce scale for high diversity
        self.scale = max(0.01, min(self.scale, 10.0)) # Keep scale within reasonable bounds

2025-06-23 22:29:38 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:29:39 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1500
2025-06-23 22:29:39 INFO FeHistory: [-183.4374929  -183.29753526 -183.30466478 ... -183.53092001 -183.58607637
 -183.56186719]
2025-06-23 22:29:39 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:29:39 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential Evolution with adaptive mutation and an archive to maintain diversity and escape local optima.
# Code:
class AdaptiveDifferentialEvolutionWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_random_vectors(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _select_random_vectors(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness_values[i]))
            else:
                worst_index = np.argmax([x[1] for x in self.archive])
                if fitness_values[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (population[i], fitness_values[i])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
      #Simple adaptation.  More sophisticated methods could be implemented here.
      std_dev = np.std(fitness_values)
      if std_dev < 0.1: #Increase exploration if solutions are too similar
          self.F = min(self.F + 0.1, 1.0)
      else:
          self.F = max(self.F-0.05, 0.5) # Reduce exploration if diverse enough
2025-06-23 22:29:39 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:29:40 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1741
2025-06-23 22:29:40 INFO FeHistory: [-183.35197975 -183.34581321 -183.31311676 ... -185.74621423 -185.74427545
 -185.74375622]
2025-06-23 22:29:40 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:29:40 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDifferentialEvolution
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDifferentialEvolution
# Description: Differential Evolution with adaptive Cauchy mutation and an archive for exploring diverse regions.
# Code:
class AdaptiveCauchyDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.scale_factor = 0.5  # Initial scale factor for differential evolution
        self.crossover_rate = 0.9
        self.cauchy_scale = 1.0 # Initial Cauchy scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_individuals(i, population)
            mutant = a + self.scale_factor * (b - c)
            trial = self._crossover(population[i], mutant)
            trial = self._cauchy_mutation(trial) #Adaptive Cauchy mutation
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_individuals(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        mask = np.random.rand(self.dim) < self.crossover_rate
        return np.where(mask, v, x)

    def _cauchy_mutation(self, individual):
        return individual + cauchy.rvs(loc=0, scale=self.cauchy_scale, size=self.dim)


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness_values[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if fitness_values[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (population[i], fitness_values[i])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]


    def _adapt_parameters(self, population, fitness_values):
          # Simple adaptive mechanism: Reduce Cauchy scale if convergence is detected.
          std_dev = np.std(fitness_values)
          if std_dev < 0.1: # Adjust the threshold as needed
              self.cauchy_scale *= 0.9
          else:
              self.cauchy_scale *=1.01


2025-06-23 22:29:40 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:29:47 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:29:47 INFO FeHistory: [ 591333.16586261 1742832.99265131 1726448.92185988 ... 1839167.0249453
 1130692.85284223 2902085.92486872]
2025-06-23 22:29:47 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:29:47 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:29:47 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:29:47 INFO FeHistory: [1204104.2183531   840169.7985516  2883646.87874292 ... 3775496.40511542
 1151963.74870886 2165162.03653956]
2025-06-23 22:29:47 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:29:47 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:29:49 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:29:49 INFO FeHistory: [ 710188.05395176  156725.57078425 2918022.44574757 ...  790323.32832891
 1009319.88598945 1796911.45238331]
2025-06-23 22:29:49 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:29:49 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:29:51 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:29:51 INFO FeHistory: [2881774.7622366  1512470.70297174  926719.62168059 ... 6833345.38321267
 4664257.00124058 3425141.11461704]
2025-06-23 22:29:51 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:29:51 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:16 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:30:16 INFO FeHistory: [149023.99229268 129061.0140953  145962.77572465 ...  -3510.43413896
  -3510.43413896  -3510.43413896]
2025-06-23 22:30:16 INFO Expected Optimum FE: -5000
2025-06-23 22:30:16 INFO Unimodal AOCC mean: 0.1530
2025-06-23 22:30:16 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:16 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:16 INFO AOCC mean: 0.0510
2025-06-23 22:30:18 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:30:18 INFO FeHistory: [164319.88914854 153614.58694436 161156.39879538 ...  17951.40410306
  29457.57860983  15991.17814348]
2025-06-23 22:30:18 INFO Expected Optimum FE: -5000
2025-06-23 22:30:18 INFO Unimodal AOCC mean: 0.1527
2025-06-23 22:30:18 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:18 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:18 INFO AOCC mean: 0.0509
2025-06-23 22:30:20 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:30:20 INFO FeHistory: [148567.32118443 158710.24186303 136784.48138853 ...  -4416.9858454
  -4419.00217792  -4417.6639776 ]
2025-06-23 22:30:20 INFO Expected Optimum FE: -5000
2025-06-23 22:30:20 INFO Unimodal AOCC mean: 0.1500
2025-06-23 22:30:20 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:20 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:20 INFO AOCC mean: 0.0500
2025-06-23 22:30:23 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:30:23 INFO FeHistory: [130224.09014379 166745.25262211 228538.87319755 ... 291934.32996368
 299025.50637705 180901.96694603]
2025-06-23 22:30:23 INFO Expected Optimum FE: -5000
2025-06-23 22:30:23 INFO Unimodal AOCC mean: 0.1741
2025-06-23 22:30:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:23 INFO AOCC mean: 0.0580
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1471
2025-06-23 22:32:20 INFO FeHistory: [-183.35612964 -183.39467191 -183.38681104 -183.35057951 -183.36467452
 -183.42508934 -183.39436087 -183.31402743 -183.37703024 -183.41492437
 -183.37510031 -183.30110295 -183.31765985 -183.33363388 -183.32830559
 -183.41027349 -183.33482898 -183.3787142  -183.28032244 -183.30634022
 -183.36990329 -183.32324746 -183.27548657 -183.29881638 -183.34930087
 -183.30004431 -183.38838896 -183.30838958 -183.27181235 -183.34622193
 -183.3067797  -183.37782129 -183.3484423  -183.36469763 -183.35106443
 -183.27514356 -183.30524316 -183.3288863  -183.46685479 -183.32702506
 -183.29915782 -183.36609017 -183.29843018 -183.36415138 -183.36881452
 -183.43259587 -183.39333096 -183.48200089 -183.31855709 -183.33849436
 -183.30993996 -183.37618557 -183.31800228 -183.30458274 -183.30859962
 -183.31673084 -183.40125913 -183.37945106 -183.38103655 -183.36490842
 -183.32783884 -183.33814363 -183.31310208 -183.3113978  -183.34532559
 -183.38914062 -183.37227552 -183.43092667 -183.317558   -183.2754764
 -183.30373563 -183.37975375 -183.25552419 -183.40169808 -183.33264517
 -183.42908473 -183.29492813 -183.35070028 -183.37157918 -183.37833904
 -183.31819444 -183.31744182 -183.41579694 -183.32129435 -183.33328652
 -183.30781519 -183.35959098 -183.34050275 -183.34041612 -183.3303243
 -183.30600995 -183.34805665 -183.30649933 -183.34213849 -183.35627984
 -183.35370389 -183.35272464 -183.26087377 -183.35920306 -183.34697653]
2025-06-23 22:32:20 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:20 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population, fitness):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population)
            mutant = self._cauchy_mutation(a, b, c)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
            self._update_archive(trial, objective_function(trial.reshape(1,-1))[0]) #Added for archive update
        return np.array(offspring)

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

2025-06-23 22:32:20 INFO Run function 6 complete. FEHistory len: 200, AOCC: 0.1476
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:20 INFO FeHistory: [-183.35586196 -183.34312973 -183.39010817 -183.35988251 -183.34224085
 -183.37602898 -183.39875938 -183.33512664 -183.35551876 -183.31928245
 -183.26122413 -183.33402513 -183.39941206 -183.31391948 -183.30437778
 -183.39252746 -183.36682037 -183.31738738 -183.37032463 -183.33466135
 -183.32077835 -183.29572112 -183.33579912 -183.4432693  -183.37656773
 -183.39220953 -183.44228179 -183.37365601 -183.35371555 -183.33790038
 -183.41698942 -183.28907006 -183.35394744 -183.34006083 -183.34843825
 -183.52341354 -183.3810762  -183.34286187 -183.32505148 -183.40789765
 -183.40887667 -183.32673755 -183.30707801 -183.34330866 -183.35064737
 -183.3223871  -183.38101451 -183.29779668 -183.30149855 -183.35877425
 -183.40323496 -183.39036595 -183.29271728 -183.33189367 -183.33691152
 -183.39625891 -183.38419453 -183.33699045 -183.24679181 -183.28590041
 -183.39843606 -183.3877312  -183.31537048 -183.35176185 -183.35239339
 -183.44245419 -183.31089499 -183.33117356 -183.33558887 -183.32590546
 -183.2962267  -183.38474381 -183.31156621 -183.4042561  -183.41902612
 -183.42102675 -183.42232367 -183.37672434 -183.38659252 -183.33771711
 -183.37974469 -183.26920768 -183.35918774 -183.38924089 -183.3345982
 -183.43213244 -183.34444659 -183.37031643 -183.36697192 -183.3464422
 -183.47736232 -183.38039931 -183.35249707 -183.42732991 -183.42092487
 -183.29282926 -183.45809236 -183.32341287 -183.35816339 -183.41455053
 -183.32369798 -183.33435371 -183.21966262 -183.24102396 -183.42395201
 -183.331355   -183.372682   -183.35900209 -183.40111826 -183.20701035
 -183.31837647 -183.48316196 -183.39579326 -183.33355035 -183.32164311
 -183.20229918 -183.30493356 -183.36143072 -183.26027706 -183.38386566
 -183.24331256 -183.28036952 -183.28368672 -183.39382893 -183.28055574
 -183.22834489 -183.33411708 -183.27559096 -183.40683958 -183.2610322
 -183.21310827 -183.34476474 -183.21572349 -183.29028197 -183.41066067
 -183.30581809 -183.30784745 -183.30361786 -183.45931941 -183.37899705
 -183.36726875 -183.33017981 -183.30903265 -183.37237939 -183.35130033
 -183.32001758 -183.38461413 -183.2672054  -183.25965353 -183.28266487
 -183.25824569 -183.26402796 -183.31832027 -183.35632784 -183.33477637
 -183.35118011 -183.33573524 -183.38873073 -183.37433628 -183.2971516
 -183.28201496 -183.20720079 -183.33487882 -183.31375264 -183.25836999
 -183.31758421 -183.34387175 -183.32147462 -183.21332643 -183.33311937
 -183.36543365 -183.38524219 -183.31397075 -183.37336442 -183.18138185
 -183.38947448 -183.39571876 -183.28210871 -183.28147876 -183.27921339
 -183.18669824 -183.30639994 -183.18036993 -183.2992049  -183.38864113
 -183.25276409 -183.45463115 -183.19814769 -183.38477252 -183.25323316
 -183.37894143 -183.25151678 -183.3094089  -183.32836934 -183.2647159
 -183.23960519 -183.35571899 -183.18888459 -183.32955385 -183.39673177]
2025-06-23 22:32:20 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:20 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveAndTournamentSelection
import numpy as np

class AdaptiveCauchyDEwithArchiveAndTournamentSelection:
    """
    Combines Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_best(offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            parents = self._tournament_selection(population, fitness_values, 5)
            mutant = self._cauchy_mutation(parents)
            offspring.append(mutant)
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _cauchy_mutation(self, parents):
        # Cauchy mutation with adaptive gamma
        base = parents[0]
        difference = parents[1] - parents[2]
        mutant = base + self.gamma * np.random.standard_cauchy(self.dim) * difference
        return mutant

    def _tournament_selection(self, population, fitness_values, tournament_size):
        tournament = np.random.choice(len(population), tournament_size, replace=False)
        winner_index = tournament[np.argmin(fitness_values[tournament])]
        return population[winner_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_combined = combined[np.argsort(combined[:, -1])]
        return sorted_combined[:min(len(sorted_combined), self.archive_size), :-1]

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            return archive, objective_function(archive) #Should not happen
        return archive[:self.population_size], objective_function(archive[:self.population_size])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:32:20 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1466
2025-06-23 22:32:20 INFO FeHistory: [-183.35518238 -183.32998289 -183.3126688  -183.3638859  -183.30448844
 -183.35887814 -183.37701086 -183.3630964  -183.41086664 -183.38344937
 -183.33653869 -183.2920118  -183.36735444 -183.37191621 -183.27377763
 -183.38145926 -183.30794673 -183.38981864 -183.31861701 -183.32020299
 -183.36755189 -183.34218928 -183.29491295 -183.33246856 -183.33799112
 -183.31263848 -183.32224915 -183.34699144 -183.33718297 -183.3436536
 -183.39256221 -183.3080996  -183.31427234 -183.27859128 -183.40822915
 -183.35342067 -183.24665393 -183.28091068 -183.35322809 -183.27688045
 -183.35936924 -183.34818832 -183.33078325 -183.38937201 -183.4002008
 -183.3697319  -183.37944005 -183.31632644 -183.33469093 -183.29706889
 -183.3120872  -183.41213623 -183.37918228 -183.35995878 -183.32579417
 -183.34563478 -183.29599042 -183.41562885 -183.35672898 -183.34613223
 -183.34258738 -183.35714987 -183.42305869 -183.39732667 -183.30142721
 -183.40043781 -183.3805867  -183.30684035 -183.38639406 -183.40721333
 -183.32557832 -183.35999465 -183.35139031 -183.36998064 -183.44807055
 -183.31591299 -183.39821072 -183.37234261 -183.31905366 -183.34229542
 -183.29990379 -183.35353432 -183.28302927 -183.37573978 -183.3896684
 -183.31784069 -183.36676347 -183.30229667 -183.35092742 -183.36834426
 -183.30626481 -183.32157531 -183.39086717 -183.28864881 -183.42838819
 -183.36907665 -183.3232593  -183.38761799 -183.37633983 -183.4327219
 -183.24566034]
2025-06-23 22:32:20 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:20 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            self.gamma *= self.gamma_decay
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, x, v, fx, fv):
        tournament = np.random.choice(np.array([x, v]), self.tournament_size, replace=True)
        tournament_fitness = objective_function(tournament)
        return tournament[np.argmin(tournament_fitness)]


def objective_function(x): #Example objective function (replace with actual GNBG functions)
    return np.sum(x**2, axis=1)

2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:32:20 INFO FeHistory: [3488833.16034537 1108872.23058607 1617674.27299176 1664723.60090956
 2095949.17812256 1028403.55377407 1382321.26439844 2400199.86149695
 1758032.05280126 1077297.04269802 1935617.30001349 1230272.62268681
 3156179.56955397 3364329.16813878 1306121.90529913  589493.14886472
 1284289.49183261  889678.39367329 1261923.04516686 2071618.78653394
 2168075.58731362 1561464.32873427 1444847.41596474 1146692.91106174
  789787.02181431  984711.37198076 1536574.52779484 1924190.91691765
 2373042.06363828 2397196.74131665 2031658.17112354 2117162.86156057
 2836302.54128681 2393188.96772178 1036620.06809943 3508323.91887978
 1239490.51484496 2967977.05837121 2479831.31453672 1273322.39930354
 2897801.23405448 2692368.385462   1253568.08233667  574117.10400005
 1802643.0679953  1170798.82902801 1044688.5737797  1709258.69490383
 1890770.17001941 5188434.28603826 1427932.06461229 2016984.62395888
 1628556.1724831  1866861.19070124  589818.45413839 1269073.97087271
 1716169.8613895  1744867.09354076 3409923.64807454 1390173.24368768
  791301.73084873 1890179.30067522 3154537.29402812 1055172.5510826
 2036408.59552632 1084379.53614025 2225547.72752988 1763488.5018342
 2409640.97667737 6036386.48045908 4675505.16705968 1651393.69147344
 2123494.81909107 3044032.11838699 1749756.71830504 1975424.76967254
  743024.52547969 2219669.53526261  499471.80734    1745156.22103177
 2734839.82876962 1580879.18964497 1861188.62422131 2467170.35841483
  717984.42898447 3080754.13673387 1875131.05182276 1644888.69971245
 1989642.04850555 4051319.43412654 1765216.50683062 2115843.78148557
  973515.41877989  741622.00193904 1388855.12292105  398149.6103488
 2545472.51674284  486017.57988025 2646146.96467241 1453960.05462   ]
2025-06-23 22:32:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:32:20 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:32:20 INFO FeHistory: [1948400.63142967 1769549.81650125 1805120.97554449 1385910.97419711
 1504602.57345709 1005589.62904542 2779598.86878193 1204894.32008204
 1954022.45509867 3351671.23832441  528300.00454967 1570482.90763457
 1156940.85975326 1432260.86921998 1665662.07702697 2031491.92200867
 1953572.46669319 3257661.70620187 3939777.68171017  786699.02024487
 3024334.74628285 1783160.15901124 1737542.69590247 1179881.47074173
 1312017.28147093 2171868.65589205  590594.87179069 1605002.85650995
 2042253.08791523 1300672.11643785  994721.15877484 2710106.82743784
 1963356.21929322 2206106.17097621 1014326.3232728  1702457.51718414
 2679961.18107626 1600982.9129967  1492659.8719701  1761094.75039326
 1790648.31378712 2274105.05636381 1416422.75080388 1451683.73083428
  254848.62194392 1439302.24432763  916752.90037512 1128955.18467619
 1355772.18891565  925213.22045871 1251020.42429213 4143859.45720802
 1136783.67686493 1247345.46086001  776003.51453551 2101838.12898261
 1470776.76341294 1337782.430255   2162807.59912382 2261407.48482457
 1701953.52500637 1743883.727629    279006.55692782 1238490.83808846
 1487044.74924556 2479418.95590639 2448907.78487437 2344328.83008952
 4038687.26244612 2643496.68434031  718038.12867441 3992614.5686877
 1815859.04556149 1287193.1563208  1409757.89645355 2707769.07695843
 2315066.54472425  964267.95275085 2454738.86255925 1572198.80225398
 1101070.56801358  886583.91205984 3064426.26693234 1446183.78010613
 4141713.52770755 1055633.26937747 2442526.0146277   286370.39193245
  616830.67554778 2625176.68388623 1626666.45069488 1091761.21040594
 2049240.59068086 2828345.4304827   626867.00020722 1553777.80348805
  711215.31316555 2261647.75624237  912657.95956345 2235727.21922899
 6513671.28784814]
2025-06-23 22:32:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:20 INFO Run function 13 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 22:32:20 INFO FeHistory: [ 991341.94610421 2559006.8482283   693639.55938376 1626390.66328574
 2259854.71222804 2074423.20699985 2116544.54685399 1017350.32259253
 1794891.70514223 1425877.14511066 3227106.52507846 1401596.13460077
 1250119.83588546 2071161.7633646  2375750.5509285  2420817.3432059
  991812.29973327 1311662.68823018  474546.61072435 2555217.16932897
 2747519.98348821 2605072.69855549 1358394.86090143 1405684.1071102
 1740709.11216735 1907620.72148974 1113449.33134002 4357008.79519853
 1529420.05061884 1655265.37518266 1976325.58889123 1413063.44284373
 1679614.7560907  1352017.85519957  570768.79304326 1432914.71752456
 2650473.08608957 2501129.00612828 2584876.61726423 3131324.03229509
 3787154.02051269 1193857.47615644 2271817.22996235 1022245.88457453
 1899716.21258238 1791201.8590851   600848.40536955 3238038.98792828
 2248718.30471814 1509431.28358561  896401.11658344 1327450.56897669
 2492971.71895211 3744664.91385462 2082013.21155539 1334830.50638224
 1098583.62244726 1792784.83908899 1994645.82165783 2262331.13014557
 2523019.88277269 1824681.10594617  583902.22684303  808627.78062402
 2754731.9818125  2994445.57485022 2196595.05483731 2144458.54084561
 1794589.99892587  639749.82026442 2526029.70937393 3175328.50132778
  206878.42346724 2985639.91153994  856124.23261632 1402171.83192707
 2537954.14921657 1768550.26496986  727853.95353125 3602346.73734527
 2195499.2589678  1085888.96048851 1498494.02709294 1453451.78635089
 1674050.36586452 1525185.65915586 2873315.52943559 1181792.92227383
 1540627.4860982  2473987.41854246  122920.91766005 1837877.68359354
  869695.6930861  3586014.93664667 2842456.612137   2928255.04377526
 3612929.76971477  643805.96852279 1911032.40927537 1893955.18501962
 3539380.69842288 1008640.44277511 2690091.47815364 4390183.00139564
 3827197.06003165 2674021.60144416 4983982.59745324 1241738.42690303
 6111649.29754106 3684602.97687102 1201939.24556128 2008427.44078921
 2548225.68299475 1481017.10786439 1674280.83288714 1511925.81610292
 1316478.82396181 3216251.11944608 2572406.33687515 1619666.93053698
 1944829.53733429 2038914.56668183 4097937.54367085 3247637.67700723
 3573684.97554104 2915887.12070405  696024.83811317 1707600.44812894
 2387648.97179454 1704761.49080111 1106821.72458047 3483855.67602322
 2497798.2327021   658394.15554312 2700039.96508365 2219252.02844529
 1588991.51670432 1698102.53396529 2700132.91598842 2044965.99893256
 3342530.39686379 1881324.75169004 2196265.31102177 3624432.1996166
 2389375.92919807 3355946.15733575 2228798.95650817 3220110.01412574
 3294710.85020714 3976301.78937538  771924.8630422  1637363.79497579
 2990200.10442268 3284527.84161694 1421653.97948295  915442.19393574
 2481392.82917263 4144224.00989187 2587115.285772   6240626.2564465
 4753588.89412171  259631.14642849 3113506.64800308 1523654.19208987
 3680845.30265285 1252026.05115649 3026166.11575534 2576209.80467044
 2367536.30210032 4417224.26044383 3065776.71211982 2521198.80758367
 4332467.26314835 1968262.66910272 1628397.740829   4639989.96335369
 4790692.79737034 2580901.2141782  4709634.57449729 1774807.71149964
 3123978.00146959 1111698.16053167 3306905.56462982  990410.28870837
 4207448.386388   2430987.60542045 4502081.4051458  2767450.00033857
 2180370.16416285 1519554.28675803 6405081.75869984 3521149.314437
 3061881.3464115   899463.92562187 1528620.43947608 1713920.86660208
 3946729.70004601 2398952.12004737 2069407.41290279  796521.14539853]
2025-06-23 22:32:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:32:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:20 ERROR Can not run the algorithm
2025-06-23 22:32:21 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:32:21 INFO FeHistory: [181990.72325782 132483.66920466 152836.616767   186092.11203638
 161767.23879038  99410.72607527 189846.34879825 219462.32884129
 137011.98280549 153825.66984761 112556.08697479 140239.92749092
 165799.44623224 147395.76747858 142463.68082463 172496.08940335
 154630.35209241 101568.99746131 202839.72250259 142059.28212751
 111220.28853891 121125.6040411  187908.12015207 107845.25616488
 120244.5257253  132742.3449605  147932.16490252 177310.97022093
 111031.52683724 147125.61329457 148300.42652961 199083.70767416
 152398.21751516 139000.46255651 178227.79086944 161057.07091793
 231950.27157126 119005.13245928 148030.91446696 131409.65876061
 158595.01472901 159855.57826606 175932.92803888 194106.96826416
  95116.03409059 150026.07280226 159715.38254415 149014.75085084
 146226.5820744  180468.95391005 136487.14612197 128156.48224495
 112350.72751822 158002.35852212 135468.74817282 110724.56331246
 237123.87448324 154709.47625248 130844.92860558 136932.15951521
 156697.61783651 152757.36916386 138265.53482736 168519.31624189
 155726.27352352 178759.75235422 121209.20038591 125802.47485513
 145512.81025741 117451.41473522 159249.16752079 155186.89878642
 128138.37603764 193101.21842277 174840.07328992 176575.45186408
 127538.78664613 185572.68121939 145433.49584718 170145.24772245
  93262.71462758 129058.72549576 176713.20789608 127878.50496055
 102242.6627851  138497.30721414 162440.88474712 166402.83334388
 153339.67081755 113936.76784046 186399.32345925 145230.17352352
  89609.83968585 192326.75558243 185917.90476984 116265.01869914
  98878.63756197 198537.81385379 127407.75295183 180252.18158776]
2025-06-23 22:32:21 INFO Expected Optimum FE: -5000
2025-06-23 22:32:21 INFO Unimodal AOCC mean: 0.1471
2025-06-23 22:32:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:32:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:32:21 INFO AOCC mean: 0.0490
2025-06-23 22:32:21 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:21 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:32:21 INFO FeHistory: [117280.90084007 160554.39860852 159189.88067362 123068.20189359
 132118.5211603  148925.53183568 201061.73920546 100328.50850278
 139535.6344448  123577.34568778 203239.70421747 230382.84117251
 127537.9936676  141510.87475291 139325.92981319 158406.29278007
 147480.27192835 191994.2833881  207972.23811442 223786.96880278
 170899.262707   107841.3022055  115275.63170318 120955.63908628
 134724.67680879 151387.25706953  94540.78038644  88478.15120505
 113412.07791592 186160.37324767 154303.38873939 213505.14938439
 201158.78166673 122763.48384837 153520.08179629 150192.12699742
 154672.36185024 130989.31418527 138797.63494099 151362.53343385
 151591.25927079 149499.09952206 133648.33967398 141177.67274837
 115380.53429272 138491.97553028 197430.31971732 185555.89134416
 119762.50396195 128002.15986652 138665.75929001 234171.29141642
 189345.42460353 152837.08274007 138063.47772957 120112.13537612
 150454.26317202 113400.84063381 176070.11548511 140530.74925326
 149406.19313809 150537.76092162 259326.64055828 113371.12931034
 170673.18830259 165872.65790279 123188.68016498 130421.54808593
 135928.41524869 192541.4574233  106295.75001093 142032.9050739
 141491.63112938 135398.92182101 198899.03451401 227529.93185336
 120047.7512839  191081.83070816 147746.92162098 170921.62213237
 162150.31288188 133992.42023684 154057.32321241 122527.57873201
 147377.20497931 108558.93717174 155860.44486589 200053.26637256
 199258.9448895   95606.01781759 155248.00115428 183069.40862012
 159204.8687891  126544.32793042 130325.64411201  88815.71249368
 199007.97314083 168450.80384951  87505.45491464 250630.48569904
 326680.0130915 ]
2025-06-23 22:32:21 INFO Expected Optimum FE: -5000
2025-06-23 22:32:21 INFO Unimodal AOCC mean: 0.1466
2025-06-23 22:32:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:32:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:32:21 INFO AOCC mean: 0.0489
2025-06-23 22:32:21 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:21 INFO Run function 18 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 22:32:21 INFO FeHistory: [123586.20494977 162007.01435995  97212.74181539 182829.83183595
 122400.78626414 113125.04737126 123249.57751044 146552.33007332
 121819.02315175 169729.10401455 106043.16824786 199643.18031616
 172541.68168906 199189.04197851 173726.76693738 124242.0998117
 138671.4595493  102868.24092119  87730.84482698 135463.02158562
 198530.13880199 116994.75428883 148354.36409367 191820.4882546
 195637.30475139 115302.1214278  135015.51022844 146287.19815344
 127136.87625459 182586.31598407 137813.53508524 158239.9128439
 117326.88001291 205827.94151796 194220.78686193 166120.3956571
 146371.32265501 188599.74509495 130367.01602014 177952.46590388
  96246.79503056  99629.93764711 143777.60043267 149409.74766916
 188520.1850228  171834.29328519 137461.7628664  120742.63284483
 226167.7937718  234943.66027052 200131.2900324  177746.42899249
  72417.08678035 122406.30315855 117377.77450903 207445.07899694
 175564.54257679 175296.34712247 155700.41593656 114489.28411501
 145807.34305416 126610.89419797 182289.92084607 157881.23761849
 164688.90052228 180890.36667264 165078.76273428 142563.86796512
 148259.75911983  83351.52609108 202708.14059002 172769.85267857
 218018.87852539  84795.27507637 176465.86161761 109071.17978655
 162141.92319754 143410.32572632 149217.22944032 136496.06729247
 174335.05768346 205426.42002103 115678.85164283 131736.13923195
  80146.14809415 128091.21889971 186403.26912534 106711.44602943
 175915.63000519 156274.41364663 171072.22112954 138123.44661482
 155676.57264738 129806.2797677  128080.62999529 121187.86615354
 171549.42092857 147269.53138728 156298.16683801 113111.62712597
 224366.33677521 241242.74756962 254422.50004121 293283.31834824
 298962.42702749 221605.94517272 121839.15104492 181988.97300343
 297642.51204966 155072.71625881 176930.19312478 347041.9750945
 212255.4304914  283648.57646993 144950.55746643 224295.16292411
 218862.86809922 129075.07063833 180405.05952189 260322.61576929
 160626.84360372 108741.95868043 196647.58033886 221661.58616492
 101337.96630865 286528.17888798 150630.45998048 223593.48391142
 121819.02435753 178223.1938767  354346.15553667 242607.87223828
 303278.93634148 314580.52589799 216295.90065054  97644.21088238
 267086.46741438 237360.81910704 175321.36619317 117500.74379269
 436302.20455767 271103.96924809 268010.58771027 184769.38302077
 237649.30019073 124233.51360921 256025.49902215 101404.28406326
 116333.49519671 144522.14891682 331265.27169639 131731.17740127
 317157.40130368 237000.98348243 220264.37364846 181366.86308956
 148461.86166648 266622.82305708 221556.79666461 363112.57225078
 106451.37151581 387111.46768125 103670.39484757 180247.09872672
 356617.19689258 129010.22365796 288114.88656772 123071.50750475
 145078.93707716 293650.64132663 242508.45626336 133595.56927339
 251794.34489656 170379.88448851 243586.68204594 182120.02172094
 211318.01708964 265684.67492187  89140.58282217 203898.1861482
 253302.63596115 153308.70824042 206827.55916829 108703.04787471
 168668.76198394 153725.15570004 244849.48826017 116460.7737781
 176880.27209344 172593.05120258 174581.56042188 211234.77354791
 280370.29399667 176550.02424368 312963.932223   226308.22651016
 147985.01185899 317290.03440107 109586.50388308 108041.37317837]
2025-06-23 22:32:21 INFO Expected Optimum FE: -5000
2025-06-23 22:32:21 INFO Unimodal AOCC mean: 0.1476
2025-06-23 22:32:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:32:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:32:21 INFO AOCC mean: 0.0492
2025-06-23 22:32:21 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:32:31 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1681
2025-06-23 22:32:31 INFO FeHistory: [-183.35320395 -183.39977232 -183.35675042 ... -185.26112213 -185.26323104
 -185.27318996]
2025-06-23 22:32:31 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:31 INFO Good algorithm:
Algorithm Name: ArchiveGuidedCauchyDEwithTournament
import numpy as np
from scipy.stats import cauchy

# Name: ArchiveGuidedCauchyDEwithTournament
# Description: Combines Differential Evolution, adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
# Code:
class ArchiveGuidedCauchyDEwithTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.F = 0.8
        self.CR = 0.9
        self.tournament_size = 5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._cauchy_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._tournament_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)
            a, b, c = population[indices]
            mutant = a + self.F * (b - c)
            crossover_mask = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crossover_mask, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _cauchy_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        mutated_offspring = offspring + mutation
        return np.clip(mutated_offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]

    def _tournament_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:32:31 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:31 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1593
2025-06-23 22:32:31 INFO FeHistory: [-183.31665363 -183.41783547 -183.3586099  ... -184.37738395 -184.37738395
 -184.37738395]
2025-06-23 22:32:31 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:31 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            #Tournament Selection for next generation
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]

2025-06-23 22:32:31 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:34 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1598
2025-06-23 22:32:34 INFO FeHistory: [-183.39623479 -183.34284985 -183.35478058 ... -184.44851722 -184.44851745
 -184.44851731]
2025-06-23 22:32:34 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:34 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentAndArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Heuristic population size
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

2025-06-23 22:32:34 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:35 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1672
2025-06-23 22:32:35 INFO FeHistory: [-183.32372484 -183.35520923 -183.36437326 ... -185.11978639 -185.14356242
 -185.12817093]
2025-06-23 22:32:35 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:32:35 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentAndArchiveSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchiveSelection
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and a sophisticated archive-enhanced tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchiveSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.archive_size = 200  # Increased archive size
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.98  # Slower decay for better exploration
        self.F = 0.7 # Increased F for stronger mutation
        self.tournament_size = 10 # Larger tournament


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])

            # Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))

        #Enhanced Tournament Selection with Archive Integration
        if len(self.archive) > 0:
            archive_pop = np.array([sol for sol, _ in self.archive])
            archive_fit = np.array([fit for _, fit in self.archive])
            combined_pop = np.vstack((combined_pop, archive_pop))
            combined_fit = np.concatenate((combined_fit, archive_fit))

        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)

        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit


    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
2025-06-23 22:32:35 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:32:41 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:32:41 INFO FeHistory: [2.10631016e+06 1.19484474e+06 3.81281949e+06 ... 2.83821007e+03
 2.83821007e+03 2.83821007e+03]
2025-06-23 22:32:41 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:41 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:32:42 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:32:42 INFO FeHistory: [1621614.34620808 1843127.0247265  1935985.57095279 ...    2111.01503757
    2111.01503753    2111.01503753]
2025-06-23 22:32:42 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:42 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:32:46 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:32:46 INFO FeHistory: [1270387.81783364 2037641.42204171 1624831.16923597 ...    2538.06879885
    2538.06880046    2538.06880073]
2025-06-23 22:32:46 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:46 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:32:48 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:32:48 INFO FeHistory: [1.66126827e+06 4.98551207e+05 2.24241337e+06 ... 1.56313653e+03
 1.57488947e+03 1.55705798e+03]
2025-06-23 22:32:48 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:32:48 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:33:11 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:33:11 INFO FeHistory: [119777.42039439  88213.26954159 119660.91543331 ...  22522.76270502
  22522.76270502  22522.76270502]
2025-06-23 22:33:11 INFO Expected Optimum FE: -5000
2025-06-23 22:33:11 INFO Unimodal AOCC mean: 0.1593
2025-06-23 22:33:11 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:33:11 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:33:11 INFO AOCC mean: 0.0531
2025-06-23 22:33:11 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:33:11 ERROR Can not run the algorithm
2025-06-23 22:33:12 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1475
2025-06-23 22:33:12 INFO FeHistory: [-183.30924545 -183.37253772 -183.33498689 -183.37055096 -183.40473208
 -183.37681569 -183.41268934 -183.44097113 -183.33765449 -183.27985271
 -183.35679983 -183.37075768 -183.36576553 -183.35440996 -183.29718466
 -183.37830198 -183.36953143 -183.39841517 -183.28642276 -183.27659994
 -183.29667273 -183.42143994 -183.4035925  -183.37596919 -183.25727938
 -183.32869304 -183.25196006 -183.30105705 -183.40940618 -183.31682733
 -183.35009557 -183.31799922 -183.35963123 -183.3204635  -183.33522106
 -183.33521186 -183.36108039 -183.42977993 -183.34049917 -183.37347841
 -183.36789795 -183.36189125 -183.43986358 -183.3412018  -183.28650669
 -183.33078979 -183.36832921 -183.29937662 -183.35095812 -183.5118987
 -183.37427868 -183.29352255 -183.26210354 -183.36929118 -183.35792838
 -183.39490592 -183.39357786 -183.27864036 -183.2985332  -183.38902995
 -183.31520638 -183.29822642 -183.38564171 -183.32193528 -183.28299693
 -183.33624838 -183.38304337 -183.34396887 -183.32158456 -183.42678778
 -183.36807813 -183.30563062 -183.40355747 -183.32871995 -183.32461519
 -183.28193396 -183.29564138 -183.33348698 -183.31559374 -183.336926
 -183.31765644 -183.3971386  -183.41221161 -183.40112686 -183.33687042
 -183.27852463 -183.2972557  -183.39173281 -183.36087243 -183.28889366
 -183.39699443 -183.38613818 -183.35994703 -183.35922141 -183.3784354
 -183.38781681 -183.34605699 -183.29257672 -183.38112691 -183.37325027
 -183.21312012]
2025-06-23 22:33:12 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:33:12 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            fitness = self._evaluate_population(objective_function, population) #Re-evaluate after tournament
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, ind1, ind2, fit1, fit2):
        tournament = np.random.choice(np.array([ind1, ind2]), size=self.tournament_size, replace=True)
        tournament_fitness = np.array([fit1 if t is ind1 else fit2 for t in tournament])
        return tournament[np.argmin(tournament_fitness)]
2025-06-23 22:33:12 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:33:12 ERROR Can not run the algorithm
2025-06-23 22:33:12 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:33:12 INFO FeHistory: [1622122.57329203 2217071.48400918 2428325.68281291 1732263.95107448
 2699003.86596262  638367.26787746  446007.11334699 1645539.59522335
  312322.09078154 2805624.94850217  595947.11058512  386742.4474219
  771770.87434703 1806148.17050375  696149.37077389 1356507.33958398
 2232128.94466165 3815833.85274221 2550784.78792491  910331.01975681
  887819.93500925 2090218.53623197 1077105.32102727 2436123.11190369
 1188625.56194352  689940.92185428  923426.74720799  930821.92777333
 2707194.4219101   770570.08445558 1280062.64572284 2748990.28455255
 3246684.25650626  640960.56887129 3071760.83189138  641811.27133476
 1416652.0383375  1817779.07966631 2446148.64502658 1828934.1389019
 1266295.70437507  880074.28288085 2370248.68866245 2077796.55790293
 2970045.51084279 2075469.22911776 1049819.46636972 1334962.84719513
 1529505.25404141  717596.60942153 2981322.39163678  770192.34196485
  832889.91908521 1648359.01621894 1623339.15970026 3515380.32785113
  731870.76623308 2225062.44965459 1489174.11919248 1090906.98228368
 1785332.6826171   781689.31955985 1544637.30788233 2222117.66720906
 1727736.51854076  927382.1926065   970065.51910005 1309667.82785382
 1927105.12433034 3073973.49782525  517438.64475488 2957269.32407363
 3970682.44497369  806913.68718957  808832.68416376 1733643.56896962
 1076875.66251926 2770341.64509961 1154785.4937511  1787165.29997363
 2170388.44926653  814553.77160374 1354998.56480703 1285631.14537051
 1502581.93199393 1196271.93516906 2309184.47661148 1517827.72558247
 2413123.54962121 4453094.13503113 1521023.39966369 2337334.38150974
 5275580.22282417  673249.88800118 3114321.09719244 1432658.44729034
 1600704.05355939 1815423.97237058 2969460.79532605 2953088.64866227
 3349557.15938264]
2025-06-23 22:33:12 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:33:12 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:33:12 ERROR Can not run the algorithm
2025-06-23 22:33:12 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:33:12 INFO FeHistory: [159961.51875235 114198.99833163 210935.58177693  91592.49778525
 178322.27149342 101634.54046465 201735.644571   174259.14484221
 152583.09477551 135345.16542088 170448.28714666 171769.04673867
 150434.93087952 124612.69764437 173780.76669008 140000.61827047
 102494.33403715 198667.56246238 124980.46721273 139439.90549728
 138534.31841081 157416.13166196  96520.92162655 172998.64057727
  73640.76827088  90638.79292678 123940.09081388 119957.42687516
 240413.36402507 220178.32871546 172383.95298481 148758.13867644
 159977.91835014 143917.67112141 143733.56257266 178336.93035239
 108126.70860888 165435.54258209 148475.97445842 108620.31511329
 148089.86937934 173733.036172   211385.89704698 176526.03970919
 103706.00705203 164211.70348651  71144.1226018  158975.16205455
 198739.28320496 138958.22403538 143156.87949526 124216.44836218
 171629.74691583 107611.03733945 230504.27878627 105137.06792759
 191972.6673874  218781.15435059 174942.44875989 187705.0572425
 148989.26181513 229838.10054972 158330.02521852 153925.03833339
 109852.44154472 111402.22682773 118438.60721407 178731.06372009
 170299.28775042 121690.88612362 149098.17868673 124830.56808159
 159654.76753538 169941.82532126 164612.74589506 127556.55719146
 118716.94131683 204886.65560239 148411.71883682 159851.97961539
 182737.47552282 200968.17003217  96496.93818425 132137.01387887
 139061.61657746 191518.79749264 146805.23771701 183917.81595659
 192789.83874553 144383.41387851 164704.65690154 163047.55824948
 137690.22149515 138082.59992761 198350.04642482 129463.34612255
 161379.62618084 115700.64122203 146253.78136109 130275.64164995
 294326.03053419]
2025-06-23 22:33:12 INFO Expected Optimum FE: -5000
2025-06-23 22:33:12 INFO Unimodal AOCC mean: 0.1475
2025-06-23 22:33:12 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:33:12 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:33:12 INFO AOCC mean: 0.0492
2025-06-23 22:33:12 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:33:13 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:33:13 INFO FeHistory: [ 69844.17632118 151641.65874423 135184.63919968 ...    649.45194838
    649.45195765    649.45194517]
2025-06-23 22:33:13 INFO Expected Optimum FE: -5000
2025-06-23 22:33:13 INFO Unimodal AOCC mean: 0.1681
2025-06-23 22:33:13 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:33:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:33:13 INFO AOCC mean: 0.0560
2025-06-23 22:33:19 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:33:19 INFO FeHistory: [219604.99699217 103661.224241   118930.52822368 ...  -3010.85002689
  -3010.85001139  -3010.85002029]
2025-06-23 22:33:19 INFO Expected Optimum FE: -5000
2025-06-23 22:33:19 INFO Unimodal AOCC mean: 0.1598
2025-06-23 22:33:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:33:19 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:33:19 INFO AOCC mean: 0.0533
2025-06-23 22:33:23 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:33:23 INFO FeHistory: [ 1.23732840e+05  1.48940206e+05  2.07037366e+05 ... -4.52587706e+01
 -6.51578880e+01 -6.51511031e+01]
2025-06-23 22:33:23 INFO Expected Optimum FE: -5000
2025-06-23 22:33:23 INFO Unimodal AOCC mean: 0.1672
2025-06-23 22:33:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:33:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:33:23 INFO AOCC mean: 0.0557
2025-06-23 22:33:25 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1643
2025-06-23 22:33:25 INFO FeHistory: [-183.39270838 -183.38708046 -183.36064443 ... -184.88166483 -184.88040959
 -184.88160381]
2025-06-23 22:33:25 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:33:25 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8
        self.CR = 0.9
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95
        self.tournament_size = 5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_best(population, fitness_values)
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._tournament_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(population, fitness_values)
            self._update_archive(population, fitness_values)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutate(a, b, c)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _mutate(self, a, b, c):
        mutant = a + self.F * (b - c)
        cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
        mutant += cauchy_noise
        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        child = np.where(crosspoints, mutant, parent)
        return child

    def _tournament_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness_values[i]))
            else:
                worst_idx = np.argmax([f for _, f in self.archive])
                if fitness_values[i] < self.archive[worst_idx][1]:
                    self.archive[worst_idx] = (population[i], fitness_values[i])

2025-06-23 22:33:25 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:33:37 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:33:37 INFO FeHistory: [ 643347.19187028 2744675.99323139 2273436.86555033 ...    3994.53769547
    3994.53768877    3994.53769913]
2025-06-23 22:33:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:33:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:34:08 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:34:08 INFO FeHistory: [162901.91984768  92867.31957843 152597.24249361 ...   2975.63252895
   2975.63252895   2975.63252895]
2025-06-23 22:34:08 INFO Expected Optimum FE: -5000
2025-06-23 22:34:08 INFO Unimodal AOCC mean: 0.1643
2025-06-23 22:34:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:34:08 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:34:08 INFO AOCC mean: 0.0548
2025-06-23 22:34:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:34:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:34:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:34:53 ERROR Can not run the algorithm
2025-06-23 22:34:53 ERROR Can not run the algorithm
2025-06-23 22:34:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:34:53 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1466
2025-06-23 22:34:53 INFO FeHistory: [-183.32587367 -183.3509584  -183.42688858 -183.28403377 -183.41742255
 -183.26190113 -183.35623457 -183.28687703 -183.38605994 -183.41107099
 -183.34186979 -183.38943096 -183.30736177 -183.36255765 -183.32233453
 -183.42081107 -183.3603479  -183.36724852 -183.36079431 -183.37671908
 -183.3141517  -183.34565991 -183.3456972  -183.35463972 -183.30230724
 -183.35950438 -183.35933886 -183.25619734 -183.325019   -183.30492901
 -183.3972315  -183.3033691  -183.32286868 -183.32977868 -183.35261282
 -183.44317594 -183.34627236 -183.31253428 -183.29572205 -183.34118819
 -183.34708715 -183.43678248 -183.29230823 -183.34305544 -183.26953438
 -183.26228752 -183.32939496 -183.40692596 -183.27879493 -183.3056497
 -183.36908739 -183.32396013 -183.33442446 -183.38563022 -183.38293824
 -183.33502341 -183.33816421 -183.31775925 -183.26918832 -183.37912359
 -183.37478832 -183.29480199 -183.32340503 -183.26652475 -183.31106007
 -183.32095347 -183.35817422 -183.34818249 -183.40758601 -183.3777516
 -183.27624176 -183.35566157 -183.35264614 -183.4378847  -183.40439406
 -183.28476523 -183.35935997 -183.35420054 -183.34332007 -183.28902211
 -183.36327317 -183.28843104 -183.32609669 -183.33241052 -183.33727764
 -183.28933067 -183.27244858 -183.32792691 -183.3137661  -183.26690131
 -183.43174956 -183.41055408 -183.41712863 -183.33029997 -183.28007853
 -183.34514676 -183.41578656 -183.34175116 -183.25820104 -183.30787674
 -183.29272332]
2025-06-23 22:34:53 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:34:53 INFO Good algorithm:
Algorithm Name: ArchiveEnhancedCauchyEA
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description: An evolutionary algorithm employing adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 0.1 #Cauchy scale parameter


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            #Tournament Selection with Archive Enhancement
            parents = self._tournament_selection(population, fitness_values)

            #Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Archive Management
            self._manage_archive(offspring, offspring_fitness)

            #Update population
            population, fitness_values = self._update_population(population, fitness_values, offspring, offspring_fitness)

            #Update Best
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        
        #Incorporate archive into tournament selection
        tournament_pool = np.vstack((population, np.array(self.archive)))
        tournament_fit = np.concatenate((fitness_values, [x[1] for x in self.archive]))

        for _ in range(num_parents):
            tournament = np.random.choice(len(tournament_pool), tournament_size, replace=False)
            winner_index = tournament[np.argmin(tournament_fit[tournament])]
            selected_parents.append(tournament_pool[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + np.random.standard_cauchy(size=parents.shape) * self.gamma
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _manage_archive(self, offspring, offspring_fitness):
        for i, (solution, fitness) in enumerate(zip(offspring, offspring_fitness)):
            if len(self.archive) < self.archive_size:
                self.archive.append((solution, fitness))
            else:
                worst_index = np.argmax([x[1] for x in self.archive])
                if fitness < self.archive[worst_index][1]:
                    self.archive[worst_index] = (solution, fitness)


    def _update_population(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:34:53 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1472
2025-06-23 22:34:53 INFO FeHistory: [-183.33894089 -183.3474002  -183.3423021  -183.43278548 -183.35747572
 -183.3315363  -183.38048593 -183.2806274  -183.34074948 -183.36571056
 -183.3529465  -183.35119318 -183.31886415 -183.2621314  -183.3910079
 -183.40814298 -183.34903207 -183.36490569 -183.33666741 -183.3486435
 -183.30289058 -183.41555274 -183.35283885 -183.48793313 -183.34703798
 -183.34753712 -183.36668167 -183.37676811 -183.32042684 -183.36735713
 -183.29357164 -183.36031796 -183.27985267 -183.35223248 -183.30190908
 -183.40185602 -183.25262401 -183.36800376 -183.32031273 -183.42251694
 -183.33139565 -183.29087    -183.36619329 -183.31578426 -183.42831262
 -183.36869498 -183.30438697 -183.37032975 -183.35629361 -183.34255554
 -183.24439737 -183.34952508 -183.39758595 -183.35485776 -183.35362712
 -183.43586391 -183.31497363 -183.36695992 -183.34448795 -183.32465082
 -183.26689966 -183.32329697 -183.41070769 -183.35654042 -183.2804962
 -183.32710288 -183.38312218 -183.32579337 -183.37231872 -183.36968468
 -183.36190106 -183.2928996  -183.29442273 -183.3869751  -183.29199764
 -183.32836923 -183.26738108 -183.41526837 -183.38147533 -183.27469065
 -183.3141222  -183.31429657 -183.31316951 -183.37551476 -183.40979881
 -183.3499947  -183.36097698 -183.41272579 -183.29641833 -183.34470089
 -183.43535533 -183.25998618 -183.3321803  -183.34570355 -183.3738706
 -183.35485686 -183.35163375 -183.3462231  -183.42128058 -183.40160404
 -183.46264189]
2025-06-23 22:34:53 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:34:53 INFO Good algorithm:
Algorithm Name: ArchiveEnhancedCauchyEA
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description:  Employs adaptive Cauchy mutation and archive-enhanced tournament selection for efficient multimodal optimization.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0 #Cauchy distribution scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Archive Management
            self._update_archive(population, fitness_values)

            # Enhanced Tournament Selection
            parents = self._enhanced_tournament_selection(population, fitness_values)

            # Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Selection for next generation (Elitist)
            population, fitness_values = self._elitist_selection(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _update_archive(self, population, fitness_values):
        combined = np.concatenate((np.array(self.archive), population))
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness_values))
        
        sorted_indices = np.argsort(combined_fitness)
        
        self.archive = [(combined[i],combined_fitness[i]) for i in sorted_indices[:self.archive_size]]

    def _enhanced_tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        #Add Archive members to tournament selection
        archive_tournament = np.random.choice(len(self.archive), tournament_size, replace = False)
        archive_winner = np.array([x[0] for x in self.archive])[archive_tournament[np.argmin([x[1] for x in self.archive][archive_tournament])]]
        selected_parents.append(archive_winner)
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = []
        for parent in parents:
            offspring.append(np.clip(parent + np.random.standard_cauchy(self.dim) * self.gamma, self.lower_bounds, self.upper_bounds))
        return np.array(offspring)

    def _elitist_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:34:53 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:34:53 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:34:53 ERROR Can not run the algorithm
2025-06-23 22:34:53 ERROR Can not run the algorithm
2025-06-23 22:34:54 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:34:54 INFO FeHistory: [ 697990.5912005  3225831.26594801  870257.91570831 2039007.17092749
  991922.12875478 1254940.42216908  931530.82912135 1499718.42723347
 4614815.96541513 1301202.79144784 1280417.58038039 3952665.12240935
  643803.2296574  2851439.80583779 2421085.42057654 1056525.11734368
 1380751.58763459 1185104.72708394 4036595.01939847 3948924.83126198
 1961416.31656554 1728740.34661572 2487499.33500882  716994.47956036
  886765.11239144 3480852.6703025   916119.84718615  359690.48632019
 1930537.73876466 4017178.92004958 2763093.75703182 1302849.47878865
 2604802.09687894 1491592.11825044 2220159.47601395 1700071.51182429
 2861934.28149806 2408161.41395734 2069497.44964832 1874364.55351303
 2040104.17592649 2334597.9325753  1071996.2806527  3155511.14593403
 1767994.88415045  821610.15185811 2003097.29733604 1395200.13546784
 1118882.03942734 2718836.02561582 2670072.05219779 1080476.75191998
 2816123.07945142  968345.03832483 1757725.05362993  686430.75392408
 3148763.08355202 1898283.49343249  604301.08474135 2083518.71204634
 2567977.70742304  493229.80238416 1633761.73735897 1313441.77863646
 1464694.55097745  649491.95435711  383151.95664179  628116.59131546
 4295050.77974248 1236780.08548714 3315852.727097   1466125.09658423
 3880088.38391969 2889822.63881969 2562990.57554681 1449670.14902847
 1213600.13103734 2291361.24433014  652272.7371608  4369057.62486447
 1243624.93103012 3192560.93215191 2570602.03106033 2210994.67960136
  874372.18155337  834220.00460316  879184.5961793  2933944.72696814
 1500073.30346872 2203255.32281694 1865050.88771281 2272273.87245299
 2680530.49554651 1803984.86889655 1380167.70251018 1798703.26007137
 1423408.03951203 2220129.51831746 1398042.12308272  994053.81861432
 2696734.928584  ]
2025-06-23 22:34:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:34:54 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:34:54 INFO FeHistory: [1913576.01496582 2316794.35391907 2406415.15585086 3258047.24552872
 1978014.42553178 1948730.18096091 2999703.63039441  282259.08121083
  733050.32178525 3224780.02420991  649894.63392509 2571965.67413698
  873816.00824842 2081145.35379297 2165199.01283887  805841.84138245
 2309212.95753988 2637015.38427437 3514280.69196208 1591506.25811311
 2750417.52248012 2495003.05348912 2578107.49241595 1912730.3773605
 3366371.9720336   784168.75785148 1176666.47713647 1541695.10829587
 4214421.13847369 1163998.51282593 1154144.58027282 2058553.67570903
 1415200.92715407 3006647.82261334 1158592.53028566  732095.46663172
  595650.21325984  785124.91220877 1609946.48651375 2459994.11990166
 1599797.31338333 1607311.95486734  976766.55030633 1749734.64797262
 1926126.0746519  2433181.97416382 2616875.58338935 1858383.81129182
  684711.57850667 1513075.17583326 1636388.64534125  522384.57272103
 2452779.95104804 1294070.72360173 1118329.02755822 1883294.11501535
 1643986.56733336 1993195.91398137 1512228.61795568 3957684.72122705
  899536.00461207 2899168.6663808  1649429.34221118 1835608.37124537
  468786.67664625 1180172.16808407  215852.38789496 1966301.64428888
 3752502.39453304 1193828.43097373  690851.28880877  774047.53960118
  732574.69147523 1769848.67348238 1798918.1913888  1500380.65610394
  360033.39757577  879437.09825487 1478511.288597   1774301.39838773
 2262694.18670465 1100539.91571007 1800413.97004874 4374019.28975468
 1337784.11656392 4444526.85454642  838312.86838237 1200040.53093362
  463721.28007112  920328.40095856 2364879.57664171 1000604.27266372
 2169554.56529895 1498225.87565771  924479.80835244 1730593.02874963
 1687175.56770601 2184182.95611648 2777636.28126345 1704123.61592767
  365109.78592544]
2025-06-23 22:34:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:34:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:34:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:34:54 ERROR Can not run the algorithm
2025-06-23 22:34:54 ERROR Can not run the algorithm
2025-06-23 22:34:54 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:34:54 INFO FeHistory: [133232.57248535 142260.53088584 132144.44827951 104794.62295816
 101859.10931034 187308.53723962  48352.15729404 171005.11738397
 157319.74992592 204268.71888429 141653.46768333 139110.10781579
 153199.68033851 138285.82124095 148298.01534623 142176.93938901
 164509.91691937 186147.96121087 141023.69981586  79932.59925055
 142562.89110883 122534.35716405 140797.95070795 122980.89806615
 146471.48398184 103146.6748568  179571.75934021 171754.7945402
 216222.35506126 102912.75935128 197831.03520244 165029.10340105
 151990.16839994 132181.42164937 159612.6635617  153773.96075853
 121173.55100924 148789.1292814  172973.2335788  146178.22681186
 130921.30924291 173758.09627374 233351.917087   175494.442521
  92451.79679899 200762.89946856 162000.50010232 140171.86505203
 128234.34704038 128169.62876013 143781.84248048 135734.64721302
 182653.23836167 215700.37879199  70464.20316817 139689.92140447
  74883.24959261 157407.91771715 105940.43447916 186039.76043268
 174374.08530556 174381.53164667 148532.51338765 110465.33898794
 209095.64458007 155281.19665875 175518.3792945  159981.28828391
 108046.95118164 142248.98596301 131943.6621564  132645.27886382
 199425.22953951 181633.64813741 175461.98170474 226964.17276104
 168300.93058445 127559.04830789 213704.22468226 145616.87857324
 149981.763868   179941.73073196 202545.82539856  74171.73835276
 169662.91784446  97518.43909046 126709.33893877 138264.28449381
 157360.1916299  184052.27971319 152136.19465538 132452.47844077
 185640.3881339  220533.98895586 143053.80313477 175560.10698841
 107373.06433542 192582.32874516 149858.20303643 107610.04139902
 209055.33948752]
2025-06-23 22:34:54 INFO Expected Optimum FE: -5000
2025-06-23 22:34:54 INFO Unimodal AOCC mean: 0.1472
2025-06-23 22:34:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:34:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:34:54 INFO AOCC mean: 0.0491
2025-06-23 22:34:54 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:34:54 INFO FeHistory: [162614.04270115 154685.76386004 172196.12944002 203779.03787351
 125894.30403184 176711.91025498 111913.13660482 135668.05244995
 193615.44036842 131520.35379593 146504.58788696 152615.67903559
 152681.84739246 111520.65520981 144402.13392419 243301.18338727
 134597.22029046 138948.79510493  99622.33046518 156588.73584503
 128282.07204766 131141.76443493 159404.03011256 140892.9122983
 170216.35218214 166612.92544565 198277.33841199 105557.10162653
 136696.03539842 157363.03817845 150442.004233   222335.44328559
 139706.83994572 154022.74890704 112408.33648767 142363.8380286
 180239.27286133 166411.91488583 161228.30118179 119828.01198994
 106262.18353325 102624.16319654 116219.16095474 123923.66166574
 217140.42103352 124617.4243667  109423.41565048 161327.24996385
 134403.91744913 137211.61373769 174969.70484861  97079.64318894
 157295.52003433 121272.34897677 147891.82666465 111187.89960046
 187660.72800282 122171.54325418 217845.7764479  136453.26828702
 147189.53764338 144398.0523667   94409.0032244  172329.69308595
  90591.44438367 121243.76577444 134639.4311087  124164.07438323
 124595.36565007 265255.33708618 138908.13830374 150249.35445626
 192513.28982792 134785.9794858  181661.11434161 151672.78104061
 204932.41160508 118013.58913947 187844.13297962 142850.36662912
  75053.58710467 147939.90036434 160794.64495501 119463.18225511
 146363.28188457 163678.53129406 103305.85733839 162052.50422382
 136794.9671273  167458.71602396 162429.96674968  95874.42354077
 141850.12447573 100442.08417282 130285.13718343 181366.71345781
 119307.32316428 156431.56561767 177218.80140328 160387.74050524
  83891.66764362]
2025-06-23 22:34:54 INFO Expected Optimum FE: -5000
2025-06-23 22:34:54 INFO Unimodal AOCC mean: 0.1466
2025-06-23 22:34:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:34:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:34:54 INFO AOCC mean: 0.0489
2025-06-23 22:35:02 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1604
2025-06-23 22:35:02 INFO FeHistory: [-183.34305834 -183.3735113  -183.29421282 ... -184.05177443 -184.06829747
 -183.78514911]
2025-06-23 22:35:02 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:02 INFO Good algorithm:
Algorithm Name: ArchiveEnhancedCauchyEA
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description: Employs adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy distribution scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Tournament Selection
            parents = self._tournament_selection(population, fitness_values)

            # Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            # Evaluate offspring
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            #Selection for next generation (Elitism + Random Selection from archive and offspring)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            

            # Update best solution
            self._update_best(offspring, offspring_fitness)

        if self.best_solution_overall is None and self.dim > 0: # Fallback
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + np.random.standard_cauchy(size=parents.shape) * self.gamma
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive.sort(key=lambda x: x[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        #Elitism: Keep the best solutions from the previous generation.
        next_gen = population[np.argsort(fitness_values)[:self.population_size//2]]
        next_fit = fitness_values[np.argsort(fitness_values)[:self.population_size//2]]
        #Combine with offspring and archive
        
        combined_pop = np.vstack((next_gen, offspring, np.array([x[0] for x in self.archive])))
        combined_fit = np.concatenate((next_fit, offspring_fitness, np.array([x[1] for x in self.archive])))

        #Select the best population_size
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit



    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:35:02 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:02 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1741
2025-06-23 22:35:02 INFO FeHistory: [-183.32917502 -183.33862193 -183.39406174 ... -185.56735491 -185.56325369
 -185.56840083]
2025-06-23 22:35:02 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:02 INFO Good algorithm:
Algorithm Name: ArchiveEnhancedCauchyEA
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description: Employs adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Tournament Selection
            parents = self._tournament_selection(population, fitness_values)

            # Adaptive Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            # Evaluate offspring
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Population Update (Elitism)
            population, fitness_values = self._update_population(population, fitness_values, offspring, offspring_fitness)
            
            #Update best solution
            self._update_best(offspring, offspring_fitness)

            #Adapt Cauchy parameter
            self.gamma *= 0.99

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + np.random.standard_cauchy(size=parents.shape) * self.gamma
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            solution = offspring[i]
            fitness = offspring_fitness[i]
            self.archive.append((solution, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]

    def _update_population(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:35:02 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:11 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:35:11 INFO FeHistory: [ 897609.39837505 2277216.20377444 3573966.37260528 ... 1604082.79032499
  340556.91364098  870556.5476719 ]
2025-06-23 22:35:11 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:11 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:11 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:35:11 INFO FeHistory: [2.60106921e+06 2.01941146e+06 1.15481362e+06 ... 1.92087034e+03
 1.92086947e+03 1.92087074e+03]
2025-06-23 22:35:11 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:11 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:40 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:35:40 INFO FeHistory: [104271.35743856 180969.86750673 124031.72145331 ...  13105.81026066
  13105.80950347  13105.81002137]
2025-06-23 22:35:40 INFO Expected Optimum FE: -5000
2025-06-23 22:35:40 INFO Unimodal AOCC mean: 0.1741
2025-06-23 22:35:40 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:40 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:40 INFO AOCC mean: 0.0580
2025-06-23 22:35:40 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:35:40 INFO FeHistory: [213409.77629056 187607.65780227 148851.58079552 ...  32178.04190027
  57193.98076326  43079.211495  ]
2025-06-23 22:35:40 INFO Expected Optimum FE: -5000
2025-06-23 22:35:40 INFO Unimodal AOCC mean: 0.1604
2025-06-23 22:35:40 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:40 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:40 INFO AOCC mean: 0.0535
2025-06-23 22:37:41 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:41 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:41 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:41 ERROR Can not run the algorithm
2025-06-23 22:37:41 ERROR Can not run the algorithm
2025-06-23 22:37:41 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:42 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1473
2025-06-23 22:37:42 INFO FeHistory: [-183.40585958 -183.26115827 -183.32576391 -183.29230709 -183.32961227
 -183.39161813 -183.40500087 -183.29887399 -183.34891053 -183.38096514
 -183.39653641 -183.29836289 -183.31971364 -183.36304899 -183.29249926
 -183.32698529 -183.40793366 -183.35991843 -183.40010289 -183.33840956
 -183.37929518 -183.37680748 -183.35273216 -183.36166472 -183.42443071
 -183.34656787 -183.30573654 -183.36604515 -183.36272839 -183.31577001
 -183.37191805 -183.30784116 -183.49867974 -183.38417343 -183.33843631
 -183.35946534 -183.25752265 -183.35071687 -183.35297752 -183.34132127
 -183.31819438 -183.27733733 -183.28243598 -183.30910428 -183.27618761
 -183.35799538 -183.38065869 -183.38400179 -183.38645578 -183.34771311
 -183.2814239  -183.32386148 -183.34668149 -183.350785   -183.33971404
 -183.40051533 -183.36637321 -183.38000572 -183.40159376 -183.39269645
 -183.33779074 -183.3471964  -183.31846277 -183.30236421 -183.32922792
 -183.36320911 -183.28719105 -183.32749155 -183.40291814 -183.34219121
 -183.29053175 -183.2951034  -183.33328269 -183.37175275 -183.30252118
 -183.43510788 -183.40676269 -183.40379779 -183.2935962  -183.28645736
 -183.40773746 -183.35612683 -183.36247369 -183.3711214  -183.34752958
 -183.3037098  -183.32237039 -183.3788517  -183.33592513 -183.42785337
 -183.33558123 -183.32028924 -183.33846839 -183.38884023 -183.35507359
 -183.33168054 -183.32578089 -183.33188401 -183.39224084 -183.36917519
 -183.2647004 ]
2025-06-23 22:37:42 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:37:42 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithEnhancedArchiveAndTournament
# Name: AdaptiveCauchyDEwithEnhancedArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, enhanced archive management, and tournament selection for robust multimodal optimization.
# Code:
import numpy as np
from scipy.stats import cauchy

class AdaptiveCauchyDEwithEnhancedArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an enhanced archive, and tournament selection for robust multimodal optimization in high dimensions.  The archive uses a dynamically adjusted capacity and prioritizes diverse solutions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, initial_archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = initial_archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive_growth_rate = 0.1 # Adjust archive size dynamically


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            fitness = self._evaluate_population(objective_function, population)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.gamma *= self.gamma_decay
            self._adjust_archive_size() #Dynamic archive size adjustment

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            #Prioritize diversity and solutions near the best solution
            distances = np.linalg.norm(np.array([s for s,_ in self.archive]) - solution, axis=1)
            worst_index = np.argmax(distances)  #Remove the furthest
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)


    def _tournament_selection(self, ind1, ind2, fit1, fit2):
        tournament = np.random.choice(np.array([ind1, ind2]), size=self.tournament_size, replace=True)
        tournament_fitness = np.array([fit1 if t is ind1 else fit2 for t in tournament])
        return tournament[np.argmin(tournament_fitness)]

    def _adjust_archive_size(self):
        if len(self.archive) > 0:
          self.archive_size = int(self.archive_size * (1 + self.archive_growth_rate))
          self.archive_size = min(self.archive_size, self.population_size * 2) # Limit archive growth


2025-06-23 22:37:42 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1465
2025-06-23 22:37:42 INFO FeHistory: [-183.37842585 -183.37558858 -183.33564318 -183.28650228 -183.34365123
 -183.31125679 -183.33113663 -183.32440914 -183.35581258 -183.372573
 -183.36593207 -183.33932291 -183.38150829 -183.30863237 -183.32926404
 -183.35611075 -183.36290968 -183.31043145 -183.40886817 -183.37599907
 -183.35502771 -183.26008906 -183.4025308  -183.36028104 -183.35661604
 -183.41961481 -183.36672195 -183.38222864 -183.34339256 -183.33269643
 -183.29039905 -183.35353201 -183.39341593 -183.31462002 -183.38777557
 -183.34061996 -183.42885265 -183.33079521 -183.38389579 -183.35186254
 -183.33124831 -183.36685706 -183.34245216 -183.38431936 -183.33016353
 -183.35101865 -183.33813274 -183.28452409 -183.32020367 -183.33735505
 -183.37046007 -183.3738156  -183.35494912 -183.34010179 -183.38634179
 -183.42221369 -183.29640491 -183.2858919  -183.42520062 -183.32568139
 -183.36109222 -183.30074323 -183.2790838  -183.35038024 -183.34842356
 -183.38806065 -183.40121866 -183.29512762 -183.42084283 -183.28518304
 -183.38335933 -183.31666908 -183.33359085 -183.2875746  -183.41981464
 -183.32321634 -183.38367909 -183.38465515 -183.34636899 -183.42964559
 -183.31049567 -183.37986882 -183.34821335 -183.3648018  -183.43266424
 -183.40070884 -183.28990535 -183.32699376 -183.35211391 -183.30311806
 -183.36892074 -183.38004857 -183.31517136 -183.42281172 -183.35007382
 -183.33864945 -183.37669626 -183.41855479 -183.30574336 -183.38417721
 -182.34838431]
2025-06-23 22:37:42 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:37:42 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithTournamentAndArchiveSelection
# Name: AdaptiveDEwithTournamentAndArchiveSelection
# Description: Differential Evolution with adaptive Gaussian mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
import numpy as np
from scipy.stats import norm

class AdaptiveDEwithTournamentAndArchiveSelection:
    """
    Combines Differential Evolution (DE), adaptive Gaussian mutation, tournament selection, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, sigma_init=10.0, sigma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.sigma = sigma_init
        self.sigma_decay = sigma_decay
        self.cr = cr
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._gaussian_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            fitness = self._evaluate_population(objective_function, population)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _gaussian_mutation(self, a, b, c):
        return a + self.sigma * (b - c) + norm.rvs(loc=0, scale=self.sigma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, ind1, ind2, fit1, fit2):
        tournament = np.random.choice(np.array([ind1, ind2]), size=self.tournament_size, replace=True)
        tournament_fitness = np.array([fit1 if t is ind1 else fit2 for t in tournament])
        return tournament[np.argmin(tournament_fitness)]
2025-06-23 22:37:42 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:37:42 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:37:42 ERROR Can not run the algorithm
2025-06-23 22:37:42 ERROR Can not run the algorithm
2025-06-23 22:37:42 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:37:42 INFO FeHistory: [1682336.47114367 2129090.73727833 1427418.46977294  604350.41554407
 3158775.49803353  266071.28623428 2182946.75316338 2439371.8895473
 3763210.94713274 1635147.31004519 2666035.62349193 2851369.9973603
 1150956.17809206 2581002.5469778  1442834.03403067 1557343.7550235
  620658.67910565 3113994.93268975 1285848.47125765 1395106.24988337
 2018150.77858846 1621114.5670021  1291270.38161149 1546295.26546012
 2340120.03389449 2879049.05971256  818209.02537293 1450039.47324468
  746945.42955372  492548.99509188  563089.79151508 1277697.12727398
  567137.88049549 1443945.71931253  795663.49584591 1931856.51962159
 2723147.74145493 1266761.09512045  627608.2993515  3311635.82363761
 1041860.07546398 2161115.77994152  569900.52412007  796486.12843273
 2779671.5524289  1142616.19463056 1046307.27303089 4261148.12320927
 2640800.83064044 4130415.7350373  2798921.29743121  820660.0613669
 1178818.38374015 2649282.47589315 1227384.97167099  899321.95734769
 1109574.65432397 2299435.09120655 1756583.0299988  2182761.12169213
  664335.33786285 3115194.34822007 1456323.61093855 1547777.18716682
 1037753.23794835 2157622.09482694 4753526.21284339 2319847.50057055
  820318.75784737 2895900.95474235 2922427.56086143 2395080.12741097
 1254930.06899476 2594151.29740548 1931015.43493534 2594559.47422658
 1731978.09184509 1958250.03035383 2330776.38795567  841229.07880125
 1427657.33831383 2271479.10789184 1428873.38673703 1311472.00904747
 1804639.56082061 2649574.19102211 1973290.24091354 1106141.92736392
 1506158.96769955 4358853.98597384 1270162.18747986 2170474.06317007
 1341850.99245118 3217915.043544   2789483.74540837 1602263.52674403
 1120142.56457545 1521696.90226684 5102541.29965752 3180786.50458051
 6476031.82334517]
2025-06-23 22:37:42 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:37:42 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:37:42 INFO FeHistory: [ 2308858.36028281  1613946.04842042  1789605.19032578   854528.73070793
  2849324.05174308  2319868.58089367   749064.19005274   610113.97543345
   918834.86991705  2780876.93079903  3124567.26827933  2050028.55115442
  2261680.23978321  1703257.74360027  1408393.98255809   973466.0241193
  2760064.8301175   3567332.57713638  3476867.19159826  1390283.19939483
  3340202.96676893   866556.4832358   4341262.40983824  2639922.55323454
   927768.9123588   2067682.49008694  2101722.40516444   952198.09573626
   541788.27424727  5611051.31243514  2813147.76550054  2445585.04711308
  1375207.391311    1767383.87258224  1972384.16007837  1193268.39089824
  2303048.24226137  2939431.99125323  1885798.7443585   4004976.79225313
   999985.00318264   916250.78189534  2032503.70744323   709004.04370105
  1067844.35895809   813992.48717339  1096930.34504113  2090166.13802227
  1186634.64001375  1372738.30655378  2317567.55199423   518958.52162104
  2068027.06754499   905520.14068486  3001987.64448811  3256330.30876883
  1608432.70393611  1611003.95022332  1320886.69721557  1802228.86835831
  1194289.6218678   1104986.53178692  1982492.54546677  1404969.46885287
  1572587.88639968  2831234.11320008   907019.01367513  1088820.90754192
  2920305.88728435  3846914.69755473   368551.73597473  2477541.8660885
   937285.43041393  1817004.6612631   2028427.71671814  3464394.8646721
  2914498.43863996   711805.59030546  1687015.70169322  1313406.24138505
  1707956.63003163  1331115.15525212  4264094.77525142  1005100.42310064
  4373665.51184833  4879159.69455335  2466971.23157293   732775.04142679
  1710000.56242186  1781266.43349406  1518269.48101869   462114.30617937
  1542698.21902467  1695039.58734508   834619.47874002  5431630.84733695
   929232.67520827  1594597.85923802  2011984.55431661  2524242.63169796
 67588213.84061377]
2025-06-23 22:37:42 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:37:42 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:37:42 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:37:42 ERROR Can not run the algorithm
2025-06-23 22:37:42 ERROR Can not run the algorithm
2025-06-23 22:37:42 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:37:42 INFO FeHistory: [  152825.99561489   169234.24876314   116132.09104064   172533.71440241
   139403.58455335   185615.83877559   185343.00167671   219728.26368997
   171225.89378098   220965.43079971   175073.80533481   172219.2623003
   163988.62378872   193490.29117483   167185.25336674   163002.76340555
   107763.04942452   105136.34331938   167121.61942584   107486.73868246
   289840.71436808   173175.07430482   107081.02850629   157979.92786867
   106105.1920516    152887.35869073   148296.0528172     91794.49111227
   189222.393832     166541.01860166   149084.21660328   163580.82867649
   197271.49289254   149136.38265504   192277.72993062   141480.60024773
   165286.48348827   141100.51881274   146906.66609111   160516.1721782
    90288.87356819   154399.40455704   174082.51082027   196096.67411939
   103371.60435667   103484.04130728   128462.55676507   119665.23841283
   135813.98077831   211922.38208802   207162.95634355   236553.40466978
   152109.47889459   213421.83096538   156899.9579676    165719.78616614
   162189.49417523   152670.69243126   153124.40295639   248477.56619912
   135016.70510833   143280.80265481   151227.1606186    153855.0245901
   180673.76603283   198859.62958977   136768.6901021    104791.25652595
   132316.13610521   142017.73324893   231588.84377736   130926.96239513
   157164.45454941   114907.79768299   162192.31856494   193162.19152714
   164543.28091672   140636.84520175   168733.53863269   141600.98904266
   183660.08296886   169396.42213454   141991.00826881   134184.07640611
   197961.60377931   195563.7738654    219459.06316467   147928.90401203
   134154.90544297   176680.10486221   183685.75065644   130375.22788531
   116962.02964649   222581.18588551   129882.82537038   112853.84847055
   187967.29943812   111130.12789943   121837.3874732    124849.08488455
 20187738.15131069]
2025-06-23 22:37:42 INFO Expected Optimum FE: -5000
2025-06-23 22:37:42 INFO Unimodal AOCC mean: 0.1465
2025-06-23 22:37:42 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:37:42 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:37:42 INFO AOCC mean: 0.0488
2025-06-23 22:37:42 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:37:42 INFO FeHistory: [ 63673.17336147  83472.30100076 207969.61082942 154458.42738422
 207867.43456637 269595.37826651 117495.85547488 173405.94630062
 127643.58812744 197525.90204702 167731.2115448  159492.82416363
 132284.40815746 164141.68373203 155862.60444163 170906.96841059
  99294.84534241 182061.0080191  115021.09409994 154368.39463662
 203157.27027509 129643.17928109  97014.95047846 189798.92071085
 112819.75044848 134114.08776637 149331.41076712  95553.63652767
 231353.84456506 154091.95043926 157155.55787973 267572.86605869
 126384.53563027 199888.97249209 159866.48680562 196012.90892758
 124847.59450337 207686.9334425  187064.38596278 144187.02854266
 223870.77827908 185082.60159076 179472.03455919 166614.4865603
 131565.03953697 141446.70898597  82092.71195904 149117.22338434
 141571.84559418 139425.47385388 202262.64119331 196480.44109115
 166617.67238083 230733.34693533 108707.97813176 170558.31074034
 142550.64385195 180952.4049067  167404.20567141 152583.67088337
 153127.64344701 123608.61354962 138588.07159166 144559.20846761
 255284.62880951  83680.37058417 171123.51223752 158624.27256498
 151727.96233158 199769.49210561 118034.2720513   95894.703784
 207905.85312771 112957.87564479 120193.89789125 159134.59357516
 135148.37343425 112022.19619372 205503.65018003 141803.31122173
 153940.28283183 177528.28664743 159087.53332309 166712.14223085
 180664.97880562 115245.23848116 125694.16973503 136757.8225482
 157308.57439407 143378.87642373 167472.55167307 135335.45722658
 116699.94436562 193020.61243841 141589.75880193 168930.96383153
 155405.81631231 241406.46598562 167186.27788208 123969.34782701
 344654.21195083]
2025-06-23 22:37:42 INFO Expected Optimum FE: -5000
2025-06-23 22:37:42 INFO Unimodal AOCC mean: 0.1473
2025-06-23 22:37:42 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:37:42 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:37:42 INFO AOCC mean: 0.0491
2025-06-23 22:37:42 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:42 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:42 ERROR Can not run the algorithm
2025-06-23 22:37:43 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1467
2025-06-23 22:37:43 INFO FeHistory: [-183.34685338 -183.37832309 -183.22650001 -183.32280365 -183.37732535
 -183.27794174 -183.34176975 -183.36482602 -183.2855872  -183.35539719
 -183.3850122  -183.29618818 -183.32737164 -183.36934745 -183.4107019
 -183.36312699 -183.33140117 -183.3396883  -183.35396835 -183.37070285
 -183.42774442 -183.320837   -183.27922352 -183.32939525 -183.29882242
 -183.31040713 -183.37594206 -183.37354505 -183.34369301 -183.41390083
 -183.39280364 -183.44525935 -183.34949004 -183.36227407 -183.35462768
 -183.34464773 -183.3491713  -183.36628252 -183.39037987 -183.38462699
 -183.40803085 -183.36161201 -183.38695983 -183.33725484 -183.31015032
 -183.32667384 -183.35522137 -183.36570787 -183.34123423 -183.33174178
 -183.34415448 -183.42739056 -183.28552816 -183.35926481 -183.39251927
 -183.34846931 -183.28336657 -183.3523207  -183.34601621 -183.40392694
 -183.32954495 -183.2976526  -183.34271627 -183.31959615 -183.35776022
 -183.26278734 -183.38725186 -183.38469409 -183.36121365 -183.30329875
 -183.37317973 -183.40847036 -183.40456147 -183.34387946 -183.32474245
 -183.35078017 -183.30564327 -183.38001075 -183.3353153  -183.39819766
 -183.35629242 -183.3047991  -183.39634647 -183.30341202 -183.37785891
 -183.34944929 -183.35582198 -183.35027067 -183.37947241 -183.45275145
 -183.40037476 -183.34725971 -183.34970383 -183.26675176 -183.32192759
 -183.36578947 -183.39604511 -183.39275423 -183.30042558 -183.24644126
 -183.32239662]
2025-06-23 22:37:43 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:37:43 INFO Good algorithm:
Algorithm Name: ArchiveEnhancedCauchyDE
# Name: ArchiveEnhancedCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
import numpy as np

class ArchiveEnhancedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy distribution scale parameter
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Differential Evolution crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Archive Management
            self._update_archive(population, fitness_values)

            # Differential Evolution with Cauchy Mutation
            offspring = self._cauchy_de(population, fitness_values)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Elitist Selection
            population, fitness_values = self._elitist_selection(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness_values):
        combined = np.concatenate((np.array([x[0] for x in self.archive]), population))
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness_values))
        sorted_indices = np.argsort(combined_fitness)
        self.archive = [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]

    def _cauchy_de(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            #Select three distinct vectors
            a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)
            while a == i or b == i or c == i:
                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)

            mutant = population[a] + self.F * (population[b] - population[c])

            #Cauchy mutation
            mutant += np.random.standard_cauchy(self.dim) * self.gamma

            #Crossover
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            offspring.append(np.clip(trial, self.lower_bounds, self.upper_bounds))
        return np.array(offspring)

    def _elitist_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:37:43 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:37:43 ERROR Can not run the algorithm
2025-06-23 22:37:43 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:37:43 INFO FeHistory: [1638173.79458979 3327158.4513127  2220776.59806429  599399.19696049
  786918.48615825 1581742.58534181  934227.73888    2344760.24055332
 1823613.31802728  769908.20558934 2280324.79720842 2015415.88573134
 1018491.0221629  1761080.61071888  701116.1484721  1614274.74000212
 1291144.30261202 1311373.07506055 2095542.65094469 2284836.98301482
  790710.66862697 1868111.03758248 1413900.35454365 2125869.11203155
 1873475.14168392 3047958.15446115 1149714.99795492  866395.39905235
  205825.66312743 1463982.08790781 1938547.05750011 3493737.96579429
 3014110.17165781 1105729.73239292  577953.24155493 1982627.69200132
 2088753.67237244 2079741.22781176 3776604.71581244 2346770.99983813
 1845064.54612085 1235706.92819699  673584.30098526 1346213.05347656
 1201227.37632276  769273.92872629  295002.33033296 2791046.50733644
 2804293.55197146  833415.84415609 1732908.50659872 2955534.80912237
 2381694.50341134 3371334.03758383 2354424.2893588  4434713.14377822
 1000277.56069361 1916850.76331378 2181850.4675912  2159770.59464079
 2917030.96965538 1022645.78549932 1743245.6268968  2373358.45692602
 1150256.14494049 2213068.11839968 2734313.06089013 1148484.76206299
 2250413.24901236 1930589.33352224 1851283.87822488 1302651.17379192
 2227649.86049094 1677211.36264252 1440307.57358885 1318307.19931679
 1357083.34780289  999340.8109     2101775.13839351 1597208.15677645
 2446803.28044828 4405103.76809362 3123365.69558989 4175477.21250649
  889272.20133797  985154.35310689 1195363.24634368 3592552.04383834
 1801459.04802485 1238205.91531905 1126585.49344775 1239732.3716506
 3425961.36042376 1181660.2141816  2401151.82793643 1204780.85394525
 1282791.22069073 2218848.70967099 1380200.53007496  816361.24148561
 1708394.8727614 ]
2025-06-23 22:37:43 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:37:43 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:37:43 ERROR Can not run the algorithm
2025-06-23 22:37:43 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:37:43 INFO FeHistory: [170662.79236493 141495.17848373 246358.40907369 163298.22075731
 173160.51026144 145131.66868748 170960.45314181 118974.26722578
 194662.97884172 126725.033105   167248.3094959  153134.75911284
 154553.04757875 195487.36475792 195873.46772448 145478.83576226
 198358.16170861 158067.4661293  160756.87523313 255497.50926819
 190050.67219756 104789.56321997 222754.35304012 103970.98933206
 195283.71656893 168071.89223905 156164.69783419 155097.73784839
 144538.69338397 194088.45535811 178622.60125308  76498.90083742
 167103.88618796 207117.1418269   93035.19208757 119593.29811725
 254377.71643027 153210.17227444 143778.56357617 140716.56359045
 112958.47881738 172183.33794853 164968.66068168 117635.4674153
 208106.52453348 184084.38250287  96344.2230824  190543.4896522
 144536.29045232 169007.21058669 202076.22297728 173281.90531739
 174754.57531144 164589.75926234 163758.93798112 145119.83520274
 165048.24403211  94225.81475007 187302.66699601  93498.93281899
 135483.73627356 148131.65084776 149229.53838915 168789.41592227
 158962.3616336  159566.30102442 147023.72536314 191167.90408896
  87013.15170099 167642.20198124 139863.12839593 194853.70923478
 175524.64829679 142520.45136604 109591.98055676 141617.40955166
 115152.24800281 136024.34347381 120509.79474251 160503.06110998
 122711.38954976  94104.27542284 120388.80146574 138716.63407508
 122515.81367813 182871.10534093 148287.50729819 152433.92594785
 104491.6020194  169910.79837955 215832.4716188  199061.60780419
 108815.54498386 140031.94338379 151413.80589062 105339.6647702
 115840.53788692 148747.32479321 211408.3697167  137053.60504782
 125579.84737805]
2025-06-23 22:37:43 INFO Expected Optimum FE: -5000
2025-06-23 22:37:43 INFO Unimodal AOCC mean: 0.1467
2025-06-23 22:37:43 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:37:43 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:37:43 INFO AOCC mean: 0.0489
2025-06-23 22:37:43 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:37:52 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1518
2025-06-23 22:37:52 INFO FeHistory: [-183.43592408 -183.32669072 -183.28375591 ... -183.84156926 -183.84156926
 -183.84156926]
2025-06-23 22:37:52 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:37:52 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithArchiveAndTournamentSelection
import numpy as np
from scipy.stats import norm

class AdaptiveDEwithArchiveAndTournamentSelection:
    """
    Combines Differential Evolution (DE), adaptive Gaussian mutation, an archive, and tournament selection for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._gaussian_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _gaussian_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + norm.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]

2025-06-23 22:37:52 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:38:03 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:03 INFO FeHistory: [2.19083728e+06 7.29131762e+06 1.69759296e+06 ... 1.92034173e+03
 1.92034173e+03 1.92034173e+03]
2025-06-23 22:38:03 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:38:03 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:38:03 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1582
2025-06-23 22:38:03 INFO FeHistory: [-183.35627822 -183.27274328 -183.35072465 ... -184.33821396 -184.33821397
 -184.33821397]
2025-06-23 22:38:03 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:38:03 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentAndArchiveEnhancements
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchiveEnhancements
# Description: Combines DE, adaptive Cauchy mutation, tournament selection, and an enhanced archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchiveEnhancements:
    """
    Differential Evolution with adaptive Cauchy mutation, tournament selection, and an enhanced archive for multimodal optimization.  Improves upon previous designs by incorporating a more sophisticated archive management strategy and a dynamic population size adjustment.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Initial population size, can be adjusted dynamically
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size_adjustment_factor = 1.1  #Factor to adjust population size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay
            
            #Dynamic Population Size Adjustment
            if self.eval_count % (self.population_size * 2) == 0: # Adjust every 2 generations
                if self.best_fitness_overall < 1e-2:  #Check if converging well
                    self.population_size = int(self.population_size / self.population_size_adjustment_factor)  #Reduce if converging
                else:
                    self.population_size = int(self.population_size * self.population_size_adjustment_factor) #Increase otherwise


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Enhanced archive management: remove the furthest solution from the best
                distances = np.linalg.norm(np.array([x for x, _ in self.archive]) - self.best_solution_overall, axis=1)
                worst_index = np.argmax(distances)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
2025-06-23 22:38:03 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:38:05 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1585
2025-06-23 22:38:05 INFO FeHistory: [-183.34368068 -183.27272288 -183.33988738 ... -184.31229876 -184.31229876
 -184.31229876]
2025-06-23 22:38:05 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:38:05 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithTournamentSelectionAndDynamicArchive
import numpy as np
from scipy.stats import cauchy

class AdaptiveDEwithTournamentSelectionAndDynamicArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, 
    tournament selection, and a dynamically sized archive for robust 
    multimodal optimization in high dimensions.  The archive size adapts 
    based on the diversity of the population.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, initial_archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive = []
        self.archive_size = initial_archive_size
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size
        self.diversity_threshold = 0.1 # Parameter to control archive size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            self._adapt_archive_size() #Dynamic archive size

            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
    
    def _adapt_archive_size(self):
        #Estimate diversity using standard deviation of distances
        if len(self.archive) > 1:
            distances = []
            for i in range(len(self.archive)):
                for j in range(i + 1, len(self.archive)):
                    distances.append(np.linalg.norm(self.archive[i][0] - self.archive[j][0]))
            diversity = np.std(distances)

            if diversity < self.diversity_threshold:
                self.archive_size = int(self.archive_size * 1.2) # Increase archive size if low diversity
            elif diversity > self.diversity_threshold * 2:
                self.archive_size = int(self.archive_size * 0.8) #Decrease if high diversity
            self.archive_size = max(50,min(self.archive_size, 200)) #Keep within reasonable bounds
            self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]


2025-06-23 22:38:05 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:38:07 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1585
2025-06-23 22:38:07 INFO FeHistory: [-183.397228   -183.36912272 -183.33114338 ... -184.3793528  -184.37935449
 -184.37934708]
2025-06-23 22:38:07 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:38:07 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentAndEnhancedArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndEnhancedArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an enhanced archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndEnhancedArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, tournament selection, and an enhanced archive 
    for robust multimodal optimization.  The archive uses a diversity metric to prioritize diverse solutions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Heuristic population size
        self.archive_size = 200 # Increased archive size
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.diversity_threshold = 0.1 #Parameter to control archive diversity

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                self._manage_archive(offspring[i], offspring_fitness[i])


    def _manage_archive(self, solution, fitness):
        if fitness < np.max([f for _, f in self.archive]): #add if better than worst
            worst_index = np.argmax([f for _, f in self.archive])
            self.archive[worst_index] = (solution, fitness)
        else: #Check for diversity
            distances = np.array([np.linalg.norm(solution - s) for s, _ in self.archive])
            if np.min(distances) > self.diversity_threshold:
                worst_index = np.argmax([f for _, f in self.archive])
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
2025-06-23 22:38:07 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:38:22 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:22 INFO FeHistory: [1541852.89457238  468148.76277695 1449644.56850981 ...    3417.97406623
    3417.96920016    3417.97293153]
2025-06-23 22:38:22 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:38:22 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:38:29 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:29 INFO FeHistory: [1186584.51358265 1855724.79797254 1341621.59603126 ...    2497.11848182
    2497.11848182    2497.11848182]
2025-06-23 22:38:29 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:38:29 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:38:33 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:33 INFO FeHistory: [153711.04347329 152640.35462795 168990.24187117 ...  24608.85668596
  24608.85668596  24608.85668596]
2025-06-23 22:38:33 INFO Expected Optimum FE: -5000
2025-06-23 22:38:33 INFO Unimodal AOCC mean: 0.1518
2025-06-23 22:38:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:38:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:38:33 INFO AOCC mean: 0.0506
2025-06-23 22:38:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:38:41 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:41 INFO FeHistory: [7.49148432e+05 2.01631207e+06 2.37471021e+06 ... 1.87968618e+03
 1.87968616e+03 1.87968617e+03]
2025-06-23 22:38:41 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:38:41 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:38:45 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1591
2025-06-23 22:38:45 INFO FeHistory: [-183.34668703 -183.32061961 -183.30263867 ... -184.40630533 -184.40630441
 -184.40630486]
2025-06-23 22:38:45 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:38:45 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentSelectionAndElitistArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelectionAndElitistArchive
# Description: Combines DE, adaptive Cauchy mutation, tournament selection, and an elitist archive for efficient multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelectionAndElitistArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5 #tournament size
        self.archive_size = 100 #Archive size
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter
            self._update_archive(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _update_archive(self, population, fitness):
        #add to archive, maintaining diversity and elitism
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))
        
        #Maintain archive size and elitism
        self.archive.sort(key=lambda item:item[1])
        self.archive = self.archive[:self.archive_size]
        if len(self.archive)>0:
            if self.archive[0][1] < self.best_fitness_overall:
                self.best_fitness_overall = self.archive[0][1]
                self.best_solution_overall = self.archive[0][0]


2025-06-23 22:38:45 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:38:57 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:38:57 INFO FeHistory: [1581432.33304215 2412890.75103109 1316507.41222618 ...    4010.99131581
    4010.99206516    4010.99174132]
2025-06-23 22:38:57 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:38:57 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:39:01 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:39:01 INFO FeHistory: [235855.93623858 163286.71123184 136832.80751061 ...   4022.4467837
   4022.44674731   4022.44639497]
2025-06-23 22:39:01 INFO Expected Optimum FE: -5000
2025-06-23 22:39:01 INFO Unimodal AOCC mean: 0.1582
2025-06-23 22:39:01 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:39:01 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:39:01 INFO AOCC mean: 0.0527
2025-06-23 22:39:14 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:39:14 INFO FeHistory: [187174.35857706 152141.15899381 117452.88044357 ...  12567.92184552
  12567.92184552  12567.92184552]
2025-06-23 22:39:14 INFO Expected Optimum FE: -5000
2025-06-23 22:39:14 INFO Unimodal AOCC mean: 0.1585
2025-06-23 22:39:14 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:39:14 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:39:14 INFO AOCC mean: 0.0528
2025-06-23 22:39:30 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:39:30 INFO FeHistory: [166532.1122908  106938.61384924 151377.8564865  ...   2912.44140956
   2912.44140956   2912.44140956]
2025-06-23 22:39:30 INFO Expected Optimum FE: -5000
2025-06-23 22:39:30 INFO Unimodal AOCC mean: 0.1591
2025-06-23 22:39:30 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:39:30 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:39:30 INFO AOCC mean: 0.0530
2025-06-23 22:39:32 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:39:32 INFO FeHistory: [132516.03780563 216842.20804535 118078.25099031 ...   -641.3414303
   -641.34132139   -641.34125463]
2025-06-23 22:39:32 INFO Expected Optimum FE: -5000
2025-06-23 22:39:32 INFO Unimodal AOCC mean: 0.1585
2025-06-23 22:39:32 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:39:32 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:39:32 INFO AOCC mean: 0.0528
2025-06-23 22:40:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:40:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:40:22 ERROR Can not run the algorithm
2025-06-23 22:40:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:40:22 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:40:23 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1473
2025-06-23 22:40:23 INFO FeHistory: [-183.37570698 -183.34989772 -183.32777033 -183.29583228 -183.30499038
 -183.3278022  -183.33253799 -183.35000025 -183.30865487 -183.29443608
 -183.35984086 -183.36477844 -183.31919912 -183.36596041 -183.37049277
 -183.37940718 -183.35466643 -183.2767643  -183.35087207 -183.35340785
 -183.26650906 -183.26838386 -183.33417813 -183.31090512 -183.32109568
 -183.37018878 -183.37822436 -183.33564209 -183.29088875 -183.45373573
 -183.36544328 -183.26502121 -183.40024528 -183.33093878 -183.29988002
 -183.37683488 -183.3184411  -183.39745815 -183.3833433  -183.30936251
 -183.42089691 -183.43644642 -183.35739328 -183.4431875  -183.37418117
 -183.34007164 -183.38530093 -183.34084937 -183.2792433  -183.36112788
 -183.30844221 -183.31202412 -183.33327962 -183.28655731 -183.33486758
 -183.33105978 -183.39589369 -183.3235637  -183.29210613 -183.40298696
 -183.31055221 -183.32101438 -183.37566455 -183.3069641  -183.39610604
 -183.32916095 -183.39223264 -183.37840276 -183.27658226 -183.50211629
 -183.43749086 -183.44856391 -183.3422895  -183.37558384 -183.35651137
 -183.34747337 -183.38928539 -183.39578603 -183.32305356 -183.42191493
 -183.34452685 -183.33695601 -183.3330464  -183.33626911 -183.34123468
 -183.39547958 -183.32842031 -183.30963553 -183.35769749 -183.35019945
 -183.28979318 -183.40427034 -183.38847833 -183.37070098 -183.36169641
 -183.39647292 -183.36989538 -183.38637745 -183.2980759  -183.33034753
 -183.38530511]
2025-06-23 22:40:23 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:40:23 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithLevyFlights
import numpy as np

# Name: AdaptiveDifferentialEvolutionWithLevyFlights
# Description: A differential evolution algorithm enhanced with Levy flights for robust exploration and adaptive parameter control for exploitation in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithLevyFlights:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate

        self.levy_alpha = 1.5 #Levy flight exponent

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_different_vectors(population, i)
                mutant = a + self.F * (b - c)
                trial = self._crossover(population[i], mutant, self.CR)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                # Levy Flight Mutation for Exploration
                levy_step = self._levy_flight(self.levy_alpha, self.dim)
                trial = trial + 0.1 * levy_step * (self.upper_bounds-self.lower_bounds)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)


                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    new_population.append(population[i])

                self._update_best(trial, trial_fitness)

            population = np.array(new_population)
            self.F = max(0.1, self.F * 0.99) #Adaptive F decay
            self.CR = min(1, self.CR + 0.001)  #Adaptive CR increase


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _select_different_vectors(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]


    def _crossover(self, x, v, CR):
        u = np.copy(x)
        jrand = np.random.randint(self.dim)
        for j in range(self.dim):
            if np.random.rand() < CR or j == jrand:
                u[j] = v[j]
        return u

    def _levy_flight(self, alpha, dim):
        beta = 3 / 2
        sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1/alpha)
        sigma_v = 1
        u = np.random.normal(0, sigma_u, dim)
        v = np.random.normal(0, sigma_v, dim)
        step = u / (np.abs(v)**(1/beta))
        return step


    def _update_best(self, solution, fitness):
        if fitness < self.best_fitness_overall:
            self.best_fitness_overall = fitness
            self.best_solution_overall = solution

2025-06-23 22:40:23 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:40:23 ERROR Can not run the algorithm
2025-06-23 22:40:23 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:40:23 INFO FeHistory: [2222902.63339366 2361831.30427171 2509104.04722366 2938893.212468
 1721244.75423494 3989194.70408212 1431443.0491926  2035457.52868807
 1631167.01481807 4079486.11878828  884038.38489022 1028570.75967942
  941153.13154787 1358065.8907411  2481576.24357018 2625792.71206705
  269478.52593411 1287886.18088277 1398175.39047987 2725431.92401953
 3437035.53475229 2303867.9436919  1539209.765606   2230097.94623842
 3145974.10887284 1297071.06814242 1313837.2155194  2398992.70643978
 2914336.42818022 4583766.84159113 2023720.10669739 3678827.75779505
 1198113.05146741  806154.38553915 4322033.23207122 1197879.64636087
 3139724.41852896 1263619.50100637 1598933.03811572 2202491.58025289
 5777386.10379568 2898847.48318519 2274657.27927451  934860.34742193
 2363301.05925456 2052836.25268325 1730039.52538483 2090297.31543251
  870663.82104107 2492563.07508356 1106614.95764807 3553843.42301212
 1259143.85937246  537199.9989988  2313183.66358748 1568070.88409647
 2109369.27799226 1188598.47280802  937362.97516646 2199409.5521572
 5069957.3941224  2032472.52349548 1225883.06341208 2891636.55798578
  941292.91284306  959835.76911362  896789.82958771 1017012.20134823
 1808476.81693326  858742.36838734  180077.29145036  924736.49519595
 1708777.74082521 3592586.19661724 1947428.92874796  988138.12941388
 2076471.05106394 2509433.04852928 1961652.10056959 4711250.63671771
 3097605.06336417  789273.62482676 1941450.88142159 3194917.21022198
  617471.01325201 3050009.85704342 1765838.823714    620765.90101984
 1932260.65458667  443472.29358801 1024419.79453928 2782376.84005728
  987817.79328301 3217307.90310785 2384527.49711059 3337106.53384888
 1458410.00193616 3011351.6117487  1967797.77660355 1197145.61909545
  937610.24874587]
2025-06-23 22:40:23 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:40:23 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:40:23 ERROR Can not run the algorithm
2025-06-23 22:40:23 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:40:23 INFO FeHistory: [163813.56214773 154555.11949275 165160.03263275 172682.79730593
 150265.27098635 165425.45909054 151485.49012527 157492.84895101
 100072.46167181 153188.97903764 203948.84105824 107029.72181382
 157447.91587321 202732.43055702 136222.49729284 164550.08500257
  93859.8782805  188537.89400502 181746.60191786 171444.099119
 167594.57477421 186242.96611038 191041.47975932 158417.49795421
 189281.60776819 184613.16909512 136053.82437065 135638.42356441
 137193.2519214  176719.42187029 140504.57711262 217925.30835192
 167126.43916752  95242.59893308 145664.66221766 143503.70720317
 169972.22540513 142781.82261079 148750.01141636 194369.44791948
 182077.84186798 112173.6844585  151662.13333271 107718.0435501
 111111.60681263 180653.39235623 139234.87612786 221933.76606321
 144140.53198722 158105.03929227 156068.42850494 125095.3601614
 199996.18296761 141048.63566015 104605.44465776 185890.66590285
 169292.85907365  81193.79757863 121990.63557046 186639.85824713
 127530.90829039 133021.55520587 111639.23127039 166144.51896039
 171764.00601379 136186.13978045 143294.81816167 146570.00412891
 207371.87510285 150618.25742316 197934.25807387  75322.87121803
 155666.74490569 166728.38961959 121866.31489413 150579.11401929
 184058.47901784 135811.71689805 128960.41871877 203652.21132656
  63926.70546254 227604.14564976 171829.69069054  90041.34835348
 113935.02860761 143508.75771602 252642.04300794 148232.09071995
 124189.01174785 231423.38289998 126082.39827462 146179.19119286
 166106.41622356 146459.9129496  198694.44684276 181464.71542896
  74359.12032499 145686.22355501 160977.06451537 165595.15145131
 142936.26474352]
2025-06-23 22:40:23 INFO Expected Optimum FE: -5000
2025-06-23 22:40:23 INFO Unimodal AOCC mean: 0.1473
2025-06-23 22:40:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:40:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:40:23 INFO AOCC mean: 0.0491
2025-06-23 22:40:35 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1522
2025-06-23 22:40:35 INFO FeHistory: [-183.36056065 -183.37385317 -183.39905752 ... -183.84759462 -183.84520667
 -183.78426585]
2025-06-23 22:40:35 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:40:35 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyMutation
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm enhanced with adaptive Cauchy mutation and a diversity-preserving selection mechanism for efficient multimodal optimization.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma_cauchy = 0.1 #Initial Cauchy scale parameter
        self.sigma_decay = 0.99


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            self.sigma_cauchy *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = self._select_parents(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Bound the mutant

            #Cauchy Mutation
            cauchy_mutation = cauchy.rvs(loc=0, scale=self.sigma_cauchy, size=self.dim)
            mutant += cauchy_mutation

            #Crossover
            j_rand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    offspring[i, j] = mutant[j]

        return offspring


    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:40:35 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:40:36 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1514
2025-06-23 22:40:36 INFO FeHistory: [-183.42072642 -183.37863197 -183.31149075 ... -183.84746898 -183.87490128
 -183.80568769]
2025-06-23 22:40:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:40:36 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyMutation
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm enhanced with adaptive Cauchy mutation and a diversity-preserving selection strategy for efficient multimodal optimization.
# Code:

class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.scale_factor = 0.2 # For initial Cauchy scale
        self.cauchy_scale_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        cauchy_scale = self.scale_factor * (self.upper_bounds - self.lower_bounds)

        while self.eval_count < self.budget:
            offspring = np.copy(population)
            for i in range(self.population_size):
                # Differential Evolution mutation
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])

                # Adaptive Cauchy mutation
                mutant += cauchy.rvs(loc=0, scale=cauchy_scale, size=self.dim)

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                jrand = np.random.randint(0, self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == jrand:
                        offspring[i, j] = mutant[j]

            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection (combined population, diversity-preserving)
            combined_population = np.vstack((population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))
            
            sorted_indices = np.argsort(combined_fitness)
            population = combined_population[sorted_indices[:self.population_size]]
            fitness_values = combined_fitness[sorted_indices[:self.population_size]]


            # Update best solution
            self._update_best(offspring, offspring_fitness)
            cauchy_scale *= self.cauchy_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:40:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:40:37 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1515
2025-06-23 22:40:37 INFO FeHistory: [-183.32203678 -183.32497295 -183.33290683 ... -183.7364627  -183.67312484
 -183.71442007]
2025-06-23 22:40:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:40:37 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyMutation
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A Differential Evolution variant using adaptive Cauchy mutation for efficient exploration in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.initial_cauchy_scale = 0.1
        self.cauchy_scale = self.initial_cauchy_scale


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_indices(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                trial = self._crossover(population[i], mutant)
                
                #Adaptive Cauchy Mutation
                trial = trial + cauchy.rvs(loc=0, scale=self.cauchy_scale, size=self.dim)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    offspring.append(population[i])

            population = np.array(offspring)
            self._update_best(population, fitness_values)
            self._adapt_cauchy_scale(population,fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _select_indices(self, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _adapt_cauchy_scale(self, population, fitness_values):
      #Reduce Cauchy scale if the algorithm converges
      if np.std(fitness_values) < 0.1 * (self.best_fitness_overall):
          self.cauchy_scale *= 0.9
      else: #increase if stuck
          self.cauchy_scale *= 1.1
      self.cauchy_scale = max(self.cauchy_scale, self.initial_cauchy_scale * 0.1) #Avoid extremely small scale
      self.cauchy_scale = min(self.cauchy_scale, self.initial_cauchy_scale * 10) #Avoid extremely large scale

2025-06-23 22:40:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:40:48 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:40:48 INFO FeHistory: [1448981.66746218 1689407.63301159 2362788.8956796  ...  927972.69097621
  740358.54653828 2684071.54750768]
2025-06-23 22:40:48 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:40:48 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:40:49 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:40:49 INFO FeHistory: [1298085.80923203 2255454.81317142  603567.32571965 ...  933191.13890549
 3241073.70766659 1578345.5677045 ]
2025-06-23 22:40:49 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:40:49 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:40:52 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:40:52 INFO FeHistory: [3928401.46238127 1717637.63937568 2353116.13068567 ... 3128608.04407045
 2607174.40826049 1639810.03765472]
2025-06-23 22:40:52 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:40:52 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:22 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:41:22 INFO FeHistory: [160788.99904255 150150.0414236  136974.23367886 ...  20272.23733145
  21434.80625143  16895.48540036]
2025-06-23 22:41:22 INFO Expected Optimum FE: -5000
2025-06-23 22:41:22 INFO Unimodal AOCC mean: 0.1522
2025-06-23 22:41:22 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:22 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:22 INFO AOCC mean: 0.0507
2025-06-23 22:41:23 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:41:23 INFO FeHistory: [144807.87768368 142422.66173554 154795.78776567 ...  38022.32761815
  55128.50219921  20402.45231097]
2025-06-23 22:41:23 INFO Expected Optimum FE: -5000
2025-06-23 22:41:23 INFO Unimodal AOCC mean: 0.1514
2025-06-23 22:41:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:23 INFO AOCC mean: 0.0505
2025-06-23 22:41:27 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:41:27 INFO FeHistory: [129211.46995368 116305.80019625 140562.26108544 ...  19391.39883805
  24257.72621304  43838.76734583]
2025-06-23 22:41:27 INFO Expected Optimum FE: -5000
2025-06-23 22:41:27 INFO Unimodal AOCC mean: 0.1515
2025-06-23 22:41:27 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:27 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:27 INFO AOCC mean: 0.0505
2025-06-23 22:43:24 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:43:24 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:43:24 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:43:24 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:43:24 ERROR Can not run the algorithm
2025-06-23 22:43:24 ERROR Can not run the algorithm
2025-06-23 22:43:24 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1469
2025-06-23 22:43:24 INFO FeHistory: [-183.32817119 -183.32519572 -183.43652206 -183.34609971 -183.23871403
 -183.43542179 -183.33081786 -183.31324286 -183.44051125 -183.33502418
 -183.28873582 -183.3862957  -183.37624821 -183.39938997 -183.29505597
 -183.31233968 -183.35580242 -183.3429012  -183.35187308 -183.34220971
 -183.33187596 -183.32728371 -183.3275093  -183.41267343 -183.29461664
 -183.37011321 -183.42900955 -183.34468853 -183.33537485 -183.25906331
 -183.33462888 -183.37496267 -183.35814995 -183.35104912 -183.30301085
 -183.31327455 -183.35968797 -183.46931545 -183.37984748 -183.28481875
 -183.37789181 -183.35121778 -183.3548279  -183.34365101 -183.39718527
 -183.31685905 -183.34812222 -183.30114222 -183.29984543 -183.30675724
 -183.34919485 -183.30598062 -183.31344154 -183.35725699 -183.33799178
 -183.34462166 -183.411446   -183.33222271 -183.33175477 -183.3335512
 -183.36871106 -183.33931577 -183.33422069 -183.35980215 -183.35136287
 -183.35082696 -183.25907294 -183.33937771 -183.35866334 -183.42023325
 -183.32199235 -183.3487155  -183.3586358  -183.33700073 -183.38019349
 -183.32295918 -183.29909432 -183.30813143 -183.35449785 -183.28897242
 -183.3234459  -183.38290416 -183.28271495 -183.30235235 -183.32865836
 -183.35760276 -183.30980625 -183.33169477 -183.36630623 -183.39486877
 -183.35958597 -183.28583541 -183.32567189 -183.3885607  -183.38979821
 -183.42101963 -183.36216305 -183.32819595 -183.2981393  -183.29323704
 -183.39192181]
2025-06-23 22:43:24 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:43:24 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyAndLevyFlights
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyAndLevyFlights
# Description: Combines Differential Evolution, adaptive Cauchy and Levy flight mutations for robust multimodal optimization.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyAndLevyFlights:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma_cauchy = 0.1 #Initial Cauchy scale parameter
        self.sigma_decay = 0.99
        self.levy_alpha = 1.5 #Levy flight exponent
        self.levy_scale = 0.1

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            self.sigma_cauchy *= self.sigma_decay
            self.F = max(0.1, self.F * 0.99) #Adaptive F decay
            self.CR = min(1, self.CR + 0.001)  #Adaptive CR increase

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_mutation = cauchy.rvs(loc=0, scale=self.sigma_cauchy, size=self.dim)
            mutant += cauchy_mutation

            #Levy Flight Mutation
            levy_step = self._levy_flight(self.levy_alpha, self.dim)
            mutant += self.levy_scale * levy_step * (self.upper_bounds - self.lower_bounds)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            j_rand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    offspring[i, j] = mutant[j]

        return offspring

    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _levy_flight(self, alpha, dim):
        beta = 3 / 2
        sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1/alpha)
        sigma_v = 1
        u = np.random.normal(0, sigma_u, dim)
        v = np.random.normal(0, sigma_v, dim)
        step = u / (np.abs(v)**(1/beta))
        return step
2025-06-23 22:43:24 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1473
2025-06-23 22:43:24 INFO FeHistory: [-183.35191942 -183.32534858 -183.2906125  -183.32191946 -183.26281818
 -183.29702407 -183.26353883 -183.36429536 -183.36616105 -183.3267249
 -183.33455137 -183.34966563 -183.33051357 -183.40478691 -183.34599827
 -183.36914585 -183.501657   -183.40847559 -183.42941421 -183.32524298
 -183.3618901  -183.42264606 -183.31797523 -183.34011891 -183.35842316
 -183.32907615 -183.33042141 -183.32519676 -183.3655281  -183.3724202
 -183.41410457 -183.35968105 -183.37823936 -183.33444438 -183.32307364
 -183.30012355 -183.37376643 -183.36375731 -183.32448477 -183.36533272
 -183.32590814 -183.34505753 -183.41892053 -183.26540883 -183.45559966
 -183.34569795 -183.37214258 -183.36674396 -183.4052583  -183.25641443
 -183.29860377 -183.34661448 -183.31111854 -183.34160915 -183.32588753
 -183.35957717 -183.36078597 -183.31583923 -183.32533507 -183.30518637
 -183.33668254 -183.30650158 -183.28233492 -183.38108943 -183.32784586
 -183.34517111 -183.30500881 -183.30357406 -183.40283819 -183.4165769
 -183.3460049  -183.34680557 -183.33323408 -183.3817694  -183.36029958
 -183.33902819 -183.35746649 -183.3008194  -183.40520589 -183.35196825
 -183.42389879 -183.33243128 -183.30624784 -183.3912914  -183.356298
 -183.36802245 -183.35014604 -183.32396468 -183.33992356 -183.34649766
 -183.32895188 -183.31642695 -183.39820238 -183.37541669 -183.3119026
 -183.32110507 -183.30861217 -183.35779704 -183.2550091  -183.30782575
 -183.37998508]
2025-06-23 22:43:24 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:43:24 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithLevyFlightsAndArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithLevyFlightsAndArchive
# Description: Differential Evolution with Levy flights and an archive for enhanced exploration and exploitation in multimodal landscapes.
# Code:
class AdaptiveDEwithLevyFlightsAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []  # To store good solutions
        self.archive_size = 100
        self.levy_alpha = 1.5 #Levy flight exponent


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_parents(population, i)
                mutant = a + self.F * (b - c)
                trial = self._crossover(population[i], mutant, self.CR)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                # Levy Flight Mutation for Exploration
                levy_step = self._levy_flight(self.levy_alpha, self.dim)
                trial = trial + 0.1 * levy_step * (self.upper_bounds - self.lower_bounds)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                self._update_best(trial, trial_fitness)

            population = np.array(new_population)
            self.F = max(0.1, self.F * 0.99) #Adaptive F decay
            self.CR = min(1, self.CR + 0.001)  #Adaptive CR increase


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _select_parents(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]


    def _crossover(self, x, v, CR):
        u = np.copy(x)
        jrand = np.random.randint(self.dim)
        for j in range(self.dim):
            if np.random.rand() < CR or j == jrand:
                u[j] = v[j]
        return u

    def _levy_flight(self, alpha, dim):
        beta = 3 / 2
        sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1/alpha)
        sigma_v = 1
        u = np.random.normal(0, sigma_u, dim)
        v = np.random.normal(0, sigma_v, dim)
        step = u / (np.abs(v)**(1/beta))
        return step


    def _update_best(self, solution, fitness):
        if fitness < self.best_fitness_overall:
            self.best_fitness_overall = fitness
            self.best_solution_overall = solution

    def _update_archive(self, solution, fitness):
        self.archive.append((solution, fitness))
        self.archive.sort(key=lambda item: item[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] #Keep only top archive_size

2025-06-23 22:43:24 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:43:24 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:43:24 ERROR Can not run the algorithm
2025-06-23 22:43:24 ERROR Can not run the algorithm
2025-06-23 22:43:25 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:43:25 INFO FeHistory: [1985481.95268593 1586314.39972217 1976175.71644975 1039685.00796433
 1301738.84455571 3216333.83696635 1416983.75332026 1147842.69627567
 1810615.2679347  3713953.79220749 1087591.68242185 2043390.53566948
 2447067.21694734  763677.92433387  651331.63808508 1630926.3399142
 1252428.15122934 2388752.89932238 2437642.00278811 1874250.26424596
 1217522.20231603 1357684.76602566 4104469.71802405 1499010.61943756
  924228.87303881 2797083.70117168 4552936.29277585 3250651.54703554
  868345.54131547 1566515.62214021 2039762.78688466 2339799.18549351
 1383286.32696928 1915566.96693116  837901.93855524  868462.7500553
  581952.72454593  773231.06162928 1981994.38093788 3902633.46382484
 2596220.27300446 1302639.71663077  909321.71347178  684055.40273928
 1531692.08979361 1494963.44271246 2843340.50366934 2358138.65015005
 1113988.34638608  295932.23464462 2333370.33286105 2154764.0634203
  716026.33828813 3210328.43495244 1781209.89076975 2603273.2554067
  599873.97458936 1859606.37606912  554898.84269259 2791513.94147343
 1791248.12533316 3081366.71086147 2194423.00195294 2070444.18662247
 3029434.71600056 1715721.07092582  814466.94554396  649770.60253348
  686400.85763337 1840793.2563799  3667439.64965609 1663147.49792972
 3825643.51236274  766205.13774982 1071520.00956979 2158780.293646
 2281936.77184394 1439971.13938191 1088241.48519339 1619251.12229463
 3440909.82350351 2929559.28985197 2949530.41043175 1647605.01210783
 4225906.86919675 3149736.13541726 2029759.74906297 3582441.49552146
 3827491.3502422  2326485.43760998 1649627.73106566 1492306.59104198
 1946316.39003034 2142146.41563656  325486.22369478 1774532.41387922
 1344843.15559924 2023983.59124409 1275837.77475293 1545386.54623583
 2519532.68155164]
2025-06-23 22:43:25 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:43:25 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:43:25 INFO FeHistory: [2168254.59464788 1759125.00047073 2299589.11608791  767471.81090087
  641127.32602464  310794.79194775  629254.25773064 1256937.26994526
 2259368.35594519 1138790.86238496 5216645.63134352  348237.0639401
  572798.83844332 1751265.05527927  887899.3546376  1199903.98039112
 1682084.7127102  1660240.68870069  821931.77131679 3698243.66960827
 1193690.56410551 3259725.28073085 3934173.47202793 1706700.52602697
 1652216.47396943 2127732.30264642  989689.2582986  2196886.93725931
 2625387.17054918  641190.59234256 1111845.28614918 1302378.86083379
 2383934.67681802 1405380.18565831 1296872.66495745 2518598.04540246
 1678472.05045998  375453.82235837  847729.07500998 1184025.09404961
 1795799.97270662 2502036.11055207 1677841.21447099 3105938.90977801
  823739.3634284   638638.93340201 2573127.8156879  3503179.15698982
  920255.90267492  930465.6151246  1848957.2717375  2422645.02478604
  236416.50604268 1594566.60844968 1495629.26549907 1526208.48815478
 2526876.70221386 3363996.9078348  2898282.74169613 2202676.74301055
 1796179.92257274  581833.84473538 4135846.34260315  507491.22119116
 1281324.70074397 3350151.38166626 3275563.70346289  406649.59504734
 2550508.53428088  563455.94254277 1706323.84107095 2041860.75688824
 1599153.59070413 2290455.75473512 2805967.65283621  808463.55470207
 1051758.61941798 1752093.90943036 1186455.6967853  1127166.79480239
 1613797.22828518 3272180.34570606 2774328.02812159 1665110.23301697
 3310414.59170936 1061758.06309535 1427319.34884182 2113170.92998192
 2376150.20113483 1313077.60069904 1094891.75883053 1144233.4580458
  693349.97377347 2114821.3048766   756725.58660298 1101620.89971831
  928105.68494572 1929202.1008668  1393200.44183792 2161276.38248045
 1466799.58651304]
2025-06-23 22:43:25 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:43:25 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:43:25 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:43:25 ERROR Can not run the algorithm
2025-06-23 22:43:25 ERROR Can not run the algorithm
2025-06-23 22:43:25 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:43:25 INFO FeHistory: [229897.4524276  156599.64993593  80021.15320724 126579.04302833
 143900.67179725 132644.33988331 162710.24066014 196561.94987052
 135396.61062399 138198.75525988 182840.76515165 131964.96596897
 161895.53447988 164916.64623718 157056.31941266 124890.46201359
 149595.43864016 195386.60091739 127876.76916834 189305.3401954
  99989.62508337 107455.27662004 193509.99070247 154382.92213149
 191900.97054827 129685.35999523 173716.62457527 126336.12248194
  82685.32294947 131623.12512955 179025.49692114 105285.84646485
 144637.83518598 133851.30758565 197754.98113711 146858.74627785
 156479.46607136 154857.55560174  96675.73312286 183377.09399413
  89719.36160435 138738.45190419 124432.88263552 188086.31588142
 137250.35676926 122281.27691595 134877.56234295 117020.62319787
 186807.86027556 113036.55887397 172316.20497423 219173.84905433
 170002.22355721 156972.06350056 210305.33168388 200060.14971435
 102716.51261532 107943.25426854 137535.47151812 144734.20911073
 130000.83583471 124113.86667696 180783.03527248 116837.32505604
 225310.38598352 126895.70217056 129857.39705644 135820.08212895
 152723.48888115 133779.27349833 253605.95074165 141999.51587932
 162621.48534539 147370.64646474 175501.15756518 157186.36536087
  92726.37800476 145891.33496144  88702.87763623 197626.05547683
 164650.25114792 169672.17562289 138214.99024894 138300.3268604
 147889.11846551 126887.49255369 193791.67705947 104993.57786768
 159943.8317935  134540.96278366 172421.86724728 173105.75098474
 172099.51577793 153796.58815592  88941.04921518 125288.10054854
 154699.97899651  94094.10598049 140124.7159974  151055.8356041
 267266.71826771]
2025-06-23 22:43:25 INFO Expected Optimum FE: -5000
2025-06-23 22:43:25 INFO Unimodal AOCC mean: 0.1473
2025-06-23 22:43:25 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:43:25 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:43:25 INFO AOCC mean: 0.0491
2025-06-23 22:43:25 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:43:25 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:43:25 INFO FeHistory: [124074.58977401 127477.13364388 104932.37430276 177961.17066789
 155833.58304104 114655.64550857 141854.97388178 161919.51076674
 130778.64443476 159087.25155754 131994.76979856 119910.81882924
 131495.48146107 190695.86370364 101246.66966069 194034.25005992
 241959.5443567  134362.79958909 171842.21721894 178114.6552866
 140150.96341123 139555.08433807 164363.74199271 108976.91235851
 200419.51370167 202325.0807505  149368.21957885 154357.47612842
 137762.60170744 206107.93158782 223226.64671666 191785.95603966
 117466.1607244  107998.35106759 108629.78573134 130392.53089769
 160756.42270328 100870.39880577 148647.90120154 187625.15751088
 162735.69629467 178316.70327571 104998.32555503 202383.94487711
 126346.98818629 132717.28526286 191266.36982041 152060.70009233
 132675.76639465 141194.17454741  99078.35739755 132846.57647725
 175081.99751788 204264.31941631 140022.70938449 118505.97069623
 185327.3395928  175030.25543039 222261.14440169 129317.75317047
 140617.56056954  79601.62061661 109804.79482297  96435.39396064
 104428.76802657 133723.00821819 133626.57560509 168758.66476005
 146110.30141513 160519.70439349 196081.22554108 185137.07530582
 128641.2085272  164097.94235027 168631.4326479  110714.97478812
 122042.98125836 143091.77352581 111508.7012103  150088.07997552
 120191.36230574 165141.44966603 191661.90572939 109024.8188884
 197629.01511113 152590.67315042 107326.35323058 172643.34828137
 170511.54511232  90655.91299881 169022.15584554 144018.3655496
 141433.88549229 132222.88981478 112098.84804471 194932.1184425
  97304.8281195  105223.77843063 192247.52037325 147095.06893759
 146677.99599106]
2025-06-23 22:43:25 INFO Expected Optimum FE: -5000
2025-06-23 22:43:25 INFO Unimodal AOCC mean: 0.1469
2025-06-23 22:43:25 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:43:25 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:43:25 INFO AOCC mean: 0.0490
2025-06-23 22:43:25 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:43:34 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1607
2025-06-23 22:43:34 INFO FeHistory: [-183.36467888 -183.32266732 -183.37180112 ... -184.45698105 -184.45698105
 -184.45698105]
2025-06-23 22:43:34 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:43:34 INFO Good algorithm:
Algorithm Name: AdaptiveDECauchyArchiveTournament
import numpy as np
from scipy.stats import cauchy

class AdaptiveDECauchyArchiveTournament:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation, an archive, and tournament selection.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
2025-06-23 22:43:34 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:43:37 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1787
2025-06-23 22:43:37 INFO FeHistory: [-183.3217268  -183.35261403 -183.40023516 ... -185.51881854 -185.51880044
 -185.5181398 ]
2025-06-23 22:43:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:43:37 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyMutationAndTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutationAndTournamentSelection
# Description:Combines Differential Evolution, adaptive Cauchy mutation, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutationAndTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma_cauchy = 0.1 #Initial Cauchy scale parameter
        self.sigma_decay = 0.99
        self.tournament_size = 5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._tournament_selection(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            self.sigma_cauchy *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = self._select_parents(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Bound the mutant

            #Cauchy Mutation
            cauchy_mutation = cauchy.rvs(loc=0, scale=self.sigma_cauchy, size=self.dim)
            mutant += cauchy_mutation

            #Crossover
            j_rand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    offspring[i, j] = mutant[j]

        return offspring


    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _tournament_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        next_gen = np.empty((self.population_size, self.dim))
        next_fit = np.empty(self.population_size)

        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:43:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:43:44 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1522
2025-06-23 22:43:44 INFO FeHistory: [-183.32992085 -183.35997902 -183.31528614 ... -183.72720456 -183.80207746
 -183.76727785]
2025-06-23 22:43:44 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:43:44 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyMutationAndNiching
import numpy as np
import random

# Name: AdaptiveDEwithCauchyMutationAndNiching
# Description:Combines adaptive Differential Evolution with Cauchy mutation and a niching strategy for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyMutationAndNiching:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._niching_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= 0.99 #Adapt Cauchy scale


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_step = self._cauchy_mutation(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _cauchy_mutation(self, dim):
        return np.random.standard_cauchy(dim)

    def _niching_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        selected_population = []
        selected_fitness = []
        
        while len(selected_population) < self.population_size:
            best_index = np.argmin(combined_fitness)
            best_solution = combined_population[best_index]
            best_fitness = combined_fitness[best_index]
            
            #Niching: check for distance to existing solutions
            is_niche_occupied = False
            for sol in selected_population:
                if np.linalg.norm(best_solution - sol) < self.niche_radius:
                    is_niche_occupied = True
                    break

            if not is_niche_occupied:
                selected_population.append(best_solution)
                selected_fitness.append(best_fitness)
            
            combined_population = np.delete(combined_population, best_index, axis=0)
            combined_fitness = np.delete(combined_fitness, best_index)

        return np.array(selected_population), np.array(selected_fitness)


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]
2025-06-23 22:43:44 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:43:45 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:43:45 INFO FeHistory: [1356947.07812791  531094.99565018 1671823.56463019 ...    1788.25006034
    1788.25006034    1788.25006034]
2025-06-23 22:43:45 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:43:45 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:43:47 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1659
2025-06-23 22:43:47 INFO FeHistory: [-183.39413236 -183.35480748 -183.38273103 ... -184.99779045 -185.01418325
 -184.84519348]
2025-06-23 22:43:47 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:43:47 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Combines Differential Evolution, adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveTournament:
    """
    Differential Evolution algorithm enhanced with adaptive Cauchy mutation, 
    tournament selection, and an archive to efficiently explore multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.pop_size = 10 * dim # Dynamic population size adjustment could be added here.
        self.archive_size = 200
        self.archive = []
        self.F = 0.8
        self.CR = 0.9
        self.sigma_cauchy = 0.5 #Initial Cauchy scale parameter
        self.sigma_decay = 0.99
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.pop_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.pop_size
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.sigma_cauchy *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.pop_size, self.dim))

    def _generate_offspring(self, population):
        offspring = np.zeros((self.pop_size, self.dim))
        for i in range(self.pop_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.sigma_cauchy, size=self.dim)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = np.random.randint(0, self.dim)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                u[j] = v[j]
        return u


    def _select_different(self, index, population):
        indices = np.random.choice(len(population), 3, replace=False)
        while index in indices:
            indices = np.random.choice(len(population), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                distances = np.linalg.norm(np.array([x for x, _ in self.archive]) - self.best_solution_overall, axis=1)
                worst_index = np.argmax(distances)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.pop_size, self.dim))
        next_fit = np.zeros(self.pop_size)
        for i in range(self.pop_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

2025-06-23 22:43:47 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:43:50 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:43:50 INFO FeHistory: [2849050.08618827 2348609.99375742 2853280.63092039 ...  116124.30776321
  116086.05821615  116116.9874353 ]
2025-06-23 22:43:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:43:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:44:03 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:03 INFO FeHistory: [2189872.85088343 2420929.07735345  695597.42045123 ... 2050602.74061696
  866238.56145462 4051959.78867277]
2025-06-23 22:44:03 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:44:03 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:44:07 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:07 INFO FeHistory: [3.07259696e+05 1.41890939e+06 2.66691339e+06 ... 1.06416050e+05
 1.88655709e+03 1.19606432e+03]
2025-06-23 22:44:07 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:44:07 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:44:15 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:15 INFO FeHistory: [125702.14508757 125979.70527056 126659.00047568 ...  15427.53819908
  15427.53819908  15427.53819908]
2025-06-23 22:44:15 INFO Expected Optimum FE: -5000
2025-06-23 22:44:15 INFO Unimodal AOCC mean: 0.1607
2025-06-23 22:44:15 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:44:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:44:15 INFO AOCC mean: 0.0536
2025-06-23 22:44:16 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:44:24 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:24 INFO FeHistory: [145013.41806302 172502.90302255 148612.65647004 ...   5316.8946872
   5316.89468522   5316.89468508]
2025-06-23 22:44:24 INFO Expected Optimum FE: -5000
2025-06-23 22:44:24 INFO Unimodal AOCC mean: 0.1787
2025-06-23 22:44:24 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:44:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:44:24 INFO AOCC mean: 0.0596
2025-06-23 22:44:24 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:44:26 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1616
2025-06-23 22:44:26 INFO FeHistory: [-183.34767149 -183.35718063 -183.34239175 ... -184.52884829 -184.52884829
 -184.52884829]
2025-06-23 22:44:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:44:26 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithTournamentAndArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchive
# Description: Combines adaptive Cauchy DE, tournament selection, and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
2025-06-23 22:44:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:44:36 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:36 INFO FeHistory: [8.50829387e+05 1.60191465e+06 3.39274514e+06 ... 2.17898517e+03
 2.17898517e+03 2.17898517e+03]
2025-06-23 22:44:36 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:44:36 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:44:37 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1618
2025-06-23 22:44:37 INFO FeHistory: [-183.31237447 -183.37225048 -183.27225052 ... -184.61257043 -184.61257035
 -184.61257012]
2025-06-23 22:44:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:44:37 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyArchiveAndTournament
# Description: Combines DE, adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveAndTournament:
    """
    Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive for enhanced multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Initial population size
        self.archive_size = 200  # Archive size
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Replace worst solution in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

2025-06-23 22:44:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:44:43 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:43 INFO FeHistory: [170495.51263716 111861.18684541 104350.56970114 ...  42442.93577019
  40155.25204473  32493.60266581]
2025-06-23 22:44:43 INFO Expected Optimum FE: -5000
2025-06-23 22:44:43 INFO Unimodal AOCC mean: 0.1522
2025-06-23 22:44:43 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:44:43 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:44:43 INFO AOCC mean: 0.0507
2025-06-23 22:44:48 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:48 INFO FeHistory: [135642.87471835 167991.38959183  83973.42112523 ...   1241.99501632
   2704.53558599   1249.95396099]
2025-06-23 22:44:48 INFO Expected Optimum FE: -5000
2025-06-23 22:44:48 INFO Unimodal AOCC mean: 0.1659
2025-06-23 22:44:48 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:44:48 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:44:48 INFO AOCC mean: 0.0553
2025-06-23 22:44:50 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:44:50 INFO FeHistory: [1.70882742e+06 1.35837935e+06 3.12201784e+06 ... 1.36388749e+03
 1.36388790e+03 1.36388745e+03]
2025-06-23 22:44:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:44:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:45:07 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:45:07 INFO FeHistory: [102323.67265703 160287.88999005  92070.29263352 ...  12508.07415744
  12508.07415744  12508.07415744]
2025-06-23 22:45:07 INFO Expected Optimum FE: -5000
2025-06-23 22:45:07 INFO Unimodal AOCC mean: 0.1616
2025-06-23 22:45:07 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:45:07 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:45:07 INFO AOCC mean: 0.0539
2025-06-23 22:45:23 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:45:23 INFO FeHistory: [145189.82369962 136104.26003241 112551.46148354 ...   3836.51143302
   3836.51144249   3836.51140353]
2025-06-23 22:45:23 INFO Expected Optimum FE: -5000
2025-06-23 22:45:23 INFO Unimodal AOCC mean: 0.1618
2025-06-23 22:45:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:45:23 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:45:23 INFO AOCC mean: 0.0539
2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:46:20 ERROR Can not run the algorithm
2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:46:20 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1474
2025-06-23 22:46:20 INFO FeHistory: [-183.33770396 -183.31959462 -183.2832424  -183.39310912 -183.39618899
 -183.3418513  -183.34189554 -183.37528166 -183.28842798 -183.38837017
 -183.28743228 -183.34502035 -183.36633088 -183.36955894 -183.39639545
 -183.40022728 -183.28311785 -183.31395903 -183.31737612 -183.28140037
 -183.39210905 -183.37190839 -183.43211801 -183.32019129 -183.32175506
 -183.2937961  -183.41071183 -183.39964983 -183.42974986 -183.38353899
 -183.36154311 -183.28618124 -183.50420665 -183.25710779 -183.42115767
 -183.38279437 -183.28319119 -183.34188677 -183.39548153 -183.40031424
 -183.3228749  -183.43954479 -183.4186239  -183.31949776 -183.34004428
 -183.36678835 -183.26492677 -183.36766966 -183.31815249 -183.36363505
 -183.43512025 -183.38932635 -183.45500158 -183.25630652 -183.41718619
 -183.32511147 -183.27300594 -183.4052546  -183.38869304 -183.28847524
 -183.38663652 -183.35670856 -183.39453712 -183.35785932 -183.30144145
 -183.24747534 -183.3516564  -183.35955187 -183.43247463 -183.28751163
 -183.29803421 -183.34426338 -183.39448587 -183.40587853 -183.30302627
 -183.34805946 -183.30386144 -183.27084494 -183.33954746 -183.39678489
 -183.36366333 -183.3044647  -183.33075853 -183.33513029 -183.33731698
 -183.33854921 -183.32271135 -183.30557926 -183.32347986 -183.37142358
 -183.3846062  -183.34373505 -183.3273133  -183.35105491 -183.42520189
 -183.33657489 -183.32004885 -183.39690537 -183.33915828 -183.33555308
 -183.3316543 ]
2025-06-23 22:46:20 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:46:20 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
import random

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A Differential Evolution variant incorporating clustering to escape local optima and adaptive mutation strategies.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.archive = [] #To store good solutions
        self.cluster_threshold = 0.5 #Parameter to adjust cluster size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Clustering
            clusters = self._cluster_population(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            #Adaptive Mutation based on cluster diversity
            population, fitness_values = self._adaptive_mutation(clusters)


            # Update best solution
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            if objective_function(trial.reshape(1,-1))[0] < fitness_values[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring

    def _select_different(self, i, size):
        candidates = list(range(size))
        candidates.remove(i)
        a,b,c = random.sample(candidates, 3)
        return a,b,c

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _cluster_population(self, population, fitness_values):
        #Simple clustering based on Euclidean distance.  Could be replaced with more sophisticated methods.
        clusters = []
        for i in range(len(population)):
            assigned = False
            for j, cluster in enumerate(clusters):
                centroid = np.mean(cluster[0], axis=0)
                distance = np.linalg.norm(population[i] - centroid)
                if distance < self.cluster_threshold:
                    clusters[j][0] = np.vstack((clusters[j][0], population[i]))
                    clusters[j][1] = np.concatenate((clusters[j][1], [fitness_values[i]]))
                    assigned = True
                    break
            if not assigned:
                clusters.append([np.array([population[i]]), np.array([fitness_values[i]])])
        return clusters


    def _adaptive_mutation(self, clusters):
        new_population = []
        new_fitness = []
        for cluster in clusters:
            if len(cluster[0]) > 1:  # Only mutate clusters with more than one solution
              #Calculate cluster diversity.  Higher variance implies more exploration needed.
                diversity = np.var(cluster[0], axis=0).mean()
                mutation_scale = 0.1 + 0.5 * diversity #Adjust mutation based on cluster diversity

                #Apply mutation to cluster
                mutated_cluster = cluster[0] + np.random.normal(0, mutation_scale, size=cluster[0].shape)
                mutated_cluster = np.clip(mutated_cluster, self.lower_bounds, self.upper_bounds)
                new_population.extend(list(mutated_cluster))

                #Evaluate the mutated cluster
                new_fitness.extend(list(objective_function(mutated_cluster)))
            else:
                new_population.extend(list(cluster[0]))
                new_fitness.extend(list(cluster[1]))


        #Select best from the combined population
        combined_pop = np.array(new_population)
        combined_fit = np.array(new_fitness)
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:46:20 ERROR Can not run the algorithm
2025-06-23 22:46:20 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:46:20 INFO FeHistory: [1555873.9775556  1950157.61201861  809166.96023151 1857652.65868812
 2407989.05079669 1914424.57943716 3426014.38052886 2604079.37515192
 2109539.51525991 1220857.0622282  1295494.96414664 2777669.42489554
 5186507.66147437 1458509.77182748 1960725.98067935  955785.28032913
 1125832.83083562 4025307.31918135 1602783.22887231 1883794.23604651
  743251.3714403   887357.17730793 1271558.55954245 1272790.26331181
 1700055.61431497 2264211.7609039  2329893.90938943  987264.89136213
 1165306.24095956 1116263.61883615 3401262.63413349 1894560.07324619
  917421.14345991 1553202.04070759 2043886.35904185  839422.56765348
  821917.36958777  680819.38961542 2354946.90298945 2120716.90177096
 2129186.89956698 1663566.6792115  1571372.24459895  785010.59987002
 3596991.928702   2064558.42501587 2857661.14907683 1569823.8518622
  849791.41554084 3574836.13883384 1540836.53008413 2986266.5360247
 4368651.20300573  717644.51481912 1082223.28928973  876754.3165639
 1042588.91880221 1756202.84195377 1218326.49795753 1945043.50264603
  406356.21984077 1454101.11182835  644573.73545119 1730283.72898309
 1315779.98697736 2791696.74559362 2698358.51853554 2295145.21701354
 5330052.11133084 2771695.60873128  693827.15703864 1235039.50918368
 1411025.22670083 1618334.31488633  910926.00360688  801248.05539871
 1313771.65619796 1810162.70029705 1342941.20236193 1023654.44479331
 1083927.70746803 1907496.20041656 4706314.68791767 1790754.80614222
 1744207.89468351 3360888.56755346 1172028.21592336 1329894.47013443
 2424287.80527353 2349070.52226944 1484645.70218605 3195461.91255158
 1285995.93545143 1622734.84091518  457002.37757593 2150091.68327882
 2985772.4316196  2064845.58000944 2295130.94214103  797707.90289293
 1570746.58141959]
2025-06-23 22:46:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:46:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:46:20 ERROR Can not run the algorithm
2025-06-23 22:46:21 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:46:21 INFO FeHistory: [112131.1497557  170394.44553954 235789.6519849  156683.03810352
 111247.52921205 133406.67640308 133131.94199972 207953.33247989
 127190.2155937  160534.14674414 197536.59885143 206626.96690831
 169468.82185465 151365.23490679 105074.56721852 150671.8561142
 150837.1222105  143114.72775299 115802.26772951  82172.76566635
 191455.85979285 165789.19383774 175252.85510503 111519.31870293
  98725.54695183 108191.86230176 163400.25883793 137212.31302354
 157226.05087815 159877.5096483  162153.33919812 208387.75344902
 146654.38092445 113497.09590917 108579.96771573 147202.1981666
 159966.62027575 127120.9781923  148290.26011226 178033.76681033
 123298.69299226 137936.79505696 111970.89422922 134393.14468482
 144110.21202045 157486.10764002 155779.87406718 167600.14981415
 133410.35985486 110713.34189581 174347.38840848 160336.95028734
  70515.23416967 171315.49461233 151305.18557836 113397.14601294
 204696.39894477 116410.05095936 109656.65798782 199861.17591787
 128457.67852145 177588.77125391 115027.17784468  91717.63230283
 110790.05008848 189271.64214809 181266.26643872 147492.00649555
 100541.98287342 155244.65267858 142549.96993534 137363.64841868
 174892.37391775 103321.29099683 127378.43550569 164022.51096097
 112009.73343849 133464.68959891 129663.13643248 151539.71709788
 136880.97536649 154794.71154988  86343.96614707 167024.14524266
 156365.76332352 176859.98709317 128510.54835023 155805.0724394
 162017.58872794 128575.04684038 204769.23822634 147645.30820496
 184593.9908192  137912.23553508 128317.63639729 213117.32166503
 135130.45047751 127339.69803893 149178.45179657 160959.83452194
 135910.21533132]
2025-06-23 22:46:21 INFO Expected Optimum FE: -5000
2025-06-23 22:46:21 INFO Unimodal AOCC mean: 0.1474
2025-06-23 22:46:21 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:46:21 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:46:21 INFO AOCC mean: 0.0491
2025-06-23 22:46:21 ERROR Can not run the algorithm
2025-06-23 22:46:21 INFO Run function 6 complete. FEHistory len: 901, AOCC: 0.1479
2025-06-23 22:46:21 INFO FeHistory: [-183.40186697 -183.3705651  -183.34987557 -183.4066033  -183.35800307
 -183.30913822 -183.38964596 -183.35236731 -183.33596997 -183.36844962
 -183.35357073 -183.40603581 -183.29159486 -183.42666487 -183.3345496
 -183.31229814 -183.35362213 -183.31718375 -183.34963249 -183.38368831
 -183.36028615 -183.36577735 -183.36768867 -183.41096586 -183.40659637
 -183.39929057 -183.35074289 -183.46675252 -183.34563033 -183.3775792
 -183.29112728 -183.30656228 -183.31746238 -183.42779527 -183.40056299
 -183.37470144 -183.40779523 -183.44293231 -183.30606926 -183.37306413
 -183.3473695  -183.29866293 -183.32719418 -183.34474439 -183.36905359
 -183.35878683 -183.44615005 -183.39809128 -183.30876002 -183.28287331
 -183.33345433 -183.38132556 -183.34021342 -183.33240036 -183.28813008
 -183.36372749 -183.35795848 -183.37422489 -183.28910755 -183.36243848
 -183.29717154 -183.3413166  -183.37728072 -183.42077069 -183.30977384
 -183.38697622 -183.31395065 -183.32617073 -183.37994838 -183.34437166
 -183.31127516 -183.35388309 -183.45158062 -183.30382419 -183.3251504
 -183.36033884 -183.34233034 -183.29266653 -183.34846266 -183.30750074
 -183.37203717 -183.2939582  -183.32858807 -183.40249578 -183.35678376
 -183.4056618  -183.27253335 -183.2754004  -183.38314239 -183.29947596
 -183.29610846 -183.37028116 -183.36756876 -183.35344629 -183.29608339
 -183.31489425 -183.34393488 -183.37113369 -183.35655159 -183.41183669
 -183.34859212 -183.34314905 -183.31596772 -183.48327389 -183.32530715
 -183.30246238 -183.34425117 -183.31652334 -183.32780528 -183.30478351
 -183.32750497 -183.344535   -183.26968839 -183.38315629 -183.33601375
 -183.28552766 -183.33342171 -183.29272174 -183.31622696 -183.33980402
 -183.38292713 -183.31037194 -183.34035121 -183.38420008 -183.44904946
 -183.34743695 -183.34191865 -183.43310716 -183.3269448  -183.40016972
 -183.281237   -183.28289684 -183.30277887 -183.37207668 -183.36309698
 -183.32728874 -183.39910651 -183.34379658 -183.27694609 -183.33893285
 -183.36055077 -183.30014384 -183.32581116 -183.33872332 -183.34984263
 -183.36326364 -183.39220532 -183.38309035 -183.26236666 -183.31809639
 -183.35787612 -183.41800299 -183.35686349 -183.33247265 -183.30881971
 -183.32241305 -183.30372773 -183.39694914 -183.25568173 -183.31631762
 -183.31314288 -183.36186467 -183.36788347 -183.40555242 -183.3383925
 -183.36863424 -183.27123244 -183.33971333 -183.37085817 -183.34236867
 -183.28698479 -183.37089934 -183.41645987 -183.26712252 -183.29898442
 -183.32387805 -183.29676474 -183.27466544 -183.29882704 -183.38503026
 -183.29450555 -183.29051585 -183.31062361 -183.38236857 -183.3531755
 -183.3918466  -183.33651028 -183.250231   -183.35715634 -183.30506245
 -183.29388502 -183.34464588 -183.30949044 -183.39678036 -183.27826501
 -183.29334046 -183.31504828 -183.36259983 -183.33772535 -183.36177804
 -183.3262792  -183.43939113 -183.4191847  -183.40568838 -183.39324749
 -183.41723628 -183.40949814 -183.38631089 -183.36367041 -183.54358753
 -183.35824095 -183.51906067 -183.36853042 -183.35258148 -183.40206232
 -183.33364517 -183.4451661  -183.38778691 -183.34770136 -183.38852832
 -183.40828542 -183.36286655 -183.41182074 -183.35608328 -183.30620467
 -183.3919     -183.35815976 -183.34781111 -183.39724095 -183.39328754
 -183.36772776 -183.36065084 -183.39167788 -183.31445627 -183.34160563
 -183.33906266 -183.34692141 -183.3614576  -183.34174341 -183.35884306
 -183.38572634 -183.3806475  -183.31032411 -183.33546715 -183.35677951
 -183.37642209 -183.40374123 -183.3632678  -183.43131773 -183.35204397
 -183.37018303 -183.34212266 -183.32996974 -183.31651573 -183.37024757
 -183.30696624 -183.33035829 -183.36572271 -183.33173682 -183.3745826
 -183.33114714 -183.34609856 -183.38865968 -183.34091047 -183.29889421
 -183.33694285 -183.34101275 -183.34439354 -183.37589474 -183.38473337
 -183.31388729 -183.34886132 -183.3547655  -183.32278804 -183.3335469
 -183.28643765 -183.31708612 -183.36951606 -183.31937995 -183.30580207
 -183.3528871  -183.30975383 -183.32512033 -183.34991782 -183.33331859
 -183.34784246 -183.30689495 -183.34275371 -183.29234871 -183.3312371
 -183.35434655 -183.39499244 -183.29628852 -183.35178522 -183.29785172
 -183.31702133 -183.34670542 -183.38925411 -183.32774763 -183.34158902
 -183.35704483 -183.50630312 -183.45947137 -183.43610701 -183.42475246
 -183.4281402  -183.40050898 -183.37718826 -183.36158924 -183.39762108
 -183.3900451  -183.3814538  -183.34597354 -183.34546958 -183.39947062
 -183.35419973 -183.38507194 -183.35294674 -183.34452726 -183.39309818
 -183.30083182 -183.35757713 -183.35486034 -183.35146501 -183.38132592
 -183.38719696 -183.35877958 -183.42056105 -183.37827313 -183.33460567
 -183.32377209 -183.33903603 -183.34266486 -183.34060809 -183.35169493
 -183.31296144 -183.33463108 -183.3486672  -183.36074474 -183.34335425
 -183.38501622 -183.38201923 -183.35559819 -183.35030547 -183.35470233
 -183.39310943 -183.3233113  -183.41619644 -183.3334705  -183.37245113
 -183.33139272 -183.3479618  -183.29341654 -183.35185294 -183.35784863
 -183.37400453 -183.3332597  -183.33008311 -183.3145864  -183.35460759
 -183.37047607 -183.31770766 -183.3162529  -183.34110929 -183.33968506
 -183.33852828 -183.35907539 -183.34242149 -183.39553371 -183.31799448
 -183.35133996 -183.30373059 -183.34217995 -183.27122527 -183.33741652
 -183.35401147 -183.33043966 -183.29560625 -183.34110479 -183.32269751
 -183.33184735 -183.32688114 -183.29959058 -183.33417383 -183.30431197
 -183.3102651  -183.33867527 -183.32548443 -183.29890147 -183.30119991
 -183.30126612 -183.28187082 -183.34039074 -183.31677627 -183.31824711
 -183.28054219 -183.28690429 -183.30853972 -183.37681965 -183.27602196
 -183.30359677 -183.43149733 -183.41364712 -183.41272835 -183.48010601
 -183.39835242 -183.31836453 -183.35346903 -183.42677929 -183.34621764
 -183.41144093 -183.41152103 -183.37367781 -183.34615462 -183.33243468
 -183.37106875 -183.38753273 -183.37587965 -183.4120798  -183.40073512
 -183.40219936 -183.39305414 -183.42156931 -183.34033798 -183.39558708
 -183.36664302 -183.42023618 -183.31153077 -183.36455131 -183.31904047
 -183.39762998 -183.33926712 -183.32287715 -183.37008847 -183.33044949
 -183.36888742 -183.34384519 -183.34104013 -183.30969486 -183.3554739
 -183.3384596  -183.33798369 -183.35846879 -183.37870402 -183.33220577
 -183.31739387 -183.34007065 -183.26676314 -183.32248465 -183.35192451
 -183.33049519 -183.30084235 -183.32456372 -183.3474156  -183.33068311
 -183.30674578 -183.30632755 -183.33631667 -183.31959648 -183.3270773
 -183.35872105 -183.34152808 -183.39425968 -183.34307226 -183.32785324
 -183.31219967 -183.34570107 -183.34929277 -183.37883082 -183.32122925
 -183.33886281 -183.27680611 -183.32454626 -183.33764683 -183.32275415
 -183.28268265 -183.30637262 -183.30424409 -183.32078675 -183.3671335
 -183.30028151 -183.31798216 -183.31476673 -183.320304   -183.30782385
 -183.29935541 -183.34994027 -183.33086751 -183.27954203 -183.31816041
 -183.32961004 -183.27509408 -183.28185943 -183.26668986 -183.30040561
 -183.28274724 -183.25928486 -183.26145186 -183.27798796 -183.27671603
 -183.31473059 -183.36535703 -183.38183553 -183.41356934 -183.41317112
 -183.39109665 -183.39295213 -183.37817092 -183.36765684 -183.35357207
 -183.39272905 -183.36519033 -183.43557147 -183.36906173 -183.41084069
 -183.3372769  -183.38091058 -183.34982787 -183.34834158 -183.35462877
 -183.35666905 -183.34140886 -183.34547662 -183.33999629 -183.31681735
 -183.38652307 -183.34935442 -183.3618893  -183.35973897 -183.30963945
 -183.35960658 -183.32672282 -183.34001237 -183.35507702 -183.30881485
 -183.37021527 -183.34996599 -183.29607098 -183.37828639 -183.33712737
 -183.36280305 -183.28983936 -183.37502376 -183.36628902 -183.34407023
 -183.36572677 -183.34448717 -183.36528106 -183.35406132 -183.32930998
 -183.38432721 -183.34671488 -183.35832648 -183.31774389 -183.33699446
 -183.303888   -183.36469189 -183.34895467 -183.28079978 -183.31537382
 -183.34822729 -183.36627883 -183.33669561 -183.33315961 -183.31353189
 -183.33429036 -183.36723809 -183.32696275 -183.27207071 -183.35963717
 -183.2815758  -183.35802151 -183.3899313  -183.27701716 -183.28711299
 -183.30149291 -183.3249177  -183.32498322 -183.31008628 -183.29904451
 -183.2831681  -183.29522327 -183.28387274 -183.33542591 -183.30998567
 -183.23493735 -183.26348962 -183.30373245 -183.27840668 -183.27788701
 -183.27800397 -183.30662137 -183.30583927 -183.27161204 -183.30061815
 -183.23776638 -183.29032422 -183.26726517 -183.31929726 -183.23635357
 -183.23704599 -183.40488647 -183.41223145 -183.39107021 -183.40582855
 -183.39367689 -183.32049311 -183.40121283 -183.34433766 -183.3239595
 -183.32293815 -183.40895438 -183.39966466 -183.36096576 -183.37770187
 -183.37637453 -183.3396129  -183.36848913 -183.3391447  -183.35195373
 -183.36456146 -183.33308421 -183.33279761 -183.39143712 -183.35118797
 -183.34566352 -183.36788076 -183.38718959 -183.36683252 -183.39315141
 -183.32767258 -183.34303129 -183.31938644 -183.29632594 -183.35764015
 -183.34655131 -183.33012484 -183.33930651 -183.3396476  -183.34391841
 -183.38241643 -183.32163559 -183.33318097 -183.31408183 -183.37414791
 -183.35363232 -183.39936689 -183.32107998 -183.34659037 -183.32941438
 -183.30313728 -183.29855117 -183.35450481 -183.31986347 -183.33428466
 -183.35333505 -183.36041924 -183.29384527 -183.3098873  -183.30769557
 -183.31818268 -183.30235786 -183.3322287  -183.30071341 -183.2873008
 -183.38722391 -183.3144568  -183.34836785 -183.33222683 -183.30749288
 -183.33679129 -183.36325545 -183.3040808  -183.31988029 -183.312448
 -183.33553856 -183.29898249 -183.32062933 -183.32889054 -183.27964988
 -183.29125415 -183.30118622 -183.27026808 -183.32786123 -183.3273836
 -183.33036592 -183.29682187 -183.27198451 -183.31556287 -183.26560275
 -183.30585775 -183.28564013 -183.26470068 -183.27802687 -183.23927258
 -183.31513835 -183.25384249 -183.26033107 -183.23950492 -183.22755562
 -183.24663841 -183.34776783 -183.41523667 -183.37320072 -183.40224966
 -183.36857142 -183.41403001 -183.40712603 -183.38500794 -183.41614803
 -183.3491245  -183.36508252 -183.38637763 -183.34182541 -183.36412781
 -183.4020154  -183.31660861 -183.41042391 -183.39490685 -183.32720919
 -183.35052205 -183.40540723 -183.34879947 -183.3734075  -183.35709499
 -183.32565452 -183.35414695 -183.31941395 -183.3426621  -183.36304386
 -183.34008513 -183.35523391 -183.3520215  -183.39148225 -183.29016243
 -183.29675788 -183.36542083 -183.39144194 -183.29455354 -183.3184477
 -183.35201652 -183.32229254 -183.36068661 -183.3190681  -183.35183879
 -183.34725231 -183.29865983 -183.298584   -183.28541984 -183.36523238
 -183.30223816 -183.28749107 -183.39171175 -183.34577563 -183.35833584
 -183.34204821 -183.34591399 -183.28275256 -183.32924168 -183.31102432
 -183.32038941 -183.33890539 -183.3101651  -183.33042852 -183.33755568
 -183.34752297 -183.28740115 -183.34143449 -183.29624935 -183.28239204
 -183.35098826 -183.29367098 -183.2997908  -183.32770056 -183.28096334
 -183.32394001 -183.2732995  -183.30803143 -183.30559392 -183.30420087
 -183.31805526 -183.30203865 -183.28139258 -183.31580594 -183.2777149
 -183.29938258 -183.3040418  -183.31309662 -183.31455897 -183.31472817
 -183.28029675 -183.2848981  -183.29134902 -183.28002111 -183.30394373
 -183.27306337 -183.29588843 -183.27164586 -183.30941437 -183.23102596
 -183.22711879 -183.39377924 -183.39544164 -183.40709219 -183.40670327
 -183.37338917 -183.36800576 -183.39705875 -183.43397922 -183.40084481
 -183.3706808  -183.37991866 -183.34988083 -183.4188055  -183.36480151
 -183.37669209 -183.35036782 -183.36711686 -183.40341233 -183.40049523
 -183.39892666 -183.33553666 -183.32763016 -183.33229032 -183.41324204
 -183.30527965 -183.34142561 -183.37191188 -183.38011376 -183.32588665
 -183.32693958 -183.32813988 -183.34883109 -183.37784966 -183.35447829
 -183.39633211 -183.31473958 -183.32635289 -183.28552553 -183.35008796
 -183.33976809 -183.31962419 -183.31422344 -183.38411273 -183.3643081
 -183.3116401  -183.3209115  -183.35331743 -183.37597236 -183.35051575
 -183.36856795 -183.33059511 -183.32007204 -183.32906176 -183.32227763
 -183.31748639 -183.32795624 -183.33389912 -183.35368062 -183.30606524
 -183.31045959 -183.34184677 -183.32339349 -183.31018569 -183.32948294
 -183.30194201 -183.3377303  -183.37034518 -183.29066482 -183.33549961
 -183.38212732 -183.32626151 -183.30632527 -183.34098311 -183.29039645
 -183.3091105  -183.31132627 -183.33267311 -183.28621914 -183.26020795
 -183.30396309 -183.29219858 -183.2857472  -183.31655445 -183.26624812
 -183.2787737  -183.2641408  -183.30523703 -183.30982855 -183.30095318
 -183.25947699 -183.29980259 -183.26834836 -183.29069755 -183.23228371
 -183.25485241 -183.33186149 -183.30911041 -183.31557386 -183.24501095
 -183.2317177 ]
2025-06-23 22:46:21 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:46:21 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveMultimodalEA
# Description: An evolutionary algorithm using adaptive mutation, niching, and a multi-stage exploration strategy for multimodal landscapes.
# Code:
class AdaptiveMultimodalEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.niche_radius = 0.5*(np.max(self.upper_bounds) - np.min(self.lower_bounds)) #Initial niche radius. Adapts later
        self.archive = [] # Archive of good solutions to promote diversity
        self.exploration_stage = 1 # 1: Global exploration, 2: Local refinement


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._environmental_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adaptive_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            parent = population[i]
            if self.exploration_stage == 1:  #Global exploration
                offspring.append(parent + np.random.normal(0, self.sigma, self.dim))
            else: #Local Refinement: Cauchy mutation for wider exploration
                 offspring.append(parent + cauchy.rvs(loc=0, scale=self.sigma, size=self.dim))

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _environmental_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        #Niching: only select solutions sufficiently far from existing solutions in archive
        selected_pop = []
        selected_fit = []
        for i in range(len(combined_pop)):
            is_unique = True
            for sol in self.archive:
                if np.linalg.norm(combined_pop[i] - sol) < self.niche_radius:
                    is_unique = False
                    break
            if is_unique:
                selected_pop.append(combined_pop[i])
                selected_fit.append(combined_fit[i])

        #Tournament selection among unique solutions
        sorted_indices = np.argsort(selected_fit)
        next_gen = np.array(selected_pop)[sorted_indices[:self.population_size]]
        next_fit = np.array(selected_fit)[sorted_indices[:self.population_size]]
        self.archive.extend(next_gen)
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adaptive_parameters(self):
        self.sigma *= self.sigma_decay
        #Adapt exploration stage based on progress.
        if self.eval_count > self.budget*0.7 and self.exploration_stage ==1:
             self.exploration_stage = 2
             self.niche_radius *= 0.5 #Reduce niche radius for finer local search


2025-06-23 22:46:21 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:46:22 ERROR Can not run the algorithm
2025-06-23 22:46:23 INFO Run function 13 complete. FEHistory len: 1001, AOCC: 0.0000
2025-06-23 22:46:23 INFO FeHistory: [1651472.2324864  1232438.49108782 1836779.25064221 ...  800078.19817621
 1486525.69709072 1926864.42182432]
2025-06-23 22:46:23 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:46:23 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:46:23 ERROR Can not run the algorithm
2025-06-23 22:46:24 INFO Run function 18 complete. FEHistory len: 801, AOCC: 0.0000
2025-06-23 22:46:24 INFO FeHistory: [140275.31671504 171693.64062009 150612.15922334 143733.05690992
 144461.00979542 136683.08809189 135674.4999386  143779.84635237
 165821.13611065 139894.26800283 184511.0413414  151857.44019463
 149735.34133388 185898.36886757 148711.67417487 155292.7269407
 178036.96414886 115840.47070102 169582.49483672 142895.17626101
 185753.74350151 151292.16899165 138171.39766982 157261.87733449
 174849.2075594  178309.04653093 103974.20526879 168872.15289962
 150172.74966612 130727.02910159 137293.47909727 123480.40043992
 130343.73868607 136388.82349138 179498.3313525  185354.26835444
  86410.59141203 100896.6495883  109617.8361592   96536.82449588
 175278.68402888 154546.63622693 128973.17494138 156574.1883426
 153745.05742626 111477.38525568 114500.22631687 112472.51067856
 300058.7786121  128560.15119077 131526.08888995 140846.96208774
 124859.80676154 202253.43996335 145479.20847203 170412.62099277
 141932.29873752 134101.33696371 171646.89794839 140917.44834222
 117348.91335404 173285.17277046  85365.22136747  99970.24181553
 205446.00006083 209504.20201309 221037.41265612 146251.5256435
 170642.90402662 179648.89819811 137414.6083216  113229.50697659
 126751.47553144 146381.31991513 229128.94267673  97466.37588231
 155278.06484597 126059.23705807 106726.63935488 247286.45445322
 167070.14708578 259065.43728163 118444.85656998 138811.29562588
 143586.30334011 137450.43696682 145057.48782743 145822.14612998
 157859.18508371 134561.66134611 162671.94754735 133848.27800901
 181028.62045264 246686.25633137 109231.7393146  138811.50643763
 143066.06580664 137839.26108618 203488.20478    252161.07726292
 155644.69624772 138356.64869959 161565.53817526 152481.68776938
 140528.86782763 136493.4421958  203437.74414322 133042.60878629
 154670.55714525 165400.29505374 194163.69617778 121386.5965171
 209969.46715958 256473.45549283 204067.85719907 177436.27874361
 154154.08714554 126040.19139165 213465.99963066 231240.52731783
 219787.63517451 230880.16245246 199742.39380337 123999.47923517
 151993.34991139 211129.44239289 105172.49389368 241168.92049989
 155769.29338499 140008.35768789 150158.03187471 170736.83093527
 159099.16023214 228521.84566185 162205.50292734 141333.93823908
 173817.46334943 183490.58675492 104704.56002681  93453.01354054
 185468.31513434 169507.20330449 133609.61820469 127545.72486701
 157611.64108697 123905.63387417 147921.25275749 134001.0665652
 164410.70253207 166454.05090655 235282.84102882 100621.25364649
 178484.01680933 196767.29360642 149592.06459921 195922.11192889
 193264.85281249 247550.5988607  164828.23322931 194376.49716631
 183910.98484288 203841.82509722 146794.50562301 108121.40461794
 206078.85930949 190414.3372117  177709.35727656 161799.1959538
 192329.79671817 153969.12986268 188909.28055167 148758.09683078
 182921.16623615 242074.56797413 254867.7257495  148071.85921124
 186086.36379095 141124.73175297 154703.01967167 221832.14637572
 216591.14091789 270639.3103433  237626.73274686 113719.25174656
 127863.92606473 182290.04454919 140880.30625446 172135.6503709
 171504.37772169 143062.88390574 186480.30414155 155869.98724101
 181457.22191463 141299.01816568 168050.97321913 168166.11979841
 186057.24389654 256945.03600684 218214.65918106 217298.61108726
 129897.35647366 178814.76107884 104850.90712789 119326.47330821
 117574.15246115 146996.16202389  96674.86207655 136915.68690086
 154092.34515802 158045.00632973 192214.31448987 192938.53052047
 105782.79139514 121278.94494372 118253.51997619 168167.80725877
 161569.61804176 162664.33854699 197696.3269763  111162.89737427
 158479.00671458 127585.46150937 104776.25542577 172719.99096183
 157363.39068329 189347.17982039 172868.42928838 135137.43356213
 157116.80336327 194614.60179952 178723.24034621 168628.6799533
 138372.78561899 190750.26286271 107583.03727277  98097.11259695
 134689.552376   150232.45864117 194331.7964793  235770.5325069
 142937.9136368  143776.89158825 139671.37874113 162684.19800833
 162436.62353756 125952.00300132 170446.84295439 181883.16923045
 148153.21103325 181129.52651899 236395.33174482 179169.4265613
 145636.03977172 199559.48784252 189280.90677501 230483.95582787
 164431.04753101 150384.82815497 125763.06775305 131480.60917838
 137909.63087442  94368.79812146 159485.12301205 138058.45388746
 149931.21858975 181666.08564959 166228.45360983 158659.86722796
 139710.57531152 148250.46994741 228141.74381468 138808.70803441
 168242.43017468 190458.1466172  200960.7253023  120768.37022832
 164143.12420985 135845.34306692 204527.31830064 197070.82520286
 192521.54839945 163243.27381814 166245.39482821 217910.78990418
 134685.97042219 230443.02985827 225366.81505058 209499.16914659
 146332.21583494 148079.38478467 122223.83393959 254232.5291668
 166552.19174186 141500.89734658 124414.93884653 155557.20954405
 117382.70823883 186454.88767254 127801.20627068 110363.21942305
 251445.48155793 155477.51855765 177671.67721586 134001.72778915
 188194.59095104 118333.90370471 122371.32093881 142228.16537765
 138926.00872377 234729.30303743 144675.25040266 131926.16518448
 130999.16165186 194042.19499149 165864.74842764 125523.58025583
 105651.79011161 154273.67898032 171333.26871903 170591.20259423
 108029.66039149 178481.37275044 169596.34167269 231231.19979783
 171347.86506011 157107.17090193 169174.44764615 245810.89792506
 143983.67561461 159114.38300139 140294.30567038 156852.45920037
 178626.80161531 134226.27943453 143853.71605338 200283.1410155
 165275.46834794 165252.93409433 190829.44587611 113306.65035722
 207028.50539653 206849.51782169 161007.85715094 278508.18035133
 162000.12085305 221651.33838514 231263.34247493 220229.00177826
 169655.25068756 153650.17420015 148534.75685433 114532.35529199
 237698.57202039 179030.35995346 142847.94582149 181183.80432178
 128155.61560492 220559.84789249 139864.48556697 172938.8634707
 153777.92451699 203196.60275248 145911.02141271 161053.44034922
 132136.73349591  84104.8486211  249505.47504332 141636.12758756
 206980.87053381 192735.40913561 189010.76215489 221183.87808439
 188795.94756745 246070.21027643 236663.29387399 143257.12736883
 233126.26187391 211926.11500581 128571.73464683 157742.69581335
 202943.85131419 187921.57931512 183653.97407232 141489.1847059
 146395.96749622 156576.06563724 195137.61635472 172316.88595551
 247516.45123994 179315.23474883 239665.07341354 257465.1456199
 183227.9790909  219291.157203   166826.86779848 217707.77001793
 167280.79553643 169164.22860566 348320.52139287 235171.20061446
 151282.79140976 118840.20811288 137050.84343116 180501.77323533
 107311.79266195  95941.53827255  96445.00215384 112518.14984889
 108794.00643494 156023.42953496 153479.56455723 163321.27745021
 201596.52194107 158188.55072491 182356.30192689 207623.28743496
 132808.66159829 199299.88898207 264446.85065928 187237.87362907
 176358.71882413 152869.08458348 190096.98523823 233189.42182661
 212722.80661679 242738.39678888 139119.9931543  139471.19741454
 178391.02308603 172698.03729456 251800.418517   156480.58144469
 153254.08599773 198395.32667532 174726.05595672 196637.86110818
 160201.10681085 202081.43957678 212772.50842527 164467.62170215
 270915.75090565 203813.13680412 109109.90490232 177805.22608739
  92186.51807792 142857.87502167 232618.21955517 128931.3388371
 162710.16580678 206780.8001891  230117.02434516 108682.41459322
 161455.68052336 177851.14492485 225011.1963912  213682.98704508
 172173.92671659 157000.29135739 173683.72077228 160434.84068055
 153393.13452203 304223.12805574 201324.58972616 236032.58181623
 239636.96266244 211982.73547759 125777.89527889 220533.25140201
 179518.95449977 151942.99495593 204156.03237875 196998.76222777
 198037.02318484 223560.3513847  181728.52875315 277098.89860859
 196997.92315907 278982.45425704 211277.6767838  147932.05145341
 197526.75327758 271701.5346376  168898.03344472 169274.323868
 168389.53958021 249753.37078149 195454.00276369 128729.72971834
 268980.30227719 204704.03879081 205366.78106358 217511.21923787
 181258.63015692 171463.07731376 143226.86075224 231987.87887303
 160956.83310707 189485.21626346 175035.32587083 123133.19712517
 221044.0094029  213277.48753016 181822.87640801 119154.21498402
 113338.8618631  215597.36869239 117186.49923571 153819.54516934
 184003.39758836 123584.00189204 175659.63076821 196527.62202833
 199755.14302278 164956.4598626  160154.69982929 153000.92580665
 127779.64232525 141952.76756526 133315.73120825 133554.56309941
  99911.93402368 136860.60011115 134703.55201179 159917.17947761
 222518.08024391 170982.00180391 156140.5763172  161015.88614725
 166041.13464827  95013.66719855  74445.20520971 134456.03750442
 273209.97705368 138458.10019256 123429.37232323 210654.91380641
 206933.75574189 177141.8351555  220896.41419413 179267.0324722
 195602.77227308 187183.34270641 192560.18165215 165725.90867779
 196766.00914949 200173.84481109 252998.69652745 154532.5299562
 161537.70812944 212263.95985465 216572.14316841 188340.31373483
 243874.47191279 235598.35221604 148728.39319261 207724.39187225
 198839.00918952 152312.54416871 150261.8103298  174198.68027412
 221861.83672554 185435.74767513 259455.8690198  133556.70622246
 194623.18152605 147012.29262526 211462.9417415  144339.87496282
 175038.54718345 149663.27556759 150371.30600861 209604.49170527
 136743.78448206 154112.51901652 192849.42167167 204403.19403841
 204154.71131093 139392.24775412 155713.81343396 166494.79326462
 198606.32910642 125154.82876374 174806.97335523 190785.76603609
 210929.37449603 269803.53766204 206299.37158913 268056.57044892
 133985.36600173 144646.01277915 197846.25492523 135814.36659188
 182920.56052202 177881.49769134 206238.67854654 146768.38667804
 172614.28903883 163366.68075221 177222.11073451 326055.93307811
 190458.34136082 173984.16648888 106364.34280999 167510.52256607
  93000.9416563  156572.98566    217473.79610892 124596.7512121
 176407.1855975  151149.46566208 153488.50267018 137139.08723717
 108760.48024337 183185.35180351 197812.67563258 128427.29412329
 127165.49459905 219611.82694354 192440.52095696 178341.96369136
  75083.44721414 248132.75867759 160655.61808534 170954.90477301
 165740.69954167 191943.61237006 267676.31747981 162553.43303016
 155054.36412464 211799.69159938 147279.50591126 143469.9439122
 190771.63687227 195283.60892147 153166.99894148 196814.22498822
 173883.19435858 178490.19777886 166163.37708516 213027.67265679
 153499.67788368 180908.04427283 224713.76507177 172883.76146171
 151916.41140442 179357.22065954 139472.13100497 121664.31451607
 184450.98077204 237165.4880951  271611.57979548 210542.43490963
 154971.20558194 150583.89782677 190331.61184397 202438.90825407
 193150.01805998 196569.03061654 222433.79197473 151793.9366812
 148748.37701771 174943.48491048 115082.33730767 170203.13931254
 252123.81264508 210602.09872716 163601.29948703 201391.64225455
 182650.40948146 132948.21197494 168869.01170861 163099.43270605
 232463.71831671 154016.00179387 129183.72999073 230430.15024853
 209563.44007689 195922.2100146  216508.25356399 149422.7899786
 129431.42835944 179147.56481808 216568.56997128 175161.45618353
 152183.15111188 236782.91391055 210610.77731287 113272.95686414
 171571.5088509  174845.62284728 207240.88537174 206186.18098448
 118853.62526296 192873.41206086 202487.75010338 216132.43536891
 245847.67092365 243163.43583127 244709.96229443 150673.64699662
 224071.92526867 113441.47618202 101637.52918936  97986.67389954
 126706.40516505 155895.64449028 136516.88374338 122942.56967776
 114344.86802213 140387.26468389 174099.98815339 167478.08799666
 144196.30429    174657.0412565  131701.58049891 112279.71522471
 217616.91599122 151017.4368971  159762.40120512 162355.92160439
 209775.22901899 175882.41362154 188339.89916508 180936.9906703
 183849.74743813 233972.76769299 159746.03254464 153230.22645996
 125112.26394396 123921.83504281 225334.92907266 202589.083421
 187923.66811914 165163.85099635  87483.78640966 227469.30899929
 196099.6845305  180774.93654309 132715.67128078 156935.42590855
 134877.75632887 134313.67010384 148986.96684249 167522.43699341
 180401.33508406 247511.21794167 118069.11877866 142600.90060261
 212491.34026643 221754.6956717  182344.92155826 120975.84422236
 136311.39900572 270209.61941092 142619.7907028  161848.75550912
 256262.24479229 137578.08921153 159919.05676378 197998.30422699
 182305.9763665  230854.92217173 191821.09554916 186283.76939694
 300916.72235953 282733.84370523 262348.28958369 241192.9530898
 296911.88010678 184298.98747302 204205.80352042 204053.27146131
 169081.55356974 184503.60243342 171065.8745837  185307.2093685
 132395.88213952 180374.11484863 192957.93012203 175316.11830022
 170339.18953062 213952.19202185 236471.9618572  216831.08855976
 133346.6057076  156986.60483186 195227.51053779 215023.11426649
 192443.22470466 215250.16851057 191324.30050229 271804.88611694
 169101.73348837 273220.03420646 265598.61295437 211322.0704207
 211776.26788115 240022.30881426 134017.61249051 217713.68219154
 206388.35518219]
2025-06-23 22:46:24 INFO Expected Optimum FE: -5000
2025-06-23 22:46:24 INFO Unimodal AOCC mean: 0.1479
2025-06-23 22:46:24 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:46:24 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:46:24 INFO AOCC mean: 0.0493
2025-06-23 22:46:31 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1605
2025-06-23 22:46:31 INFO FeHistory: [-183.4054734  -183.42969392 -183.30394483 ... -184.67705967 -184.66126475
 -183.97406472]
2025-06-23 22:46:31 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:46:31 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A differential evolution algorithm enhanced with adaptive mutation and clustering to escape local optima in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.archive = []  # Archive of good solutions
        self.cluster_threshold = 0.1 #parameter for clustering

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            self._adaptive_parameter_tuning(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Differential Mutation
            a, b, c = self._select_differents(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            #Cauchy Mutation for exploration
            offspring[i] += cauchy.rvs(loc=0, scale=0.1, size=self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring


    def _select_differents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]


    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]


    def _update_archive(self, offspring, offspring_fitness):
        for i, solution in enumerate(offspring):
          self.archive.append((solution, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:int(self.population_size * 0.2)]

    def _adaptive_parameter_tuning(self, population, fitness_values):
        #Adjust F and CR based on convergence and diversity
        mean_fitness = np.mean(fitness_values)
        std_fitness = np.std(fitness_values)
        if std_fitness < 0.1 * (self.upper_bounds[0] - self.lower_bounds[0]): # Low diversity
            self.F *= 1.1 # increase exploration
            self.CR *= 0.9 # reduce exploitation
        else:
            self.F *= 0.9
            self.CR *= 1.1



2025-06-23 22:46:31 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:46:43 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:46:43 INFO FeHistory: [1797985.39066122 2416655.18542397  248386.18235175 ...   14946.4347676
  158849.78079831   73887.85705762]
2025-06-23 22:46:43 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:46:43 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:47:03 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1694
2025-06-23 22:47:03 INFO FeHistory: [-183.35149918 -183.35350395 -183.399272   ... -185.55318039 -185.54371924
 -185.55389214]
2025-06-23 22:47:03 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:47:03 INFO Good algorithm:
Algorithm Name: AdaptiveMultimodalOptimizer
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveMultimodalOptimizer
# Description: An evolutionary algorithm using adaptive mutation, niching, and a dynamic exploration-exploitation balance for multimodal optimization.
# Code:
class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99
        self.niche_radius = 0.5  # Initial niche radius
        self.exploration_rate = 0.2 #Initial exploration rate
        self.archive = [] # maintain an archive of good solutions


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._update_niche_radius() # Adapt niche radius dynamically
            self.sigma *= self.sigma_decay
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:  # Exploration
                offspring.append(self._generate_exploratory_solution())
            else: # Exploitation
                parent = self._tournament_selection(population, fitness_values)
                child = self._mutate(parent)
                offspring.append(child)
        return np.array(offspring)

    def _tournament_selection(self, population, fitness_values, tournament_size=5):
        tournament = np.random.choice(len(population), tournament_size, replace=False)
        winner_index = tournament[np.argmin(fitness_values[tournament])]
        return population[winner_index]
    

    def _mutate(self, parent):
      child = parent + np.random.normal(0, self.sigma, self.dim)
      child = np.clip(child, self.lower_bounds, self.upper_bounds)
      return child


    def _generate_exploratory_solution(self):
        # Cauchy mutation for exploration
        solution = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim) + cauchy.rvs(loc=0, scale=10, size=self.dim)
        return np.clip(solution, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        #Niching
        unique_pop, unique_fit = self._apply_niching(combined_pop, combined_fit)
        
        sorted_indices = np.argsort(unique_fit)
        next_gen = unique_pop[sorted_indices[:self.population_size]]
        next_fit = unique_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _apply_niching(self, population, fitness_values):
        unique_population = []
        unique_fitness = []
        for i, sol in enumerate(population):
            is_unique = True
            for j, existing_sol in enumerate(unique_population):
                if np.linalg.norm(sol - existing_sol) < self.niche_radius:
                    is_unique = False
                    break
            if is_unique:
                unique_population.append(sol)
                unique_fitness.append(fitness_values[i])
        return np.array(unique_population), np.array(unique_fitness)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
                self.archive.append((offspring[i], fitness))

    def _update_niche_radius(self):
      #Reduce niche radius over time to allow finer grained exploitation
      self.niche_radius *= 0.99
      self.exploration_rate *=0.999 # Reduce exploration rate over time

2025-06-23 22:47:03 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:47:15 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:47:15 INFO FeHistory: [181506.59153564 116717.67447377 217242.7826212  ...  13480.16934923
   3140.03723207   5120.18662516]
2025-06-23 22:47:15 INFO Expected Optimum FE: -5000
2025-06-23 22:47:15 INFO Unimodal AOCC mean: 0.1605
2025-06-23 22:47:15 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:47:15 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:47:15 INFO AOCC mean: 0.0535
2025-06-23 22:47:46 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:47:46 INFO FeHistory: [1.25367651e+06 1.88827031e+06 1.23227250e+06 ... 1.29196917e+03
 1.29197173e+03 1.29196914e+03]
2025-06-23 22:47:46 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:47:46 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:48:49 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:48:49 INFO FeHistory: [146135.27378022 178347.60316554 192453.00089146 ...  -4399.89924704
  -4399.89945743  -4399.89938898]
2025-06-23 22:48:49 INFO Expected Optimum FE: -5000
2025-06-23 22:48:49 INFO Unimodal AOCC mean: 0.1694
2025-06-23 22:48:49 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:48:49 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:48:49 INFO AOCC mean: 0.0565
2025-06-23 22:50:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:53 ERROR Can not run the algorithm
2025-06-23 22:50:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:53 ERROR Can not run the algorithm
2025-06-23 22:50:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:54 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1466
2025-06-23 22:50:54 INFO FeHistory: [-183.36799606 -183.38982154 -183.33951348 -183.31404089 -183.36538592
 -183.37490246 -183.4243401  -183.31176034 -183.33219761 -183.38663303
 -183.31760697 -183.38938955 -183.36095039 -183.37220986 -183.36947534
 -183.37402926 -183.40576051 -183.36145956 -183.37231964 -183.31973561
 -183.34734315 -183.31531729 -183.38317182 -183.38618747 -183.33238976
 -183.30994596 -183.34565989 -183.28424007 -183.2483756  -183.35154072
 -183.3233871  -183.31773419 -183.30338988 -183.38856855 -183.3913527
 -183.38751151 -183.31762894 -183.43151372 -183.3859679  -183.37640339
 -183.35164717 -183.39907094 -183.36193793 -183.33337832 -183.35463718
 -183.36842894 -183.42155168 -183.33215814 -183.27874051 -183.41228354
 -183.35804081 -183.27256626 -183.36746146 -183.41471962 -183.29211278
 -183.44621204 -183.39146192 -183.40819336 -183.38733236 -183.28334862
 -183.41927724 -183.36752616 -183.37642355 -183.35025894 -183.37273241
 -183.27361048 -183.33197694 -183.32866749 -183.31168636 -183.25128983
 -183.37641863 -183.29652123 -183.37881745 -183.33014762 -183.37095253
 -183.35475964 -183.25787485 -183.26767891 -183.34692259 -183.43786377
 -183.35176374 -183.30638042 -183.39255206 -183.28975528 -183.37013228
 -183.37470256 -183.32864668 -183.35368874 -183.39763706 -183.33839064
 -183.28877612 -183.2693857  -183.33855619 -183.43408214 -183.37884686
 -183.39385006 -183.34074601 -183.37802412 -183.24176397 -183.32797208]
2025-06-23 22:50:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:50:54 INFO Good algorithm:
Algorithm Name: AdaptiveDEWithClusteringAndArchive
import numpy as np
import random
from scipy.stats import cauchy

# Name: AdaptiveDEWithClusteringAndArchive
# Description: Combines DE, adaptive Cauchy mutation, clustering, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDEWithClusteringAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9  # Crossover rate for DE
        self.cluster_threshold = 0.5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = self._evaluate_population(objective_function, offspring)

            combined_population = np.vstack((population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))

            clusters = self._cluster_population(combined_population, combined_fitness)
            population, fitness = self._adaptive_mutation(clusters)

            self._update_archive(population, fitness)
            self.gamma *= self.gamma_decay
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population)
            mutant = self._cauchy_mutation(a, b, c)
            trial = self._crossover(population[i], mutant)
            if objective_function(trial.reshape(1,-1))[0] < fitness_values[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness):
        for sol, fit in zip(population, fitness):
          self._update_archive_single(sol, fit)

    def _update_archive_single(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _cluster_population(self, population, fitness_values):
        clusters = []
        for i in range(len(population)):
            assigned = False
            for j, cluster in enumerate(clusters):
                centroid = np.mean(cluster[0], axis=0)
                distance = np.linalg.norm(population[i] - centroid)
                if distance < self.cluster_threshold:
                    clusters[j][0] = np.vstack((clusters[j][0], population[i]))
                    clusters[j][1] = np.concatenate((clusters[j][1], [fitness_values[i]]))
                    assigned = True
                    break
            if not assigned:
                clusters.append([np.array([population[i]]), np.array([fitness_values[i]])])
        return clusters

    def _adaptive_mutation(self, clusters):
        new_population = []
        new_fitness = []
        for cluster in clusters:
            if len(cluster[0]) > 1:
                diversity = np.var(cluster[0], axis=0).mean()
                mutation_scale = 0.1 + 0.5 * diversity
                mutated_cluster = cluster[0] + np.random.normal(0, mutation_scale, size=cluster[0].shape)
                mutated_cluster = np.clip(mutated_cluster, self.lower_bounds, self.upper_bounds)
                new_population.extend(list(mutated_cluster))
                new_fitness.extend(list(self._evaluate_population(objective_function, mutated_cluster)))
            else:
                new_population.extend(list(cluster[0]))
                new_fitness.extend(list(cluster[1]))

        return np.array(new_population)[:self.population_size], np.array(new_fitness)[:self.population_size]
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 INFO Run function 6 complete. FEHistory len: 101, AOCC: 0.1470
2025-06-23 22:50:54 INFO FeHistory: [-183.43571131 -183.43820299 -183.36970727 -183.31126075 -183.38422294
 -183.32528149 -183.32302395 -183.36910963 -183.35163812 -183.31383702
 -183.33705166 -183.36345478 -183.36220304 -183.2721199  -183.44344571
 -183.36252094 -183.37180122 -183.30517502 -183.35259834 -183.4074728
 -183.29314542 -183.26755965 -183.31189299 -183.34110231 -183.33867023
 -183.41629126 -183.28463698 -183.35727697 -183.31995548 -183.32839982
 -183.36698039 -183.40026288 -183.36677633 -183.35952093 -183.37836059
 -183.35563559 -183.34958228 -183.3764053  -183.36412488 -183.4401492
 -183.31311783 -183.26855927 -183.35549885 -183.29784445 -183.40318937
 -183.36369543 -183.29688435 -183.31264866 -183.30564255 -183.31049523
 -183.38054637 -183.39988568 -183.3649944  -183.32751958 -183.37683302
 -183.25717938 -183.38103394 -183.3276439  -183.323139   -183.32588896
 -183.41942542 -183.35131992 -183.37488562 -183.34623841 -183.31414127
 -183.32001583 -183.37791903 -183.42096047 -183.3785236  -183.29248682
 -183.31106827 -183.36890822 -183.30492289 -183.40067827 -183.47558449
 -183.41941796 -183.35805877 -183.41535826 -183.36395142 -183.34730575
 -183.37864664 -183.25419984 -183.39369369 -183.34761856 -183.37147704
 -183.38165964 -183.30140236 -183.45611839 -183.23408449 -183.36420411
 -183.3874238  -183.30300647 -183.37883184 -183.2953842  -183.38503149
 -183.339043   -183.34367831 -183.3032771  -183.33169294 -183.3491146
 -183.40556297]
2025-06-23 22:50:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:50:54 INFO Good algorithm:
Algorithm Name: AdaptiveDEWithClusteringAndArchive
import numpy as np
import random

# Name: AdaptiveDEWithClusteringAndArchive
# Description: Combines Differential Evolution, clustering, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDEWithClusteringAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.archive = []  # To store good solutions
        self.cluster_threshold = 0.5  # Parameter to adjust cluster size
        self.archive_size = 100 #Maximum archive size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Combine population and offspring
            combined_pop = np.vstack((population, offspring))
            combined_fit = np.concatenate((fitness_values, offspring_fitness))

            #Update Archive
            self._update_archive(combined_pop, combined_fit)

            #Clustering
            clusters = self._cluster_population(combined_pop, combined_fit)

            #Select next generation using archive and clustering information.
            population, fitness_values = self._select_next_generation(clusters)

            # Update best solution
            self._update_best(combined_pop, combined_fit)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            if objective_function(trial.reshape(1,-1))[0] < fitness_values[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring

    def _select_different(self, i, size):
        candidates = list(range(size))
        candidates.remove(i)
        a,b,c = random.sample(candidates, 3)
        return a,b,c

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _cluster_population(self, population, fitness_values):
        #Simple clustering based on Euclidean distance.  Could be replaced with more sophisticated methods.
        clusters = []
        for i in range(len(population)):
            assigned = False
            for j, cluster in enumerate(clusters):
                centroid = np.mean(cluster[0], axis=0)
                distance = np.linalg.norm(population[i] - centroid)
                if distance < self.cluster_threshold:
                    clusters[j][0] = np.vstack((clusters[j][0], population[i]))
                    clusters[j][1] = np.concatenate((clusters[j][1], [fitness_values[i]]))
                    assigned = True
                    break
            if not assigned:
                clusters.append([np.array([population[i]]), np.array([fitness_values[i]])])
        return clusters

    def _update_archive(self, population, fitness_values):
        sorted_indices = np.argsort(fitness_values)
        top_solutions = population[sorted_indices[:self.archive_size]]
        top_fitness = fitness_values[sorted_indices[:self.archive_size]]
        self.archive = list(zip(top_solutions, top_fitness))

    def _select_next_generation(self, clusters):
        next_gen = []
        next_fit = []
        #Prioritize solutions from diverse clusters
        for cluster in clusters:
            num_to_select = int(len(cluster[0]) * 0.8)  #Select 80% from each cluster

            if len(cluster[0]) > 0:
                sorted_indices = np.argsort(cluster[1])
                selected_solutions = cluster[0][sorted_indices[:num_to_select]]
                selected_fitness = cluster[1][sorted_indices[:num_to_select]]
                next_gen.extend(selected_solutions)
                next_fit.extend(selected_fitness)

        #add from archive to maintain diversity
        archive_solutions, archive_fitness = zip(*self.archive)
        next_gen.extend(archive_solutions)
        next_fit.extend(archive_fitness)

        #Truncate the population to the desired size
        next_gen = np.array(next_gen)
        next_fit = np.array(next_fit)
        if len(next_gen) > self.population_size:
            sorted_indices = np.argsort(next_fit)
            next_gen = next_gen[sorted_indices[:self.population_size]]
            next_fit = next_fit[sorted_indices[:self.population_size]]


        return next_gen, next_fit


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:50:54 INFO FeHistory: [1402068.8172777  2327703.74348193 2029662.0826577  1233419.84666533
 1994011.41033462 1507419.18976274 1535748.58362424 2630963.75679336
 2504203.8321544  4123731.52779698 3508157.23471135  691703.06478434
 1501876.29111884 2251822.30293705  870060.85106686  979021.69175114
 4231001.80568771  634306.34950978 1441908.18033787 1162806.54735838
 2983043.30127147 3256779.80658784 1290787.37589848 1541466.01985511
 2883396.89918022 1936287.78691984 1520426.11037594 4266040.43358633
 1930050.21312747 1294212.38224989 1712670.16589593 1229774.64940345
 1355196.68828454 2590411.36929789 3204875.40048451  898361.66219178
 1943442.28803444 3625001.9140967  1565287.07381754 1624505.36410368
 3423542.98667295 1269253.23464311 1932322.04706143 1705937.18321902
 1897933.10572265 1418183.15624226 3001537.74600281 1858396.61866285
 1443700.70955386  654422.9787937   637326.75495229 1197833.34021697
 1959973.63400589 1993302.6144916   526530.77188769 1243504.52733437
 1750659.39052227 2949211.12967914  263659.46434403 3565384.20339433
 1787757.97230269  420887.04032342 1657516.42396564 1312444.68512077
 1545675.43180843  818285.53721661 1831929.78600223  449164.9169567
 2707306.7654258  2510118.83656417 2176837.29146824 2713206.89731286
 2754772.81008695 1099596.09593044 1205032.72835528 2164138.39185706
 2573770.98696902 2646570.48817684 2560857.02827546 2275522.78101415
  955731.88887277 2997143.11320937 2918775.02840417 1405613.81628325
 2272939.861283    920938.19495051 2755979.86306486 2542360.65581836
  960097.4969517  4371305.78292696 1049755.48094063 1475328.94633265
 2302777.26857739 1766771.7792814  1371921.83769183 2075861.05825442
 2999449.16582846 1170644.5241794  3539996.74898899 1807481.68788666]
2025-06-23 22:50:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:50:54 INFO Run function 13 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:50:54 INFO FeHistory: [ 833777.29248762  950790.04633231 1961274.97559832 1399150.49860616
 1515199.4165452  2677189.64371045  962007.91721431 2414075.16132205
 1404869.927066   2459046.14302389 4325550.32688203 2394194.32530485
  594898.28599349 1380069.95970332  574895.78392829  780172.41499234
  850021.40924543 1214881.13172916 2682334.04514579  717275.75232746
 1014150.84549136 1701922.32935681 1938616.56854128 2502796.51814893
  539041.75101511 1669368.43748806 3608006.3713706  1807184.20905601
 1615804.71574464 2561897.78814562 1755103.9698201  1234457.22682737
 1590756.0313656  3768560.88020064 2015849.24217815 1625177.79810533
 1200154.17081727 3424017.34351086 1487595.63462773 2640229.9209753
 1791837.97591723 1373970.69378201 2448018.34600342  311489.19674133
  775978.93192877 3198759.8770964  1104600.61039874 1199963.49484709
 4266938.95035862 2753341.23118628  821939.75463395 1013773.50692475
 2541323.07262742 2034243.11366964 1198219.40026195 1773234.50691993
  965501.75833316 1471430.80790334 2576380.58906436 2107931.12085868
 1472049.37885123 1814375.22158605 1627553.83845528 1093727.0223398
 1277253.03187207  834200.46211327 1821365.53850337  998883.21338368
 3008240.46685035 3959556.47752764 1879766.95720924 2055622.31459779
 1309084.09949738 1647973.02793842 1430660.00847848 2008933.13283696
 1305772.57019366  631035.48298394 2961934.31268032  981640.46884341
 1997681.08933724 2472827.14585435  282663.92153156 1989230.23068766
 1624115.46145864  944455.4072689   930578.54225779 1581991.74890482
 1428663.557133   2602226.49805105 1680422.10229356 1981608.44498403
  384618.62488111 1308112.00247586 1844240.93933326 1689538.38909456
 1742046.57556773 1489894.35346555 2298022.59503531 5064232.502014
 2119301.55560259]
2025-06-23 22:50:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 INFO Run function 6 complete. FEHistory len: 210, AOCC: 0.1470
2025-06-23 22:50:54 INFO FeHistory: [-183.3535998  -183.40303578 -183.43414477 -183.39686952 -183.29192833
 -183.29980989 -183.40826196 -183.30207462 -183.29556186 -183.33621473
 -183.337255   -183.41044534 -183.35245651 -183.37668005 -183.43539045
 -183.41778859 -183.40310404 -183.26998547 -183.37576727 -183.32228807
 -183.30642997 -183.35752909 -183.40538936 -183.31410234 -183.26809998
 -183.29820884 -183.47235368 -183.39817451 -183.35568834 -183.36115207
 -183.37237216 -183.34140296 -183.3434986  -183.38680699 -183.2985504
 -183.38217114 -183.33121117 -183.34111986 -183.33408756 -183.36053379
 -183.40092744 -183.46181095 -183.32764481 -183.30525656 -183.38759606
 -183.34686076 -183.38594928 -183.33029455 -183.39633145 -183.37643623
 -183.34631699 -183.34121586 -183.325005   -183.37073942 -183.37972755
 -183.33716825 -183.40283606 -183.3268617  -183.40211764 -183.39034595
 -183.31662773 -183.29452319 -183.34790474 -183.35914676 -183.40063296
 -183.34525469 -183.30039381 -183.38176628 -183.33373376 -183.36193644
 -183.33648495 -183.3928917  -183.34048775 -183.35159454 -183.3285324
 -183.32493371 -183.46053541 -183.37536517 -183.34594343 -183.35386057
 -183.37117828 -183.34307344 -183.33379341 -183.33856967 -183.27591425
 -183.34072704 -183.32617273 -183.33697871 -183.33634013 -183.24312048
 -183.35939054 -183.29398815 -183.35569332 -183.40013148 -183.28566784
 -183.36946222 -183.33897104 -183.32215883 -183.33329743 -183.27185848
 -183.3082321  -183.16732146 -183.19515505 -183.33160755 -183.24908592
 -183.21573589 -183.19628646 -183.22407298 -183.25730749 -183.28391858
 -183.1834858  -183.19063681 -183.20866042 -183.19792998 -183.1979702
 -183.27312025 -183.16674397 -183.3210363  -183.28459495 -183.28519397
 -183.13020872 -183.37791917 -183.18465434 -183.18434255 -183.21737593
 -183.19399716 -183.23322621 -183.21194424 -183.18974222 -183.3579016
 -183.1981094  -183.21051215 -183.25653502 -183.26045494 -183.18524227
 -183.17152795 -183.1963922  -183.32593204 -183.23275679 -183.18093481
 -183.14529842 -183.18700496 -183.20257142 -183.21692886 -183.16438005
 -183.19057989 -183.23408316 -183.17171409 -183.27444893 -183.21777734
 -183.20354347 -183.23880636 -183.17443919 -183.24284263 -183.19201729
 -183.18637362 -183.35324413 -183.15389773 -183.24539743 -183.20000481
 -183.26154151 -183.28534613 -183.15488885 -183.26659474 -183.21373588
 -183.20251971 -183.21357317 -183.18558887 -183.17424086 -183.13154977
 -183.25433396 -183.32217788 -183.18585108 -183.3107842  -183.28151767
 -183.26021894 -183.23409951 -183.33206562 -183.1824949  -183.23096786
 -183.28381053 -183.15782034 -183.26924161 -183.28178297 -183.15139784
 -183.22867349 -183.25067963 -183.20168916 -183.22314775 -183.25104438
 -183.26620312 -183.110253   -183.26447047 -183.18634093 -183.23873319
 -182.91801096 -183.32565853 -183.23585497 -183.16765704 -183.25591913
 -183.32617273 -183.26809998 -183.46053541 -183.40013148 -183.31410234
 -183.25717311 -183.21498039 -183.24696469 -183.21752592 -183.33008245]
2025-06-23 22:50:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:50:54 INFO Good algorithm:
Algorithm Name: AdaptiveDECauchyArchiveClustering
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDECauchyArchiveClustering
# Description: Combines DE with adaptive Cauchy mutation, an archive, and clustering for multimodal optimization.
# Code:
class AdaptiveDECauchyArchiveClustering:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation, an archive, and clustering to handle multimodal landscapes.  
    The algorithm uses clustering to identify and exploit multiple optima.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, cluster_threshold=0.5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.cluster_threshold = cluster_threshold # Threshold for clustering

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._cluster_selection(population, fitness) #Clustering-based selection
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _cluster_selection(self, population, fitness_values):
        # Simple clustering based on Euclidean distance
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=min(len(population), 5), random_state=0).fit(population) #Adjust number of clusters as needed

        cluster_centers = kmeans.cluster_centers_
        cluster_fitnesses = []
        for center in cluster_centers:
            distances = np.linalg.norm(population - center, axis=1)
            indices_close = np.where(distances < self.cluster_threshold)[0]
            if len(indices_close)>0:
                best_index_in_cluster = indices_close[np.argmin(fitness_values[indices_close])]
                cluster_fitnesses.append((best_index_in_cluster, fitness_values[best_index_in_cluster]))
            else:
                # Handle empty cluster by selecting a random individual.
                cluster_fitnesses.append((np.random.randint(len(population)),fitness_values[np.random.randint(len(population))]))



        selected_indices = [index for index, _ in sorted(cluster_fitnesses, key=lambda item: item[1])]
        
        return population[selected_indices]
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:50:54 ERROR Can not run the algorithm
2025-06-23 22:50:54 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:50:54 INFO FeHistory: [168684.85798718 196366.09422438 220702.35360735 113536.35192054
 129986.76545619 117183.30638964 132735.41146268  94722.88012585
 130770.74630151 193973.35670972 153504.64678357 201604.24328204
 113130.05773603 169885.06233088 118462.57780821 120835.72301872
 170826.62223932 160193.17369121 116550.85108878 139484.38430653
  66220.93185131 131970.84904526 194466.13706049 124486.43561222
 113717.11007348 132726.52623123 150131.27886279 159018.27590561
 225784.50455374 101702.56925597 126069.96218818 136385.45070596
 105407.57681433 145412.39014271 126827.61441476 246316.46953406
 128884.19361252 142350.84016025 166664.18448112 138170.49025915
 188702.92683517 148369.41897655 121136.03030782 152731.26072152
 123937.54704264 155090.35051633 131273.34435316 209272.44740892
 107189.32751211 175677.45103893 173569.74215476 158574.75313448
 159349.95456933 178738.66646483 166900.12071535 113821.60975454
 130527.48103311 192777.99436699 183886.80312514 115090.2116185
 129491.89003444 159917.25066641 152323.37859246 127733.37037524
 126465.4046633  119279.68296961 137829.16333961 164892.75328201
 139365.94301403 142957.77837454 196759.94621015 134271.18571319
 194424.74419122 149950.58015007 165764.86178107 172105.15306045
 167187.23277985 118917.99047544 117665.81369528 144231.65226634
 154394.98688221 109864.99089438 172115.97438541 108720.34373153
 124972.02591967 151847.28436252 158702.56606551 115081.29710601
 183279.79179917 183874.4065599  203151.88753088 163259.83798676
 158189.28233577 143819.05041484 156502.22314861 198841.64252868
 159172.97058384 121969.13417932 120720.13719816  79556.45695894]
2025-06-23 22:50:54 INFO Expected Optimum FE: -5000
2025-06-23 22:50:54 INFO Unimodal AOCC mean: 0.1466
2025-06-23 22:50:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:50:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:50:54 INFO AOCC mean: 0.0489
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:54 INFO Run function 18 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 22:50:54 INFO FeHistory: [148419.68978918 191361.29365673 148500.44985299 122929.4754354
 149591.49229327 141288.49769539 213196.81518667 178620.50955504
 155319.94366541 191701.64658787  91557.84595274 134948.27720323
 124517.88696954 134136.52490887 137460.168774   151559.93796087
 195987.92189167 138790.23636552 113631.0643209  166900.11961378
 181556.78352232 129066.35154384 121435.02767985 136103.28090566
 159762.4076182  130333.16623244 174536.79312069 104411.57590072
 149065.39630695 124065.41779651 238972.16483411 142331.72843098
 113062.77759335 178907.7597653  125436.48810974 102006.84505111
 145145.36831952 136128.03478961 173889.70967813 133151.75935969
 129225.9033039  138510.8869709  115744.7826808  168561.48026114
 120670.37123962 249271.43371078 113534.07194791 172243.13215934
 163641.59979263 143357.33118596 188008.15658013 208349.51511235
 138191.99535086 139505.86954565 172090.41237466 248733.81078147
 134150.79638215 177554.19782184 145442.64894301 238206.40753243
 129179.80473416 106286.63121847 139095.11896755 140725.55029955
 136478.03421629 124372.39120643 122558.57544627 216514.21009269
 146899.09287971 114685.89071693 151699.7614918   87353.78354357
 154672.68336549 239550.48029674 136917.71892254 147248.39225265
 171435.24864156 158453.12998701 196624.12229414 152361.96205744
 104486.29476964  83955.26782892 173442.72970907 103443.50249239
 177947.29282659 110531.21234948 117859.18465513 224163.66779859
 137308.8014977  119240.65903467 118912.91234151 183582.42517971
 211231.84852131 151588.80113426 167288.68728915 107903.80718351
 145101.1989617  197951.34473255 123028.45051136 165945.72061949
 129986.18990228]
2025-06-23 22:50:54 INFO Expected Optimum FE: -5000
2025-06-23 22:50:54 INFO Unimodal AOCC mean: 0.1470
2025-06-23 22:50:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:50:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:50:54 INFO AOCC mean: 0.0490
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:50:54 INFO Run function 13 complete. FEHistory len: 210, AOCC: 0.0000
2025-06-23 22:50:54 INFO FeHistory: [  767482.41903763  2125534.48007905  1027455.35863821  1504560.82439479
  1588315.2078029   2024866.53434835  2107290.08806783  1837411.92342291
  1614388.78264845   974193.14584513  1441999.05457919  1636674.17149704
  2405522.26316127  1959204.52272213   377381.47207156  3075051.86899402
  2906209.31201626  2241702.85736207  5537209.33432168  1847054.86750465
   870042.40165963  3804910.7886501   1248619.17213447  1053371.36754684
  2243873.0052258   2195144.22039734  3574623.86064157  1506181.68554168
  1209150.42277544  1378502.11550451  1894064.80446905   761678.60077987
  1101164.38421724  2963782.66083402  2145769.9395795   1104798.476189
  1784743.57378789  1269062.2289162   1823776.50876408   562727.51409834
  1287325.47684537  1306582.90525317  2347353.42060611   934317.97306935
  5408158.66488536  1330182.60684676  2104077.91948529  3574143.05278343
  1037251.40390378  2555311.65503099  1559171.65428353  1558855.12928589
  2726145.66517646  2636524.04196881  3285172.6955176   1084283.96754236
  3125341.35654571  1705714.69426349  1465829.00402593  2765159.85363075
  2311761.85364168  1698742.93342237  2633187.71390083  1336447.70801008
  1093800.04006182  1177460.22438826  2323568.33123926  2487132.72044452
  1114774.59344585  1402934.96041905   737398.41207207  1595196.56715042
  3102058.94338018  1138394.13398289   589285.4251509   1030140.04976145
  2396480.92004198  1446254.45021543   759848.72955368  2050202.62563514
  4497134.79908791  1429293.4089748   1880331.78211495  1512200.43091265
  1810303.86074177  1664300.95401329   978274.09301577  2222313.80252613
   870805.53383282   805979.6101406   1092734.80328248  2409890.08635996
  2569119.5884709   1454547.75435895  2826458.29404548  3705385.26109812
  1470307.69540545  1414594.56307638  3364553.02680293  2669271.55639483
   839629.41647789  9419759.17924162  1938482.76725901  4231422.5762288
  6399992.53854713  3059443.68179858  4011321.29537225  2357856.51055242
  4733352.23779419  5569643.0607614   2163847.93395249  5465369.80211626
  1882299.65317768  3585738.01603837  2807472.75929584  4751823.16523288
  1704472.39456145  5313635.72210618  3497112.28082568  2824396.2407314
  4466306.05754148  1644465.00507276  1366277.59503397  7685808.06746701
  4537315.14503776  3633739.66097823  2582662.15071283  5287994.32181728
  5413361.06607466  1030991.93233743  2486625.16575934  7248672.64870956
  4319534.51373613  1637921.36002046  4828901.30026077  3901938.78570954
  8648606.81873745  1681180.51083895  2787759.71082265 11846798.49715472
  5035791.73940641  6544496.58704428  2690314.20728174   970900.92834832
  5555784.28592561  3868202.43158469  3355509.64685733   401756.31091283
  1300347.25865261  7734365.8001044   3688505.46236043  3436369.60612917
  6243056.69816486  1674036.09133407  4667547.27755719  3777158.68762827
  1665303.93324837  2759504.84401475  3924297.14937796  5329135.79375775
  3533380.34367318  5295505.29898529  4830167.05241124  2807727.26156695
  5135907.71351383  4317237.0951633   3053590.86088434  1999378.82781648
  7300994.27854761  1020523.88502192  3108749.30946652  5155463.77641609
  4269347.58645065  5088629.14894978 14286176.09985153  3487553.67841447
  6059801.57911778  3620437.71691048   670382.01226139  5570712.2152333
  1768269.02360663  2744558.21535183  2633269.6657364   2675644.01183703
  1480342.40965891  6887057.85710827  2328422.90470938  2435318.07672231
  1581613.56287698  5217735.70088829  8264291.21920552  2498279.21117868
  3903660.33145718  4071753.82862609  1863873.46490971  3026288.43705111
  2624524.49393767  6917543.4884664    549574.00230377  6347653.2055556
   589285.4251509   1674036.09133407  1429293.4089748   2582662.15071283
  2633187.71390083  1463906.45224757  7284704.56361402  1449284.58014908
  6975248.29027748  4492031.74954103]
2025-06-23 22:50:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:50:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:50:55 ERROR Can not run the algorithm
2025-06-23 22:50:55 INFO Run function 18 complete. FEHistory len: 210, AOCC: 0.0000
2025-06-23 22:50:55 INFO FeHistory: [  196937.23619714   134245.74265591   168684.66974322   149366.39836266
   203033.07921705   219660.10971564   147335.94777954   130061.8482126
   225530.57655914   110776.38496645   143210.37837009   147404.71546999
   177901.30218706   128435.24827575   210049.75109677   114994.5546571
   218126.04115472   144255.63589728   151060.63817459   195912.33985367
   162594.93728619   167614.73948509   156906.1417476    222437.52768952
   168924.29693178   172891.48605827   133020.27800224   232376.01146826
   133662.61999301   162496.7101469    170572.51575673   147223.52438269
    72422.57193595   175642.44141062   179846.90250529   173099.00923179
   125311.31878837   197332.81534147    91860.03206042    97093.90832406
   214510.38720746   146284.86028996   110386.98318816   130042.45848432
   166120.55146307   166886.18710176   205054.76417429    83197.19893023
   150931.47818885   137078.61643033   169124.3330788    132176.90084085
   137804.00886489   203306.80582799   139193.68711403   140135.30760404
   177816.28162751   117565.32680594   108380.72902454   218520.64446397
   197682.17860677   160497.9859177    125388.50659004   188489.10278703
   157644.4416512    140461.71753048   172611.64736775   143245.796626
   105111.47438146   142526.41219587   200972.08406828   130521.6423324
   183117.26401242   167797.08060625   147573.33493218   168451.45186799
   145789.29271209   122561.68537441   139200.12696743   168138.24747365
   171970.23732214   184567.7710786    186483.64860328   127257.5152541
   112930.77109782   105158.48893694   137705.82012834   121882.89445131
   187008.9410991    165791.39680757   104248.30227702   157816.77152223
   154303.98376243   172880.93835882   196171.72449652   173048.46256168
    89514.38813961   110438.1241555     97143.17909672   125025.35723705
   311137.5113573    234753.43238257   340360.98677476   292625.03200021
   279407.23940705   187005.75701749   408263.04982749   300493.57311609
   192707.34645566 11048494.88472917   255925.91798176   383065.3454348
   684369.96836525   448922.99579807   290851.02797847   248831.12112207
   495560.57684357   351007.38552513   451386.0021592    249397.96574064
   453452.81409774   390364.14974076   223342.20312605   294679.18465197
   344500.09445772   256886.06566047   232826.61625115   455692.53944501
   288578.1610033    226834.58856403   291657.28821522   383103.18888427
   282339.33633418   473872.94733256   274976.24219691   363588.88247372
   348130.3772091    365833.92084723   352916.90921656   307708.13792513
   218583.62995977   392948.8934511    354015.63164374   740330.91164544
   303661.40357131   171440.21530105   455085.44411242   379383.97678194
   395519.22433254  3277330.54890058   402421.73924686   343961.56142957
   277033.92647178   281718.80973999   464019.2038019    164689.25663931
   234653.31019968   255231.19367838   601867.32404142   648255.82492532
   295834.63510022   235996.29438013   416395.2176339    332666.57645913
   315256.24812943   284003.64323396   259793.80643582   344279.89595587
   433085.50069718   451637.41367317   264378.49090899   369514.25829435
   270630.04437076   403884.64759571   319517.40509192   538488.34731013
   384224.71835486   353047.84074331   399916.52775035   373777.51769548
   179092.8033628    317749.37085979   299955.01778974   462202.74996159
   314093.99016819   365535.54525714   486831.30174682   307578.0663298
   388825.02695432   388517.88749345   255022.93412049   317755.72517382
   213286.62557085   428249.70932584   346453.88720905   273818.64379611
   483319.04204735   418553.90027232   191006.50756166   280768.06626402
   127257.5152541    172880.93835882   151060.63817459   200972.08406828
   200972.08406828   369510.46073451   276786.10316643   310664.87589924
   298969.25390539   362615.59637769]
2025-06-23 22:50:55 INFO Expected Optimum FE: -5000
2025-06-23 22:50:55 INFO Unimodal AOCC mean: 0.1470
2025-06-23 22:50:55 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:50:55 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:50:55 INFO AOCC mean: 0.0490
2025-06-23 22:50:55 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:51:05 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1593
2025-06-23 22:51:05 INFO FeHistory: [-183.38909389 -183.33115786 -183.31912828 ... -184.38411579 -184.38411579
 -184.38411579]
2025-06-23 22:51:05 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:51:05 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveAndTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyArchiveAndTournamentSelection
# Description: Combines DE, adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveAndTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = 5


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
2025-06-23 22:51:05 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:51:06 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1527
2025-06-23 22:51:06 INFO FeHistory: [-183.32972587 -183.41007469 -183.37549218 ... -183.83741597 -183.83689224
 -183.83219023]
2025-06-23 22:51:06 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:51:06 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveClustering
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyArchiveClustering
# Description: Combines DE with adaptive Cauchy mutation, an archive, and clustering to escape local optima.
# Code:
class AdaptiveDEwithCauchyArchiveClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.cluster_threshold = 0.5 #parameter for clustering


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            
            population, fitness = self._selection(population, fitness, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            self._adaptive_parameter_tuning(population, fitness)
            self._cluster_and_replace(population, fitness) #added clustering

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population)
            mutant = a + self.F * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, offspring, offspring_fitness):
        for sol, fit in zip(offspring, offspring_fitness):
            self._add_to_archive(sol, fit)

    def _add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _adaptive_parameter_tuning(self, population, fitness_values):
        self.gamma *= self.gamma_decay

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _cluster_and_replace(self, population, fitness_values):
        #Simple clustering based on Euclidean distance.  Replace solutions in dense clusters.
        if len(population) < 2: return

        distances = np.linalg.norm(population[:, np.newaxis] - population, axis=2)
        np.fill_diagonal(distances, np.inf) #ignore self-distance

        for i in range(len(population)):
            close_neighbors = np.where(distances[i] < self.cluster_threshold)[0]
            if len(close_neighbors) > 0.5 * self.population_size:  #Check for dense clusters
                #Replace with new random solution
                population[i] = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                fitness_values[i] = objective_function(population[i].reshape(1,-1))[0]
                self.eval_count += 1


2025-06-23 22:51:06 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:51:07 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1487
2025-06-23 22:51:07 INFO FeHistory: [-183.30191729 -183.33612114 -183.33165787 ... -183.33157951 -183.35761303
 -183.35835373]
2025-06-23 22:51:07 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:51:07 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyClusteringTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyClusteringTournament
# Description: Combines DE, adaptive Cauchy mutation, clustering, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyClusteringTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, 
    k-means clustering for diversity, and tournament selection for 
    robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, cluster_k=5, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.cluster_k = cluster_k
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            population = self._maintain_diversity(population, fitness) #Clustering for diversity
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
    
    def _maintain_diversity(self, population, fitness_values):
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=self.cluster_k, random_state=0)
        kmeans.fit(population)
        labels = kmeans.labels_

        #Ensure at least one member from each cluster
        cluster_members = [[] for _ in range(self.cluster_k)]
        for i, label in enumerate(labels):
            cluster_members[label].append((population[i], fitness_values[i]))

        new_population = []
        for cluster in cluster_members:
            if cluster: #handle empty cluster
                best_individual = min(cluster, key=lambda x: x[1])[0]
                new_population.append(best_individual)
        #Fill remaining spots randomly
        while len(new_population) < self.population_size:
            new_population.append(np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim))

        return np.array(new_population)

2025-06-23 22:51:07 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:51:14 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1562
2025-06-23 22:51:14 INFO FeHistory: [-183.37780508 -183.37743433 -183.28889273 ... -184.20528326 -184.20528326
 -184.20528326]
2025-06-23 22:51:14 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:51:14 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveAndClustering
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyArchiveAndClustering
# Description: Combines DE, adaptive Cauchy mutation, archive, and clustering for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveAndClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = 5
        self.cluster_radius = 0.1  # Initial cluster radius, adjust as needed

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._clustering_selection(population, fitness) #Added Clustering
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _clustering_selection(self, population, fitness_values):
        #Simple Clustering for Diversity
        selected_population = []
        while len(selected_population) < self.population_size:
            best_index = np.argmin(fitness_values)
            selected_population.append(population[best_index])
            fitness_values[best_index] = np.inf #Remove from consideration
            
            #Remove nearby solutions
            for i in range(len(fitness_values)):
                if np.linalg.norm(population[i]-population[best_index]) < self.cluster_radius:
                    fitness_values[i] = np.inf

        return np.array(selected_population)
2025-06-23 22:51:14 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:51:16 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:51:16 INFO FeHistory: [1.69383838e+06 3.64191194e+06 1.67848372e+06 ... 1.92767798e+03
 1.92767798e+03 1.92767798e+03]
2025-06-23 22:51:16 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:51:16 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:51:19 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:51:19 INFO FeHistory: [2659786.94924972 4681695.47560945 2759339.26309987 ... 3517794.16703878
 3369116.30380332 1320153.03716412]
2025-06-23 22:51:19 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:51:19 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:51:19 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:51:19 INFO FeHistory: [1636225.6119045  1488724.2118826  2054287.41415231 ...  702728.16886105
 2631376.12345894  745686.6649927 ]
2025-06-23 22:51:19 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:51:19 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:51:33 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:51:33 INFO FeHistory: [2.17654766e+06 2.30662231e+06 8.87719813e+05 ... 2.05422983e+03
 2.05422983e+03 2.05422983e+03]
2025-06-23 22:51:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:51:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:51:47 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:51:47 INFO FeHistory: [142510.87494497 198080.44914941 129717.40293885 ...   8051.32003987
   8051.32003987   8051.32003987]
2025-06-23 22:51:47 INFO Expected Optimum FE: -5000
2025-06-23 22:51:47 INFO Unimodal AOCC mean: 0.1593
2025-06-23 22:51:47 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:51:47 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:51:47 INFO AOCC mean: 0.0531
2025-06-23 22:51:51 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:51:51 INFO FeHistory: [122147.45763951 121723.00521335 138317.97587919 ... 172194.49926435
  93453.11903595 193210.88265305]
2025-06-23 22:51:51 INFO Expected Optimum FE: -5000
2025-06-23 22:51:51 INFO Unimodal AOCC mean: 0.1487
2025-06-23 22:51:51 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:51:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:51:51 INFO AOCC mean: 0.0496
2025-06-23 22:51:53 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:51:53 INFO FeHistory: [143832.81922197  88332.25180758 146559.5195089  ...   8082.8828235
  14326.3867991    9322.90031008]
2025-06-23 22:51:53 INFO Expected Optimum FE: -5000
2025-06-23 22:51:53 INFO Unimodal AOCC mean: 0.1527
2025-06-23 22:51:53 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:51:53 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:51:53 INFO AOCC mean: 0.0509
2025-06-23 22:52:13 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:52:13 INFO FeHistory: [128134.90044572 145803.12508488 169206.28296714 ...   -996.70019196
   -996.70019196   -996.70019195]
2025-06-23 22:52:13 INFO Expected Optimum FE: -5000
2025-06-23 22:52:13 INFO Unimodal AOCC mean: 0.1562
2025-06-23 22:52:13 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:52:13 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:52:13 INFO AOCC mean: 0.0521
2025-06-23 22:52:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:52:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:52:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:52:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:53:07 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1579
2025-06-23 22:53:07 INFO FeHistory: [-183.33512914 -183.31308855 -183.32842669 ... -183.80430482 -183.7652668
 -183.70519723]
2025-06-23 22:53:07 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:53:07 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A differential evolution algorithm enhanced with adaptive mutation, clustering-based diversity preservation, and a refined selection strategy to efficiently explore multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.cluster_threshold = 0.1 #parameter to adjust clustering


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_indices(i)
            mutant = self._mutate(population[a], population[b], population[c])
            offspring[i] = self._crossover(population[i], mutant)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_indices(self, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return indices

    def _mutate(self, x, y, z):
        return x + self.F * (y - z)

    def _crossover(self, x, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        return np.where(crosspoints, mutant, x)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        # Adaptive F and CR (simple example -  replace with more sophisticated adaptation)
        avg_fitness = np.mean(fitness_values)
        if avg_fitness < np.median(fitness_values):
            self.F = max(0.2, self.F * 0.9) #reduce exploration
            self.CR = max(0.2, self.CR * 0.9)
        else:
            self.F = min(1.8, self.F * 1.1) # increase exploration
            self.CR = min(0.99, self.CR * 1.1)
        

        #Clustering based diversity preservation.  (Rudimentary example, improve as needed)
        distances = np.linalg.norm(population[:, np.newaxis, :] - population[np.newaxis, :, :], axis=2)
        avg_distance = np.mean(distances[np.triu_indices(self.population_size, k=1)])

        if avg_distance < self.cluster_threshold:
            #Inject some noise or diversity
            population += np.random.normal(0, 0.1 * (self.upper_bounds - self.lower_bounds), size=population.shape)
            population = np.clip(population, self.lower_bounds, self.upper_bounds)

2025-06-23 22:53:07 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:53:09 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1526
2025-06-23 22:53:09 INFO FeHistory: [-183.37551302 -183.37973807 -183.32976049 ... -183.77300338 -183.82564558
 -183.90747219]
2025-06-23 22:53:09 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:53:09 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyMutation
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm with adaptive mutation strength and Cauchy mutation for escaping local optima in multimodal landscapes.

class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.gamma = 0.95 #Cauchy scale factor decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf') if self.dim > 0 else 0

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        cauchy_scale = 0.1 * (self.upper_bounds - self.lower_bounds) # Initial Cauchy scale

        while self.eval_count < self.budget:
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_different(population, i)
                mutant = a + self.F * (b - c)
                
                #Cauchy Mutation
                mutant += cauchy.rvs(loc=0, scale=cauchy_scale, size=self.dim)

                #Crossover
                jrand = np.random.randint(self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == jrand:
                        offspring[i,j] = mutant[j]
                    else:
                        offspring[i,j] = population[i,j]
                
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)


            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            cauchy_scale *= self.gamma #Decay Cauchy scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 22:53:09 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:53:09 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1521
2025-06-23 22:53:09 INFO FeHistory: [-183.39464813 -183.30939879 -183.38869573 ... -183.76821937 -183.85403437
 -183.84899097]
2025-06-23 22:53:09 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:53:09 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithCauchyMutation
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm with adaptive mutation scale and Cauchy mutation for escaping local optima in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.scale_factor = 1.0 #Initial Cauchy scale factor
        self.scale_decay = 0.95 #Decay rate for scale factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_differents(population, i)
                mutant = a + self.F * (b - c)
                trial = self._crossover(population[i], mutant)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
                #Cauchy mutation for exploration
                trial += cauchy.rvs(loc=0, scale=self.scale_factor, size=self.dim)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    new_population.append(population[i])

                self._update_best(trial, trial_fitness)

            population = np.array(new_population)
            self.scale_factor *= self.scale_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _select_differents(self, population, i):
        candidates = list(range(self.population_size))
        candidates.remove(i)
        a, b, c = np.random.choice(candidates, 3, replace=False)
        return population[a], population[b], population[c]

    def _crossover(self, x, v):
        u = np.copy(x)
        indices = np.random.rand(self.dim) < self.CR
        u[indices] = v[indices]
        return u

    def _update_best(self, solution, fitness):
        if fitness < self.best_fitness_overall:
            self.best_fitness_overall = fitness
            self.best_solution_overall = solution
2025-06-23 22:53:09 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:53:10 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1516
2025-06-23 22:53:10 INFO FeHistory: [-183.38889308 -183.34089281 -183.32356264 ... -183.70276547 -183.69746384
 -183.74344374]
2025-06-23 22:53:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:53:10 INFO Good algorithm:
Algorithm Name: AdaptiveDifferentialEvolutionWithClustering
import numpy as np
import random

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A differential evolution algorithm incorporating adaptive mutation strength and population clustering for enhanced exploration and exploitation in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.k = 5 # Number of clusters for k-means

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            #Clustering
            centroids = self._kmeans_clustering(population, self.k)
            
            offspring = []
            offspring_fitness = []
            for i in range(self.population_size):
                #Adaptive Mutation using Centroid information.
                closest_centroid_index = self._closest_centroid(population[i], centroids)
                centroid = centroids[closest_centroid_index]
                
                #Differential Evolution Mutation
                a, b, c = self._select_differents(population, i) #Avoid self
                mutant = population[a] + self.F * (population[b] - population[c])

                #Binomial Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    offspring_fitness.append(trial_fitness)
                else:
                    offspring.append(population[i])
                    offspring_fitness.append(fitness_values[i])
            population = np.array(offspring)
            fitness_values = np.array(offspring_fitness)

            #Update Best
            self._update_best(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _kmeans_clustering(self, population, k):
        # Simple k-means++ initialization
        centroids = random.sample(list(population), k)
        
        while True:
            clusters = [[] for _ in range(k)]
            for point in population:
                distances = np.linalg.norm(point - np.array(centroids), axis=1)
                closest_centroid_index = np.argmin(distances)
                clusters[closest_centroid_index].append(point)
            
            new_centroids = np.array([np.mean(cluster, axis=0) if cluster else centroid for cluster, centroid in zip(clusters, centroids)])
            if np.allclose(centroids, new_centroids):
                break
            centroids = new_centroids
        return centroids

    def _closest_centroid(self, point, centroids):
        distances = np.linalg.norm(point - np.array(centroids), axis=1)
        return np.argmin(distances)

    def _select_differents(self, population, current_index):
        indices = list(range(len(population)))
        indices.remove(current_index)
        return random.sample(indices, 3)


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:53:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:53:18 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:53:18 INFO FeHistory: [2878346.31713984  739361.79185198 2921539.28909463 ...  173821.62205344
   76099.48499218  131054.35702144]
2025-06-23 22:53:18 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:53:18 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:53:21 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:53:21 INFO FeHistory: [1374040.31192611 2080034.51317961 1614993.67331783 ... 1657829.27484676
  530156.74883236 1275415.14272834]
2025-06-23 22:53:21 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:53:21 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:53:22 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:53:22 INFO FeHistory: [3062661.10132107 2071953.86478477 1556350.91744139 ... 1859472.64837851
 2449458.09477191 3373571.82098561]
2025-06-23 22:53:22 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:53:22 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:53:24 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:53:24 INFO FeHistory: [1340017.63767482 1401015.20840273 1121883.09039589 ... 2484625.11363501
  723900.17487054 1462703.16737586]
2025-06-23 22:53:24 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:53:24 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:53:49 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:53:49 INFO FeHistory: [ 99523.44274574 108179.49187573 110834.05443495 ...  13016.22012635
   5502.07315181   9647.96311852]
2025-06-23 22:53:49 INFO Expected Optimum FE: -5000
2025-06-23 22:53:49 INFO Unimodal AOCC mean: 0.1579
2025-06-23 22:53:49 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:53:49 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:53:49 INFO AOCC mean: 0.0526
2025-06-23 22:53:55 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:53:55 INFO FeHistory: [199397.38121418 187901.37712001  97704.08598375 ...  40264.6198581
  27068.97506108  19470.41792568]
2025-06-23 22:53:55 INFO Expected Optimum FE: -5000
2025-06-23 22:53:55 INFO Unimodal AOCC mean: 0.1526
2025-06-23 22:53:55 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:53:55 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:53:55 INFO AOCC mean: 0.0509
2025-06-23 22:53:56 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:53:56 INFO FeHistory: [154468.5902182  112402.70779805 153645.15634836 ...  56424.21722782
  69565.61377191  73608.8324862 ]
2025-06-23 22:53:56 INFO Expected Optimum FE: -5000
2025-06-23 22:53:56 INFO Unimodal AOCC mean: 0.1521
2025-06-23 22:53:56 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:53:56 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:53:56 INFO AOCC mean: 0.0507
2025-06-23 22:54:00 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:54:00 INFO FeHistory: [106235.42925085 188356.229887   151004.15490783 ...  40774.68872466
  35494.82945599  37208.79139337]
2025-06-23 22:54:00 INFO Expected Optimum FE: -5000
2025-06-23 22:54:00 INFO Unimodal AOCC mean: 0.1516
2025-06-23 22:54:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:00 INFO AOCC mean: 0.0505
2025-06-23 22:55:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:55:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:55:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:55:56 ERROR Can not run the algorithm
2025-06-23 22:55:56 INFO Run function 6 complete. FEHistory len: 100, AOCC: 0.1469
2025-06-23 22:55:56 INFO FeHistory: [-183.35300295 -183.33053682 -183.27591948 -183.28711608 -183.39823545
 -183.39800579 -183.36271789 -183.37313321 -183.30690136 -183.2723279
 -183.40002313 -183.37013129 -183.31066879 -183.36445597 -183.40821259
 -183.33496034 -183.36151501 -183.36260128 -183.38556386 -183.35661864
 -183.34419004 -183.35196874 -183.26406276 -183.36482365 -183.322287
 -183.36603174 -183.41415989 -183.3060936  -183.30575073 -183.39258945
 -183.30093848 -183.41304981 -183.32316125 -183.31289017 -183.27747932
 -183.34544292 -183.31639706 -183.41074243 -183.32548779 -183.26446468
 -183.32879358 -183.31718258 -183.31574881 -183.3321643  -183.28558804
 -183.34950094 -183.38548578 -183.45076967 -183.31803265 -183.40141155
 -183.4278809  -183.378055   -183.29062034 -183.29098671 -183.31959414
 -183.45171143 -183.386109   -183.46831162 -183.27829454 -183.31737003
 -183.42292727 -183.3824138  -183.32710184 -183.38582508 -183.43856053
 -183.40079813 -183.37546736 -183.45464937 -183.40141071 -183.34143461
 -183.33069984 -183.33392035 -183.36238848 -183.34311466 -183.41077259
 -183.38605492 -183.36608334 -183.3586503  -183.31680154 -183.37339179
 -183.35726425 -183.36420036 -183.38889433 -183.36602449 -183.3504242
 -183.3563376  -183.35335201 -183.34339599 -183.33945143 -183.32566791
 -183.35514834 -183.433534   -183.40074113 -183.33447294 -183.3159564
 -183.43788973 -183.35830058 -183.31406881 -183.27162922 -183.3482334 ]
2025-06-23 22:55:56 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:55:56 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyAndTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyAndTournamentSelection
# Description: Combines DE, adaptive Cauchy mutation, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyAndTournamentSelection:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and tournament selection 
    for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, tournament_size=5, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.tournament_size = tournament_size
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                parents = self._tournament_selection(population, fitness)
                mutant = self._cauchy_mutation(parents)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _tournament_selection(self, population, fitness_values):
        tournament_indices = np.random.choice(len(population), self.tournament_size, replace=False)
        winner_index = tournament_indices[np.argmin(fitness_values[tournament_indices])]
        return population[winner_index]

    def _cauchy_mutation(self, a):
        b,c = self._select_different(a,len(population))
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
    
    def _select_different(self, a, pop_size):
        b = np.random.randint(0,pop_size)
        while b == a:
            b = np.random.randint(0,pop_size)
        c = np.random.randint(0,pop_size)
        while c == a or c == b:
            c = np.random.randint(0,pop_size)
        return population[b], population[c]

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
2025-06-23 22:55:56 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:55:56 ERROR Can not run the algorithm
2025-06-23 22:55:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:55:56 INFO Run function 13 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:55:56 INFO FeHistory: [2352707.03585428 2824739.81997099 3584587.17754124  991900.20668599
  888348.85638211 2208853.49196774 2370215.81474854 2306834.60731403
  762709.86665963 1121383.2887656  1685005.56580305 2815123.64536693
 2254643.88435901 2633572.590633   1201491.64614885  704249.77618274
  804785.96936616 2377364.47627018 2114351.63632916 3545317.70791617
  470899.10058449  740170.36561457 2238637.25891037 1470822.60902723
 1666235.14850847 1424340.26358535  983626.62903581 3773616.35312486
 1459072.92054733 2822989.79477406 2499824.49686441 1839173.23147737
 7296554.83980128 2291954.14394739  979998.91271942 2702765.54425546
 2804475.08981935 1613149.00532367  997031.65385472 1234839.70385082
  540474.41301117 2268759.58610518 3011206.68209883 1187323.36680244
 4474438.26727685 3783517.64334606  660291.05208625 1356096.04596907
 2347731.01971137 1468297.53462054  222530.17272641 2309942.03805452
 3034919.75296408 1056242.41663702 2482742.99501197  518089.84777707
  981704.07048089 3724758.4568605  1386568.29692549  991096.57834732
  961289.66891039 2538882.41284141 2449166.93196771 1292737.04400229
  737011.4797443  1593497.64752184 2944662.91239189 1708076.96116819
 2044394.74719996 4489498.25610397 2863934.77391408 1426318.38357321
 3862550.79173069 1462156.41665466 1027712.48160345 1366761.8077019
  871703.05102576 1125740.971332   2044792.91963273 1930121.67768412
 1782759.18607524  852887.44525319 6310118.65303068 1719891.03002452
 1042939.34505408 1595496.38512309  878805.39737392 2720284.95501017
  735238.22144482 1380589.38604943 1551346.42409381 2109702.05684041
  566728.86147588 2667295.46686411 2767989.50033507  816434.76992214
 2020912.48725482 1029893.30511025 1061773.60614276 3657972.56675483]
2025-06-23 22:55:56 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:55:56 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:55:56 ERROR Can not run the algorithm
2025-06-23 22:55:57 INFO Run function 18 complete. FEHistory len: 100, AOCC: 0.0000
2025-06-23 22:55:57 INFO FeHistory: [218611.8793648  135285.96232024 123846.3234486  143324.94417876
 156154.5592389  124913.18315202 167451.03883327 139994.07249797
 107460.30957534  88156.88489021 135500.91187493 283163.34909061
 166802.45455842 106958.56902065 110145.32138492 190125.82767507
 140216.61400621 179176.41039029 136915.8212449  166711.31803397
 173620.70600703 132824.98522612 110736.94391538 161987.58504384
 114166.95199749  84408.53997056 139414.29254255 196815.26269625
 186528.14596563 193611.19727162 196200.74349884  92154.8687865
 179033.73645142 190645.89164699 166289.07997297 195715.26862639
 101411.21870407 191119.13903506 122749.47656143 124746.92621453
 153983.40635177 155709.24010806  93329.96060917 135930.21535608
 189170.00988024 113149.7510687   97798.29472738 111745.45478956
 112958.4965774   56474.86397438 119946.90527809 157845.20000094
 157852.95590779 176755.44074604 246392.76789405 175091.4170808
 146350.18174317 195649.11560362 134047.77600889 107646.58630594
 169186.71512476 212309.19701553 240414.57342705  91620.98674138
 161591.77207618 130987.23245245 100676.0659957   95061.09547705
 190147.44361722 177878.99797967 193897.39652283 131148.35781188
 124263.57671236 226775.99061136 150946.85749123 175392.33817462
 227780.603523   133360.29535218  86848.76081099 128386.74300524
 137129.26639027 229973.82677525 176913.53984744  93084.30727666
 150350.211628   171785.57137631 176439.3566508  224909.63667027
 120251.33413416 167782.76418737 206491.03082656 223642.13517539
 157769.44885097 116315.93616452 169086.05175245 138946.20240564
 139368.67280562 201621.61206106 158520.544824   126634.32363577]
2025-06-23 22:55:57 INFO Expected Optimum FE: -5000
2025-06-23 22:55:57 INFO Unimodal AOCC mean: 0.1469
2025-06-23 22:55:57 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:55:57 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:55:57 INFO AOCC mean: 0.0490
2025-06-23 22:55:57 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:55:57 ERROR Can not run the algorithm
2025-06-23 22:55:57 INFO Run function 6 complete. FEHistory len: 200, AOCC: 0.1472
2025-06-23 22:55:57 INFO FeHistory: [-183.3561265  -183.25118738 -183.33321238 -183.30692554 -183.33540611
 -183.36882838 -183.31086172 -183.37106539 -183.33345612 -183.41024652
 -183.32333418 -183.34056452 -183.32848237 -183.31216512 -183.31813477
 -183.39488676 -183.36105479 -183.31291045 -183.33833563 -183.3687585
 -183.39557619 -183.31680531 -183.22521436 -183.34228969 -183.37871995
 -183.38792667 -183.3961519  -183.40698122 -183.40359692 -183.32519174
 -183.39572346 -183.29465598 -183.40088344 -183.35416255 -183.37003165
 -183.35867685 -183.43787637 -183.32536672 -183.44908373 -183.31601214
 -183.34498351 -183.31069139 -183.40718673 -183.40683202 -183.34537989
 -183.29894751 -183.33142778 -183.42704691 -183.30391862 -183.49453761
 -183.33800021 -183.40267406 -183.33880068 -183.33454281 -183.35094453
 -183.3804602  -183.38196663 -183.38618469 -183.31650513 -183.36830022
 -183.2819398  -183.4007521  -183.30970158 -183.29956981 -183.35701187
 -183.34726123 -183.40663508 -183.43274141 -183.32798737 -183.3017992
 -183.39330796 -183.34602004 -183.30564414 -183.4231706  -183.29462462
 -183.37820548 -183.43021037 -183.32556842 -183.35976568 -183.32106772
 -183.46011912 -183.36537357 -183.31264355 -183.31340524 -183.41651224
 -183.36011151 -183.26666502 -183.30452803 -183.36865982 -183.4140012
 -183.41355418 -183.32503659 -183.30626012 -183.39615957 -183.31322332
 -183.42903561 -183.42257795 -183.35665106 -183.31666622 -183.39189447
 -183.29627571 -183.20504294 -183.35396796 -183.32019783 -183.39507838
 -183.369977   -183.26932525 -183.40287553 -183.31443386 -183.33985288
 -183.27243955 -183.3364477  -183.26356958 -183.35881843 -183.31380993
 -183.30508629 -183.28583429 -183.30726205 -183.26979296 -183.32480959
 -183.31814126 -183.28900873 -183.28062064 -183.35759238 -183.27229368
 -183.26428908 -183.39550866 -183.29376844 -183.2687214  -183.40603681
 -183.21638487 -183.3036106  -183.29925925 -183.24389349 -183.2283465
 -183.23838754 -183.34840764 -183.31746351 -183.31022087 -183.30446691
 -183.28435243 -183.31234392 -183.30895403 -183.31521295 -183.40169507
 -183.40103337 -183.35469309 -183.31280425 -183.39619931 -183.39560306
 -183.38316314 -183.27237365 -183.31547115 -183.31375058 -183.39371359
 -183.27747362 -183.30343664 -183.39881983 -183.24468454 -183.37177241
 -183.36677499 -183.30752409 -183.26294422 -183.28757343 -183.40217154
 -183.1912696  -183.36532758 -183.26311736 -183.28887188 -183.26803539
 -183.33616271 -183.48045667 -183.34406793 -183.33758539 -183.30899014
 -183.32276443 -183.37712115 -183.3821687  -183.33675508 -183.27635337
 -183.46338109 -183.35276621 -183.29674461 -183.31498485 -183.31097628
 -183.33454282 -183.33564369 -183.29529292 -183.36879546 -183.33214113
 -183.32569922 -183.2922029  -183.33279475 -183.35276693 -183.38452881
 -183.30198268 -183.36565417 -183.27779192 -183.34539351 -183.44087631]
2025-06-23 22:55:57 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:55:57 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveTournamentAndClustering
import numpy as np
from scipy.stats import cauchy
import random

# Name: AdaptiveDEwithCauchyArchiveTournamentAndClustering
# Description:Combines DE, adaptive Cauchy mutation, archive, tournament selection, and clustering for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveTournamentAndClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.archive = [] # Archive of good solutions
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius
        self.cluster_radius = 0.2 * self.niche_radius # Radius for clustering


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._archive_tournament_selection_with_clustering(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_step = np.random.standard_cauchy(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _archive_tournament_selection_with_clustering(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        #Tournament Selection with Archive and Clustering
        tournament_size = 5
        next_gen = []
        next_fit = []
        for i in range(self.population_size):
            tournament_indices = np.random.choice(len(combined_population), tournament_size, replace=False)
            winner_index = tournament_indices[np.argmin(combined_fitness[tournament_indices])]
            winner = combined_population[winner_index]
            winner_fit = combined_fitness[winner_index]

            #Check for Archive and Clustering
            is_unique = True
            for sol in self.archive:
                if np.linalg.norm(winner - sol) < self.cluster_radius: #Cluster Check
                    is_unique = False
                    break

            if is_unique :
                next_gen.append(winner)
                next_fit.append(winner_fit)
                self.archive.append(winner) # Add to archive

        return np.array(next_gen), np.array(next_fit)



    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self):
        self.gamma *= 0.99 # Adapt Cauchy scale
        self.niche_radius *= 0.99 #Gradually reduce niche radius for finer local search
        self.cluster_radius *=0.99 #Adapt cluster radius

2025-06-23 22:55:57 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:55:57 ERROR Can not run the algorithm
2025-06-23 22:55:57 INFO Run function 13 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 22:55:57 INFO FeHistory: [2454833.6412611  1406954.48786107 4541889.21896701 2698514.36884276
 1209614.0606288  1796606.02569942 1667237.33275589  760095.92948683
 1502341.57185709 1003673.53729141  423612.40377183 2845338.02625146
 2144994.18307867 1896803.85377    1836271.67465083  473644.99419131
 2146666.52339327 1088077.25531316 3930989.55028793 2154115.94521776
  938289.51662867 2467877.97786614  854201.3671124  1290577.81363682
 3733268.09683095 3212858.3863671  3431872.15601134 1980321.78023843
  851600.59364552 3757602.35102988 2364155.65282531 3492427.85289334
 2380297.97607254 2925495.89939013 1042873.32795243 1322274.97396306
 1468382.4126976  4457697.87826066 3577556.5821936  2295390.3891135
 2857690.01847425 2758058.99242537 1736236.06831365 1165499.86092895
 5899395.67269819 3140581.29202876 2582283.92041859 2125367.29036029
 2226571.85397337 1553457.32202723  873930.41926364 1449593.80903134
 2113609.12877057 2993681.34324617 3086789.61031545 1343548.40205846
 2757575.21038024 1378283.60011824  575205.31531104 1286654.14705398
 1026373.30415287 4183007.52987266  508522.49571661 4909982.59704566
 2307666.70805969 2472692.4739559  1245152.39622173 1125779.97775656
 1656953.82223851 4674115.55462555 1149657.99711139  849131.84072831
 3051717.52342978  932519.65110362 2508974.5085777   772522.21042577
 1430791.45200234 1059574.26202456 1005702.13160583 4142628.46805772
 2207158.89200773 1034326.94553446 1082158.87208763 1778996.82439909
 2446877.77219216 1705389.37603058 2081577.57810014 1758641.12966144
 2080648.24242513 1640348.92286538 1247370.14296962  782876.45829562
 3992688.83183668  974548.34062268 1557126.61158245 1712599.2717903
  281075.50487391 2620231.56708587 1280089.28630704 1972534.77434465
 4993396.42164427 2526296.11786341  850114.11654829 3245156.92921191
 1241799.61909715 2781791.7537649  1781361.68516797  918561.19755219
 3576626.844008   1750617.60567808 1248347.68855967 1417077.91453203
 4930073.61802479 3513257.10700678 2683232.39830508  869926.21342737
 2973968.61763299 2564766.01082688 4221288.73252866 1995684.29715106
  583682.84909409 2477309.71720203 1336132.44150019 1025724.5059017
 3229474.18322111  620055.95406987 1051745.99280231 2529410.40435791
 5685094.51341797 5718597.5396051  2941129.15825256 2145038.27924857
 2067310.71178618 1274590.97358039 2940191.6597347  1141761.68230828
 1472374.76479678 5285053.24352189 2633736.42725126 1679300.13556533
 1951408.27473416 1111685.72424018  870233.73903539 2286975.46827472
 2127073.66714228  654291.86574288 3384225.92426034 2413621.97000723
 1620846.65671247 1077077.21617551 2988512.2660095  2611815.05673201
 1432953.8054004  2292125.03642244 1682049.22598049 1173419.02942239
 1819935.13735644 1787100.6409889  2128440.54812443 2957805.29624713
 2062449.88489995 2086536.90844498 1397649.61887312 1489968.10687238
 2167331.16975386 2064350.63764709 1582873.80460047 1690530.97550415
 1140432.17150801 2440130.83913564 4654875.55920846 3003665.49456746
 2747100.8322     1380433.28337005 4191745.32378355 3563229.95187448
 3194006.79025235  989714.83470597 2665336.2913259  2131505.60974378
 3024799.504985   2734636.10322039  946915.80163977 2052041.28761681
 4512814.37563454 3945909.25399535 3065778.36898807 2481929.44327809
 3551604.35821894 1872789.39347062 2066085.67383373 3393965.92421507
  972269.30229796 1280860.57037323  259821.67162539 1817459.9851572
  800450.53438078 2320058.99952217 1357108.42744094 1897815.07596827]
2025-06-23 22:55:57 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:55:57 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:55:57 ERROR Can not run the algorithm
2025-06-23 22:55:58 INFO Run function 18 complete. FEHistory len: 200, AOCC: 0.0000
2025-06-23 22:55:58 INFO FeHistory: [126062.85776427 144111.09962743 114972.92874738 165102.54412093
 200938.65978302 158012.1132416  116884.68281275 154366.0683287
 136091.73337077 153637.72457348 147603.98664583 233404.66954195
 119258.20575204 148295.18580636 169344.1374595  172999.09055527
 174321.15132437 110352.139034   131642.6048229  204156.11736964
 122770.12398436 162471.20424013 123837.79155498 100346.52210867
 143097.47081081 117617.73883916 148583.07469055  84596.18621098
 150805.54810817 130513.78647761 138260.03349664 178382.99242391
 172951.77637056 162239.37467971 140716.06476741 168026.58600552
 158013.97534278 109394.93651017 120697.46498212 160805.3089264
 162219.03226786 133503.57448206 129593.3976971  122756.16568004
 186610.50981562 123920.28260136 100970.31924519 197167.90508721
 165111.50937631 130389.39917006 152214.7506881  124747.81099974
 116829.98599621 159949.73460071 130546.98421241 181262.24401739
 136823.75495793 175175.2799445  143891.35872802 178083.70776342
  83416.08607191 199986.02144688 145853.39274164 172355.0562737
 128045.88374978 130431.20368306 176223.97866227 244428.86699754
 184837.57904998 177317.18065206 137037.23907658 125824.04028049
 182712.02351613 132027.9528308   96775.45420391 210626.23802438
 181197.27306336 185312.90304239 178091.72766622 141863.10663262
 212129.27057169  90510.39441827 123836.01990594 123617.71613842
 100784.94157309 112617.89327994 119537.47097777 156018.01992609
 139096.49815007 110577.15109854 123440.95259276 157020.62261465
 137854.3781607  157981.07716117 149255.78830608 116941.91339443
 129245.8551125  106994.95988275 114418.04998522 159651.35864777
 184947.60302392 206935.63815257 144058.1729565   93158.38975905
 162195.15423268 134702.98982246 196187.45907223 103771.31897207
 236606.68392835 222054.6165118  197811.13002702 161368.45301193
 142622.75127594 197804.97982248 123137.03300621 212259.90181896
 188708.46917219 225132.2073106  120341.28597382 178186.49602248
 148148.58928721 132017.73614499 187880.72176756 165768.8557957
 223030.56997869 211600.91280331 234824.98793526 196740.08797735
 206778.05557778 192760.09779073 208259.47560532 130400.47636618
 178119.53528675 143493.25057068 167267.64159108 267083.52387467
 123235.79972065 148244.86205061 113151.97648121 116582.31296026
 254828.5580528  243087.82709311 171386.25411018 248434.76681375
 131170.65498067 208913.2181648  214009.6326056  189939.28134976
 228726.50145608 150645.27081562 186966.96932943 273572.0936877
 245306.50278608 264633.39894372 226838.23394831 150895.32895036
 215243.20296195 207211.09872617 202717.54680522 151086.89975194
 167250.26092105 101719.98476569 206467.86195633 114392.5283827
 187856.8674191  150926.38897409 245697.15593768 170891.39991157
 145662.76688034 235713.43763703 228835.38800241 127021.25367713
 205317.73979401 195496.18922172 174512.00818084 155596.71039012
 231145.01384045 136025.58258585 143570.57045664 147323.81084658
 213523.37100248 198799.12795224 196501.32577402 151589.86223352
 149169.86947097 130701.02291216 143103.89981772 214459.33627437
 158813.75182719 227212.19890427 221741.88048536 134631.10157345
 131170.66833687 214652.08602057 169545.47425487 226137.25278835
 180559.22097984 200554.41442943 193031.27316226 233442.37406753]
2025-06-23 22:55:58 INFO Expected Optimum FE: -5000
2025-06-23 22:55:58 INFO Unimodal AOCC mean: 0.1472
2025-06-23 22:55:58 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:55:58 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:55:58 INFO AOCC mean: 0.0491
2025-06-23 22:55:58 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:56:07 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1484
2025-06-23 22:56:07 INFO FeHistory: [-183.4007253  -183.31779803 -183.33731704 ... -183.35779095 -183.41784555
 -183.40410386]
2025-06-23 22:56:07 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:56:07 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveClustering
import numpy as np
from scipy.stats import cauchy
from sklearn.cluster import KMeans
import random

# Name: AdaptiveDEwithCauchyArchiveClustering
# Description: Combines DE, adaptive Cauchy mutation, archive, and clustering for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveClustering:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, 
    an archive for elite solutions, k-means clustering to maintain diversity,
    and tournament selection for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, cluster_k=5, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5, archive_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.cluster_k = cluster_k
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size
        self.archive = []
        self.archive_size = archive_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
        self.archive = self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            population = self._tournament_selection(np.vstack((population, offspring)), np.concatenate((fitness, offspring_fitness)))
            self.archive = self._update_archive(np.vstack((self.archive, offspring)), np.concatenate((np.array([f[1] for f in self.archive]), offspring_fitness)))
            population = self._maintain_diversity(population)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population)
            mutant = self._cauchy_mutation(a, b, c)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)


    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
    
    def _maintain_diversity(self, population):
        if len(population) < self.cluster_k:
            return population
        kmeans = KMeans(n_clusters=self.cluster_k, random_state=0)
        kmeans.fit(population)
        labels = kmeans.labels_
        
        new_population = []
        for i in range(self.cluster_k):
            cluster_members = np.where(labels == i)[0]
            if len(cluster_members)>0:
                new_population.append(population[np.random.choice(cluster_members)])
        while len(new_population) < self.population_size:
            new_population.append(np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim))
        return np.array(new_population)
    
    def _update_archive(self, population, fitness):
        combined = list(zip(population, fitness))
        combined.sort(key=lambda x: x[1]) # Sort by fitness
        archive = [x[0] for x in combined[:self.archive_size]]
        return np.array(archive)
2025-06-23 22:56:07 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:56:09 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1566
2025-06-23 22:56:09 INFO FeHistory: [-183.37996405 -183.3092013  -183.37424679 ... -184.19488575 -184.19488575
 -184.19488575]
2025-06-23 22:56:09 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:56:09 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyAndTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyAndTournamentSelection
# Description: Combines DE with adaptive Cauchy mutation and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyAndTournamentSelection:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and tournament selection
    for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, tournament_size=5, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.tournament_size = tournament_size
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                #Tournament Selection
                if trial_fitness < self._tournament_selection(population, fitness):
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])


            population = np.array(new_population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _tournament_selection(self, population, fitness_values):
        tournament_indices = np.random.choice(self.population_size, self.tournament_size, replace=False)
        tournament_fitness = fitness_values[tournament_indices]
        best_tournament_index = tournament_indices[np.argmin(tournament_fitness)]
        return fitness_values[best_tournament_index]
2025-06-23 22:56:09 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:56:10 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1603
2025-06-23 22:56:10 INFO FeHistory: [-183.3274833  -183.46119656 -183.31990039 ... -184.40306076 -184.40306076
 -184.40306076]
2025-06-23 22:56:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:56:10 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyClusteringTournamentSelection
import numpy as np
from scipy.stats import cauchy
from sklearn.cluster import KMeans

# Name: AdaptiveDEwithCauchyClusteringTournamentSelection
# Description: Combines DE, adaptive Cauchy mutation, clustering, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyClusteringTournamentSelection:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, 
    k-means clustering for diversity, and tournament selection for 
    robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, cluster_k=5, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.cluster_k = cluster_k
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            population, fitness = self._select_next_generation(population, fitness, offspring, offspring_fitness)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        return fitness

    def _generate_offspring(self, population, fitness):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population)
            mutant = self._cauchy_mutation(a, b, c)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        #Tournament Selection
        next_gen, next_fit = self._tournament_selection(combined_pop, combined_fit)
        
        return next_gen, next_fit

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices], fitness_values[selected_indices]
2025-06-23 22:56:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:56:18 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:56:18 INFO FeHistory: [1539043.12157755  827564.86824267 1778212.91016994 ... 1673931.5615478
 1929878.17131402 2449689.00846775]
2025-06-23 22:56:18 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:56:18 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:56:21 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:56:21 INFO FeHistory: [1.19971845e+06 2.83833927e+06 1.63086468e+06 ... 1.99909322e+03
 1.99909322e+03 1.99909322e+03]
2025-06-23 22:56:21 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:56:21 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:56:22 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:56:22 INFO FeHistory: [2056580.76166836 2835643.96220036 1843329.55150184 ...    3738.09452552
    3738.09452552    3738.09452552]
2025-06-23 22:56:22 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:56:22 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:56:50 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:56:50 INFO FeHistory: [119217.13507662 118375.64800266 121436.95878838 ... 102490.4553354
 119692.18502459 214175.22877859]
2025-06-23 22:56:50 INFO Expected Optimum FE: -5000
2025-06-23 22:56:50 INFO Unimodal AOCC mean: 0.1484
2025-06-23 22:56:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:56:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:56:50 INFO AOCC mean: 0.0495
2025-06-23 22:56:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:56:54 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:56:54 INFO FeHistory: [145313.26748715 161743.39581244 135961.36222263 ...  34595.61965433
  34595.61965433  34595.61965433]
2025-06-23 22:56:54 INFO Expected Optimum FE: -5000
2025-06-23 22:56:54 INFO Unimodal AOCC mean: 0.1603
2025-06-23 22:56:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:56:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:56:54 INFO AOCC mean: 0.0534
2025-06-23 22:56:54 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:56:57 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:56:57 INFO FeHistory: [205534.53835286 146206.2092533  127059.94328405 ...   3718.77289655
   3718.77289655   3718.77289655]
2025-06-23 22:56:57 INFO Expected Optimum FE: -5000
2025-06-23 22:56:57 INFO Unimodal AOCC mean: 0.1566
2025-06-23 22:56:57 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:56:57 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:56:57 INFO AOCC mean: 0.0522
2025-06-23 22:56:57 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:57:07 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1478
2025-06-23 22:57:07 INFO FeHistory: [-183.30145365 -183.3192012  -183.35404435 ... -183.25142756 -183.2956382
 -183.38256736]
2025-06-23 22:57:07 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:57:07 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyMutationAndTournamentSelection
import numpy as np
from scipy.stats import cauchy
from scipy.spatial.distance import cdist

# Name: AdaptiveDEwithCauchyMutationAndTournamentSelection
# Description: Combines DE, adaptive Cauchy mutation, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyMutationAndTournamentSelection:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and tournament selection
    for efficient exploration and exploitation in multimodal optimization problems.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, tournament_size=5, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.tournament_size = tournament_size
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self._tournament_selection(population, fitness, trial, trial_fitness):
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, population):
        indices = np.random.choice(len(population), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _tournament_selection(self, population, fitness, trial, trial_fitness):
        tournament = np.random.choice(len(population), self.tournament_size, replace=False)
        tournament_fitness = fitness[tournament]
        best_tournament_index = tournament[np.argmin(tournament_fitness)]
        if fitness[best_tournament_index] < trial_fitness:
            return fitness[best_tournament_index]
        else:
            return trial_fitness
2025-06-23 22:57:07 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:57:08 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1523
2025-06-23 22:57:08 INFO FeHistory: [-183.33808944 -183.29064359 -183.40551825 ... -183.81157725 -183.80764786
 -183.86657074]
2025-06-23 22:57:08 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:57:08 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyMutationAndClustering
import numpy as np
from scipy.stats import cauchy
import random

# Name: AdaptiveDEwithCauchyMutationAndClustering
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and k-means clustering for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyMutationAndClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.gamma = 0.95  # Cauchy scale factor decay
        self.k = 5 # Number of clusters for k-means


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        cauchy_scale = 0.1 * (self.upper_bounds - self.lower_bounds)

        while self.eval_count < self.budget:
            centroids = self._kmeans_clustering(population, self.k)
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = self._select_different(population, i)
                mutant = a + self.F * (b - c)

                #Adaptive Cauchy Mutation based on cluster distance
                closest_centroid_index = self._closest_centroid(population[i], centroids)
                centroid = centroids[closest_centroid_index]
                distance_to_centroid = np.linalg.norm(population[i] - centroid)
                cauchy_scale_i = cauchy_scale * (1 + distance_to_centroid / np.linalg.norm(self.upper_bounds - self.lower_bounds))
                mutant += cauchy.rvs(loc=0, scale=cauchy_scale_i, size=self.dim)

                jrand = np.random.randint(self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == jrand:
                        offspring[i, j] = mutant[j]
                    else:
                        offspring[i, j] = population[i, j]
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            cauchy_scale *= self.gamma

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _kmeans_clustering(self, population, k):
        centroids = random.sample(list(population), k)
        while True:
            clusters = [[] for _ in range(k)]
            for point in population:
                distances = np.linalg.norm(point - np.array(centroids), axis=1)
                closest_centroid_index = np.argmin(distances)
                clusters[closest_centroid_index].append(point)
            new_centroids = np.array([np.mean(cluster, axis=0) if cluster else centroid for cluster, centroid in zip(clusters, centroids)])
            if np.allclose(centroids, new_centroids):
                break
            centroids = new_centroids
        return centroids

    def _closest_centroid(self, point, centroids):
        distances = np.linalg.norm(point - np.array(centroids), axis=1)
        return np.argmin(distances)

2025-06-23 22:57:08 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:57:20 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:57:20 INFO FeHistory: [2083438.49793925 3409915.22748259 2630808.15160336 ... 2248250.38000543
 1441715.37661894 1631181.21589285]
2025-06-23 22:57:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:57:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:57:21 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1793
2025-06-23 22:57:21 INFO FeHistory: [-183.41420264 -183.3171921  -183.30820776 ... -185.54789625 -185.54789861
 -185.54789353]
2025-06-23 22:57:21 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:57:21 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyMutationAndTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyMutationAndTournamentSelection
# Description: Differential Evolution with adaptive Cauchy mutation and tournament selection for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyMutationAndTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.scale_factor = 1.0  # Initial Cauchy scale factor
        self.scale_decay = 0.95  # Decay rate for scale factor
        self.tournament_size = 5


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Tournament Selection
                parents = self._tournament_selection(population, fitness_values)
                
                a,b,c = self._select_differents(parents,0) #select from parents

                # Differential Evolution
                mutant = a + self.F * (b - c)
                trial = self._crossover(parents[0], mutant) #crossover with best parent
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                # Cauchy mutation for exploration
                trial += cauchy.rvs(loc=0, scale=self.scale_factor, size=self.dim)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    new_population.append(population[i])

                self._update_best(trial, trial_fitness)

            population = np.array(new_population)
            self.scale_factor *= self.scale_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _select_differents(self, population, i):
        candidates = list(range(len(population)))
        candidates.remove(i)
        a, b, c = np.random.choice(candidates, 3, replace=False)
        return population[a], population[b], population[c]

    def _crossover(self, x, v):
        u = np.copy(x)
        indices = np.random.rand(self.dim) < self.CR
        u[indices] = v[indices]
        return u

    def _update_best(self, solution, fitness):
        if fitness < self.best_fitness_overall:
            self.best_fitness_overall = fitness
            self.best_solution_overall = solution

    def _tournament_selection(self, population, fitness_values):
        tournament_size = self.tournament_size
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

2025-06-23 22:57:21 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:57:26 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:57:26 INFO FeHistory: [1361429.08323823 1996436.94094016 1954288.20064139 ... 1986945.62798591
 1799011.3449495  1508625.17215699]
2025-06-23 22:57:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:57:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:57:54 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:57:54 INFO FeHistory: [131145.23886479 161706.24935094 176500.42033858 ... 128134.51665871
 153706.72684594 158399.33736614]
2025-06-23 22:57:54 INFO Expected Optimum FE: -5000
2025-06-23 22:57:54 INFO Unimodal AOCC mean: 0.1478
2025-06-23 22:57:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:57:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:57:54 INFO AOCC mean: 0.0493
2025-06-23 22:58:05 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:58:05 INFO FeHistory: [ 84498.47726262 118924.24491497 119431.24100833 ...   5982.49913719
   9000.81835035   9802.14485215]
2025-06-23 22:58:05 INFO Expected Optimum FE: -5000
2025-06-23 22:58:05 INFO Unimodal AOCC mean: 0.1523
2025-06-23 22:58:05 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:58:05 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:58:05 INFO AOCC mean: 0.0508
2025-06-23 22:58:44 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 22:58:44 INFO FeHistory: [2668864.71391455 1064900.39178992 1051037.0022603  ...    2896.82107772
    2896.82107772    2896.82107772]
2025-06-23 22:58:44 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:58:44 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:00:28 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 23:00:28 INFO FeHistory: [176697.33269802 171670.68295129 173159.98003829 ...  -4392.0333471
  -4392.0333471   -4392.0333471 ]
2025-06-23 23:00:28 INFO Expected Optimum FE: -5000
2025-06-23 23:00:28 INFO Unimodal AOCC mean: 0.1793
2025-06-23 23:00:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:00:28 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:00:28 INFO AOCC mean: 0.0598
2025-06-23 23:02:30 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1528
2025-06-23 23:02:30 INFO FeHistory: [-183.36766199 -183.3783918  -183.28595409 ... -183.88165451 -183.87344134
 -183.92334266]
2025-06-23 23:02:30 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:02:30 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCauchyArchiveAndGaussianRefinement
import numpy as np
from scipy.stats import cauchy
import random

# Name: AdaptiveDEwithCauchyArchiveAndGaussianRefinement
# Description: Combines DE with Cauchy mutation, an archive, and Gaussian refinement for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveAndGaussianRefinement:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.archive = [] # Archive of good solutions
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius
        self.refinement_sigma = 0.1 * (self.upper_bounds - self.lower_bounds) #Initial Gaussian refinement width
        self.refinement_rate = 0.9 #Refinement sigma decay rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._archive_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters()
            #Gaussian Refinement of best solution
            self._gaussian_refinement(objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            cauchy_step = np.random.standard_cauchy(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _archive_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fitness)
        next_gen = combined_population[sorted_indices[:self.population_size]]
        next_fit = combined_fitness[sorted_indices[:self.population_size]]

        for sol in next_gen:
            is_unique = True
            for archived_sol in self.archive:
                if np.linalg.norm(sol - archived_sol) < self.niche_radius:
                    is_unique = False
                    break
            if is_unique:
                self.archive.append(sol)

        return next_gen, next_fit



    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self):
        self.gamma *= 0.99 # Adapt Cauchy scale
        self.niche_radius *= 0.99 #Gradually reduce niche radius
        self.refinement_sigma *= self.refinement_rate

    def _gaussian_refinement(self, objective_function):
        if self.best_solution_overall is not None:
            refined_solution = np.random.normal(self.best_solution_overall, self.refinement_sigma, size=(10, self.dim))
            refined_solution = np.clip(refined_solution, self.lower_bounds, self.upper_bounds)
            refined_fitness = objective_function(refined_solution)
            self.eval_count += len(refined_fitness)
            self._update_best(refined_solution, refined_fitness)
2025-06-23 23:02:30 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:03:54 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 23:03:54 INFO FeHistory: [ 863493.79243978 2436177.23819932 1098696.51005509 ... 1604611.40295431
 1571905.9078275   714281.42151692]
2025-06-23 23:03:54 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:03:54 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:07:38 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 23:07:38 INFO FeHistory: [109606.36955802 180114.12715327 113863.97835634 ...   5983.53291848
  20317.97179627  12897.48683641]
2025-06-23 23:07:38 INFO Expected Optimum FE: -5000
2025-06-23 23:07:38 INFO Unimodal AOCC mean: 0.1528
2025-06-23 23:07:38 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:07:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:07:38 INFO AOCC mean: 0.0509
2025-06-23 23:08:43 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:08:53 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1524
2025-06-23 23:08:53 INFO FeHistory: [-183.34564167 -183.37228311 -183.46053809 ... -183.87760121 -183.82403803
 -183.78605086]
2025-06-23 23:08:53 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:08:53 INFO Good algorithm:
Algorithm Name: AdaptiveCauchyDEwithDiversityArchive
import numpy as np
from scipy.spatial.distance import cdist

# Name: AdaptiveCauchyDEwithDiversityArchive
# Description: Differential Evolution with adaptive Cauchy mutation and a diversity archive for escaping local optima in multimodal landscapes.
# Code:

class AdaptiveCauchyDEwithDiversityArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.gamma = 1.0 #Cauchy scale parameter
        self.gamma_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Differential Evolution
            a, b, c = self._select_differents(i, population.shape[0])
            mutant = population[a] + self.F * (population[b] - population[c])
            
            #Cauchy Mutation
            mutant += np.random.standard_cauchy(self.dim) * self.gamma

            #Binomial Crossover
            jrand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = population[i, j]
            
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring


    def _select_differents(self, exclude_index, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        combined = np.hstack((population, fitness_values.reshape(-1,1)))
        if len(self.archive) < self.archive_size:
            self.archive.extend(combined)
        else:
            distances = cdist(np.array(self.archive)[:,:-1], population)
            closest_index = np.argmin(distances, axis=0)
            for i in range(len(population)):
                if combined[i,-1] < self.archive[closest_index[i]][-1]:
                    self.archive[closest_index[i]] = combined[i]
                    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

2025-06-23 23:08:53 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:09:05 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 23:09:05 INFO FeHistory: [3189810.44782236 3770496.38738653 1133317.95729067 ... 1662200.83400459
 1213638.08736575 2018696.27865698]
2025-06-23 23:09:05 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:09:05 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:09:36 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-23 23:09:36 INFO FeHistory: [178493.25893873 147501.38324797 182872.14312884 ...  37727.25741981
  15184.38377462  42587.42947255]
2025-06-23 23:09:36 INFO Expected Optimum FE: -5000
2025-06-23 23:09:36 INFO Unimodal AOCC mean: 0.1524
2025-06-23 23:09:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:09:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:09:36 INFO AOCC mean: 0.0508
