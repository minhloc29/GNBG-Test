2025-06-24 09:06:46 INFO Initializing first population
2025-06-24 09:06:46 INFO Initializing population from 9 seed files...
2025-06-24 09:11:08 INFO Started evolutionary loop, best so far: 0.29829348684141954
2025-06-24 09:11:08 INFO Population length is: 10
2025-06-24 09:11:08 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-24 09:11:08 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------

### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 18 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 18: 2.9829e-01# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 3 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 4 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 5 (Overall AOCC Score on function 18: 0.0000e+00# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random

class EnhancedArchiveGuidedDE: #aocc 0.15
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale  # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 6 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 7 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 8 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 9 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 10 (Overall AOCC Score on function 18: 0.0000e+00# Name: 
# Description: 
# Code:
```python

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 09:11:14 INFO Full response text: **Analysis:**
Comparing (EnhancedArchiveGuidedDE - rank 1) vs (AdaptiveGaussianSamplingEAwithArchive - rank 9), EnhancedArchiveGuidedDE uses differential evolution which maintains population diversity more robustly compared to the simpler gaussian recombination approach. AdaptiveGaussianSamplingEAwithArchive has less adaptive mechanisms compared to EnhancedArchiveGuidedDE. EnhancedArchiveGuidedDE has better archive management.
Comparing (AdaptiveGaussianSamplingEA - rank 2) vs (AdaptiveMultimodalOptimizerImproved - rank 8), AdaptiveGaussianSamplingEA uses a simple sigma decay while AdaptiveMultimodalOptimizerImproved employs tabu list, more nuanced stagnation detection, adaptive perturbation and simulated annealing style acceptance for move sophisticated handling multimodal optimisation. AdaptiveGaussianSamplingEA concentrates Gaussian sampling in parent generation.
Comparing (EnhancedArchiveGuidedDE - rank 1) vs (AdaptiveGaussianSamplingEA - rank 2), EnhancedArchiveGuidedDE uses archive for pbest selection and updates this archive promoting population diversity whereas AdaptiveGaussianSamplingEA apply tournament selection and sigma decay. Differential evolution mechanism is the most different.
Comparing (AdaptiveGaussianArchiveEA - rank 3) vs (AdaptiveGaussianMutationDE - rank 4), AdaptiveGaussianArchiveEA maintain an external archive to encourage exploration. AdaptiveGaussianMutationDE introduce adaptive perturbation. They all has mutation scale or adaptive mutation parameter which decrease over generation.
Comparing (AdaptiveGaussianSamplingEAwithArchive - rank 9) vs (AdaptiveMultimodalOptimizerImproved - rank 8),AdaptiveMultimodalOptimizerImproved includes Simulated Annealing combined with tabu list whereas AdaptiveGaussianSamplingEAwithArchive doesn't, so they have a very different mechanisms.
Comparing (AdaptiveMultimodalOptimizerImproved - rank 8) vs (AdaptiveDifferentialEvolutionWithEnhancedInitialization - rank 7), Both methods incorporate adaptive components and techniques to manage complex optimization landscapes. AdaptiveDifferentialEvolutionWithEnhancedInitialization, the "enhanced initialization" may sometimes be more effective with domain knowledge such as known optima. Overall: Enhanced exploration with adaptive parameters leads to better performing heuristics for this benchmark. Archive mechanisms may also help.

**Experience:**
Effective heuristics for multimodal optimization involve adaptive parameters for exploration/exploitation balance, robust population diversity mechanisms like differential evolution or external archives, and techniques to avoid local optima like tabu lists, perturbation, or simulated annealing acceptance criteria. Domain knowledge (if available) can improve initial population.

2025-06-24 09:11:16 INFO Full response text: Okay, here's a refined take on self-reflection to generate better heuristics for multimodal optimization, keeping in mind effective strategies and pitfalls:

*   **Keywords:** Adaptive parameters, diversity maintenance, local optima avoidance, knowledge integration.

*   **Advice:** Focus on understanding problem landscape. Explore parameter self-tuning. Experiment with hybridizing methods for combined strengths. Quantify exploration/exploitation trade-offs.

*   **Avoid:** Premature convergence, stagnation, reliance on fixed parameters, neglecting domain insights where available.

*   **Explanation:** Superior heuristics emerge from adaptable mechanisms, robust search techniques, and an awareness of the specific optimization landscape to overcome local optima while retaining population diversity and problem understanding.

2025-06-24 09:11:16 INFO Generating offspring via Crossover...
2025-06-24 09:15:08 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------


### Better code
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Worse code
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Analyze & experience
- Comparing (EnhancedArchiveGuidedDE - rank 1) vs (AdaptiveGaussianSamplingEAwithArchive - rank 9), EnhancedArchiveGuidedDE uses differential evolution which maintains population diversity more robustly compared to the simpler gaussian recombination approach. AdaptiveGaussianSamplingEAwithArchive has less adaptive mechanisms compared to EnhancedArchiveGuidedDE. EnhancedArchiveGuidedDE has better archive management.
Comparing (AdaptiveGaussianSamplingEA - rank 2) vs (AdaptiveMultimodalOptimizerImproved - rank 8), AdaptiveGaussianSamplingEA uses a simple sigma decay while AdaptiveMultimodalOptimizerImproved employs tabu list, more nuanced stagnation detection, adaptive perturbation and simulated annealing style acceptance for move sophisticated handling multimodal optimisation. AdaptiveGaussianSamplingEA concentrates Gaussian sampling in parent generation.
Comparing (EnhancedArchiveGuidedDE - rank 1) vs (AdaptiveGaussianSamplingEA - rank 2), EnhancedArchiveGuidedDE uses archive for pbest selection and updates this archive promoting population diversity whereas AdaptiveGaussianSamplingEA apply tournament selection and sigma decay. Differential evolution mechanism is the most different.
Comparing (AdaptiveGaussianArchiveEA - rank 3) vs (AdaptiveGaussianMutationDE - rank 4), AdaptiveGaussianArchiveEA maintain an external archive to encourage exploration. AdaptiveGaussianMutationDE introduce adaptive perturbation. They all has mutation scale or adaptive mutation parameter which decrease over generation.
Comparing (AdaptiveGaussianSamplingEAwithArchive - rank 9) vs (AdaptiveMultimodalOptimizerImproved - rank 8),AdaptiveMultimodalOptimizerImproved includes Simulated Annealing combined with tabu list whereas AdaptiveGaussianSamplingEAwithArchive doesn't, so they have a very different mechanisms.
Comparing (AdaptiveMultimodalOptimizerImproved - rank 8) vs (AdaptiveDifferentialEvolutionWithEnhancedInitialization - rank 7), Both methods incorporate adaptive components and techniques to manage complex optimization landscapes. AdaptiveDifferentialEvolutionWithEnhancedInitialization, the "enhanced initialization" may sometimes be more effective with domain knowledge such as known optima. Overall: Enhanced exploration with adaptive parameters leads to better performing heuristics for this benchmark. Archive mechanisms may also help.
- Okay, here's a refined take on self-reflection to generate better heuristics for multimodal optimization, keeping in mind effective strategies and pitfalls:

*   **Keywords:** Adaptive parameters, diversity maintenance, local optima avoidance, knowledge integration.

*   **Advice:** Focus on understanding problem landscape. Explore parameter self-tuning. Experiment with hybridizing methods for combined strengths. Quantify exploration/exploitation trade-offs.

*   **Avoid:** Premature convergence, stagnation, reliance on fixed parameters, neglecting domain insights where available.

*   **Explanation:** Superior heuristics emerge from adaptable mechanisms, robust search techniques, and an awareness of the specific optimization landscape to overcome local optima while retaining population diversity and problem understanding.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 09:15:08 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------


Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- Okay, here's a refined take on self-reflection to generate better heuristics for multimodal optimization, keeping in mind effective strategies and pitfalls:

*   **Keywords:** Adaptive parameters, diversity maintenance, local optima avoidance, knowledge integration.

*   **Advice:** Focus on understanding problem landscape. Explore parameter self-tuning. Experiment with hybridizing methods for combined strengths. Quantify exploration/exploitation trade-offs.

*   **Avoid:** Premature convergence, stagnation, reliance on fixed parameters, neglecting domain insights where available.

*   **Explanation:** Superior heuristics emerge from adaptable mechanisms, robust search techniques, and an awareness of the specific optimization landscape to overcome local optima while retaining population diversity and problem understanding.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-24 09:16:25 INFO Perform Harmony Search...
2025-06-24 09:16:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:37 ERROR Can not run the algorithm
2025-06-24 09:16:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:37 INFO FeHistory: []
2025-06-24 09:16:37 INFO Expected Optimum FE: -5000
2025-06-24 09:16:37 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:37 INFO AOCC mean: 0.0000
2025-06-24 09:16:37 INFO Weighed AOCC mean: nan
2025-06-24 09:16:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:37 ERROR Can not run the algorithm
2025-06-24 09:16:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:37 INFO FeHistory: []
2025-06-24 09:16:37 INFO Expected Optimum FE: -5000
2025-06-24 09:16:37 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:37 INFO AOCC mean: 0.0000
2025-06-24 09:16:37 INFO Weighed AOCC mean: nan
2025-06-24 09:16:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:37 ERROR Can not run the algorithm
2025-06-24 09:16:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:37 INFO FeHistory: []
2025-06-24 09:16:37 INFO Expected Optimum FE: -5000
2025-06-24 09:16:37 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:37 INFO AOCC mean: 0.0000
2025-06-24 09:16:37 INFO Weighed AOCC mean: nan
2025-06-24 09:16:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:37 ERROR Can not run the algorithm
2025-06-24 09:16:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:37 INFO FeHistory: []
2025-06-24 09:16:37 INFO Expected Optimum FE: -5000
2025-06-24 09:16:37 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:37 INFO AOCC mean: 0.0000
2025-06-24 09:16:37 INFO Weighed AOCC mean: nan
2025-06-24 09:16:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:37 ERROR Can not run the algorithm
2025-06-24 09:16:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:37 INFO FeHistory: []
2025-06-24 09:16:37 INFO Expected Optimum FE: -5000
2025-06-24 09:16:37 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:37 INFO AOCC mean: 0.0000
2025-06-24 09:16:37 INFO Weighed AOCC mean: nan
2025-06-24 09:16:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:37 ERROR Can not run the algorithm
2025-06-24 09:16:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:37 INFO FeHistory: []
2025-06-24 09:16:37 INFO Expected Optimum FE: -5000
2025-06-24 09:16:37 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:37 INFO AOCC mean: 0.0000
2025-06-24 09:16:37 INFO Weighed AOCC mean: nan
2025-06-24 09:16:38 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:38 ERROR Can not run the algorithm
2025-06-24 09:16:38 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:38 INFO FeHistory: []
2025-06-24 09:16:38 INFO Expected Optimum FE: -5000
2025-06-24 09:16:38 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:38 INFO AOCC mean: 0.0000
2025-06-24 09:16:38 INFO Weighed AOCC mean: nan
2025-06-24 09:16:38 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:38 ERROR Can not run the algorithm
2025-06-24 09:16:38 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:38 INFO FeHistory: []
2025-06-24 09:16:38 INFO Expected Optimum FE: -5000
2025-06-24 09:16:38 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:38 INFO AOCC mean: 0.0000
2025-06-24 09:16:38 INFO Weighed AOCC mean: nan
2025-06-24 09:16:38 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:38 ERROR Can not run the algorithm
2025-06-24 09:16:38 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:38 INFO FeHistory: []
2025-06-24 09:16:38 INFO Expected Optimum FE: -5000
2025-06-24 09:16:38 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:38 INFO AOCC mean: 0.0000
2025-06-24 09:16:38 INFO Weighed AOCC mean: nan
2025-06-24 09:16:38 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:16:38 ERROR Can not run the algorithm
2025-06-24 09:16:38 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:16:38 INFO FeHistory: []
2025-06-24 09:16:38 INFO Expected Optimum FE: -5000
2025-06-24 09:16:38 INFO Unimodal AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:16:38 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:16:38 INFO AOCC mean: 0.0000
2025-06-24 09:16:38 INFO Weighed AOCC mean: nan
2025-06-24 09:16:38 INFO Generation 1, best so far: 0.7606208200367927
2025-06-24 09:16:38 INFO Population length is: 10
2025-06-24 09:16:38 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-24 09:16:38 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------

### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 18 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridDE
# Description: Combines Adaptive Gaussian Mutation with archive-guided differential evolution to explore multimodal landscapes effectively.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDE
# Description: Combines Adaptive Gaussian Mutation with archive-guided differential evolution to explore multimodal landscapes effectively.
# Code:
class AdaptiveHybridDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        """
        Initializes the AdaptiveHybridDE algorithm.

        Args:
            budget: The maximum number of function evaluations allowed.
            dim: The dimensionality of the problem.
            lower_bounds: A list of lower bounds for each dimension.
            upper_bounds: A list of upper bounds for each dimension.
        """
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Common heuristic
        self.population = None
        self.fitness_values = None
        self.archive_size = 100
        self.archive = []
        self.mutation_scale = 0.8  # Initial mutation scale
        self.mutation_scale_decay = 0.99  # Decay factor for the mutation scale
        self.crossover_rate = 0.5
        self.F_scale = 0.5 # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """
        Optimizes the given objective function using the AdaptiveHybridDE algorithm.

        Args:
            objective_function: The function to optimize.  It should accept a 2D numpy array (N, dim)
                                  and return a 1D numpy array of N fitness values.
            acceptance_threshold: The acceptance threshold for convergence (not actively used).

        Returns:
            A tuple containing the best solution found, its fitness, and optimization information.
        """
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Archive-guided Differential Mutation
                if self.archive:
                    pbest_index = np.random.choice(len(self.archive))
                    pbest = self.archive[pbest_index][0]
                else:
                     pbest = self.population[np.argmin(self.fitness_values)]

                a, b = random.sample(range(self.population_size), 2)
                while a == i or b == i :
                    a, b = random.sample(range(self.population_size), 2)
                
                # DE mutation with pbest guidance
                mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])

                #Adaptive Gaussian perturbation for escaping local optima
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)

                # Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.population[i])

                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]  # Ensure correct input shape

                self.eval_count += 1  # Increment evaluation counter inside loop!!
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)

                    #Update Archive when a trial is successful.
                    self._update_archive(trial,trial_fitness)

                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                #Find best candidate for current populations
                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                #See the Global results
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay  # Decay mutation scale
            # Adaptive scaling factor (introduce after each generation)
            self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        """Initializes the population with uniformly random values within the bounds."""
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
         """Evaluates the fitness of all individuals in the population."""
         population_reshaped = self.population.reshape(-1, self.dim) #This solve the errors
         fitness = objective_function(population_reshaped) #Pass the well shaped array
         self.eval_count += self.population_size
         return fitness


    def _select_different(self, index):
        """Selects three different indices from the population, excluding the given index."""
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        """Finds the best solution in the population."""
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, offspring, offspring_fitness):
        """Update the external archive with new offspring for guiding search direction."""
        if len(self.archive) < self.archive_size:
            self.archive.append((offspring, offspring_fitness))
        else:
            #Prioritize diversity in archive by replacing the worst member
            worst_index = np.argmax([f for _, f in self.archive])
            if offspring_fitness < self.archive[worst_index][1] :
                self.archive[worst_index] = (offspring, offspring_fitness)
```

### Rank 2 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridDEWithArchiveAndSA
# Description: Combines differential evolution with an archive and simulated annealing for robust global search.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDEWithArchiveAndSA
# Description: Combines differential evolution with an archive and simulated annealing for robust global search.

class AdaptiveHybridDEWithArchiveAndSA:
    """
    Combines adaptive differential evolution, an external archive for diversity, 
    and simulated annealing to escape local optima.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.5  # DE Parameter
        self.CR = 0.9 # DE Parameter
        self.temperature = 100  # Simulated Annealing Parameters
        self.cooling_rate = 0.995
        self.min_temperature = 1e-4

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Differential Evolution Mutation
                indices = list(range(self.population_size))
                indices.remove(i)
                a, b, c = random.sample(indices, 3)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                crossover_mask = np.random.rand(self.dim) < self.CR
                trial_vector = np.where(crossover_mask, mutant, population[i])

                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
                self.eval_count += 1

                # Simulated Annealing acceptance criterion
                delta = trial_fitness - fitness_values[i]
                if delta < 0:
                    population[i] = trial_vector
                    fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector
                else:
                    acceptance_probability = np.exp(-delta / self.temperature)
                    if random.random() < acceptance_probability:
                        population[i] = trial_vector
                        fitness_values[i] = trial_fitness

            # Update archive
            self.archive = self._update_archive(population, fitness_values)

            # Cool the temperature
            self.temperature *= self.cooling_rate
            self.temperature = max(self.temperature, self.min_temperature)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 3 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation
# Description: Combines archive-guided DE with adaptive Gaussian perturbation to balance exploration and exploitation.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation
# Description: Combines archive-guided DE with adaptive Gaussian perturbation to balance exploration and exploitation.
# Code:
class AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation:
    """
    Combines archive-guided DE with adaptive Gaussian perturbation to balance exploration and exploitation,
    tackling multimodal landscapes effectively.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor
        self.mutation_scale = 0.1 # Gaussian mutation scaling
        self.mutation_decay = 0.99 #decay mutation
        self.crossover_rate = 0.5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            self.mutation_scale *= self.mutation_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            #Adaptive Gaussian Perturbation
            mutant += np.random.normal(0, self.mutation_scale, self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling
            
            # Crossover operation
            cross_points = np.random.rand(self.dim) < self.crossover_rate
            offspring[i] = np.where(cross_points, offspring[i], population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 4 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridDEWithLocalSearch
# Description: Combines adaptive differential evolution with local search and archive to improve exploration and exploitation.
# Code:
```python
import numpy as np
import random
from scipy.optimize import minimize

# Name: AdaptiveHybridDEWithLocalSearch
# Description: Combines adaptive differential evolution with local search and archive to improve exploration and exploitation.
# Code:
class AdaptiveHybridDEWithLocalSearch:
    """
    Combines adaptive differential evolution with local search and archive to improve exploration and exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50  # Adjusted population size
        self.archive_size = 50 # Archive to keep diverse solutions
        self.archive = [] #list of solution in archive
        self.population = None
        self.F = 0.5 # Differential Evolution scaling factor, will adapt.
        self.CR = 0.7 # Crossover rate.
        self.local_search_freq = 10 # Frequency of performing local search
        self.lr_local_search = 0.1  # learning rate for local search step


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        generation = 0
        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation using combination of population and offspring
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]
             
            # Adaptive F
            self.F = 0.5 + 0.3*np.random.rand()  # Adapt F dynamically

            # Local Search
            if generation % self.local_search_freq == 0:
                # Apply local search to the best individual of the current population
                index_best = np.argmin(fitness)
                best_individual = self.population[index_best].copy()  # Create copy for local search

                # Use L-BFGS-B for local search
                result = minimize(objective_function, best_individual, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < fitness[index_best]: #If the result improves the fitness, replace the old individual by the optimized one
                    best_individual = result.x
                    fitness[index_best] = result.fun
                    self.eval_count += result.nfev
                    self.population[index_best] = best_individual
                    if fitness[index_best] < self.best_fitness_overall:
                         self.best_solution_overall = best_individual
                         self.best_fitness_overall = fitness[index_best]


            #Update best solution so far
            if np.min(fitness) < self.best_fitness_overall:
                self.best_solution_overall = self.population[np.argmin(fitness)]
                self.best_fitness_overall = np.min(fitness)

            generation += 1 #Count generation




        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Use pbest from the archive with a higher probability if archive is sufficiently full
            if self.archive and random.random() < 0.7:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                # If the archive is not available or the random condition is not met, use current best from pop
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            # DE mutation. Use adaptive scaling factor.
            offspring[i] = population[i] + self.F * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive. Replace worst member with probability
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or random.random() < 0.1 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 5 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridDEwithArchive
# Description: Combines adaptive differential evolution with an archive for exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDEwithArchive
# Description: Combines adaptive differential evolution with an archive for exploration and exploitation in multimodal landscapes.
# Code:
class AdaptiveHybridDEwithArchive:
    """
    Combines adaptive differential evolution with an archive to enhance exploration
    and exploitation, uses gaussian mutation and an external archive.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # Differential evolution parameter
        self.CR = 0.7  # Crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling
        self.sigma_decay = 0.99 # Sigma decay rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Mutation
                indices = np.random.choice(self.population_size, 3, replace=False)
                x1, x2, x3 = population[indices]

                # Use pbest from archive
                if len(self.archive) > 0 and random.random() < 0.1:
                    pbest_index = np.argmin(self.archive[:, -1])
                    pbest = self.archive[pbest_index, :-1]
                    mutant = pbest + self.F * (x2 - x3)
                else:
                     mutant = x1 + self.F * (x2 - x3)   # original DE

                # Gaussian mutation hybrid
                mutant = mutant + np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial_vector = np.copy(population[i])
                for j in range(self.dim):
                    if random.random() < self.CR or j == random.randint(0, self.dim - 1):
                        trial_vector[j] = mutant[j]

                trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
                self.eval_count += 1

                # Selection
                if trial_fitness < fitness_values[i]:
                    population[i] = trial_vector
                    fitness_values[i] = trial_fitness

                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector

            self.archive = self._update_archive(population, fitness_values)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1]) # sort to archive best ones
        if len(new_archive) > 0: #prevent error if the new archive if empty
            new_archive = np.array(new_archive)
            if len(self.archive) > 0 :
                combined_archive = np.vstack((self.archive, new_archive))
                combined_archive = combined_archive[np.argsort(combined_archive[:, -1])]  # Sort archive based on fitness
                self.archive = combined_archive[:self.archive_size]
            else:
                self.archive = new_archive[:self.archive_size]
        return self.archive
```

### Rank 6 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveGaussianDifferentialEvolutionArchive
# Description: Integrates adaptive Gaussian mutation with differential evolution, leveraging an archive to maintain diversity.
# Code:
```python
import numpy as np
from scipy.optimize import minimize

# Name: AdaptiveGaussianDifferentialEvolutionArchive
# Description: Integrates adaptive Gaussian mutation with differential evolution, leveraging an archive to maintain diversity.
# Code:
class AdaptiveGaussianDifferentialEvolutionArchive:
    """
    Combines Adaptive Gaussian Mutation, Differential Evolution, and Archiving for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 100
        self.F = 0.7  # DE scaling factor, reduced magnitude
        self.CR = 0.8  # Crossover rate, reduced magnitude
        self.sigma = 0.1 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.995 # Sigmma decay rate
        self.archive_size = 50
        self.archive = []
        self.archive_fitness = []

    def _initialize_population(self):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _update_archive(self, population, fitness):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append(population[i].copy())
                self.archive_fitness.append(fitness[i])
            else:
                worst_index = np.argmax(self.archive_fitness)
                if fitness[i] < self.archive_fitness[worst_index]:
                    self.archive[worst_index] = population[i].copy()
                    self.archive_fitness[worst_index] = fitness[i]

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += len(fitness)

        best_index = np.argmin(fitness)
        self.best_solution_overall = population[best_index].copy()
        self.best_fitness_overall = fitness[best_index]

        self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                #DE
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c]) # DE mutation

                #Archive interaction
                if np.random.rand() < 0.1 and len(self.archive) > 0: # Archive interaction Probability
                    arc_idx = np.random.randint(len(self.archive))
                    mutant = population[a] + self.F * (self.archive[arc_idx] - population[c]) # Archive interaction

                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Adaptive Gaussian Mutation
                mutant = mutant + np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1

                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population

            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index].copy()

            self._update_archive(population, fitness)

            self.sigma *= self.sigma_decay #Sigma decay
        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 7 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveDifferentialEvolutionArchiveGaussianMutation
# Description: Combines DE with archive, adaptive mutation scaling, and Gaussian perturbation.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolutionArchiveGaussianMutation
# Description: Combines DE with archive, adaptive mutation scaling, and Gaussian perturbation.
# Code:
class AdaptiveDifferentialEvolutionArchiveGaussianMutation:
    """
    Combines DE with archive for enhanced exploration, adaptive mutation scaling, and gaussian perturbation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 100
        self.archive = []
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        self.archive = self._update_archive(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                # Adaptive Gaussian perturbation + Archive-guided perturbation
                archive_contribution = np.zeros(self.dim)
                if self.archive:
                    archive_individual = random.choice(self.archive)[:, :-1] #choose a random indiv from the archive, removing its fitness
                    archive_contribution = 0.1 * (archive_individual - self.population[i]) #bias mutation towards archive
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim) + archive_contribution

                # Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                
                if trial_fitness < self.best_fitness_overall:
                   self.best_solution_overall = trial
                   self.best_fitness_overall = trial_fitness

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay
            self.archive = self._update_archive(self.population, self.fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1]) #sort by fitness before trim
        self.archive = new_archive[:self.archive_size]  # Trim to archive size
        return np.array(self.archive)
```

### Rank 8 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveGaussianDEWithArchive
# Description: Combines adaptive Gaussian mutation with differential evolution and an archive to balance exploration/exploitation.
# Code:
```python
import numpy as np

# Name: AdaptiveGaussianDEWithArchive
# Description: Combines adaptive Gaussian mutation with differential evolution and an archive to balance exploration/exploitation.

class AdaptiveGaussianDEWithArchive:
    """
    Combines adaptive Gaussian mutation with differential evolution and an archive
    to promote diversity and escape local optima in multimodal optimization.
    """

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        """
        Initializes the Adaptive Gaussian DE with Archive optimizer.

        Args:
            budget (int): The maximum number of function evaluations.
            dim (int): The dimensionality of the problem.
            lower_bounds (list[float]): The lower bounds of the search space for each dimension.
            upper_bounds (list[float]): The upper bounds of the search space for each dimension.
        """
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50  # Reduced population size for efficiency. It appears that a small value for the population helps
        self.archive_size = 100
        self.archive = []
        self.F = 0.7  # Differential evolution parameter
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.1 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian mutation scale (small)
        self.sigma_decay = 0.995  # Reduced decay rate
        self.adaptive_mutation_prob = 0.1  # Probability of applying Gaussian mutation
        self.perturbation_frequency = 10  # Reduce perturbation frequency
        self.stagnation_counter = 0

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """
        Optimizes the given objective function using Adaptive Gaussian DE with Archive.

        Args:
            objective_function (callable): The objective function to minimize.  It accepts
                  a 2D numpy array of shape (N, dim) as input, and returns a 1D numpy
                  array of length N as output
            acceptance_threshold (float): The acceptance threshold for early stopping (not used).

        Returns:
            tuple: A tuple containing the best solution found, its fitness, and optimization information.
        """
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([]) # Empty solution
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            new_population = np.copy(population)  # Create a copy for modification

            for i in range(self.population_size):
                # Differential Evolution Mutation
                idxs = [idx for idx in range(self.population_size) if idx != i]
                a, b, c = np.random.choice(idxs, 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])

                # Adaptive Gaussian Mutation with probability
                if np.random.rand() < self.adaptive_mutation_prob:
                    mutant = mutant + np.random.normal(0, self.sigma, self.dim)

                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                cross_points = np.random.rand(self.dim) < self.CR
                if not np.any(cross_points):
                    cross_points[np.random.randint(0, self.dim)] = True # Ensure at least one point is crossed

                trial = np.where(cross_points, mutant, population[i])

                # Evaluation
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                
                # Selection
                if trial_fitness < fitness_values[i]:
                    new_population[i] = trial
                    fitness_values[i] = trial_fitness

                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial

            # Archive Update
            self.archive = self._update_archive(new_population, fitness_values)

            #Perturb occasionally to jump out of local optima using information from the archive
            if self.eval_count % self.perturbation_frequency == 0 and len(self.archive) > 0:
                    archive_idx = np.random.randint(0, len(self.archive))
                    archive_sol = self.archive[archive_idx][:-1]
                    population[np.random.randint(0, self.population_size)] = archive_sol
            
            # Adaptive sigma adjustment
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        """Initializes the population with random values within the bounds."""
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _update_archive(self, population, fitness_values):
        """Updates the archive with new solutions, sorted by fitness."""
        combined = np.column_stack((population, fitness_values)) # shape (N, dim + 1) where last column represents fitness score
        
        # Filter out already-present individuals by comparing individual solutions
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-8) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive = np.array(new_archive)
        # combine with archive if we have enough space otherwise, replace
        if len(new_archive) > 0:
            combined_archive = np.vstack((self.archive,new_archive))
        else:
            combined_archive = self.archive
        # Ensure we only select at maximum the archive size. This helps maintain diversity.
        sorted_indices = np.argsort(combined_archive[:, -1]) # Sort with respect to fitness score
        combined_archive_sorted = combined_archive[sorted_indices]
        
        return combined_archive_sorted[:self.archive_size] if len(combined_archive_sorted) > self.archive_size else combined_archive_sorted
```

### Rank 9 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptivePopulationDE
# Description: 
# Code:
```python
import numpy as np
import random

# Name: AdaptivePopulationDE
# Description: An adaptive Differential Evolution algorithm with dynamic population size, enhanced mutation strategies, and a restart mechanism to escape local optima in complex multimodal landscapes.
# Code:
class AdaptivePopulationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 initial_population_size_multiplier: int = 6.259517085235587,
                 crossover_rate: float = 0.6302144719768078,
                 mutation_factor: float = 0.8404438983598091,
                 archive_size: int = 198.41542957652703,
                 min_population_size_multiplier: int = 7.099100844498888,
                 max_population_size_multiplier: int = 27.00620506135386,
                 population_adaptation_rate: float = 0.24796802791365374,
                 stagnation_threshold: int = 8712.034667801843,
                 archive_selection_probability: float = 0.22025513634507973,
                 population_increase_factor: float = 1.1991376223688384,
                 population_decrease_factor: float = 0.9485870556564804,
                 restart_population_percentage: float = 0.7705322591007826):

        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = initial_population_size_multiplier * self.dim
        self.population = None
        self.fitness = None
        self.F = crossover_rate  # Crossover rate
        self.Cr = mutation_factor # Mutation factor

        self.archive = []
        self.archive_size = archive_size

        self.min_population_size = min_population_size_multiplier * self.dim
        self.max_population_size = max_population_size_multiplier * self.dim
        self.population_adaptation_rate = population_adaptation_rate
        self.stagnation_counter = 0
        self.stagnation_threshold = stagnation_threshold  # Number of evaluations without improvement before restart
        self.archive_selection_probability = archive_selection_probability
        self.population_increase_factor = population_increase_factor
        self.population_decrease_factor = population_decrease_factor
        self.restart_population_percentage = restart_population_percentage


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0

        # Initialize population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness)]
        self.best_fitness_overall = np.min(self.fitness)

        self.stagnation_counter = 0 # Reset Stagnation counter


        while self.eval_count < self.budget:
            # Generate offspring using an enhanced DE mutation strategy
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

             # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Selection: Replace parents with better offspring
            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            #Update best solution
            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0 # Reset if improvement occurs

            else:
                 self.stagnation_counter += len(offspring)

            # Adaptive population size adjustment
            self.adjust_population_size()


            # Stagnation check and restart mechanism
            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info



    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Mutation: "DE/current-to-best/1" with archive influence
            if self.archive and random.random() < self.archive_selection_probability:  # Utilize the archive probabilistically
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0] # Select a random member of the archive
            else:
                pbest = self.population[np.argmin(self.fitness)] #Fall back to best in current population

            indices = list(range(self.population_size))
            indices.remove(i) # Ensure distinct indices
            a, b = random.sample(indices, 2) # Select two unique indices

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            # Crossover: Binomial crossover
            for j in range(self.dim):
                if random.random() > self.Cr: # Perform binomial crossover
                    mutant[j] = self.population[i][j]  # Keep parent's gene

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive replacement
                worst_index = np.argmax([f for _, f in self.archive]) # Find worst fitness in archive
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])




    def adjust_population_size(self):
        if random.random() < self.population_adaptation_rate: # Control adaptation frequency
            if self.stagnation_counter > self.stagnation_threshold / 2: # Stagnation suggests too small, increase pop
                self.population_size = min(int(self.population_size * self.population_increase_factor), self.max_population_size)
            else: # Otherwise may reduce population to encourage convergence
                self.population_size = max(int(self.population_size * self.population_decrease_factor), self.min_population_size)
        self.population_size = int(self.population_size) # Ensure population size remains an integer.



    def restart_population(self, objective_function):
        # Option 1: Re-initialize entire population
        # self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        # self.fitness = objective_function(self.population)
        # self.eval_count += self.population_size
        # best_index = np.argmin(self.fitness)
        # if self.fitness[best_index] < self.best_fitness_overall:
        #      self.best_solution_overall = self.population[best_index]
        #      self.best_fitness_overall = self.fitness[best_index]

        # Option 2: Keep best solution and re-initialize the rest (exploitation of best)
        num_reinitialized = int(self.restart_population_percentage * self.population_size)  # Re-initialize 80% of the pop.
        self.population[num_reinitialized:] = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size - num_reinitialized, self.dim))
        self.fitness[num_reinitialized:] = objective_function(self.population[num_reinitialized:])
        self.eval_count += (self.population_size - num_reinitialized) # Update evaluation count
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 09:16:43 INFO Full response text: **Analysis:**
Comparing (AdaptiveHybridDE) vs (AdaptivePopulationDE), we see AdaptiveHybridDE employs a simpler mutation strategy combining archive guidance and Gaussian perturbation, while AdaptivePopulationDE uses "DE/current-to-best/1" with probabilistic archive influence, and adaptive population size, and a restart mechanism. AdaptiveHybridDE focuses more on intensification around promising regions, while AdaptivePopulationDE balances exploration and exploitation more aggressively with frequent population adjustments and restarts. AdaptiveHybridDE applies the global archive only on best candidate.

Comparing (AdaptiveHybridDEWithArchiveAndSA) vs (AdaptiveGaussianDEWithArchive), AdaptiveHybridDEWithArchiveAndSA uses simulated annealing for further exploration to escape local optima, in addition to differential evolution and archiving. AdaptiveGaussianDEWithArchive simply uses adaptive Gaussian mutation with differential evolution and an archive. AdaptiveHybridDEWithArchiveAndSA incorporates a more explicit mechanism (SA) for jumping out of local optima. AdaptiveGaussianDEWithArchive maintains constant Archive size along processing, which allows memory constant and better performance.

Comparing (AdaptiveHybridDE) vs (AdaptiveHybridDEWithArchiveAndSA), the use of Simulated Annealing in AdaptiveHybridDEWithArchiveAndSA introduces a probabilistic acceptance criterion based on temperature, allowing it to escape local optima by sometimes accepting worse solutions. Archive-guided Differential Mutation appears to be more efficient without the SA element. AdaptiveHybridDE maintains contant F_scale along proccessing.

Comparing (AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation) vs (AdaptiveHybridDEWithLocalSearch), AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation uses a decay schedule for the Gaussian mutation scaling to reduce perturbation over time. AdaptiveHybridDEWithLocalSearch applies local search using L-BFGS-B to the best individual periodically. AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation seems simpler but less precise, local search is a more guided and precise step that helps jump quickly on promising areas.

Comparing (AdaptiveHybridDEwithArchive) vs (AdaptiveDifferentialEvolutionArchiveGaussianMutation), AdaptiveHybridDEwithArchive adapts the width of the Gaussian noise along proccessing, in contrast with AdaptiveDifferentialEvolutionArchiveGaussianMutation which adapts its mutation scale. Also AdaptiveHybridDEwithArchive decays the sigma along processing. Both implementations use the archive to influence the mutation.

Overall: Archive usage is frequent and the adaptive nature of the parameters influences success substantially. Gaussian Perturbation and Local Search are two more common mechanisms. Differential Mutation plays an important role.

**Experience:**
Combining adaptive parameter control with archive-guided mutation and periodic, local search with the top candidates should create an excellent performing heuristic. Exploration vs exploitation needs a balance.

2025-06-24 09:16:45 INFO Full response text: Okay, let's refine that self-reflection to guide better heuristic design, focusing on concrete strategies and avoiding generic pronouncements.
Here's the breakdown:

*   **Keywords:** Adaptive parameters, archive (external), diversity maintenance, local search intensification, perturbation, multimodal landscape.
*   **Advice:** Design adaptive parameters with explicit triggers (e.g., stagnation detection); implement a diversity metric to guide archive usage; incorporate a focused local search around promising archive members with occasional perturbations.
*   **Avoid:** Vague terms like "exploration/exploitation balance" without specifics.
*   **Explanation:** Move from general principles to concrete design elements and mechanisms addressing multimodal challenges to guide the design of high quality algorithms.

2025-06-24 09:16:45 INFO Generating offspring via Crossover...
2025-06-24 09:23:04 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------


### Better code
AdaptiveGaussianDifferentialEvolutionArchive
import numpy as np
from scipy.optimize import minimize

# Name: AdaptiveGaussianDifferentialEvolutionArchive
# Description: Integrates adaptive Gaussian mutation with differential evolution, leveraging an archive to maintain diversity.
# Code:
class AdaptiveGaussianDifferentialEvolutionArchive:
    """
    Combines Adaptive Gaussian Mutation, Differential Evolution, and Archiving for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 100
        self.F = 0.7  # DE scaling factor, reduced magnitude
        self.CR = 0.8  # Crossover rate, reduced magnitude
        self.sigma = 0.1 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.995 # Sigmma decay rate
        self.archive_size = 50
        self.archive = []
        self.archive_fitness = []

    def _initialize_population(self):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _update_archive(self, population, fitness):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append(population[i].copy())
                self.archive_fitness.append(fitness[i])
            else:
                worst_index = np.argmax(self.archive_fitness)
                if fitness[i] < self.archive_fitness[worst_index]:
                    self.archive[worst_index] = population[i].copy()
                    self.archive_fitness[worst_index] = fitness[i]

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += len(fitness)

        best_index = np.argmin(fitness)
        self.best_solution_overall = population[best_index].copy()
        self.best_fitness_overall = fitness[best_index]

        self._update_archive(population, fitness)

        while self.eval_count < self.budget:
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                #DE
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c]) # DE mutation

                #Archive interaction
                if np.random.rand() < 0.1 and len(self.archive) > 0: # Archive interaction Probability
                    arc_idx = np.random.randint(len(self.archive))
                    mutant = population[a] + self.F * (self.archive[arc_idx] - population[c]) # Archive interaction

                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Adaptive Gaussian Mutation
                mutant = mutant + np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1

                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population

            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index].copy()

            self._update_archive(population, fitness)

            self.sigma *= self.sigma_decay #Sigma decay
        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

### Worse code
AdaptiveHybridDE
import numpy as np
import random

# Name: AdaptiveHybridDE
# Description: Combines Adaptive Gaussian Mutation with archive-guided differential evolution to explore multimodal landscapes effectively.
# Code:
class AdaptiveHybridDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        """
        Initializes the AdaptiveHybridDE algorithm.

        Args:
            budget: The maximum number of function evaluations allowed.
            dim: The dimensionality of the problem.
            lower_bounds: A list of lower bounds for each dimension.
            upper_bounds: A list of upper bounds for each dimension.
        """
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Common heuristic
        self.population = None
        self.fitness_values = None
        self.archive_size = 100
        self.archive = []
        self.mutation_scale = 0.8  # Initial mutation scale
        self.mutation_scale_decay = 0.99  # Decay factor for the mutation scale
        self.crossover_rate = 0.5
        self.F_scale = 0.5 # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """
        Optimizes the given objective function using the AdaptiveHybridDE algorithm.

        Args:
            objective_function: The function to optimize.  It should accept a 2D numpy array (N, dim)
                                  and return a 1D numpy array of N fitness values.
            acceptance_threshold: The acceptance threshold for convergence (not actively used).

        Returns:
            A tuple containing the best solution found, its fitness, and optimization information.
        """
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Archive-guided Differential Mutation
                if self.archive:
                    pbest_index = np.random.choice(len(self.archive))
                    pbest = self.archive[pbest_index][0]
                else:
                     pbest = self.population[np.argmin(self.fitness_values)]

                a, b = random.sample(range(self.population_size), 2)
                while a == i or b == i :
                    a, b = random.sample(range(self.population_size), 2)
                
                # DE mutation with pbest guidance
                mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])

                #Adaptive Gaussian perturbation for escaping local optima
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)

                # Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.population[i])

                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]  # Ensure correct input shape

                self.eval_count += 1  # Increment evaluation counter inside loop!!
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)

                    #Update Archive when a trial is successful.
                    self._update_archive(trial,trial_fitness)

                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                #Find best candidate for current populations
                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                #See the Global results
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay  # Decay mutation scale
            # Adaptive scaling factor (introduce after each generation)
            self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        """Initializes the population with uniformly random values within the bounds."""
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
         """Evaluates the fitness of all individuals in the population."""
         population_reshaped = self.population.reshape(-1, self.dim) #This solve the errors
         fitness = objective_function(population_reshaped) #Pass the well shaped array
         self.eval_count += self.population_size
         return fitness


    def _select_different(self, index):
        """Selects three different indices from the population, excluding the given index."""
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        """Finds the best solution in the population."""
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, offspring, offspring_fitness):
        """Update the external archive with new offspring for guiding search direction."""
        if len(self.archive) < self.archive_size:
            self.archive.append((offspring, offspring_fitness))
        else:
            #Prioritize diversity in archive by replacing the worst member
            worst_index = np.argmax([f for _, f in self.archive])
            if offspring_fitness < self.archive[worst_index][1] :
                self.archive[worst_index] = (offspring, offspring_fitness)

### Analyze & experience
- Comparing (AdaptiveHybridDE) vs (AdaptivePopulationDE), we see AdaptiveHybridDE employs a simpler mutation strategy combining archive guidance and Gaussian perturbation, while AdaptivePopulationDE uses "DE/current-to-best/1" with probabilistic archive influence, and adaptive population size, and a restart mechanism. AdaptiveHybridDE focuses more on intensification around promising regions, while AdaptivePopulationDE balances exploration and exploitation more aggressively with frequent population adjustments and restarts. AdaptiveHybridDE applies the global archive only on best candidate.

Comparing (AdaptiveHybridDEWithArchiveAndSA) vs (AdaptiveGaussianDEWithArchive), AdaptiveHybridDEWithArchiveAndSA uses simulated annealing for further exploration to escape local optima, in addition to differential evolution and archiving. AdaptiveGaussianDEWithArchive simply uses adaptive Gaussian mutation with differential evolution and an archive. AdaptiveHybridDEWithArchiveAndSA incorporates a more explicit mechanism (SA) for jumping out of local optima. AdaptiveGaussianDEWithArchive maintains constant Archive size along processing, which allows memory constant and better performance.

Comparing (AdaptiveHybridDE) vs (AdaptiveHybridDEWithArchiveAndSA), the use of Simulated Annealing in AdaptiveHybridDEWithArchiveAndSA introduces a probabilistic acceptance criterion based on temperature, allowing it to escape local optima by sometimes accepting worse solutions. Archive-guided Differential Mutation appears to be more efficient without the SA element. AdaptiveHybridDE maintains contant F_scale along proccessing.

Comparing (AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation) vs (AdaptiveHybridDEWithLocalSearch), AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation uses a decay schedule for the Gaussian mutation scaling to reduce perturbation over time. AdaptiveHybridDEWithLocalSearch applies local search using L-BFGS-B to the best individual periodically. AdaptiveDifferentialEvolutionWithArchiveAndGaussianPerturbation seems simpler but less precise, local search is a more guided and precise step that helps jump quickly on promising areas.

Comparing (AdaptiveHybridDEwithArchive) vs (AdaptiveDifferentialEvolutionArchiveGaussianMutation), AdaptiveHybridDEwithArchive adapts the width of the Gaussian noise along proccessing, in contrast with AdaptiveDifferentialEvolutionArchiveGaussianMutation which adapts its mutation scale. Also AdaptiveHybridDEwithArchive decays the sigma along processing. Both implementations use the archive to influence the mutation.

Overall: Archive usage is frequent and the adaptive nature of the parameters influences success substantially. Gaussian Perturbation and Local Search are two more common mechanisms. Differential Mutation plays an important role.
- Okay, let's refine that self-reflection to guide better heuristic design, focusing on concrete strategies and avoiding generic pronouncements.
Here's the breakdown:

*   **Keywords:** Adaptive parameters, archive (external), diversity maintenance, local search intensification, perturbation, multimodal landscape.
*   **Advice:** Design adaptive parameters with explicit triggers (e.g., stagnation detection); implement a diversity metric to guide archive usage; incorporate a focused local search around promising archive members with occasional perturbations.
*   **Avoid:** Vague terms like "exploration/exploitation balance" without specifics.
*   **Explanation:** Move from general principles to concrete design elements and mechanisms addressing multimodal challenges to guide the design of high quality algorithms.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 09:23:04 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------


Current heuristics:
AdaptivePopulationDE
import numpy as np
import random

# Name: AdaptivePopulationDE
# Description: An adaptive Differential Evolution algorithm with dynamic population size, enhanced mutation strategies, and a restart mechanism to escape local optima in complex multimodal landscapes.
# Code:
class AdaptivePopulationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.population = None
        self.fitness = None
        self.F = 0.5  # Crossover rate
        self.Cr = 0.7 # Mutation factor

        self.archive = []
        self.archive_size = 100

        self.min_population_size = 5 * self.dim
        self.max_population_size = 20 * self.dim
        self.population_adaptation_rate = 0.1
        self.stagnation_counter = 0
        self.stagnation_threshold = 5000  # Number of evaluations without improvement before restart


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0

        # Initialize population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness)]
        self.best_fitness_overall = np.min(self.fitness)

        self.stagnation_counter = 0 # Reset Stagnation counter


        while self.eval_count < self.budget:
            # Generate offspring using an enhanced DE mutation strategy
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

             # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Selection: Replace parents with better offspring
            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            #Update best solution
            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0 # Reset if improvement occurs

            else:
                 self.stagnation_counter += len(offspring)

            # Adaptive population size adjustment
            self.adjust_population_size()


            # Stagnation check and restart mechanism
            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info



    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Mutation: "DE/current-to-best/1" with archive influence
            if self.archive and random.random() < 0.5:  # Utilize the archive probabilistically
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0] # Select a random member of the archive
            else:
                pbest = self.population[np.argmin(self.fitness)] #Fall back to best in current population
            
            indices = list(range(self.population_size))
            indices.remove(i) # Ensure distinct indices
            a, b = random.sample(indices, 2) # Select two unique indices

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            # Crossover: Binomial crossover
            for j in range(self.dim):
                if random.random() > self.Cr: # Perform binomial crossover
                    mutant[j] = self.population[i][j]  # Keep parent's gene

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive replacement
                worst_index = np.argmax([f for _, f in self.archive]) # Find worst fitness in archive
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])




    def adjust_population_size(self):
        if random.random() < self.population_adaptation_rate: # Control adaptation frequency
            if self.stagnation_counter > self.stagnation_threshold / 2: # Stagnation suggests too small, increase pop
                self.population_size = min(int(self.population_size * 1.1), self.max_population_size)
            else: # Otherwise may reduce population to encourage convergence
                self.population_size = max(int(self.population_size * 0.9), self.min_population_size)
        self.population_size = int(self.population_size) # Ensure population size remains an integer.



    def restart_population(self, objective_function):
        # Option 1: Re-initialize entire population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
             self.best_solution_overall = self.population[best_index]
             self.best_fitness_overall = self.fitness[best_index]

        # Option 2: Keep best solution and re-initialize the rest (exploitation of best)
        # num_reinitialized = int(0.8 * self.population_size)  # Re-initialize 80% of the pop.
        # self.population[num_reinitialized:] = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size - num_reinitialized, self.dim))
        # self.fitness[num_reinitialized:] = objective_function(self.population[num_reinitialized:])
        # self.eval_count += (self.population_size - num_reinitialized) # Update evaluation count


Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- Okay, let's refine that self-reflection to guide better heuristic design, focusing on concrete strategies and avoiding generic pronouncements.
Here's the breakdown:

*   **Keywords:** Adaptive parameters, archive (external), diversity maintenance, local search intensification, perturbation, multimodal landscape.
*   **Advice:** Design adaptive parameters with explicit triggers (e.g., stagnation detection); implement a diversity metric to guide archive usage; incorporate a focused local search around promising archive members with occasional perturbations.
*   **Avoid:** Vague terms like "exploration/exploitation balance" without specifics.
*   **Explanation:** Move from general principles to concrete design elements and mechanisms addressing multimodal challenges to guide the design of high quality algorithms.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-24 09:24:21 INFO Perform Harmony Search...
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 09:24:34 ERROR Can not run the algorithm
2025-06-24 09:24:34 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-24 09:24:34 INFO FeHistory: []
2025-06-24 09:24:34 INFO Expected Optimum FE: -5000
2025-06-24 09:24:34 INFO Unimodal AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 09:24:34 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 09:24:34 INFO AOCC mean: 0.0000
2025-06-24 09:24:34 INFO Weighed AOCC mean: nan
2025-06-24 09:24:34 INFO Generation 2, best so far: 0.7606208200367927
2025-06-24 09:24:34 INFO Population length is: 10
2025-06-24 09:24:34 INFO --- Performing Long-Term Reflection at Generation 3 ---
2025-06-24 09:24:34 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------

### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on function 18 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridGaussianDE
# Description: Combines Adaptive Gaussian Mutation with hybrid DE using archive and local search for increased exploitation.
# Code:
```python
import numpy as np
from scipy.optimize import minimize
import random

# Name: AdaptiveHybridGaussianDE
# Description: Combines Adaptive Gaussian Mutation with hybrid DE using archive and local search for increased exploitation.
# Code:
class AdaptiveHybridGaussianDE:
    """
    Combines Adaptive Gaussian Mutation, Differential Evolution, Archive, and Local Search.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50
        self.F = 0.7  # DE scaling factor
        self.CR = 0.8  # Crossover rate
        self.sigma = 0.1 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.995
        self.archive_size = 50
        self.archive = []
        self.archive_fitness = []
        self.local_search_freq = 10

    def _initialize_population(self):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        return population

    def _update_archive(self, population, fitness):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (population[i], fitness[i])

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += len(fitness)

        best_index = np.argmin(fitness)
        self.best_solution_overall = population[best_index].copy()
        self.best_fitness_overall = fitness[best_index]

        self._update_archive(population, fitness)

        generation = 0
        while self.eval_count < self.budget:
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                #DE
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])

                #Archive interaction
                if np.random.rand() < 0.1 and len(self.archive) > 0:
                    arc_idx = np.random.randint(len(self.archive))
                    mutant = population[a] + self.F * (self.archive[arc_idx][0] - population[c])

                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Adaptive Gaussian Mutation
                mutant = mutant + np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1

                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population

            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index].copy()

            self._update_archive(population, fitness)

            # Local Search
            if generation % self.local_search_freq == 0:
                index_best = np.argmin(fitness)
                best_individual = population[index_best].copy()
                result = minimize(objective_function, best_individual, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < fitness[index_best]:
                    best_individual = result.x
                    fitness[index_best] = result.fun
                    self.eval_count += result.nfev
                    population[index_best] = best_individual
                    if fitness[index_best] < self.best_fitness_overall:
                         self.best_solution_overall = best_individual
                         self.best_fitness_overall = fitness[index_best]

            self.sigma *= self.sigma_decay #Sigma decay
            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 2 (Overall AOCC Score on function 18: 0.0000e+00# Name: ArchiveGuidedDEWithAdaptivePerturbationAndRestart
# Description: Combines archive-guided DE with adaptive Gaussian perturbation, and population restarts upon stagnation to solve multimodal problems.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedDEWithAdaptivePerturbationAndRestart
# Description: Combines archive-guided DE with adaptive Gaussian perturbation, and population restarts upon stagnation to solve multimodal problems.
# Code:
class ArchiveGuidedDEWithAdaptivePerturbationAndRestart:
    """
    Archive-guided DE with adaptive Gaussian perturbation and population restarts.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor
        self.mutation_scale = 0.1  # Gaussian mutation scaling
        self.mutation_decay = 0.99  # decay mutation
        self.crossover_rate = 0.5
        self.stagnation_counter = 0
        self.stagnation_threshold = 5000

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        self.stagnation_counter = 0  # Reset counter for each optimization run

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution and stagnation counter
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness[best_index]
                self.stagnation_counter = 0  # Reset if improvement
            else:
                self.stagnation_counter += len(offspring) # Increment if no improvement

            # Decay mutation scale
            self.mutation_scale *= self.mutation_decay

            # Restart population if stagnating
            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            # Adaptive Gaussian Perturbation
            mutant += np.random.normal(0, self.mutation_scale, self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling

            # Crossover operation
            cross_points = np.random.rand(self.dim) < self.crossover_rate
            offspring[i] = np.where(cross_points, offspring[i], population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
                    
    def restart_population(self, objective_function):
        #Re-initialize entire population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = fitness[best_index]
```

### Rank 3 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveDEWithArchiveAndLocalSearch
# Description: Integrates DE with archive, adaptive mutation, and local search for multimodal exploration.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEWithArchiveAndLocalSearch
# Description: Integrates DE with archive, adaptive mutation, and local search for multimodal exploration.
# Code:
class AdaptiveDEWithArchiveAndLocalSearch:
    """
    Combines Differential Evolution with an archive for diversification, 
    adaptive mutation parameters, and periodic local search to refine solutions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.mutation_scale = 0.5  # Mutation factor
        self.crossover_rate = 0.7  # Crossover probability
        self.local_search_frequency = 10000  # Perform local search every n evaluations

        self.F_adaptation_rate = 0.1  # Rate to adapt F (mutation scale)

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        self.archive = self._update_archive(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Mutation (DE/rand/1 with archive guidance)
                a, b, c = self._select_different(i)

                # Archive Influence
                if self.archive and random.random() < 0.2:
                    archive_individual = random.choice(self.archive)[:, :-1]
                    mutant = self.archive_individual + self.mutation_scale * (self.population[a] - self.population[b])
                else:
                    mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])


                # Crossover
                trial = np.copy(self.population[i])
                crossover_points = np.random.rand(self.dim) < self.crossover_rate
                trial[crossover_points] = mutant[crossover_points]

                # Clipping
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                # Evaluate Trial Solution
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                # Selection
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                    trial_fitness = self.fitness_values[i]
                    trial = self.population[i]

                if trial_fitness < self.best_fitness_overall:
                    self.best_solution_overall = trial
                    self.best_fitness_overall = trial_fitness
                 # Adapt Mutation scale
                if random.random() < self.F_adaptation_rate:
                   self.mutation_scale = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)  # Adapt mutation factor

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.archive = self._update_archive(self.population, self.fitness_values)

            # Local Search
            if self.eval_count % self.local_search_frequency < self.population_size and self.eval_count > self.local_search_frequency:
                best_index = np.argmin(self.fitness_values)
                local_search_solution, local_search_fitness = self._perform_local_search(self.population[best_index], objective_function)
                
                if local_search_fitness < self.fitness_values[best_index]: # Accept Local Search result if beneficial
                    self.population[best_index] = local_search_solution
                    self.fitness_values[best_index] = local_search_fitness
                    if local_search_fitness < self.best_fitness_overall:
                        self.best_solution_overall = local_search_solution
                        self.best_fitness_overall = local_search_fitness
                
                self.archive = self._update_archive(self.population, self.fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-8) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1]) #sort by fitness before trim
        self.archive = new_archive[:self.archive_size]  # Trim to archive size
        return np.array(self.archive)

    def _perform_local_search(self, initial_solution, objective_function, max_iterations=50):
          # Perturb the initial solution with gaussian noise
        perturbed_solution = initial_solution + np.random.normal(0, 0.1 * (self.upper_bounds - self.lower_bounds), self.dim)
        perturbed_solution = np.clip(perturbed_solution, self.lower_bounds, self.upper_bounds)
        current_solution = perturbed_solution
        current_fitness = objective_function(current_solution.reshape(1, -1))[0]
        eval_count_local = 1
        
        best_solution = current_solution
        best_fitness = current_fitness
        
        for i in range(max_iterations):
            # Generate a neighbor by randomly changing one dimension
            dimension_to_change = random.randint(0, self.dim - 1)
            step_size = 0.05 * (self.upper_bounds[dimension_to_change] - self.lower_bounds[dimension_to_change])
            
            # Randomly choose to increase or decrease the dimension
            if random.random() < 0.5:
                new_solution = current_solution.copy()
                new_solution[dimension_to_change] += step_size
            else:
                new_solution = current_solution.copy()
                new_solution[dimension_to_change] -= step_size
            
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            new_fitness = objective_function(new_solution.reshape(1, -1))[0]
            eval_count_local += 1
        
            if new_fitness < current_fitness:
                current_solution = new_solution
                current_fitness = new_fitness
                if new_fitness < best_fitness:
                    best_solution = new_solution
                    best_fitness = new_fitness

        self.eval_count += eval_count_local
        return best_solution, best_fitness
```

### Rank 4 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridDEwithArchiveAndLocalSearch
# Description: Combines DE with archive, adaptive Gaussian mutation, and local search to escape local optima.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDEwithArchiveAndLocalSearch
# Description: Combines DE with archive, adaptive Gaussian mutation, and local search to escape local optima.
# Code:
class AdaptiveHybridDEwithArchiveAndLocalSearch:
    """
    Combines differential evolution, an archive, adaptive Gaussian mutation,
    and local search (L-BFGS-B) to effectively navigate multimodal optimization landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 100
        self.archive = []
        self.F = 0.5  # Differential evolution parameter
        self.CR = 0.7  # Crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling
        self.sigma_decay = 0.99
        self.local_search_frequency = 5000 # Reduce Frequency

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Mutation
                indices = np.random.choice(self.population_size, 3, replace=False)
                x1, x2, x3 = population[indices]

                # Use pbest from archive
                if len(self.archive) > 0 and random.random() < 0.1:
                    pbest_index = np.argmin(self.archive[:, -1])
                    pbest = self.archive[pbest_index, :-1]
                    mutant = pbest + self.F * (x2 - x3)
                else:
                    mutant = x1 + self.F * (x2 - x3)   # original DE

                # Gaussian mutation hybrid
                mutant = mutant + np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial_vector = np.copy(population[i])
                for j in range(self.dim):
                    if random.random() < self.CR or j == random.randint(0, self.dim - 1):
                        trial_vector[j] = mutant[j]

                trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
                self.eval_count += 1

                # Selection
                if trial_fitness < fitness_values[i]:
                    population[i] = trial_vector
                    fitness_values[i] = trial_fitness

                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector

            self.archive = self._update_archive(population, fitness_values)
            self.sigma *= self.sigma_decay

            #Apply local search to the best performing solution on archive to intensify search (periodically)
            if self.eval_count % self.local_search_frequency == 0 and len(self.archive) > 0:
                best_archive_idx = np.argmin(self.archive[:, -1])
                best_archive_solution = self.archive[best_archive_idx, :-1].copy()

                # Simple gradient descent implementation for local search
                learning_rate = 0.01
                num_iterations = 5
                for _ in range(num_iterations):
                   gradient = self._approximate_gradient(best_archive_solution, objective_function)
                   best_archive_solution -= learning_rate * gradient
                   best_archive_solution = np.clip(best_archive_solution, self.lower_bounds, self.upper_bounds) # Keep solution inside the bounds

                   local_fitness = objective_function(best_archive_solution.reshape(1, -1))[0]
                   self.eval_count += 1

                   if local_fitness < self.best_fitness_overall:
                       self.best_fitness_overall = local_fitness
                       self.best_solution_overall = best_archive_solution
                       
                #Update Best solution to incorporate effect of local_search
                self.archive[best_archive_idx, :-1] = best_archive_solution  #Update Archive

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1]) # sort to archive best ones
        if len(new_archive) > 0: #prevent error if the new archive if empty
            new_archive = np.array(new_archive)
            if len(self.archive) > 0 :
                combined_archive = np.vstack((self.archive, new_archive))
                combined_archive = combined_archive[np.argsort(combined_archive[:, -1])]  # Sort archive based on fitness
                self.archive = combined_archive[:self.archive_size]
            else:
                self.archive = new_archive[:self.archive_size]
        return self.archive

    def _approximate_gradient(self, x, objective_function, step_size=1e-5):
        """Approximates the gradient of the objective function at a point x."""
        gradient = np.zeros_like(x)
        for i in range(self.dim):
            # Evaluate function at x + h
            x_plus_h = x.copy()
            x_plus_h[i] += step_size
            f_plus_h = objective_function(x_plus_h.reshape(1, -1))[0]
            self.eval_count +=1

            # Evaluate function at x - h
            x_minus_h = x.copy()
            x_minus_h[i] -= step_size
            f_minus_h = objective_function(x_minus_h.reshape(1, -1))[0]
            self.eval_count += 1

            # Approximate the gradient
            gradient[i] = (f_plus_h - f_minus_h) / (2 * step_size)
        return gradient
```

### Rank 5 (Overall AOCC Score on function 18: 0.0000e+00# Name: ArchiveGuidedHybridDE
# Description: Integrates archive-guided DE mutation, adaptive Gaussian perturbation, and periodic local search for robust exploration and exploitation.
# Code:
```python
import numpy as np
import random
from scipy.optimize import minimize

# Name: ArchiveGuidedHybridDE
# Description: Integrates archive-guided DE mutation, adaptive Gaussian perturbation, and periodic local search for robust exploration and exploitation.
# Code:
class ArchiveGuidedHybridDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        """
        Initializes the ArchiveGuidedHybridDE algorithm.

        Args:
            budget: The maximum number of function evaluations allowed.
            dim: The dimensionality of the problem.
            lower_bounds: A list of lower bounds for each dimension.
            upper_bounds: A list of upper bounds for each dimension.
        """
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Common heuristic
        self.population = None
        self.fitness_values = None
        self.archive_size = 100
        self.archive = []
        self.mutation_scale = 1.0  # Initial mutation scale
        self.mutation_scale_decay = 0.995  # Decay factor for the mutation scale
        self.crossover_rate = 0.5
        self.F_scale = 0.5 # initial scaling factor
        self.local_search_frequency = 500 #Frequency to do local search

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """
        Optimizes the given objective function using the ArchiveGuidedHybridDE algorithm.

        Args:
            objective_function: The function to optimize.  It should accept a 2D numpy array (N, dim)
                                  and return a 1D numpy array of N fitness values.
            acceptance_threshold: The acceptance threshold for convergence (not actively used).

        Returns:
            A tuple containing the best solution found, its fitness, and optimization information.
        """
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Archive-guided Differential Mutation
                if self.archive:
                    pbest_index = np.random.choice(len(self.archive))
                    pbest = self.archive[pbest_index][0]
                else:
                     pbest = self.population[np.argmin(self.fitness_values)]

                a, b = random.sample(range(self.population_size), 2)
                while a == i or b == i :
                    a, b = random.sample(range(self.population_size), 2)
                
                # DE mutation with pbest guidance
                mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])

                #Adaptive Gaussian perturbation for escaping local optima
                mutant += np.random.normal(0, self.mutation_scale, self.dim)

                # Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.population[i])

                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]  # Ensure correct input shape

                self.eval_count += 1  # Increment evaluation counter inside loop!!
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)

                    #Update Archive when a trial is successful.
                    self._update_archive(trial,trial_fitness)

                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                #Find best candidate for current populations
                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                #See the Global results
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay  # Decay mutation scale
            # Adaptive scaling factor (introduce after each generation)
            self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

            #Periodic Local Search every specified number of evaluations
            if self.eval_count % self.local_search_frequency == 0:
               self._perform_local_search(objective_function)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        """Initializes the population with uniformly random values within the bounds."""
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
         """Evaluates the fitness of all individuals in the population."""
         population_reshaped = self.population.reshape(-1, self.dim) #This solve the errors
         fitness = objective_function(population_reshaped) #Pass the well shaped array
         self.eval_count += self.population_size
         return fitness


    def _select_different(self, index):
        """Selects three different indices from the population, excluding the given index."""
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        """Finds the best solution in the population."""
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, offspring, offspring_fitness):
        """Update the external archive with new offspring for guiding search direction."""
        if len(self.archive) < self.archive_size:
            self.archive.append((offspring, offspring_fitness))
        else:
            #Prioritize diversity in archive by replacing the worst member
            worst_index = np.argmax([f for _, f in self.archive])
            if offspring_fitness < self.archive[worst_index][1] :
                self.archive[worst_index] = (offspring, offspring_fitness)

    def _perform_local_search(self, objective_function):
        """
        Performs local search on the best solution found so far.
        """
        #Initial guess is the current overall best solution:
        x0 = self.best_solution_overall
        bounds = list(zip(self.lower_bounds, self.upper_bounds))
        # Define a wrapper for the objective function that increments the evaluation count.

        def objective_wrapper(x):
           fitness = objective_function(x.reshape(1, -1))[0]
           self.eval_count +=1  #Increment eval_count
           return fitness

        result = minimize(objective_wrapper, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': 50})

        if result.fun < self.best_fitness_overall and result.success :
            self.best_solution_overall = result.x
            self.best_fitness_overall = result.fun
```

### Rank 6 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaDiffEvolArchLocalGauss
# Description: Combines adaptive Differential Evolution with Archive, Local Search and adaptive Gaussian mutation.
# Code:
```python
import numpy as np
import random
from scipy.optimize import minimize

# Name: AdaDiffEvolArchLocalGauss
# Description: Combines adaptive Differential Evolution with Archive, Local Search and adaptive Gaussian mutation.
# Code:
class AdaDiffEvolArchLocalGauss:
    """
    Combines adaptive Differential Evolution with Archive, Local Search and adaptive Gaussian mutation
    to exploit promising areas and maintain diversity.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50  # Adjusted population size
        self.archive_size = 50
        self.archive = []
        self.population = None
        self.F = 0.5
        self.CR = 0.7
        self.local_search_freq = 10
        self.sigma = 0.1 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.995  # Sigma decay rate
        self.lr_local_search = 0.1

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        generation = 0
        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive F

            if generation % self.local_search_freq == 0:
                index_best = np.argmin(fitness)
                best_individual = self.population[index_best].copy()

                result = minimize(objective_function, best_individual, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < fitness[index_best]:
                    best_individual = result.x
                    fitness[index_best] = result.fun
                    self.eval_count += result.nfev
                    self.population[index_best] = best_individual
                    if fitness[index_best] < self.best_fitness_overall:
                         self.best_solution_overall = best_individual
                         self.best_fitness_overall = fitness[index_best]



            if np.min(fitness) < self.best_fitness_overall:
                self.best_solution_overall = self.population[np.argmin(fitness)]
                self.best_fitness_overall = np.min(fitness)

            generation += 1
            self.sigma *= self.sigma_decay #Adaptive gaussian mutation parameter.

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            if self.archive and random.random() < 0.7:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

            # Adaptive Gaussian Mutation
            offspring[i] = offspring[i] + np.random.normal(0, self.sigma, self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling



        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or random.random() < 0.1:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 7 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridDEWithArchiveAndScaledMutation
# Description: Combines adaptive differential evolution, archive, and scaled gaussian mutation for robustness in rugged landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDEWithArchiveAndScaledMutation
# Description: Combines adaptive differential evolution, archive, and scaled gaussian mutation for robustness in rugged landscapes.
# Code:
class AdaptiveHybridDEWithArchiveAndScaledMutation:
    """
    Combines adaptive differential evolution with an archive, uses a scaled Gaussian mutation based on objective function curvature,
    and incorporates a stagnation counter to promote diversity.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # Differential evolution parameter
        self.CR = 0.7  # Crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling
        self.sigma_decay = 0.99  # Sigma decay rate
        self.stagnation_counter = 0
        self.stagnation_threshold = 5000 # Stagnation is number function call since the last improvement of best fitness

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.stagnation_counter = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Mutation
                indices = np.random.choice(self.population_size, 3, replace=False)
                x1, x2, x3 = population[indices]

                # Use pbest from archive
                if len(self.archive) > 0 and random.random() < 0.1:
                    pbest_index = np.argmin(self.archive[:, -1])
                    pbest = self.archive[pbest_index, :-1]
                    mutant = pbest + self.F * (x2 - x3)
                else:
                    mutant = x1 + self.F * (x2 - x3)   # original DE

                # Gaussian mutation hybrid - scaled
                # Estimate curvature by fitness differences from random sample in the current population
                sample_index = random.choice(range(self.population_size))
                fitness_current = fitness_values[i]
                fitness_sample = fitness_values[sample_index]
                curvature_scale = abs(fitness_current - fitness_sample)
                mutant = mutant + np.random.normal(0, self.sigma * curvature_scale, self.dim) # Scaled according fitness score
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial_vector = np.copy(population[i])
                for j in range(self.dim):
                    if random.random() < self.CR or j == random.randint(0, self.dim - 1):
                        trial_vector[j] = mutant[j]

                trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
                self.eval_count += 1

                # Selection
                if trial_fitness < fitness_values[i]:
                    population[i] = trial_vector
                    fitness_values[i] = trial_fitness

                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector
                        self.stagnation_counter = 0 #Stagnation counter reset with improvement
                else:
                   self.stagnation_counter +=1


            self.archive = self._update_archive(population, fitness_values)
            self.sigma *= self.sigma_decay

            if self.stagnation_counter > self.stagnation_threshold:
                population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim)) # Restart, diversification
                fitness_values = objective_function(population)
                self.eval_count += self.population_size
                self.archive = self._update_archive(population, fitness_values)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])  # sort to archive best ones
        if len(new_archive) > 0:  # prevent error if the new archive if empty
            new_archive = np.array(new_archive)
            if len(self.archive) > 0:
                combined_archive = np.vstack((self.archive, new_archive))
                combined_archive = combined_archive[np.argsort(combined_archive[:, -1])]  # Sort archive based on fitness
                self.archive = combined_archive[:self.archive_size]
            else:
                self.archive = new_archive[:self.archive_size]
        return self.archive
```

### Rank 8 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptiveHybridDEwithArchiveAndAdaptiveSigma
# Description: Combines DE, archive guidance, and adaptive Gaussian mutation width for enhanced exploration.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDEwithArchiveAndAdaptiveSigma
# Description: Combines DE, archive guidance, and adaptive Gaussian mutation width for enhanced exploration.
# Code:
class AdaptiveHybridDEwithArchiveAndAdaptiveSigma:
    """
    Adaptive Differential Evolution with Archive and Adaptive Gaussian Mutation.

    This class implements a hybrid Differential Evolution algorithm with an external
    archive to enhance exploration and adaptive Gaussian mutation to fine-tune the search.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        """
        Initializes the AdaptiveHybridDEwithArchiveAndAdaptiveSigma algorithm.

        Args:
            budget (int): The maximum number of function evaluations allowed.
            dim (int): The dimensionality of the problem.
            lower_bounds (list[float]): A list of lower bounds for each dimension.
            upper_bounds (list[float]): A list of upper bounds for each dimension.
        """
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Common heuristic
        self.population = None
        self.fitness_values = None
        self.archive_size = 100
        self.archive = []
        self.sigma = 0.1 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width, per dimension
        self.sigma_decay = 0.995  # Decay factor for the Gaussian width, per dimension
        self.crossover_rate = 0.5
        self.F_scale = 0.5  # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """
        Optimizes the given objective function using the AdaptiveHybridDEwithArchiveAndAdaptiveSigma algorithm.

        Args:
            objective_function (callable): The function to optimize. It should accept a 2D numpy array (N, dim)
                                          and return a 1D numpy array of N fitness values.
            acceptance_threshold (float): The acceptance threshold for convergence (not actively used).

        Returns:
            tuple: A tuple containing the best solution found, its fitness, and optimization information.
        """
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Archive-guided Differential Mutation
                if self.archive:
                    pbest_index = np.random.choice(len(self.archive))
                    pbest = self.archive[pbest_index][0]
                else:
                    pbest = self.population[np.argmin(self.fitness_values)]

                a, b = random.sample(range(self.population_size), 2)
                while a == i or b == i:
                    a, b = random.sample(range(self.population_size), 2)

                # DE mutation with pbest guidance
                mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])

                # Adaptive Gaussian perturbation, applied to each dimension independently
                mutant += np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.population[i])

                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]  # Ensure correct input shape

                self.eval_count += 1  # Increment evaluation counter inside loop!!
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)

                    # Update Archive when a trial is successful.
                    self._update_archive(trial, trial_fitness)

                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                # Find best candidate for current populations
                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                # See the Global results
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.sigma *= self.sigma_decay  # Decay the Gaussian width along processing
            # Adaptive scaling factor (introduce after each generation)
            self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_sigma': self.sigma.tolist()  # List of sigmas for each dimension
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        """Initializes the population with uniformly random values within the bounds."""
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        """Evaluates the fitness of all individuals in the population."""
        population_reshaped = self.population.reshape(-1, self.dim)  # This solve the errors
        fitness = objective_function(population_reshaped)  # Pass the well shaped array
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        """Selects three different indices from the population, excluding the given index."""
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        """Finds the best solution in the population."""
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, offspring, offspring_fitness):
        """Update the external archive with new offspring for guiding search direction."""
        if len(self.archive) < self.archive_size:
            self.archive.append((offspring, offspring_fitness))
        else:
            # Prioritize diversity in archive by replacing the worst member
            worst_index = np.argmax([f for _, f in self.archive])
            if offspring_fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (offspring, offspring_fitness)
```

### Rank 9 (Overall AOCC Score on function 18: 0.0000e+00# Name: AdaptivePopulationDE2
# Description: 
# Code:
```python
import numpy as np
import random

# Name: AdaptivePopulationDE2
# Description: An adaptive Differential Evolution algorithm with dynamic population size, enhanced mutation strategies, and a restart mechanism to escape local optima in complex multimodal landscapes.
# Code:
class AdaptivePopulationDE2:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 initial_population_size_factor: int = 10.537068217000208,
                 crossover_rate: float = 0.730147827059343,
                 mutation_factor: float = 0.42983879846439743,
                 archive_size: int = 108.5422128708941,
                 min_population_size_factor: int = 3.731902212944628,
                 max_population_size_factor: int = 18.26976954399769,
                 population_adaptation_rate: float = 0.4339656126991939,
                 stagnation_threshold: int = 3979.0959715659537,
                 archive_probability: float = 0.19138424015215466,
                 archive_replacement_threshold: float = 0.777424773300974,
                 population_increase_factor: float = 1.067014532538653,
                 population_decrease_factor: float = 0.8247102209602067,
                 restart_percentage: float = 0.8855333081124759):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = initial_population_size_factor * self.dim
        self.population = None
        self.fitness = None
        self.F = crossover_rate  # Crossover rate
        self.Cr = mutation_factor # Mutation factor

        self.archive = []
        self.archive_size = archive_size

        self.min_population_size = min_population_size_factor * self.dim
        self.max_population_size = max_population_size_factor * self.dim
        self.population_adaptation_rate = population_adaptation_rate
        self.stagnation_counter = 0
        self.stagnation_threshold = stagnation_threshold  # Number of evaluations without improvement before restart
        self.archive_probability = archive_probability
        self.archive_replacement_threshold = archive_replacement_threshold
        self.population_increase_factor = population_increase_factor
        self.population_decrease_factor = population_decrease_factor
        self.restart_percentage = restart_percentage


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0

        # Initialize population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness)]
        self.best_fitness_overall = np.min(self.fitness)

        self.stagnation_counter = 0 # Reset Stagnation counter


        while self.eval_count < self.budget:
            # Generate offspring using an enhanced DE mutation strategy
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

             # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Selection: Replace parents with better offspring
            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            #Update best solution
            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0 # Reset if improvement occurs

            else:
                 self.stagnation_counter += len(offspring)

            # Adaptive population size adjustment
            self.adjust_population_size()


            # Stagnation check and restart mechanism
            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info



    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Mutation: "DE/current-to-best/1" with archive influence
            if self.archive and random.random() < self.archive_probability:  # Utilize the archive probabilistically
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0] # Select a random member of the archive
            else:
                pbest = self.population[np.argmin(self.fitness)] #Fall back to best in current population

            indices = list(range(self.population_size))
            indices.remove(i) # Ensure distinct indices
            a, b = random.sample(indices, 2) # Select two unique indices

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            # Crossover: Binomial crossover
            for j in range(self.dim):
                if random.random() > self.Cr: # Perform binomial crossover
                    mutant[j] = self.population[i][j]  # Keep parent's gene

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive replacement
                worst_index = np.argmax([f for _, f in self.archive]) # Find worst fitness in archive
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_replacement_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])




    def adjust_population_size(self):
        if random.random() < self.population_adaptation_rate: # Control adaptation frequency
            if self.stagnation_counter > self.stagnation_threshold / 2: # Stagnation suggests too small, increase pop
                self.population_size = min(int(self.population_size * self.population_increase_factor), self.max_population_size)
            else: # Otherwise may reduce population to encourage convergence
                self.population_size = max(int(self.population_size * self.population_decrease_factor), self.min_population_size)
        self.population_size = int(self.population_size) # Ensure population size remains an integer.



    def restart_population(self, objective_function):
        # Option 1: Re-initialize entire population
        # self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        # self.fitness = objective_function(self.population)
        # self.eval_count += self.population_size
        # best_index = np.argmin(self.fitness)
        # if self.fitness[best_index] < self.best_fitness_overall:
        #      self.best_solution_overall = self.population[best_index]
        #      self.best_fitness_overall = self.fitness[best_index]

        # Option 2: Keep best solution and re-initialize the rest (exploitation of best)
        num_reinitialized = int(self.restart_percentage * self.population_size)  # Re-initialize percentage of the pop.
        self.population[num_reinitialized:] = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size - num_reinitialized, self.dim))
        self.fitness[num_reinitialized:] = objective_function(self.population[num_reinitialized:])
        self.eval_count += (self.population_size - num_reinitialized) # Update evaluation count
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 09:24:40 INFO Full response text: **Analysis:**

Comparing (AdaptiveHybridGaussianDE) vs (AdaptivePopulationDE2), we see AdaptiveHybridGaussianDE employs a hybrid approach combining DE with archive interaction, adaptive Gaussian mutation, crossover, and local search to refine solutions, whilst AdaptivePopulationDE2 focused on adaptive population sizing and stochastic universal sampling for parent selection. In terms of diversification strategies, AdaptiveHybridGaussianDE uses an archive, a Gaussian width decay strategy, and Local Search frequency; adaptive to exploitation and exploration. AdaptivePopulationDE2 features on adaptive population size adjustment and restart mechanisms for exploration purposes. 
(ArchiveGuidedDEWithAdaptivePerturbationAndRestart) vs (AdaptiveHybridDEwithArchiveAndScaledMutation): The former emphasized restarting the population, while AdaptiveHybridDEwithArchiveAndScaledMutation restarts only a subset of solutions.
Comparing (AdaptiveHybridGaussianDE) vs (ArchiveGuidedDEWithAdaptivePerturbationAndRestart), we see that the first uses local search to intensify solutions, with a decay strategy, while the second restarts the population. This provides more robust behaviour. Comparing (ArchiveGuidedDEWithAdaptivePerturbationAndRestart) vs (AdaptiveDEWithArchiveAndLocalSearch), archiveGuidedDEWithAdaptivePerturbationAndRestart relies on F Scale adaptation rate with stagnation counter, while AdaptiveDEWithArchiveAndLocalSearch features a higher number of more localized adaptations.
Comparing (AdaptiveDEWithArchiveAndLocalSearch) vs (AdaptiveHybridDEwithArchiveAndLocalSearch), the first uses a Gaussian perturbation local search, whilst the second a numerical approximation with L-BFGS gradient descent. The former has an adaptation rate F. 
Comparing (AdaptiveHybridDEwithArchiveAndScaledMutation) vs (AdaptiveHybridDEwithArchiveAndAdaptiveSigma), AdaptiveHybridDEwithArchiveAndScaledMutation scale mutation using current population sample curvature estimation, while the AdaptiveHybridDEwithArchiveAndAdaptiveSigma decays according to a static amount Sigma.

Overall: Good heuristics favor hybrid approaches like DE with adaptive strategies, a suitable local search frequency and a high number of re-evaluations to reduce the exploration rate of the population with archive memory. Adaptability (adaptive F, CR, Gaussian widths) appears critical for robust performance on complex landscapes. It is useful to have population restarts.

**Experience:**

Designing robust heuristics requires a balanced approach, combining global search (DE) with localized refinement. Archive memory provides population diversification. Adaptive parameter control (mutation, population size) is essential for responding to landscape complexity. Combining archive with a local search appears especially promising.

2025-06-24 09:24:43 INFO Full response text: Okay, I understand. The goal is to redefine "Current self-reflection" into a more actionable and insightful guide for designing better heuristics, specifically addressing the weaknesses identified in "Ineffective self-reflection."  We need to move beyond simple combinations of techniques toward a deeper understanding of how these elements interact and adapt.

Here's a refined perspective, designed to stimulate the development of improved heuristics:

*   **Keywords:** Adaptive Landscapes, Exploration-Exploitation, Population Dynamics, Hybrid Algorithms, Adaptive Memory, Constraint Satisfaction, Sensitivity Analysis.

*   **Advice:** Instead of blindly combining methods, focus on the *interaction* between them. Implement a system that monitors performance *metrics* (e.g., convergence rate, diversity levels, objective function improvements per iteration) and dynamically adjusts the weighting of different search components (global vs. local).  Consider sensitivity analysis to understand how each parameter *truly* affects performance in varied search spaces. The Archive needs strategies to discard points to avoid memory overload, in order to store diversity data. It helps reduce the effect from random noise.

*   **Avoid:** Simplistic recipes like "combine X with Y." Avoid static schedules for parameter adaptation; instead, design *reactive* systems. Move away from "top candidates" selection, which encourages premature convergence. Avoid focusing solely on objective function improvement; diversity metrics are equally crucial. Limit the "black-box" approach; aim for *explainable* adaptations.

*   **Explanation:** The core issue is that simply *having* various search components (adaptive DE, archive, local search) doesn't guarantee a good heuristic. The *way* they interact and respond to the problem landscape is critical. The ideal heuristic dynamically adjusts its behavior based on the perceived difficulty and characteristics of the search space. The archive serves not merely as a memory but as a guide, shaping the evolutionary process, and the local search assists when global search stagnates. Focus on a reactive, interconnected system. Remember constraints are extremely important, so focus on ways to satisfy constraints and discard constraint violating solutions.

2025-06-24 09:24:43 INFO Generating offspring via Crossover...
2025-06-24 09:42:49 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------


### Better code
ArchiveGuidedDEWithAdaptivePerturbationAndRestart
import numpy as np
import random

# Name: ArchiveGuidedDEWithAdaptivePerturbationAndRestart
# Description: Combines archive-guided DE with adaptive Gaussian perturbation, and population restarts upon stagnation to solve multimodal problems.
# Code:
class ArchiveGuidedDEWithAdaptivePerturbationAndRestart:
    """
    Archive-guided DE with adaptive Gaussian perturbation and population restarts.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor
        self.mutation_scale = 0.1  # Gaussian mutation scaling
        self.mutation_decay = 0.99  # decay mutation
        self.crossover_rate = 0.5
        self.stagnation_counter = 0
        self.stagnation_threshold = 5000

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        self.stagnation_counter = 0  # Reset counter for each optimization run

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution and stagnation counter
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness[best_index]
                self.stagnation_counter = 0  # Reset if improvement
            else:
                self.stagnation_counter += len(offspring) # Increment if no improvement

            # Decay mutation scale
            self.mutation_scale *= self.mutation_decay

            # Restart population if stagnating
            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            # Adaptive Gaussian Perturbation
            mutant += np.random.normal(0, self.mutation_scale, self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling

            # Crossover operation
            cross_points = np.random.rand(self.dim) < self.crossover_rate
            offspring[i] = np.where(cross_points, offspring[i], population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
                    
    def restart_population(self, objective_function):
        #Re-initialize entire population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = fitness[best_index]

### Worse code
ArchiveGuidedDEWithAdaptivePerturbationAndRestart
import numpy as np
import random

# Name: ArchiveGuidedDEWithAdaptivePerturbationAndRestart
# Description: Combines archive-guided DE with adaptive Gaussian perturbation, and population restarts upon stagnation to solve multimodal problems.
# Code:
class ArchiveGuidedDEWithAdaptivePerturbationAndRestart:
    """
    Archive-guided DE with adaptive Gaussian perturbation and population restarts.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor
        self.mutation_scale = 0.1  # Gaussian mutation scaling
        self.mutation_decay = 0.99  # decay mutation
        self.crossover_rate = 0.5
        self.stagnation_counter = 0
        self.stagnation_threshold = 5000

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        self.stagnation_counter = 0  # Reset counter for each optimization run

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution and stagnation counter
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness[best_index]
                self.stagnation_counter = 0  # Reset if improvement
            else:
                self.stagnation_counter += len(offspring) # Increment if no improvement

            # Decay mutation scale
            self.mutation_scale *= self.mutation_decay

            # Restart population if stagnating
            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            # Adaptive Gaussian Perturbation
            mutant += np.random.normal(0, self.mutation_scale, self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling

            # Crossover operation
            cross_points = np.random.rand(self.dim) < self.crossover_rate
            offspring[i] = np.where(cross_points, offspring[i], population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
                    
    def restart_population(self, objective_function):
        #Re-initialize entire population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = fitness[best_index]

### Analyze & experience
- Comparing (AdaptiveHybridGaussianDE) vs (AdaptivePopulationDE2), we see AdaptiveHybridGaussianDE employs a hybrid approach combining DE with archive interaction, adaptive Gaussian mutation, crossover, and local search to refine solutions, whilst AdaptivePopulationDE2 focused on adaptive population sizing and stochastic universal sampling for parent selection. In terms of diversification strategies, AdaptiveHybridGaussianDE uses an archive, a Gaussian width decay strategy, and Local Search frequency; adaptive to exploitation and exploration. AdaptivePopulationDE2 features on adaptive population size adjustment and restart mechanisms for exploration purposes. 
(ArchiveGuidedDEWithAdaptivePerturbationAndRestart) vs (AdaptiveHybridDEwithArchiveAndScaledMutation): The former emphasized restarting the population, while AdaptiveHybridDEwithArchiveAndScaledMutation restarts only a subset of solutions.
Comparing (AdaptiveHybridGaussianDE) vs (ArchiveGuidedDEWithAdaptivePerturbationAndRestart), we see that the first uses local search to intensify solutions, with a decay strategy, while the second restarts the population. This provides more robust behaviour. Comparing (ArchiveGuidedDEWithAdaptivePerturbationAndRestart) vs (AdaptiveDEWithArchiveAndLocalSearch), archiveGuidedDEWithAdaptivePerturbationAndRestart relies on F Scale adaptation rate with stagnation counter, while AdaptiveDEWithArchiveAndLocalSearch features a higher number of more localized adaptations.
Comparing (AdaptiveDEWithArchiveAndLocalSearch) vs (AdaptiveHybridDEwithArchiveAndLocalSearch), the first uses a Gaussian perturbation local search, whilst the second a numerical approximation with L-BFGS gradient descent. The former has an adaptation rate F. 
Comparing (AdaptiveHybridDEwithArchiveAndScaledMutation) vs (AdaptiveHybridDEwithArchiveAndAdaptiveSigma), AdaptiveHybridDEwithArchiveAndScaledMutation scale mutation using current population sample curvature estimation, while the AdaptiveHybridDEwithArchiveAndAdaptiveSigma decays according to a static amount Sigma.

Overall: Good heuristics favor hybrid approaches like DE with adaptive strategies, a suitable local search frequency and a high number of re-evaluations to reduce the exploration rate of the population with archive memory. Adaptability (adaptive F, CR, Gaussian widths) appears critical for robust performance on complex landscapes. It is useful to have population restarts.
- Okay, I understand. The goal is to redefine "Current self-reflection" into a more actionable and insightful guide for designing better heuristics, specifically addressing the weaknesses identified in "Ineffective self-reflection."  We need to move beyond simple combinations of techniques toward a deeper understanding of how these elements interact and adapt.

Here's a refined perspective, designed to stimulate the development of improved heuristics:

*   **Keywords:** Adaptive Landscapes, Exploration-Exploitation, Population Dynamics, Hybrid Algorithms, Adaptive Memory, Constraint Satisfaction, Sensitivity Analysis.

*   **Advice:** Instead of blindly combining methods, focus on the *interaction* between them. Implement a system that monitors performance *metrics* (e.g., convergence rate, diversity levels, objective function improvements per iteration) and dynamically adjusts the weighting of different search components (global vs. local).  Consider sensitivity analysis to understand how each parameter *truly* affects performance in varied search spaces. The Archive needs strategies to discard points to avoid memory overload, in order to store diversity data. It helps reduce the effect from random noise.

*   **Avoid:** Simplistic recipes like "combine X with Y." Avoid static schedules for parameter adaptation; instead, design *reactive* systems. Move away from "top candidates" selection, which encourages premature convergence. Avoid focusing solely on objective function improvement; diversity metrics are equally crucial. Limit the "black-box" approach; aim for *explainable* adaptations.

*   **Explanation:** The core issue is that simply *having* various search components (adaptive DE, archive, local search) doesn't guarantee a good heuristic. The *way* they interact and respond to the problem landscape is critical. The ideal heuristic dynamically adjusts its behavior based on the perceived difficulty and characteristics of the search space. The archive serves not merely as a memory but as a guide, shaping the evolutionary process, and the local search assists when global search stagnates. Focus on a reactive, interconnected system. Remember constraints are extremely important, so focus on ways to satisfy constraints and discard constraint violating solutions.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 09:42:49 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving GNBG benchmark on function 18, particularly:

The f18 problem is a complex optimization benchmark designed to test the robustness of algorithms. It shares structural similarities with the f16 problem but introduces several key variations to increase difficulty:
Component parameters are randomly selected from uniform distributions: the mean values range between 0.2 and 0.5, and the weight parameters range between 5 and 50.
Each component has a fixed probability value of 0.5, which creates varying interaction structures and connectivity patterns.
The angles within each component are randomly chosen from the full range of negative to positive pi, introducing rotational complexity.
These settings result in a highly multimodal landscape characterized by irregular, rugged terrain and noticeable asymmetry both at local and global levels. Although each component is separable, they differ significantly in the shape and structure of their local optima. This diversity in basin morphology makes it particularly challenging for optimization algorithms to avoid getting trapped in local optima and to effectively explore the search space.

The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).
Following is detail about the function: 
--- GNBG Problem Parameters for f18 ---
  Dimension: 30
  MaxEvals: 1000000
  AcceptanceThreshold: 1e-08
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
  Component Sigma: [-4470.4 -4399.9 -5000.  -4317.9 -4419.9]
  Component H: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
  Omega: [15.79314916  5.8359291  19.28130842 38.54004939 27.21963714  8.15099647
 49.48772695 35.11548021 32.89800733 26.88552999 31.08853487 16.92138009
 42.30414048 32.28482577 22.10635277  7.98506755 12.05561276 30.59831467
 29.79266986 21.65378891]
  RotationMatrix Shape: (30, 30, 5)
  Optimum Position: [-79.98170003 -24.71028367 -47.28764004   9.39037255 -29.85213149
 -73.75123468  73.26232482  53.5401075  -35.12896127 -33.02173626
 -46.13950144 -56.52342802  31.10402524   2.38225793 -57.71578444
 -24.35746244  40.15078944  74.37440754  -8.01405864  11.78871787
  61.75073589  68.7099574   69.21527409  67.68392569 -75.47096192
  54.72494278   9.76483508 -17.94229695 -70.41316968  34.07823686]
----------------------------------------


Current heuristics:
AdaptivePopulationDE
import numpy as np
import random

# Name: AdaptivePopulationDE
# Description: An adaptive Differential Evolution algorithm with dynamic population size, enhanced mutation strategies, and a restart mechanism to escape local optima in complex multimodal landscapes.
# Code:
class AdaptivePopulationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.population = None
        self.fitness = None
        self.F = 0.5  # Crossover rate
        self.Cr = 0.7 # Mutation factor

        self.archive = []
        self.archive_size = 100

        self.min_population_size = 5 * self.dim
        self.max_population_size = 20 * self.dim
        self.population_adaptation_rate = 0.1
        self.stagnation_counter = 0
        self.stagnation_threshold = 5000  # Number of evaluations without improvement before restart


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0

        # Initialize population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness)]
        self.best_fitness_overall = np.min(self.fitness)

        self.stagnation_counter = 0 # Reset Stagnation counter


        while self.eval_count < self.budget:
            # Generate offspring using an enhanced DE mutation strategy
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

             # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Selection: Replace parents with better offspring
            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            #Update best solution
            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0 # Reset if improvement occurs

            else:
                 self.stagnation_counter += len(offspring)

            # Adaptive population size adjustment
            self.adjust_population_size()


            # Stagnation check and restart mechanism
            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info



    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Mutation: "DE/current-to-best/1" with archive influence
            if self.archive and random.random() < 0.5:  # Utilize the archive probabilistically
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0] # Select a random member of the archive
            else:
                pbest = self.population[np.argmin(self.fitness)] #Fall back to best in current population
            
            indices = list(range(self.population_size))
            indices.remove(i) # Ensure distinct indices
            a, b = random.sample(indices, 2) # Select two unique indices

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            # Crossover: Binomial crossover
            for j in range(self.dim):
                if random.random() > self.Cr: # Perform binomial crossover
                    mutant[j] = self.population[i][j]  # Keep parent's gene

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive replacement
                worst_index = np.argmax([f for _, f in self.archive]) # Find worst fitness in archive
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])




    def adjust_population_size(self):
        if random.random() < self.population_adaptation_rate: # Control adaptation frequency
            if self.stagnation_counter > self.stagnation_threshold / 2: # Stagnation suggests too small, increase pop
                self.population_size = min(int(self.population_size * 1.1), self.max_population_size)
            else: # Otherwise may reduce population to encourage convergence
                self.population_size = max(int(self.population_size * 0.9), self.min_population_size)
        self.population_size = int(self.population_size) # Ensure population size remains an integer.



    def restart_population(self, objective_function):
        # Option 1: Re-initialize entire population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
             self.best_solution_overall = self.population[best_index]
             self.best_fitness_overall = self.fitness[best_index]

        # Option 2: Keep best solution and re-initialize the rest (exploitation of best)
        # num_reinitialized = int(0.8 * self.population_size)  # Re-initialize 80% of the pop.
        # self.population[num_reinitialized:] = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size - num_reinitialized, self.dim))
        # self.fitness[num_reinitialized:] = objective_function(self.population[num_reinitialized:])
        # self.eval_count += (self.population_size - num_reinitialized) # Update evaluation count


Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- Okay, I understand. The goal is to redefine "Current self-reflection" into a more actionable and insightful guide for designing better heuristics, specifically addressing the weaknesses identified in "Ineffective self-reflection."  We need to move beyond simple combinations of techniques toward a deeper understanding of how these elements interact and adapt.

Here's a refined perspective, designed to stimulate the development of improved heuristics:

*   **Keywords:** Adaptive Landscapes, Exploration-Exploitation, Population Dynamics, Hybrid Algorithms, Adaptive Memory, Constraint Satisfaction, Sensitivity Analysis.

*   **Advice:** Instead of blindly combining methods, focus on the *interaction* between them. Implement a system that monitors performance *metrics* (e.g., convergence rate, diversity levels, objective function improvements per iteration) and dynamically adjusts the weighting of different search components (global vs. local).  Consider sensitivity analysis to understand how each parameter *truly* affects performance in varied search spaces. The Archive needs strategies to discard points to avoid memory overload, in order to store diversity data. It helps reduce the effect from random noise.

*   **Avoid:** Simplistic recipes like "combine X with Y." Avoid static schedules for parameter adaptation; instead, design *reactive* systems. Move away from "top candidates" selection, which encourages premature convergence. Avoid focusing solely on objective function improvement; diversity metrics are equally crucial. Limit the "black-box" approach; aim for *explainable* adaptations.

*   **Explanation:** The core issue is that simply *having* various search components (adaptive DE, archive, local search) doesn't guarantee a good heuristic. The *way* they interact and respond to the problem landscape is critical. The ideal heuristic dynamically adjusts its behavior based on the perceived difficulty and characteristics of the search space. The archive serves not merely as a memory but as a guide, shaping the evolutionary process, and the local search assists when global search stagnates. Focus on a reactive, interconnected system. Remember constraints are extremely important, so focus on ways to satisfy constraints and discard constraint violating solutions.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
