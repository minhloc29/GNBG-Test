2025-06-24 21:16:37 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:16:37 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:16:37 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:16:37 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:17:19 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.6969
2025-06-24 21:17:19 INFO FeHistory: [134271.17514379 108050.59726538 118123.52389099 ...  -5000.
  -5000.          -5000.        ]
2025-06-24 21:17:19 INFO Expected Optimum FE: -5000
2025-06-24 21:17:19 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

2025-06-24 21:17:19 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:17:20 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:17:20 INFO FeHistory: [138823.75592733 142463.25238682 153096.74605249 ... 105193.14710702
 122850.51593246 107461.69148281]
2025-06-24 21:17:20 INFO Expected Optimum FE: -5000
2025-06-24 21:17:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:17:21 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:17:21 INFO FeHistory: [149575.63675534 106376.51243134 147547.82514467 ...  -4418.68541868
  -4418.6854191   -4418.68541861]
2025-06-24 21:17:21 INFO Expected Optimum FE: -5000
2025-06-24 21:17:21 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:17:58 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:17:58 INFO FeHistory: [199223.28633099 102074.41446403 214914.0921154  ...  -4317.89954693
  -4317.89954693  -4317.89954693]
2025-06-24 21:17:58 INFO Expected Optimum FE: -5000
2025-06-24 21:17:58 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:17:59 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:17:59 INFO FeHistory: [165813.87704407 152037.70343858  99529.11455611 ...  19057.02567107
  33331.18577956  53518.55745243]
2025-06-24 21:17:59 INFO Expected Optimum FE: -5000
2025-06-24 21:17:59 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:18:01 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:18:01 INFO FeHistory: [117960.66833734 165708.40446134 103992.81533835 ...  -4419.8999965
  -4419.89999643  -4419.89999697]
2025-06-24 21:18:01 INFO Expected Optimum FE: -5000
2025-06-24 21:18:01 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:18:36 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.4069
2025-06-24 21:18:36 INFO FeHistory: [167492.49667317 219687.82667175 193824.95217318 ...  -4999.99957679
  -4999.99957679  -4999.99957679]
2025-06-24 21:18:36 INFO Expected Optimum FE: -5000
2025-06-24 21:18:36 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

2025-06-24 21:18:36 INFO Unimodal AOCC mean: nan
2025-06-24 21:18:36 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:18:36 INFO Multimodal (multiple components) AOCC mean: 0.3679
2025-06-24 21:18:36 INFO AOCC mean: 0.3679
2025-06-24 21:18:36 INFO Weighed AOCC mean: nan
2025-06-24 21:18:38 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.6449
2025-06-24 21:18:38 INFO FeHistory: [119561.93035993 168332.57099031 107606.14058934 ... 106111.14399209
 149766.46630419 165512.3594137 ]
2025-06-24 21:18:38 INFO Expected Optimum FE: -5000
2025-06-24 21:18:38 INFO Good algorithm:
Algorithm Name: AdaptivePopulationDE
import numpy as np
import random
# f18 aocc 0.8
# f20 aocc 0.5
# not so good again, get stuck in local optima
class AdaptivePopulationDE: 
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.min_population_size = 5 * self.dim
        self.max_population_size = 20 * self.dim
        self.population_adaptation_rate = 0.1

        self.F = 0.5  # Mutation factor
        self.Cr = 0.7 # Crossover rate

        self.stagnation_counter = 0
        self.stagnation_threshold = 5000

        self.archive = []
        self.archive_size = 100

        self.population = None
        self.fitness = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.stagnation_counter = 0

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(self.fitness)
        self.best_solution_overall = self.population[best_index]
        self.best_fitness_overall = self.fitness[best_index]

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0
            else:
                self.stagnation_counter += len(offspring)

            self.adjust_population_size(objective_function)

            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            indices = list(range(self.population_size))
            indices.remove(i)
            if len(indices) < 2:
                continue  # Skip if not enough individuals

            a, b = random.sample(indices, 2)

            if self.archive and random.random() < 0.5:
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0]
            else:
                pbest = self.population[np.argmin(self.fitness)]

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            for j in range(self.dim):
                if random.random() > self.Cr:
                    mutant[j] = self.population[i][j]

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adjust_population_size(self, objective_function):
        if random.random() < self.population_adaptation_rate:
            if self.stagnation_counter > self.stagnation_threshold / 2:
                new_size = min(int(self.population_size * 1.1), self.max_population_size)
            else:
                new_size = max(int(self.population_size * 0.9), self.min_population_size)

            new_size = int(new_size)
            if new_size > self.population_size:
                additional = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(new_size - self.population_size, self.dim))
                additional_fitness = objective_function(additional)
                self.population = np.vstack((self.population, additional))
                self.fitness = np.concatenate((self.fitness, additional_fitness))
                self.eval_count += len(additional)
            elif new_size < self.population_size:
                best_indices = np.argsort(self.fitness)[:new_size]
                self.population = self.population[best_indices]
                self.fitness = self.fitness[best_indices]

            self.population_size = new_size

    def restart_population(self, objective_function):
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = self.fitness[best_index]
2025-06-24 21:18:38 INFO Unimodal AOCC mean: nan
2025-06-24 21:18:38 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:18:38 INFO Multimodal (multiple components) AOCC mean: 0.2150
2025-06-24 21:18:38 INFO AOCC mean: 0.2150
2025-06-24 21:18:38 INFO Weighed AOCC mean: nan
2025-06-24 21:18:40 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:18:40 INFO FeHistory: [143163.19011675 110688.69787521 119319.84644869 ...  -4399.89188621
  -4399.88244858  -4399.89043629]
2025-06-24 21:18:40 INFO Expected Optimum FE: -5000
2025-06-24 21:18:40 INFO Unimodal AOCC mean: nan
2025-06-24 21:18:40 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:18:40 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 21:18:40 INFO AOCC mean: 0.0000
2025-06-24 21:18:40 INFO Weighed AOCC mean: nan
2025-06-24 21:18:52 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:18:52 INFO FeHistory: [160628.3260048  174739.32313109 137916.87260259 ...  -4399.9
  -4399.9         -4399.9       ]
2025-06-24 21:18:52 INFO Expected Optimum FE: -5000
2025-06-24 21:18:52 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:20:56 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:20:56 INFO FeHistory: [105665.00496683 165968.32319233 271897.94201932 ...  -4317.9
  -4317.9         -4317.9       ]
2025-06-24 21:20:56 INFO Expected Optimum FE: -5000
2025-06-24 21:20:56 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:23:00 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.8369
2025-06-24 21:23:00 INFO FeHistory: [ 56466.21089546 262046.16373349 317816.1849323  ...  -5000.
  -5000.          -5000.        ]
2025-06-24 21:23:00 INFO Expected Optimum FE: -5000
2025-06-24 21:23:00 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 21:23:00 INFO Unimodal AOCC mean: nan
2025-06-24 21:23:00 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:23:00 INFO Multimodal (multiple components) AOCC mean: 0.2790
2025-06-24 21:23:00 INFO AOCC mean: 0.2790
2025-06-24 21:23:00 INFO Weighed AOCC mean: nan
