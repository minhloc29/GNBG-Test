{
  "name": "AdaptiveGaussianDEImprovedLocalSearch",
  "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, incorporating a local search phase for intensified exploitation around promising solutions.",
  "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedLocalSearch:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n        self.local_search_iterations = 10\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0), best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        current_solution = self.best_solution_overall.copy()\n                        for k in range(self.local_search_iterations):\n                            neighbor = current_solution + np.random.normal(0, 0.1, self.dim)\n                            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)\n                            neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]\n                            self.eval_count += 1\n                            if neighbor_fitness < self.best_fitness_overall:\n                                self.best_fitness_overall = neighbor_fitness\n                                self.best_solution_overall = neighbor.copy()\n                                current_solution = neighbor.copy()\n\n            for j in range(self.population_size):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((population[j], fitness_values[j]))\n                else:\n                    if fitness_values[j] < np.max([f for _, f in self.archive]):\n                        self.archive.pop(np.argmax([f for _, f in self.archive]))\n                        self.archive.append((population[j], fitness_values[j]))\n\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info"
}
