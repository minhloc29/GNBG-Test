2025-06-23 11:57:43 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:57:50 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.1948
2025-06-23 11:57:50 INFO FeHistory: [-701.29290702 -701.29036377 -701.33535857 ... -702.24288257 -702.2574629
 -702.24331273]
2025-06-23 11:57:50 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:57:50 INFO Good algorithm:
Algorithm Name: AdaptiveDEMultimodalOptimizer
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDEMultimodalOptimizer
# Description: Combines adaptive DE with Gaussian mutation and an archive for efficient multimodal optimization.

class AdaptiveDEMultimodalOptimizer:
    """
    Combines adaptive Differential Evolution (DE) with Gaussian mutation and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, initial_F: float = 0.5, initial_CR: float = 0.9, initial_sigma_multiplier: float = 0.3):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.F = initial_F
        self.CR = initial_CR
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) #Adaptive Gaussian sigma
        self.sigma_decay = 0.99 # Gaussian sigma decay rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_gaussian = self._generate_offspring_gaussian(population)
            offspring = np.vstack((offspring_de, offspring_gaussian))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self.sigma *= self.sigma_decay # Adapt Gaussian mutation strength

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population[:self.population_size//2])
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_gaussian(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            new_solution = population[i] + np.random.normal(0, self.sigma, self.dim)
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        #Simple distance-based archive update (can be improved)
        distances = np.linalg.norm(population[:, np.newaxis, :] - self.archive[:, :-1], axis=2)
        min_distances = np.min(distances, axis=1)
        novel_indices = np.where(min_distances > 0.1)[0]  #0.1 is a threshold, can be tuned
        novel_solutions = combined[novel_indices]

        if len(self.archive) + len(novel_solutions) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

2025-06-23 11:57:50 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:57:57 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1194
2025-06-23 11:57:57 INFO FeHistory: [-220.70312207 -222.41709684 -222.1086877  ... -228.78283794 -228.77826551
 -228.78086556]
2025-06-23 11:57:57 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:57:57 INFO Good algorithm:
Algorithm Name: AdaptiveDEMultimodalOptimizer
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDEMultimodalOptimizer
# Description: Combines adaptive DE with Gaussian mutation and an archive for efficient multimodal optimization.

class AdaptiveDEMultimodalOptimizer:
    """
    Combines adaptive Differential Evolution (DE) with Gaussian mutation and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, initial_F: float = 0.5, initial_CR: float = 0.9, initial_sigma_multiplier: float = 0.3):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.F = initial_F
        self.CR = initial_CR
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds) #Adaptive Gaussian sigma
        self.sigma_decay = 0.99 # Gaussian sigma decay rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_gaussian = self._generate_offspring_gaussian(population)
            offspring = np.vstack((offspring_de, offspring_gaussian))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self.sigma *= self.sigma_decay # Adapt Gaussian mutation strength

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population[:self.population_size//2])
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_gaussian(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            new_solution = population[i] + np.random.normal(0, self.sigma, self.dim)
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        #Simple distance-based archive update (can be improved)
        distances = np.linalg.norm(population[:, np.newaxis, :] - self.archive[:, :-1], axis=2)
        min_distances = np.min(distances, axis=1)
        novel_indices = np.where(min_distances > 0.1)[0]  #0.1 is a threshold, can be tuned
        novel_solutions = combined[novel_indices]

        if len(self.archive) + len(novel_solutions) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

2025-06-23 11:57:57 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:58:16 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0164
2025-06-23 11:58:16 INFO FeHistory: [171.81841814 155.67271535 188.71271126 ... -39.4934253  -39.51100102
 -39.47347547]
2025-06-23 11:58:16 INFO Expected Optimum FE: -100
2025-06-23 11:58:16 INFO Unimodal AOCC mean: 0.1948
2025-06-23 11:58:16 INFO Multimodal (single component) AOCC mean: 0.1194
2025-06-23 11:58:16 INFO Multimodal (multiple components) AOCC mean: 0.0164
2025-06-23 11:58:16 INFO AOCC mean: 0.1102
