2025-06-24 21:03:14 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:03:14 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:03:14 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:03:14 INFO --- GNBG Problem Parameters for f16 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0 0 0 0 0 0 0 0 0 0]
----------------------------------------
2025-06-24 21:03:56 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:03:56 INFO FeHistory: [104593.98152729 106464.22579378 153975.30610169 ...  -4317.9
  -4317.9         -4317.9       ]
2025-06-24 21:03:56 INFO Expected Optimum FE: -5000
2025-06-24 21:03:56 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:03:58 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.8166
2025-06-24 21:03:58 INFO FeHistory: [114141.70246181 150284.74232097 160904.61804218 ...  -3712.52793027
  -2337.44052628  -3313.02546376]
2025-06-24 21:03:58 INFO Expected Optimum FE: -5000
2025-06-24 21:03:58 INFO Good algorithm:
Algorithm Name: AdaptivePopulationDE
import numpy as np
import random
# f18 aocc 0.8
# f20 aocc 0.5
# not so good again, get stuck in local optima
class AdaptivePopulationDE: 
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.min_population_size = 5 * self.dim
        self.max_population_size = 20 * self.dim
        self.population_adaptation_rate = 0.1

        self.F = 0.5  # Mutation factor
        self.Cr = 0.7 # Crossover rate

        self.stagnation_counter = 0
        self.stagnation_threshold = 5000

        self.archive = []
        self.archive_size = 100

        self.population = None
        self.fitness = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.stagnation_counter = 0

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(self.fitness)
        self.best_solution_overall = self.population[best_index]
        self.best_fitness_overall = self.fitness[best_index]

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0
            else:
                self.stagnation_counter += len(offspring)

            self.adjust_population_size(objective_function)

            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            indices = list(range(self.population_size))
            indices.remove(i)
            if len(indices) < 2:
                continue  # Skip if not enough individuals

            a, b = random.sample(indices, 2)

            if self.archive and random.random() < 0.5:
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0]
            else:
                pbest = self.population[np.argmin(self.fitness)]

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            for j in range(self.dim):
                if random.random() > self.Cr:
                    mutant[j] = self.population[i][j]

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adjust_population_size(self, objective_function):
        if random.random() < self.population_adaptation_rate:
            if self.stagnation_counter > self.stagnation_threshold / 2:
                new_size = min(int(self.population_size * 1.1), self.max_population_size)
            else:
                new_size = max(int(self.population_size * 0.9), self.min_population_size)

            new_size = int(new_size)
            if new_size > self.population_size:
                additional = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(new_size - self.population_size, self.dim))
                additional_fitness = objective_function(additional)
                self.population = np.vstack((self.population, additional))
                self.fitness = np.concatenate((self.fitness, additional_fitness))
                self.eval_count += len(additional)
            elif new_size < self.population_size:
                best_indices = np.argsort(self.fitness)[:new_size]
                self.population = self.population[best_indices]
                self.fitness = self.fitness[best_indices]

            self.population_size = new_size

    def restart_population(self, objective_function):
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = self.fitness[best_index]
2025-06-24 21:03:58 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:03:58 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:03:58 INFO FeHistory: [125318.17655762 170302.84292839 158030.30981433 ...  -4317.9
  -4317.9         -4317.9       ]
2025-06-24 21:03:58 INFO Expected Optimum FE: -5000
2025-06-24 21:03:58 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:04:37 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:04:37 INFO FeHistory: [141622.11450503 144250.59770218 156121.32636634 ...  -4399.69670413
  -4399.69670413  -4399.69670413]
2025-06-24 21:04:37 INFO Expected Optimum FE: -5000
2025-06-24 21:04:37 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:04:39 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:04:39 INFO FeHistory: [162305.12808135 168225.21109178 146292.36596467 ...  38101.69543619
  86597.45139055  14326.43847239]
2025-06-24 21:04:39 INFO Expected Optimum FE: -5000
2025-06-24 21:04:39 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:04:39 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:04:39 INFO FeHistory: [172730.37650918 150899.20433177 163787.35496785 ...  -4419.8999997
  -4419.89999983  -4419.89999961]
2025-06-24 21:04:39 INFO Expected Optimum FE: -5000
2025-06-24 21:04:39 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:05:16 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:05:16 INFO FeHistory: [208034.90948178 306451.17255251 157736.26846811 ...  -4379.6662306
  -4379.6662306   -4379.6662306 ]
2025-06-24 21:05:16 INFO Expected Optimum FE: -5000
2025-06-24 21:05:16 INFO Unimodal AOCC mean: nan
2025-06-24 21:05:16 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:05:16 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 21:05:16 INFO AOCC mean: 0.0000
2025-06-24 21:05:16 INFO Weighed AOCC mean: nan
2025-06-24 21:05:19 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:05:19 INFO FeHistory: [229329.8522932  109523.32806601 139268.74602403 ...  74086.53029335
  50172.96845234  91414.10246242]
2025-06-24 21:05:19 INFO Expected Optimum FE: -5000
2025-06-24 21:05:19 INFO Unimodal AOCC mean: nan
2025-06-24 21:05:19 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:05:19 INFO Multimodal (multiple components) AOCC mean: 0.2722
2025-06-24 21:05:19 INFO AOCC mean: 0.2722
2025-06-24 21:05:19 INFO Weighed AOCC mean: nan
2025-06-24 21:05:20 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:05:20 INFO FeHistory: [178223.55344389 224642.87424591 147110.11466478 ...  -4317.89951439
  -4317.89976115  -4317.89971918]
2025-06-24 21:05:20 INFO Expected Optimum FE: -5000
2025-06-24 21:05:20 INFO Unimodal AOCC mean: nan
2025-06-24 21:05:20 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:05:20 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 21:05:20 INFO AOCC mean: 0.0000
2025-06-24 21:05:20 INFO Weighed AOCC mean: nan
2025-06-24 21:05:34 INFO Run function 16 complete. FEHistory len: 150000, AOCC: 0.8389
2025-06-24 21:05:34 INFO FeHistory: [ 96295.55145297 160700.5448868  211616.47244751 ...  -5000.
  -5000.          -5000.        ]
2025-06-24 21:05:34 INFO Expected Optimum FE: -5000
2025-06-24 21:05:34 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 21:05:34 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 21:07:48 INFO Run function 18 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:07:48 INFO FeHistory: [124372.19376472 282079.5873402  134459.0420169  ...  -4470.4
  -4470.4         -4470.4       ]
2025-06-24 21:07:48 INFO Expected Optimum FE: -5000
2025-06-24 21:07:48 INFO --- GNBG Problem Parameters for f19 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]
----------------------------------------
2025-06-24 21:10:00 INFO Run function 19 complete. FEHistory len: 150000, AOCC: 0.0000
2025-06-24 21:10:00 INFO FeHistory: [205607.06808482 165085.0301488  203190.57572903 ...  -4317.9
  -4317.9         -4317.9       ]
2025-06-24 21:10:00 INFO Expected Optimum FE: -5000
2025-06-24 21:10:00 INFO Unimodal AOCC mean: nan
2025-06-24 21:10:00 INFO Multimodal (single component) AOCC mean: nan
2025-06-24 21:10:00 INFO Multimodal (multiple components) AOCC mean: 0.2796
2025-06-24 21:10:00 INFO AOCC mean: 0.2796
2025-06-24 21:10:00 INFO Weighed AOCC mean: nan
