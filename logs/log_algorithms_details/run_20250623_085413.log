2025-06-23 08:54:14 INFO Initializing first population
2025-06-23 08:54:14 INFO Initializing population from 8 seed files...
2025-06-23 08:54:43 INFO Started evolutionary loop, best so far: 0.1912754551816446
2025-06-23 08:54:43 INFO Population length is: 8
2025-06-23 08:54:43 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-23 08:54:43 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.9128e-01 |             AOCC Score on Unimodal instances: 1.9128e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 2 (Overall AOCC Score: 1.8184e-01 |             AOCC Score on Unimodal instances: 1.8184e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 3 (Overall AOCC Score: 1.8137e-01 |             AOCC Score on Unimodal instances: 1.8137e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 4 (Overall AOCC Score: 1.8135e-01 |             AOCC Score on Unimodal instances: 1.8135e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 5 (Overall AOCC Score: 1.8015e-01 |             AOCC Score on Unimodal instances: 1.8015e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 6 (Overall AOCC Score: 1.7939e-01 |             AOCC Score on Unimodal instances: 1.7939e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 7 (Overall AOCC Score: 1.7916e-01 |             AOCC Score on Unimodal instances: 1.7916e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 8 (Overall AOCC Score: 1.7663e-01 |             AOCC Score on Unimodal instances: 1.7663e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 08:54:47 INFO Full response text: **Analysis:**

Comparing `AdaptiveMultimodalOptimizerImproved` (best) vs `AdaptiveGaussianMutationDE` (worst), we see that the best utilizes a tabu list and adaptive temperature for simulated annealing, improving exploration and exploitation.  The worst uses a simpler differential evolution with Gaussian mutation, lacking the sophisticated control mechanisms of the best. `AdaptiveGaussianArchiveEA` (second best) vs `EnhancedArchiveGuidedDE` (second worst) shows that maintaining a diverse archive significantly improves performance.  `AdaptiveGaussianArchiveEA` uses an increased archive size and a slightly faster sigma decay, preventing premature convergence. `EnhancedArchiveGuidedDE` has a less sophisticated archive update strategy, potentially leading to less diverse exploration. Comparing `AdaptiveMultimodalOptimizerImproved` (1st) vs `AdaptiveGaussianArchiveEA` (2nd), we see that the former's local search and tabu list provide a significant advantage in unimodal landscapes. The latter's archive helps, but may be less effective in purely unimodal scenarios. `AdaptiveGaussianSamplingEA` (3rd) vs `AdaptiveGaussianSamplingEAwithArchive` (4th) shows the value of an archive in this specific case, with the archive-based approach offering better robustness in exploration. Comparing `AdaptiveGaussianMutationDE` (second worst) vs `EnhancedArchiveGuidedDE` (worst), we see that while both use archives and differential evolution, the adaptive scaling factor and archive management in `EnhancedArchiveGuidedDE` is not as effective. Overall:  The top-performing algorithms incorporate sophisticated exploration mechanisms such as adaptive temperature, tabu lists, and diverse archives, coupled with effective exploitation techniques. Adaptive mutation strategies and well-managed archives are crucial for success across different landscape complexities.


**Experience:**

Combining adaptive parameter tuning with multiple exploration strategies, such as archive-based search and local search, proves highly beneficial.  A well-managed archive promotes diversity and avoids premature convergence.  Adaptive temperature and tabu lists add significant robustness.

2025-06-23 08:54:48 INFO Full response text: * **Keywords:** Adaptive parameter tuning, diverse exploration, archive-based search, local search, robust optimization.

* **Advice:** Focus on mechanisms ensuring exploration breadth before intensification.  Prioritize diverse archive management to prevent stagnation.  Dynamically adjust exploration parameters based on search progress. Implement sophisticated mechanisms to avoid revisiting unproductive areas.

* **Avoid:**  Premature convergence, overly simplistic parameter tuning, reliance on single exploration strategy.

* **Explanation:**  Effective heuristics balance exploration and exploitation.  By dynamically adapting parameters and employing multiple diverse search strategies guided by a well-managed archive, the risk of getting stuck in local optima is significantly reduced, leading to better solutions.  Avoid static strategies that lack adaptability.

2025-06-23 08:54:48 INFO Generating offspring via Crossover...
2025-06-23 08:56:05 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveGaussianSamplingEAwithArchive
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Worse code
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

### Analyze & experience
- Comparing `AdaptiveMultimodalOptimizerImproved` (best) vs `AdaptiveGaussianMutationDE` (worst), we see that the best utilizes a tabu list and adaptive temperature for simulated annealing, improving exploration and exploitation.  The worst uses a simpler differential evolution with Gaussian mutation, lacking the sophisticated control mechanisms of the best. `AdaptiveGaussianArchiveEA` (second best) vs `EnhancedArchiveGuidedDE` (second worst) shows that maintaining a diverse archive significantly improves performance.  `AdaptiveGaussianArchiveEA` uses an increased archive size and a slightly faster sigma decay, preventing premature convergence. `EnhancedArchiveGuidedDE` has a less sophisticated archive update strategy, potentially leading to less diverse exploration. Comparing `AdaptiveMultimodalOptimizerImproved` (1st) vs `AdaptiveGaussianArchiveEA` (2nd), we see that the former's local search and tabu list provide a significant advantage in unimodal landscapes. The latter's archive helps, but may be less effective in purely unimodal scenarios. `AdaptiveGaussianSamplingEA` (3rd) vs `AdaptiveGaussianSamplingEAwithArchive` (4th) shows the value of an archive in this specific case, with the archive-based approach offering better robustness in exploration. Comparing `AdaptiveGaussianMutationDE` (second worst) vs `EnhancedArchiveGuidedDE` (worst), we see that while both use archives and differential evolution, the adaptive scaling factor and archive management in `EnhancedArchiveGuidedDE` is not as effective. Overall:  The top-performing algorithms incorporate sophisticated exploration mechanisms such as adaptive temperature, tabu lists, and diverse archives, coupled with effective exploitation techniques. Adaptive mutation strategies and well-managed archives are crucial for success across different landscape complexities.
- * **Keywords:** Adaptive parameter tuning, diverse exploration, archive-based search, local search, robust optimization.

* **Advice:** Focus on mechanisms ensuring exploration breadth before intensification.  Prioritize diverse archive management to prevent stagnation.  Dynamically adjust exploration parameters based on search progress. Implement sophisticated mechanisms to avoid revisiting unproductive areas.

* **Avoid:**  Premature convergence, overly simplistic parameter tuning, reliance on single exploration strategy.

* **Explanation:**  Effective heuristics balance exploration and exploitation.  By dynamically adapting parameters and employing multiple diverse search strategies guided by a well-managed archive, the risk of getting stuck in local optima is significantly reduced, leading to better solutions.  Avoid static strategies that lack adaptability.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 08:56:05 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveMultimodalOptimizerImproved
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability









Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:** Adaptive parameter tuning, diverse exploration, archive-based search, local search, robust optimization.

* **Advice:** Focus on mechanisms ensuring exploration breadth before intensification.  Prioritize diverse archive management to prevent stagnation.  Dynamically adjust exploration parameters based on search progress. Implement sophisticated mechanisms to avoid revisiting unproductive areas.

* **Avoid:**  Premature convergence, overly simplistic parameter tuning, reliance on single exploration strategy.

* **Explanation:**  Effective heuristics balance exploration and exploitation.  By dynamically adapting parameters and employing multiple diverse search strategies guided by a well-managed archive, the risk of getting stuck in local optima is significantly reduced, leading to better solutions.  Avoid static strategies that lack adaptability.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 08:56:24 INFO Perform Harmony Search...
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:56:33 ERROR Can not run the algorithm
2025-06-23 08:56:33 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:56:33 INFO FeHistory: []
2025-06-23 08:56:33 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:56:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:56:33 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:56:33 INFO AOCC mean: 0.0000
2025-06-23 08:56:33 INFO Generation 1, best so far: 0.19144400559668218
2025-06-23 08:56:33 INFO Population length is: 7
2025-06-23 08:56:33 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-23 08:56:33 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.7725e-01 |             AOCC Score on Unimodal instances: 1.7725e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveArchiveOptimizer
# Description: A hybrid evolutionary algorithm employing adaptive parameter tuning, diverse exploration via multiple mutation strategies, and an archive-based search to effectively navigate multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveOptimizer
# Description: A hybrid evolutionary algorithm employing adaptive parameter tuning, diverse exploration via multiple mutation strategies, and an archive-based search to effectively navigate multimodal landscapes.

class AdaptiveArchiveOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive = []  # Archive of diverse solutions
        self.archive_size = 100  # Maximum archive size
        self.population_size = 50
        self.mutation_rate = 0.2
        self.exploration_factor = 1.0 # Initially high exploration
        self.exploitation_factor = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self._update_best(population, fitness_values)
        self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)

            population = self._select_population(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += self.population_size

            #Adapt parameters based on search progress
            self._adapt_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(low=self.lower_bounds, high=self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population):
        offspring = []
        for i in range(self.population_size):
            parent1 = population[random.randint(0, self.population_size -1)]
            parent2 = population[random.randint(0, self.population_size -1)]

            child = self._crossover(parent1, parent2)
            child = self._mutate(child)
            offspring.append(child)

        return np.array(offspring)


    def _crossover(self, parent1, parent2):
        crossover_point = random.randint(1, self.dim - 1)
        child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))
        return child

    def _mutate(self, individual):
        for i in range(self.dim):
            if random.random() < self.mutation_rate:
                individual[i] += np.random.normal(0, self.exploration_factor * (self.upper_bounds[i] - self.lower_bounds[i]))
        individual = np.clip(individual, self.lower_bounds, self.upper_bounds)
        return individual

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        for i, solution in enumerate(population):
            self._add_to_archive(solution, fitness_values[i])
        #Maintaining diversity.  This is a rudimentary method, more sophisticated ones could be implemented.
        if len(self.archive) > self.archive_size:
            self.archive.sort(key=lambda x: x[1]) #Sort by fitness
            self.archive = self.archive[:self.archive_size]



    def _add_to_archive(self, solution, fitness):
        self.archive.append((solution, fitness))


    def _select_population(self, parent_population, parent_fitness, offspring_population, offspring_fitness):
        combined_population = np.concatenate((parent_population, offspring_population))
        combined_fitness = np.concatenate((parent_fitness, offspring_fitness))
        
        indices = np.argsort(combined_fitness)
        selected_population = combined_population[indices[:self.population_size]]
        
        return selected_population


    def _adapt_parameters(self):
        #Simple adaptive mechanism.  More sophisticated methods could be used here.
        if self.eval_count > self.budget * 0.7: #Shift towards exploitation later in the search
            self.exploration_factor *= 0.9
            self.exploitation_factor *= 1.1
        



```

### Rank 2 (Overall AOCC Score: 1.7615e-01 |             AOCC Score on Unimodal instances: 1.7615e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: ArchiveGuidedAdaptiveDEwithLocalSearch
# Description: Combines Differential Evolution, adaptive archive, and local search for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDEwithLocalSearch
# Description: Combines Differential Evolution, adaptive archive, and local search for multimodal optimization.
# Code:
class ArchiveGuidedAdaptiveDEwithLocalSearch:
    """
    Combines Differential Evolution, adaptive archive, and local search for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Local Search on offspring
            offspring, offspring_fitness = self.local_search(offspring, offspring_fitness, objective_function)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            #Select best
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()

        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def local_search(self, offspring, offspring_fitness, objective_function):
        local_search_iterations = 5
        for i in range(len(offspring)):
            current = offspring[i]
            for _ in range(local_search_iterations):
                neighbor = current + np.random.normal(0, 0.1, self.dim)
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                self.eval_count += 1
                if neighbor_fitness < offspring_fitness[i]:
                    current = neighbor
                    offspring_fitness[i] = neighbor_fitness
            offspring[i] = current
        return offspring, offspring_fitness
```

### Rank 3 (Overall AOCC Score: 1.7561e-01 |             AOCC Score on Unimodal instances: 1.7561e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: ArchiveGuidedAdaptiveDE
# Description: Differential Evolution with adaptive scaling and archive-guided exploration for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Differential Evolution with adaptive scaling and archive-guided exploration for multimodal optimization.
class ArchiveGuidedAdaptiveDE:
    """
    Differential Evolution with adaptive scaling and archive-guided exploration for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim  # Heuristic: population size
        self.archive_size = 200  # Increased archive size for diversity
        self.archive = []
        self.F_scale = 0.5  # Initial scaling factor
        self.F_scale_delta = 0.1 # Adaptive parameter for F_scale adjustment
        self.CR = 0.9 # Crossover Rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population,fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            self.population, fitness = self._select_next_generation(offspring,offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population,fitness)
            self._adapt_F_scale(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different_indices(i)
            mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(self.population[i], mutant)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]
        else:
            return self.population[np.argmin(np.array([f for _, f in self.archive]))]

    def _select_different_indices(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c
    
    def _crossover(self,x,v):
        return np.where(np.random.rand(self.dim) < self.CR, v, x)

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _select_next_generation(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _adapt_F_scale(self, fitness):
        if np.min(fitness) < self.best_fitness_overall:
            self.F_scale = min(1.0, self.F_scale + self.F_scale_delta)
        else:
            self.F_scale = max(0.0, self.F_scale - self.F_scale_delta)
    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
```

### Rank 4 (Overall AOCC Score: 1.7560e-01 |             AOCC Score on Unimodal instances: 1.7560e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: ArchiveGuidedAdaptiveDE
# Description: Differential Evolution with adaptive scaling and archive-guided exploration for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Differential Evolution with adaptive scaling and archive-guided exploration for multimodal optimization.
class ArchiveGuidedAdaptiveDE:
    """
    Differential Evolution with adaptive scaling factor and archive-guided exploration for efficiently solving multimodal optimization problems.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population, fitness = self.selection(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()  # Adaptive scaling factor
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant, self.CR)

        return offspring


    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]
        else:
            return self.population[np.argmin(np.concatenate((self.best_fitness_overall,self.population)))]

    def _crossover(self, x, v, CR):
        mask = np.random.rand(self.dim) < CR
        return np.where(mask, v, x)

    def _select_different(self, index, population_size):
        a, b, c = random.sample(range(population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def selection(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _find_best(self, population, fitness):
        best_index = np.argmin(fitness)
        return population[best_index], fitness[best_index]
```

### Rank 5 (Overall AOCC Score: 1.7526e-01 |             AOCC Score on Unimodal instances: 1.7526e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveArchiveSimulatedAnnealingEA
# Description: Combines adaptive Gaussian sampling, an archive, and simulated annealing for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveArchiveSimulatedAnnealingEA:
    """
    Combines adaptive Gaussian sampling with an archive and simulated annealing to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []
        self.temperature = 1.0
        self.cooling_rate = 0.95

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                solution = population[i]
                neighbor = self._generate_neighbor(solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1
                
                if self._accept(neighbor_fitness, fitness_values[i], self.temperature):
                    population[i] = neighbor
                    fitness_values[i] = neighbor_fitness

            self.archive = self._update_archive(population, fitness_values)
            self._update_best(population, fitness_values)
            self.sigma *= self.sigma_decay
            self.temperature *= self.cooling_rate

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _generate_neighbor(self, solution):
        neighbor = solution + np.random.normal(0, self.sigma, self.dim)
        return np.clip(neighbor, self.lower_bounds, self.upper_bounds)

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 6 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveMultimodalExplorationOptimizer
# Description: 
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalExplorationOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 307.9672737470231, archive_size: int = 827.5385954678039, mutation_rate: float = 0.4631531864521847,
                 exploration_rate: float = 0.21194291009438804, diversity_threshold: float = 0.3439612542823555):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = population_size  # Initial population size
        self.archive = []  # Archive of diverse solutions
        self.archive_size = archive_size  # Maximum archive size
        self.mutation_rate = mutation_rate  # Initial mutation rate
        self.exploration_rate = exploration_rate  # Initial exploration rate (global vs. local search)
        self.diversity_threshold = diversity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection: Tournament selection
            parents = self._tournament_selection(population, fitness)

            # Genetic Operators: Mutation & Crossover
            offspring = self._generate_offspring(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)


            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Adaptive Parameter Tuning
            self._adapt_parameters()

            # Combine population and offspring
            population = np.vstack((population, offspring))
            fitness = np.concatenate((fitness, offspring_fitness))

            # Select top individuals
            idx = np.argsort(fitness)
            population = population[idx[:self.population_size]]
            fitness = fitness[idx[:self.population_size]]


            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_rate': self.mutation_rate,
            'final_exploration_rate': self.exploration_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _tournament_selection(self, population, fitness, tournament_size=5):
        selected_indices = np.random.choice(len(population), size=self.population_size, replace=True)
        fitness_selected = fitness[selected_indices]

        best_in_tournament = np.argmin(fitness_selected)
        best_index = selected_indices[best_in_tournament]
        return population[[best_index]]


    def _generate_offspring(self, parents):
        offspring = []
        for _ in range(self.population_size):
            parent = parents[0]
            offspring_individual = parent + np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring_individual = np.clip(offspring_individual, self.lower_bounds, self.upper_bounds)
            offspring.append(offspring_individual)

        return np.array(offspring)


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Simple replacement strategy (replace worst in archive)
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _adapt_parameters(self):
        if len(self.archive) > 0:
             diversity = np.std([np.linalg.norm(x) for x, _ in self.archive])
             if diversity < self.diversity_threshold :
                self.mutation_rate *= 1.1 #increase mutation rate
             else:
                 self.mutation_rate *= 0.9 #decrease mutation rate
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 08:56:37 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveArchiveOptimizer vs (worst) AdaptiveMultimodalExplorationOptimizer, we see that AdaptiveArchiveOptimizer uses a more sophisticated archive management strategy, adaptive parameters (mutation rate, exploration/exploitation factors), and a more robust selection mechanism. AdaptiveMultimodalExplorationOptimizer uses simpler tournament selection and a less refined archive update, leading to inferior performance.  (second best) ArchiveGuidedAdaptiveDEwithLocalSearch vs (second worst) AdaptiveArchiveSimulatedAnnealingEA shows that incorporating local search significantly improves performance, as ArchiveGuidedAdaptiveDEwithLocalSearch demonstrates. AdaptiveArchiveSimulatedAnnealingEA relies solely on simulated annealing and lacks the adaptive parameter tuning and diversity mechanisms found in higher-ranked algorithms. Comparing (1st) vs (2nd), we see that while both use archives, the adaptive parameter control and multiple mutation strategies in AdaptiveArchiveOptimizer provide an edge. (3rd) vs (4th) both are ArchiveGuidedAdaptiveDE, the improvement is in code quality and a potentially more robust archive update. Comparing (second worst) vs (worst), we see that AdaptiveArchiveSimulatedAnnealingEA, despite its simulated annealing, underperforms AdaptiveMultimodalExplorationOptimizer due to its lack of adaptive parameter tuning and a less effective archive. Overall: The best-performing algorithms utilize adaptive parameter control, archive-based diversity maintenance, and incorporate sophisticated selection mechanisms (beyond simple tournament selection) to effectively explore and exploit the search space.  Local search also demonstrates a noticeable performance boost.


**Experience:**

Adaptive parameter tuning, diverse exploration strategies (multiple mutation operators or local search), and sophisticated archive management are crucial for handling high-dimensionality and multimodality.  Combining different evolutionary operators synergistically is vital for superior performance.

2025-06-23 08:56:39 INFO Full response text: * **Keywords:** Adaptive parameter control, diverse exploration (e.g., mutation, local search, archive-based), synergistic operator combinations,  robustness.

* **Advice:** Focus on dynamically adjusting parameters based on search progress.  Combine multiple fundamentally different exploration strategies (e.g., global vs. local).  Prioritize archive management to maintain diversity and prevent premature convergence.  Experiment with diverse operator combinations.

* **Avoid:** Static parameter settings, reliance on a single exploration strategy, neglecting archive management,  lack of robustness to problem characteristics.

* **Explanation:** Effective heuristics require dynamic adaptation to the problem landscape. Combining multiple diverse search strategies with adaptive parameter control and sophisticated archive management leads to more robust and effective search, mitigating the risks of premature convergence and stagnation inherent in simpler heuristics.  Synergy between operators is key to superior performance.

2025-06-23 08:56:39 INFO Generating offspring via Crossover...
2025-06-23 08:57:42 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveArchiveSimulatedAnnealingEA
import numpy as np
import random

class AdaptiveArchiveSimulatedAnnealingEA:
    """
    Combines adaptive Gaussian sampling with an archive and simulated annealing to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []
        self.temperature = 1.0
        self.cooling_rate = 0.95

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                solution = population[i]
                neighbor = self._generate_neighbor(solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1
                
                if self._accept(neighbor_fitness, fitness_values[i], self.temperature):
                    population[i] = neighbor
                    fitness_values[i] = neighbor_fitness

            self.archive = self._update_archive(population, fitness_values)
            self._update_best(population, fitness_values)
            self.sigma *= self.sigma_decay
            self.temperature *= self.cooling_rate

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _generate_neighbor(self, solution):
        neighbor = solution + np.random.normal(0, self.sigma, self.dim)
        return np.clip(neighbor, self.lower_bounds, self.upper_bounds)

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])


### Worse code
ArchiveGuidedAdaptiveDEwithLocalSearch
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDEwithLocalSearch
# Description: Combines Differential Evolution, adaptive archive, and local search for multimodal optimization.
# Code:
class ArchiveGuidedAdaptiveDEwithLocalSearch:
    """
    Combines Differential Evolution, adaptive archive, and local search for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Local Search on offspring
            offspring, offspring_fitness = self.local_search(offspring, offspring_fitness, objective_function)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            #Select best
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()

        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def local_search(self, offspring, offspring_fitness, objective_function):
        local_search_iterations = 5
        for i in range(len(offspring)):
            current = offspring[i]
            for _ in range(local_search_iterations):
                neighbor = current + np.random.normal(0, 0.1, self.dim)
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                self.eval_count += 1
                if neighbor_fitness < offspring_fitness[i]:
                    current = neighbor
                    offspring_fitness[i] = neighbor_fitness
            offspring[i] = current
        return offspring, offspring_fitness

### Analyze & experience
- Comparing (best) AdaptiveArchiveOptimizer vs (worst) AdaptiveMultimodalExplorationOptimizer, we see that AdaptiveArchiveOptimizer uses a more sophisticated archive management strategy, adaptive parameters (mutation rate, exploration/exploitation factors), and a more robust selection mechanism. AdaptiveMultimodalExplorationOptimizer uses simpler tournament selection and a less refined archive update, leading to inferior performance.  (second best) ArchiveGuidedAdaptiveDEwithLocalSearch vs (second worst) AdaptiveArchiveSimulatedAnnealingEA shows that incorporating local search significantly improves performance, as ArchiveGuidedAdaptiveDEwithLocalSearch demonstrates. AdaptiveArchiveSimulatedAnnealingEA relies solely on simulated annealing and lacks the adaptive parameter tuning and diversity mechanisms found in higher-ranked algorithms. Comparing (1st) vs (2nd), we see that while both use archives, the adaptive parameter control and multiple mutation strategies in AdaptiveArchiveOptimizer provide an edge. (3rd) vs (4th) both are ArchiveGuidedAdaptiveDE, the improvement is in code quality and a potentially more robust archive update. Comparing (second worst) vs (worst), we see that AdaptiveArchiveSimulatedAnnealingEA, despite its simulated annealing, underperforms AdaptiveMultimodalExplorationOptimizer due to its lack of adaptive parameter tuning and a less effective archive. Overall: The best-performing algorithms utilize adaptive parameter control, archive-based diversity maintenance, and incorporate sophisticated selection mechanisms (beyond simple tournament selection) to effectively explore and exploit the search space.  Local search also demonstrates a noticeable performance boost.
- * **Keywords:** Adaptive parameter control, diverse exploration (e.g., mutation, local search, archive-based), synergistic operator combinations,  robustness.

* **Advice:** Focus on dynamically adjusting parameters based on search progress.  Combine multiple fundamentally different exploration strategies (e.g., global vs. local).  Prioritize archive management to maintain diversity and prevent premature convergence.  Experiment with diverse operator combinations.

* **Avoid:** Static parameter settings, reliance on a single exploration strategy, neglecting archive management,  lack of robustness to problem characteristics.

* **Explanation:** Effective heuristics require dynamic adaptation to the problem landscape. Combining multiple diverse search strategies with adaptive parameter control and sophisticated archive management leads to more robust and effective search, mitigating the risks of premature convergence and stagnation inherent in simpler heuristics.  Synergy between operators is key to superior performance.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 08:57:42 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveMultimodalExplorationOptimizer
import numpy as np
import random

# Name: AdaptiveMultimodalExplorationOptimizer
# Description: An adaptive evolutionary algorithm combining diverse exploration strategies and an archive for robust multimodal optimization.
# Code:
class AdaptiveMultimodalExplorationOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50  # Initial population size
        self.archive = []  # Archive of diverse solutions
        self.archive_size = 100  # Maximum archive size
        self.mutation_rate = 0.1  # Initial mutation rate
        self.exploration_rate = 0.8  # Initial exploration rate (global vs. local search)
        self.diversity_threshold = 0.1

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection: Tournament selection
            parents = self._tournament_selection(population, fitness)

            # Genetic Operators: Mutation & Crossover
            offspring = self._generate_offspring(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)


            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Adaptive Parameter Tuning
            self._adapt_parameters()

            # Combine population and offspring
            population = np.vstack((population, offspring))
            fitness = np.concatenate((fitness, offspring_fitness))

            # Select top individuals
            idx = np.argsort(fitness)
            population = population[idx[:self.population_size]]
            fitness = fitness[idx[:self.population_size]]
            

            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_rate': self.mutation_rate,
            'final_exploration_rate': self.exploration_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _tournament_selection(self, population, fitness, tournament_size=5):
        selected_indices = np.random.choice(len(population), size=self.population_size, replace=True)
        fitness_selected = fitness[selected_indices]
        
        best_in_tournament = np.argmin(fitness_selected)
        best_index = selected_indices[best_in_tournament]
        return population[[best_index]]
        

    def _generate_offspring(self, parents):
        offspring = []
        for _ in range(self.population_size):
            parent = parents[0]
            offspring_individual = parent + np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring_individual = np.clip(offspring_individual, self.lower_bounds, self.upper_bounds)
            offspring.append(offspring_individual)

        return np.array(offspring)


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Simple replacement strategy (replace worst in archive)
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _adapt_parameters(self):
        if len(self.archive) > 0:
             diversity = np.std([np.linalg.norm(x) for x, _ in self.archive])
             if diversity < self.diversity_threshold :
                self.mutation_rate *= 1.1 #increase mutation rate
             else:
                 self.mutation_rate *= 0.9 #decrease mutation rate
                 



Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:** Adaptive parameter control, diverse exploration (e.g., mutation, local search, archive-based), synergistic operator combinations,  robustness.

* **Advice:** Focus on dynamically adjusting parameters based on search progress.  Combine multiple fundamentally different exploration strategies (e.g., global vs. local).  Prioritize archive management to maintain diversity and prevent premature convergence.  Experiment with diverse operator combinations.

* **Avoid:** Static parameter settings, reliance on a single exploration strategy, neglecting archive management,  lack of robustness to problem characteristics.

* **Explanation:** Effective heuristics require dynamic adaptation to the problem landscape. Combining multiple diverse search strategies with adaptive parameter control and sophisticated archive management leads to more robust and effective search, mitigating the risks of premature convergence and stagnation inherent in simpler heuristics.  Synergy between operators is key to superior performance.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 08:58:08 INFO Perform Harmony Search...
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:58:18 ERROR Can not run the algorithm
2025-06-23 08:58:18 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:58:18 INFO FeHistory: []
2025-06-23 08:58:18 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:58:18 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:58:18 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:58:18 INFO AOCC mean: 0.0000
2025-06-23 08:58:18 INFO Generation 2, best so far: 0.19144400559668218
2025-06-23 08:58:18 INFO Population length is: 7
2025-06-23 08:58:18 INFO --- Performing Long-Term Reflection at Generation 3 ---
2025-06-23 08:58:18 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.7636e-01 |             AOCC Score on Unimodal instances: 1.7636e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveDEwithArchiveAndLocalSearch
# Description: Combines Differential Evolution, adaptive archive, and local search for multimodal optimization with adaptive parameters.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithArchiveAndLocalSearch
# Description: Combines Differential Evolution, adaptive archive, and local search for multimodal optimization with adaptive parameters.
# Code:
class AdaptiveDEwithArchiveAndLocalSearch:
    """
    Combines Differential Evolution, an adaptive archive, and local search for efficient multimodal optimization.  Adapts mutation strength and crossover rate based on performance.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9
        self.F_adapt_rate = 0.1
        self.CR_adapt_rate = 0.05

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Local Search on offspring
            offspring, offspring_fitness = self.local_search(offspring, offspring_fitness, objective_function)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            #Select best
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution and adapt parameters
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            self.adapt_parameters(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def local_search(self, offspring, offspring_fitness, objective_function):
        local_search_iterations = 5
        for i in range(len(offspring)):
            current = offspring[i]
            for _ in range(local_search_iterations):
                neighbor = current + np.random.normal(0, 0.1, self.dim)
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                self.eval_count += 1
                if neighbor_fitness < offspring_fitness[i]:
                    current = neighbor
                    offspring_fitness[i] = neighbor_fitness
            offspring[i] = current
        return offspring, offspring_fitness

    def adapt_parameters(self, fitness):
        # Simple adaptive scheme based on average fitness improvement
        avg_fitness_improvement = np.mean(fitness) - self.best_fitness_overall
        if avg_fitness_improvement > 0 : # Improve
            self.F_scale = max(0.1, self.F_scale - self.F_adapt_rate)
            self.CR = max(0.1, self.CR - self.CR_adapt_rate)
        else: #Not Improve
            self.F_scale = min(1.0, self.F_scale + self.F_adapt_rate)
            self.CR = min(1.0, self.CR + self.CR_adapt_rate)

```

### Rank 2 (Overall AOCC Score: 1.7597e-01 |             AOCC Score on Unimodal instances: 1.7597e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveArchiveDEwithLocalSearch
# Description: Differential Evolution with adaptive parameters, archive, and local search for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDEwithLocalSearch
# Description: Differential Evolution with adaptive parameters, archive, and local search for multimodal optimization.
class AdaptiveArchiveDEwithLocalSearch:
    """
    Combines Differential Evolution (DE) with adaptive parameters, an archive to maintain diversity, and local search to escape local optima.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive = []
        self.archive_size = 200
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.local_search_iterations = 5


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_best(population, fitness_values)
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Local Search
            for i in range(len(offspring)):
                offspring[i] = self._local_search(offspring[i], objective_function)
            
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)

            population = self._select_population(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += self.population_size
            self._adapt_parameters()

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(low=self.lower_bounds, high=self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_individuals(population, i)
            mutant = self._mutate(a, b, c)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
        return np.array(offspring)

    def _select_individuals(self, population, i):
        indices = list(range(self.population_size))
        indices.remove(i)
        random.shuffle(indices)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _mutate(self, a, b, c):
        return np.clip(a + self.F * (b - c), self.lower_bounds, self.upper_bounds)

    def _crossover(self, x, v):
        trial = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        for i, solution in enumerate(population):
            self._add_to_archive(solution, fitness_values[i])
        if len(self.archive) > self.archive_size:
            self.archive.sort(key=lambda x: x[1])
            self.archive = self.archive[:self.archive_size]


    def _add_to_archive(self, solution, fitness):
        already_present = any(np.allclose(solution, arch[0], atol=1e-6) for arch in self.archive)
        if not already_present:
            self.archive.append((solution, fitness))


    def _select_population(self, parent_population, parent_fitness, offspring_population, offspring_fitness):
        combined_population = np.concatenate((parent_population, offspring_population))
        combined_fitness = np.concatenate((parent_fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        selected_population = combined_population[indices[:self.population_size]]
        return selected_population

    def _adapt_parameters(self):
        if self.eval_count > self.budget * 0.7:
            self.F *= 0.9
            self.CR *= 0.95

    def _local_search(self, solution, objective_function):
        current_solution = np.copy(solution)
        current_fitness = objective_function(current_solution.reshape(1,-1))[0]
        for _ in range(self.local_search_iterations):
            neighbor = current_solution + np.random.normal(0, 0.1 * (self.upper_bounds - self.lower_bounds), self.dim)
            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
            neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
            if neighbor_fitness < current_fitness:
                current_solution = neighbor
                current_fitness = neighbor_fitness
        return current_solution

```

### Rank 3 (Overall AOCC Score: 1.7547e-01 |             AOCC Score on Unimodal instances: 1.7547e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveArchiveDEwithLocalSearch
# Description: Differential Evolution with adaptive scaling, archive, and local search for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDEwithLocalSearch
# Description: Differential Evolution with adaptive scaling, archive, and local search for multimodal optimization.
class AdaptiveArchiveDEwithLocalSearch:
    """
    Combines Differential Evolution with adaptive scaling, an archive for diversity, and local search to escape local optima in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.F_scale_delta = 0.1
        self.CR = 0.9
        self.local_search_iterations = 5 # Number of local search steps

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring = self._local_search(offspring, objective_function) # Apply local search
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            self.population, fitness = self._select_next_generation(offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)
            self._adapt_F_scale(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different_indices(i)
            mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(self.population[i], mutant)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]  # Randomly select from archive for diversity
        else:
            return self.population[np.argmin(objective_function(self.population))]

    def _select_different_indices(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.CR, v, x)

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _select_next_generation(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _adapt_F_scale(self, fitness):
        if np.min(fitness) < self.best_fitness_overall:
            self.F_scale = min(1.0, self.F_scale + self.F_scale_delta)
        else:
            self.F_scale = max(0.0, self.F_scale - self.F_scale_delta)

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _local_search(self, offspring, objective_function):
        for i in range(len(offspring)):
            current_solution = offspring[i].copy()
            current_fitness = objective_function(current_solution.reshape(1,-1))[0]
            for _ in range(self.local_search_iterations):
                neighbor = current_solution + np.random.normal(0, 0.1, self.dim) #Small perturbation
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                if neighbor_fitness < current_fitness:
                    current_solution = neighbor
                    current_fitness = neighbor_fitness
            offspring[i] = current_solution
        return offspring

```

### Rank 4 (Overall AOCC Score: 1.7527e-01 |             AOCC Score on Unimodal instances: 1.7527e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveMultimodalOptimizerWithClustering
# Description: An adaptive EA using clustering to maintain diversity and guide exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalOptimizerWithClustering
# Description: An adaptive EA using clustering to maintain diversity and guide exploration in multimodal landscapes.
# Code:
class AdaptiveMultimodalOptimizerWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 100
        self.archive = []  # Archive of diverse solutions
        self.archive_size = 200
        self.mutation_rate = 0.2
        self.crossover_rate = 0.7
        self.exploration_rate = 0.5  # Balance between global and local exploration
        self.clustering_threshold = 0.2 #parameter for determining clusters


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection: Tournament selection with fitness scaling to emphasize diversity
            parents = self._tournament_selection(population, fitness)

            # Genetic Operators: Blend crossover and Gaussian mutation
            offspring = self._generate_offspring(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management with Clustering
            self._update_archive(offspring, offspring_fitness)

            # Adaptive Parameter Tuning based on archive diversity and convergence
            self._adapt_parameters()

            # Combine population and offspring, then select the best
            population = np.vstack((population, offspring))
            fitness = np.concatenate((fitness, offspring_fitness))
            idx = np.argsort(fitness)
            population = population[idx[:self.population_size]]
            fitness = fitness[idx[:self.population_size]]


            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_rate': self.mutation_rate,
            'final_exploration_rate': self.exploration_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _tournament_selection(self, population, fitness, tournament_size=5):
        parents = []
        for _ in range(self.population_size // 2):  # Select pairs of parents
            tournament = np.random.choice(len(population), size=tournament_size, replace=False)
            #Fitness scaling for diversity
            scaled_fitness = fitness[tournament] / np.max(fitness[tournament])
            
            best1_index = tournament[np.argmin(scaled_fitness)]
            tournament = np.delete(tournament, np.argmin(scaled_fitness))
            best2_index = tournament[np.argmin(scaled_fitness)]
            parents.extend([population[best1_index], population[best2_index]])
        return np.array(parents)


    def _generate_offspring(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]

            if random.random() < self.crossover_rate:
                offspring1 = self._blend_crossover(parent1, parent2)
                offspring2 = self._blend_crossover(parent2, parent1)
            else:
                offspring1 = parent1.copy()
                offspring2 = parent2.copy()
                
            offspring1 += np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring2 += np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)


            offspring1 = np.clip(offspring1, self.lower_bounds, self.upper_bounds)
            offspring2 = np.clip(offspring2, self.lower_bounds, self.upper_bounds)
            offspring.extend([offspring1, offspring2])

        return np.array(offspring)

    def _blend_crossover(self, parent1, parent2, alpha=0.5):
        return alpha * parent1 + (1 - alpha) * parent2

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Smart replacement with clustering
                distances = np.array([np.linalg.norm(offspring[i] - x) for x, _ in self.archive])
                closest_index = np.argmin(distances)
                if offspring_fitness[i] < self.archive[closest_index][1] and distances[closest_index] > self.clustering_threshold:
                    self.archive[closest_index] = (offspring[i], offspring_fitness[i])


    def _adapt_parameters(self):
        if len(self.archive) > 0:
            avg_distance = np.mean([np.linalg.norm(x1 - x2) for (x1, _), (x2, _) in zip(self.archive, self.archive[1:])])
            
            if avg_distance < self.clustering_threshold:  # Population converging, increase exploration
                self.mutation_rate *= 1.1
                self.exploration_rate *= 1.1
            else:  # Population diverse, refine local search
                self.mutation_rate *= 0.9
                self.exploration_rate *= 0.9
                

```

### Rank 5 (Overall AOCC Score: 1.7525e-01 |             AOCC Score on Unimodal instances: 1.7525e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveArchiveDEwithLocalSearch
# Description: Differential Evolution with adaptive scaling, archive, and local search for multimodal optimization.
# Code:
```python
# Name: AdaptiveArchiveDEwithLocalSearch
# Description: Differential Evolution with adaptive scaling, archive, and local search for multimodal optimization.

import numpy as np
import random

class AdaptiveArchiveDEwithLocalSearch:
    """
    Combines Differential Evolution (DE) with adaptive scaling, an archive for diversity, and local search to escape local optima in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9
        self.local_search_iterations = 10 # Number of iterations for local search


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring = self.local_search(offspring, objective_function) #Apply local search
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population, fitness = self.selection(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand()
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant, self.CR)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]
        else:
            return self.population[np.argmin(self.population)] #Fallback to best in population

    def _crossover(self, x, v, CR):
        mask = np.random.rand(self.dim) < CR
        return np.where(mask, v, x)

    def _select_different(self, index, population_size):
        a, b, c = random.sample(range(population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def selection(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _find_best(self, population, fitness):
        best_index = np.argmin(fitness)
        return population[best_index], fitness[best_index]

    def local_search(self, population, objective_function):
        for i in range(len(population)):
            current_solution = population[i].copy()
            current_fitness = objective_function(current_solution.reshape(1,-1))[0]
            for _ in range(self.local_search_iterations):
                neighbor = current_solution + np.random.normal(0, 0.1, self.dim) #Small perturbation
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                if neighbor_fitness < current_fitness:
                    current_solution = neighbor
                    current_fitness = neighbor_fitness
            population[i] = current_solution
        return population

```

### Rank 6 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveMultimodalExplorationOptimizer
# Description: 
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalExplorationOptimizer
# Description: An adaptive evolutionary algorithm combining diverse exploration strategies and an archive for robust multimodal optimization.
# Code:
class AdaptiveMultimodalExplorationOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 974.7618849764722, archive_size: int = 64.29483390958212, mutation_rate: float = 0.4603977549305898,
                 exploration_rate: float = 0.33559062822659447, diversity_threshold: float = 0.002669334368696208):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = population_size  # Initial population size
        self.archive = []  # Archive of diverse solutions
        self.archive_size = archive_size  # Maximum archive size
        self.mutation_rate = mutation_rate  # Initial mutation rate
        self.exploration_rate = exploration_rate  # Initial exploration rate (global vs. local search)
        self.diversity_threshold = diversity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection: Tournament selection
            parents = self._tournament_selection(population, fitness)

            # Genetic Operators: Mutation & Crossover
            offspring = self._generate_offspring(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)


            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Adaptive Parameter Tuning
            self._adapt_parameters()

            # Combine population and offspring
            population = np.vstack((population, offspring))
            fitness = np.concatenate((fitness, offspring_fitness))

            # Select top individuals
            idx = np.argsort(fitness)
            population = population[idx[:self.population_size]]
            fitness = fitness[idx[:self.population_size]]


            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_rate': self.mutation_rate,
            'final_exploration_rate': self.exploration_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _tournament_selection(self, population, fitness, tournament_size: int = 5):
        selected_indices = np.random.choice(len(population), size=self.population_size, replace=True)
        fitness_selected = fitness[selected_indices]

        best_in_tournament = np.argmin(fitness_selected)
        best_index = selected_indices[best_in_tournament]
        return population[[best_index]]


    def _generate_offspring(self, parents):
        offspring = []
        for _ in range(self.population_size):
            parent = parents[0]
            offspring_individual = parent + np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring_individual = np.clip(offspring_individual, self.lower_bounds, self.upper_bounds)
            offspring.append(offspring_individual)

        return np.array(offspring)


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Simple replacement strategy (replace worst in archive)
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _adapt_parameters(self):
        if len(self.archive) > 0:
             diversity = np.std([np.linalg.norm(x) for x, _ in self.archive])
             if diversity < self.diversity_threshold :
                self.mutation_rate *= 1.1 #increase mutation rate
             else:
                 self.mutation_rate *= 0.9 #decrease mutation rate
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 08:58:22 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveDEwithArchiveAndLocalSearch vs (worst) AdaptiveMultimodalExplorationOptimizer, we see that the best-performing algorithm uses Differential Evolution (DE), an adaptive archive, and local search, adapting mutation strength and crossover rate based on performance.  This is significantly more sophisticated than the worst, which uses simple tournament selection, Gaussian mutation, and lacks adaptive parameter tuning or a sophisticated archive management strategy.  (second best) AdaptiveArchiveDEwithLocalSearch also uses DE, an adaptive archive, and local search, but its parameter adaptation is less sophisticated. (second worst) AdaptiveMultimodalOptimizerWithClustering incorporates clustering to maintain diversity but still performs worse than the top two. Comparing (1st) vs (2nd), we see that AdaptiveDEwithArchiveAndLocalSearch's more refined parameter adaptation leads to a slight performance advantage. (3rd) vs (4th) shows similar use of archives and local search, with AdaptiveArchiveDEwithLocalSearch's slightly better adaptive scaling giving it an edge. Comparing (second worst) vs (worst), we see that incorporating more advanced search operators and better archive management significantly improves performance.  Overall: The top algorithms leverage DE, adaptive archives, and local search, with the best incorporating advanced parameter adaptation mechanisms.  Adaptive parameter tuning and sophisticated archive management are crucial.  Simpler algorithms lack adaptability and struggle with complex landscapes.


**Experience:**

Effective heuristics for high-dimensional optimization require adaptive parameter control, diverse exploration strategies (like DE), and mechanisms to maintain population diversity (archives and/or clustering).  Local search significantly improves exploitation.

2025-06-23 08:58:23 INFO Full response text: * **Keywords:** Adaptive parameter control, exploration-exploitation balance, diversity preservation,  local search enhancement.

* **Advice:** Focus on quantifiable metrics to measure the effectiveness of each component (e.g., diversity index, convergence rate, exploration vs. exploitation ratio).  Prioritize simplicity and robustness over complexity.  Empirically validate improvements through rigorous testing on diverse benchmark problems.

* **Avoid:** Vague terms like "synergistic combination" and "sophisticated archive management."  Avoid simply listing techniques; instead, focus on the *interactions* and trade-offs between them. Don't over-engineer; simpler, well-tuned methods often outperform complex ones.

* **Explanation:** The improved heuristics should explicitly address how to balance exploration and exploitation, dynamically adjust parameters based on performance feedback, and maintain sufficient population diversity without excessive computational overhead.  Empirical validation is paramount.

2025-06-23 08:58:23 INFO Generating offspring via Crossover...
2025-06-23 08:59:26 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveMultimodalOptimizerWithClustering
import numpy as np
import random

# Name: AdaptiveMultimodalOptimizerWithClustering
# Description: An adaptive EA using clustering to maintain diversity and guide exploration in multimodal landscapes.
# Code:
class AdaptiveMultimodalOptimizerWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 100
        self.archive = []  # Archive of diverse solutions
        self.archive_size = 200
        self.mutation_rate = 0.2
        self.crossover_rate = 0.7
        self.exploration_rate = 0.5  # Balance between global and local exploration
        self.clustering_threshold = 0.2 #parameter for determining clusters


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection: Tournament selection with fitness scaling to emphasize diversity
            parents = self._tournament_selection(population, fitness)

            # Genetic Operators: Blend crossover and Gaussian mutation
            offspring = self._generate_offspring(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management with Clustering
            self._update_archive(offspring, offspring_fitness)

            # Adaptive Parameter Tuning based on archive diversity and convergence
            self._adapt_parameters()

            # Combine population and offspring, then select the best
            population = np.vstack((population, offspring))
            fitness = np.concatenate((fitness, offspring_fitness))
            idx = np.argsort(fitness)
            population = population[idx[:self.population_size]]
            fitness = fitness[idx[:self.population_size]]


            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_rate': self.mutation_rate,
            'final_exploration_rate': self.exploration_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _tournament_selection(self, population, fitness, tournament_size=5):
        parents = []
        for _ in range(self.population_size // 2):  # Select pairs of parents
            tournament = np.random.choice(len(population), size=tournament_size, replace=False)
            #Fitness scaling for diversity
            scaled_fitness = fitness[tournament] / np.max(fitness[tournament])
            
            best1_index = tournament[np.argmin(scaled_fitness)]
            tournament = np.delete(tournament, np.argmin(scaled_fitness))
            best2_index = tournament[np.argmin(scaled_fitness)]
            parents.extend([population[best1_index], population[best2_index]])
        return np.array(parents)


    def _generate_offspring(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]

            if random.random() < self.crossover_rate:
                offspring1 = self._blend_crossover(parent1, parent2)
                offspring2 = self._blend_crossover(parent2, parent1)
            else:
                offspring1 = parent1.copy()
                offspring2 = parent2.copy()
                
            offspring1 += np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring2 += np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)


            offspring1 = np.clip(offspring1, self.lower_bounds, self.upper_bounds)
            offspring2 = np.clip(offspring2, self.lower_bounds, self.upper_bounds)
            offspring.extend([offspring1, offspring2])

        return np.array(offspring)

    def _blend_crossover(self, parent1, parent2, alpha=0.5):
        return alpha * parent1 + (1 - alpha) * parent2

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Smart replacement with clustering
                distances = np.array([np.linalg.norm(offspring[i] - x) for x, _ in self.archive])
                closest_index = np.argmin(distances)
                if offspring_fitness[i] < self.archive[closest_index][1] and distances[closest_index] > self.clustering_threshold:
                    self.archive[closest_index] = (offspring[i], offspring_fitness[i])


    def _adapt_parameters(self):
        if len(self.archive) > 0:
            avg_distance = np.mean([np.linalg.norm(x1 - x2) for (x1, _), (x2, _) in zip(self.archive, self.archive[1:])])
            
            if avg_distance < self.clustering_threshold:  # Population converging, increase exploration
                self.mutation_rate *= 1.1
                self.exploration_rate *= 1.1
            else:  # Population diverse, refine local search
                self.mutation_rate *= 0.9
                self.exploration_rate *= 0.9
                


### Worse code
AdaptiveArchiveDEwithLocalSearch
import numpy as np
import random

# Name: AdaptiveArchiveDEwithLocalSearch
# Description: Differential Evolution with adaptive scaling, archive, and local search for multimodal optimization.
class AdaptiveArchiveDEwithLocalSearch:
    """
    Combines Differential Evolution with adaptive scaling, an archive for diversity, and local search to escape local optima in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.F_scale_delta = 0.1
        self.CR = 0.9
        self.local_search_iterations = 5 # Number of local search steps

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring = self._local_search(offspring, objective_function) # Apply local search
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            self.population, fitness = self._select_next_generation(offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)
            self._adapt_F_scale(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different_indices(i)
            mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(self.population[i], mutant)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]  # Randomly select from archive for diversity
        else:
            return self.population[np.argmin(objective_function(self.population))]

    def _select_different_indices(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.CR, v, x)

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _select_next_generation(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _adapt_F_scale(self, fitness):
        if np.min(fitness) < self.best_fitness_overall:
            self.F_scale = min(1.0, self.F_scale + self.F_scale_delta)
        else:
            self.F_scale = max(0.0, self.F_scale - self.F_scale_delta)

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _local_search(self, offspring, objective_function):
        for i in range(len(offspring)):
            current_solution = offspring[i].copy()
            current_fitness = objective_function(current_solution.reshape(1,-1))[0]
            for _ in range(self.local_search_iterations):
                neighbor = current_solution + np.random.normal(0, 0.1, self.dim) #Small perturbation
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                if neighbor_fitness < current_fitness:
                    current_solution = neighbor
                    current_fitness = neighbor_fitness
            offspring[i] = current_solution
        return offspring


### Analyze & experience
- Comparing (best) AdaptiveDEwithArchiveAndLocalSearch vs (worst) AdaptiveMultimodalExplorationOptimizer, we see that the best-performing algorithm uses Differential Evolution (DE), an adaptive archive, and local search, adapting mutation strength and crossover rate based on performance.  This is significantly more sophisticated than the worst, which uses simple tournament selection, Gaussian mutation, and lacks adaptive parameter tuning or a sophisticated archive management strategy.  (second best) AdaptiveArchiveDEwithLocalSearch also uses DE, an adaptive archive, and local search, but its parameter adaptation is less sophisticated. (second worst) AdaptiveMultimodalOptimizerWithClustering incorporates clustering to maintain diversity but still performs worse than the top two. Comparing (1st) vs (2nd), we see that AdaptiveDEwithArchiveAndLocalSearch's more refined parameter adaptation leads to a slight performance advantage. (3rd) vs (4th) shows similar use of archives and local search, with AdaptiveArchiveDEwithLocalSearch's slightly better adaptive scaling giving it an edge. Comparing (second worst) vs (worst), we see that incorporating more advanced search operators and better archive management significantly improves performance.  Overall: The top algorithms leverage DE, adaptive archives, and local search, with the best incorporating advanced parameter adaptation mechanisms.  Adaptive parameter tuning and sophisticated archive management are crucial.  Simpler algorithms lack adaptability and struggle with complex landscapes.
- * **Keywords:** Adaptive parameter control, exploration-exploitation balance, diversity preservation,  local search enhancement.

* **Advice:** Focus on quantifiable metrics to measure the effectiveness of each component (e.g., diversity index, convergence rate, exploration vs. exploitation ratio).  Prioritize simplicity and robustness over complexity.  Empirically validate improvements through rigorous testing on diverse benchmark problems.

* **Avoid:** Vague terms like "synergistic combination" and "sophisticated archive management."  Avoid simply listing techniques; instead, focus on the *interactions* and trade-offs between them. Don't over-engineer; simpler, well-tuned methods often outperform complex ones.

* **Explanation:** The improved heuristics should explicitly address how to balance exploration and exploitation, dynamically adjust parameters based on performance feedback, and maintain sufficient population diversity without excessive computational overhead.  Empirical validation is paramount.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 08:59:26 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveMultimodalExplorationOptimizer
import numpy as np
import random

# Name: AdaptiveMultimodalExplorationOptimizer
# Description: An adaptive evolutionary algorithm combining diverse exploration strategies and an archive for robust multimodal optimization.
# Code:
class AdaptiveMultimodalExplorationOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50  # Initial population size
        self.archive = []  # Archive of diverse solutions
        self.archive_size = 100  # Maximum archive size
        self.mutation_rate = 0.1  # Initial mutation rate
        self.exploration_rate = 0.8  # Initial exploration rate (global vs. local search)
        self.diversity_threshold = 0.1

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection: Tournament selection
            parents = self._tournament_selection(population, fitness)

            # Genetic Operators: Mutation & Crossover
            offspring = self._generate_offspring(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)


            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Adaptive Parameter Tuning
            self._adapt_parameters()

            # Combine population and offspring
            population = np.vstack((population, offspring))
            fitness = np.concatenate((fitness, offspring_fitness))

            # Select top individuals
            idx = np.argsort(fitness)
            population = population[idx[:self.population_size]]
            fitness = fitness[idx[:self.population_size]]
            

            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_rate': self.mutation_rate,
            'final_exploration_rate': self.exploration_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _tournament_selection(self, population, fitness, tournament_size=5):
        selected_indices = np.random.choice(len(population), size=self.population_size, replace=True)
        fitness_selected = fitness[selected_indices]
        
        best_in_tournament = np.argmin(fitness_selected)
        best_index = selected_indices[best_in_tournament]
        return population[[best_index]]
        

    def _generate_offspring(self, parents):
        offspring = []
        for _ in range(self.population_size):
            parent = parents[0]
            offspring_individual = parent + np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring_individual = np.clip(offspring_individual, self.lower_bounds, self.upper_bounds)
            offspring.append(offspring_individual)

        return np.array(offspring)


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Simple replacement strategy (replace worst in archive)
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _adapt_parameters(self):
        if len(self.archive) > 0:
             diversity = np.std([np.linalg.norm(x) for x, _ in self.archive])
             if diversity < self.diversity_threshold :
                self.mutation_rate *= 1.1 #increase mutation rate
             else:
                 self.mutation_rate *= 0.9 #decrease mutation rate
                 



Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:** Adaptive parameter control, exploration-exploitation balance, diversity preservation,  local search enhancement.

* **Advice:** Focus on quantifiable metrics to measure the effectiveness of each component (e.g., diversity index, convergence rate, exploration vs. exploitation ratio).  Prioritize simplicity and robustness over complexity.  Empirically validate improvements through rigorous testing on diverse benchmark problems.

* **Avoid:** Vague terms like "synergistic combination" and "sophisticated archive management."  Avoid simply listing techniques; instead, focus on the *interactions* and trade-offs between them. Don't over-engineer; simpler, well-tuned methods often outperform complex ones.

* **Explanation:** The improved heuristics should explicitly address how to balance exploration and exploitation, dynamically adjust parameters based on performance feedback, and maintain sufficient population diversity without excessive computational overhead.  Empirical validation is paramount.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 08:59:47 INFO Perform Harmony Search...
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 08:59:57 ERROR Can not run the algorithm
2025-06-23 08:59:57 INFO Run function 2 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 08:59:57 INFO FeHistory: []
2025-06-23 08:59:57 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 08:59:57 INFO Unimodal AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Multimodal (single component) AOCC mean: nan
2025-06-23 08:59:57 INFO Multimodal (multiple components) AOCC mean: nan
2025-06-23 08:59:57 INFO AOCC mean: 0.0000
2025-06-23 08:59:57 INFO Generation 3, best so far: 0.19144400559668218
2025-06-23 08:59:57 INFO Population length is: 7
2025-06-23 08:59:57 INFO --- Performing Long-Term Reflection at Generation 4 ---
2025-06-23 08:59:57 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.7572e-01 |             AOCC Score on Unimodal instances: 1.7572e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveDEwithArchiveAndLocalSearchPlus
# Description: Differential Evolution with adaptive scaling, archive, and local search enhanced for multimodal optimization.
# Code:
```python
# Name: AdaptiveDEwithArchiveAndLocalSearchPlus
# Description: Differential Evolution with adaptive scaling, archive, and local search enhanced for multimodal optimization.
import numpy as np
import random

class AdaptiveDEwithArchiveAndLocalSearchPlus:
    """
    Combines Differential Evolution (DE) with adaptive scaling, an archive for diversity, and local search to escape local optima in multimodal landscapes.  Improves upon previous versions by adding a more sophisticated archive management strategy and adaptive parameter control.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9
        self.local_search_iterations = 10  # Number of iterations for local search
        self.archive_diversity_threshold = 0.1 # Threshold for archive diversity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring = self.local_search(offspring, objective_function)  # Apply local search
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population, fitness = self.selection(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)
            self.adapt_parameters(fitness) # Adapt parameters based on performance

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant, self.CR)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]
        else:
            return self.population[np.argmin(self.population)] #Fallback to best in population

    def _crossover(self, x, v, CR):
        mask = np.random.rand(self.dim) < CR
        return np.where(mask, v, x)

    def _select_different(self, index, population_size):
        a, b, c = random.sample(range(population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                self._cull_archive() # More sophisticated culling
                self.archive.append((offspring[i], offspring_fitness[i]))

    def _cull_archive(self):
        #Cull based on fitness and diversity
        self.archive.sort(key=lambda item: item[1]) #Sort by fitness
        self.archive = self.archive[:int(self.archive_size * 0.8)] #Keep top 80%
        #Add diversity check and cull if needed
        if self._check_archive_diversity() < self.archive_diversity_threshold:
            self._remove_similar_solutions()



    def _check_archive_diversity(self):
        #Simple diversity check (can be replaced with more sophisticated methods)
        if len(self.archive) < 2:
            return 1.0 #Consider fully diverse if less than 2 solutions
        solutions = np.array([x[0] for x in self.archive])
        distances = np.linalg.norm(solutions[:, np.newaxis, :] - solutions[np.newaxis, :, :], axis=2)
        min_distance = np.min(distances[np.nonzero(distances)])
        return min_distance / (np.max(self.upper_bounds) - np.min(self.lower_bounds))


    def _remove_similar_solutions(self):
        #Remove solutions that are close to each other (simple approach)
        solutions = np.array([x[0] for x in self.archive])
        distances = np.linalg.norm(solutions[:, np.newaxis, :] - solutions[np.newaxis, :, :], axis=2)
        to_remove = []
        for i in range(len(self.archive)):
            for j in range(i+1, len(self.archive)):
                if distances[i,j] < 0.1*(np.max(self.upper_bounds) - np.min(self.lower_bounds)): # Adjust threshold as needed
                    if self.archive[i][1] > self.archive[j][1]:
                        to_remove.append(i)
                    else:
                        to_remove.append(j)
        
        to_remove = list(set(to_remove)) #Avoid duplicates
        to_remove.sort(reverse=True) #remove from the end to avoid index issues

        for index in to_remove:
            del self.archive[index]


    def selection(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _find_best(self, population, fitness):
        best_index = np.argmin(fitness)
        return population[best_index], fitness[best_index]

    def local_search(self, population, objective_function):
        for i in range(len(population)):
            current_solution = population[i].copy()
            current_fitness = objective_function(current_solution.reshape(1,-1))[0]
            for _ in range(self.local_search_iterations):
                neighbor = current_solution + np.random.normal(0, 0.1, self.dim) #Small perturbation
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                if neighbor_fitness < current_fitness:
                    current_solution = neighbor
                    current_fitness = neighbor_fitness
            population[i] = current_solution
        return population
    
    def adapt_parameters(self, fitness):
        #Adapt F_scale based on improvement
        if np.min(fitness) < self.best_fitness_overall:
            self.F_scale = min(1.0, self.F_scale + 0.1) #Increase exploration
        else:
            self.F_scale = max(0.0, self.F_scale - 0.05) #Decrease exploration
        #Adapt CR based on diversity (example - could be improved)
        if self._check_archive_diversity() < 0.05:
            self.CR = max(0.1, self.CR - 0.1) #Reduce CR to intensify exploitation around promising regions
        elif self._check_archive_diversity() > 0.2:
            self.CR = min(0.99, self.CR + 0.1) #Increase CR to enhance exploration



```

### Rank 2 (Overall AOCC Score: 1.7565e-01 |             AOCC Score on Unimodal instances: 1.7565e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveDEwithClusteringAndLocalSearch
# Description: Differential Evolution with adaptive scaling, clustering, and local search for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithClusteringAndLocalSearch
# Description: Differential Evolution with adaptive scaling, clustering, and local search for multimodal optimization.
# Code:
class AdaptiveDEwithClusteringAndLocalSearch:
    """
    Combines Differential Evolution, adaptive scaling, clustering for diversity, and local search to escape local optima in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.F_scale_delta = 0.1
        self.CR = 0.9
        self.local_search_iterations = 5  # Number of local search steps
        self.clustering_threshold = 0.2 #parameter for determining clusters


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring = self._local_search(offspring, objective_function)  # Apply local search
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            self.population, fitness = self._select_next_generation(offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)
            self._adapt_F_scale(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_F_scale': self.F_scale
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different_indices(i)
            mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(self.population[i], mutant)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]  # Randomly select from archive for diversity
        else:
            return self.population[np.argmin(objective_function(self.population))]

    def _select_different_indices(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.CR, v, x)

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Smart replacement with clustering
                distances = np.array([np.linalg.norm(offspring[i] - x) for x, _ in self.archive])
                closest_index = np.argmin(distances)
                if offspring_fitness[i] < self.archive[closest_index][1] and distances[closest_index] > self.clustering_threshold:
                    self.archive[closest_index] = (offspring[i], offspring_fitness[i])


    def _select_next_generation(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _adapt_F_scale(self, fitness):
        if np.min(fitness) < self.best_fitness_overall:
            self.F_scale = min(1.0, self.F_scale + self.F_scale_delta)
        else:
            self.F_scale = max(0.0, self.F_scale - self.F_scale_delta)

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _local_search(self, offspring, objective_function):
        for i in range(len(offspring)):
            current_solution = offspring[i].copy()
            current_fitness = objective_function(current_solution.reshape(1,-1))[0]
            for _ in range(self.local_search_iterations):
                neighbor = current_solution + np.random.normal(0, 0.1, self.dim) #Small perturbation
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                if neighbor_fitness < current_fitness:
                    current_solution = neighbor
                    current_fitness = neighbor_fitness
            offspring[i] = current_solution
        return offspring

```

### Rank 3 (Overall AOCC Score: 1.7565e-01 |             AOCC Score on Unimodal instances: 1.7565e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveDEwithArchiveAndLocalSearch
# Description: Differential Evolution with adaptive archive, local search, and parameter control for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithArchiveAndLocalSearch
# Description: Differential Evolution with adaptive archive, local search, and parameter control for multimodal optimization.
# Code:
class AdaptiveDEwithArchiveAndLocalSearch:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  #Heuristic population size
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.CR = 0.9
        self.local_search_iterations = 10
        self.adaptation_factor = 0.1 #controls adaptation speed

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring = self.local_search(offspring, objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self.update_archive(offspring, offspring_fitness)
            self.population, fitness = self.selection(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, fitness)
            self.adapt_parameters(fitness) # Adapt parameters after each generation

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_F_scale': self.F_scale,
            'final_CR': self.CR
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant, self.CR)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]
        else:
            return self.population[np.argmin(self.population)]

    def _crossover(self, x, v, CR):
        mask = np.random.rand(self.dim) < CR
        return np.where(mask, v, x)

    def _select_different(self, index, population_size):
        a, b, c = random.sample(range(population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(population_size), 3)
        return a, b, c

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def selection(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _find_best(self, population, fitness):
        best_index = np.argmin(fitness)
        return population[best_index], fitness[best_index]

    def local_search(self, population, objective_function):
        for i in range(len(population)):
            current_solution = population[i].copy()
            current_fitness = objective_function(current_solution.reshape(1,-1))[0]
            for _ in range(self.local_search_iterations):
                neighbor = current_solution + np.random.normal(0, 0.1, self.dim)
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                if neighbor_fitness < current_fitness:
                    current_solution = neighbor
                    current_fitness = neighbor_fitness
            population[i] = current_solution
        return population

    def adapt_parameters(self, fitness):
        #Adapt F_scale and CR based on fitness improvement.  Simpler adaptation for clarity.
        avg_fitness_improvement = np.mean(fitness) - self.best_fitness_overall
        if avg_fitness_improvement > 0 : #if some improvement
            self.F_scale *= (1 + self.adaptation_factor)
            self.CR *= (1 + self.adaptation_factor)
            self.F_scale = min(self.F_scale, 1.0) #bound to be reasonable
            self.CR = min(self.CR, 1.0)
        else:
            self.F_scale *= (1 - self.adaptation_factor)
            self.CR *= (1 - self.adaptation_factor)
            self.F_scale = max(self.F_scale, 0.1) #bound to be reasonable
            self.CR = max(self.CR, 0.1)

```

### Rank 4 (Overall AOCC Score: 1.7563e-01 |             AOCC Score on Unimodal instances: 1.7563e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveDEwithArchiveAndLocalSearchPlus
# Description: Differential Evolution with adaptive archive, local search, and refined parameter control for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithArchiveAndLocalSearchPlus
# Description: Differential Evolution with adaptive archive, local search, and refined parameter control for multimodal optimization.
# Code:
class AdaptiveDEwithArchiveAndLocalSearchPlus:
    """
    Combines Differential Evolution (DE), an adaptive archive, local search, and refined parameter control for robust multimodal optimization.  Improves upon previous versions by incorporating a more sophisticated adaptive scaling mechanism and archive management.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim  # Adjust as needed
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5
        self.F_scale_delta = 0.1
        self.CR = 0.9
        self.local_search_iterations = 5
        self.stagnation_count = 0 #Counter for stagnation
        self.stagnation_threshold = 10 * dim # Number of iterations without improvement before reset

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring = self._local_search(offspring, objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            self.population, fitness = self._select_next_generation(offspring, offspring_fitness)
            prev_best_fitness = self.best_fitness_overall
            self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)
            self._adapt_F_scale(fitness)

            # Stagnation handling: Reset if no improvement after threshold
            if self.best_fitness_overall == prev_best_fitness:
                self.stagnation_count += 1
                if self.stagnation_count >= self.stagnation_threshold:
                    self._reset_population()
                    self.stagnation_count = 0
            else:
                self.stagnation_count = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different_indices(i)
            mutant = self.population[i] + self.F_scale * (pbest - self.population[i] + self.population[a] - self.population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(self.population[i], mutant)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[0]
        else:
            return self.population[np.argmin(objective_function(self.population))] # Needs objective_function in scope.


    def _select_different_indices(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.CR, v, x)

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _select_next_generation(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness)) #fitness needs to be in scope.
        indices = np.argsort(combined_fitness)
        return combined_population[indices[:self.population_size]], combined_fitness[indices[:self.population_size]]

    def _adapt_F_scale(self, fitness):
        # More sophisticated adaptation: considers both improvement and diversity.
        improvement = np.min(fitness) < self.best_fitness_overall
        diversity = np.std(fitness) > 0.1 * (self.upper_bounds - self.lower_bounds).mean() # Check for diversity in fitness values

        if improvement or diversity:
            self.F_scale = min(1.0, self.F_scale + self.F_scale_delta)
        else:
            self.F_scale = max(0.0, self.F_scale - self.F_scale_delta)

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _local_search(self, offspring, objective_function):
        for i in range(len(offspring)):
            current_solution = offspring[i].copy()
            current_fitness = objective_function(current_solution.reshape(1,-1))[0]
            for _ in range(self.local_search_iterations):
                neighbor = current_solution + np.random.normal(0, 0.1, self.dim)
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                if neighbor_fitness < current_fitness:
                    current_solution = neighbor
                    current_fitness = neighbor_fitness
            offspring[i] = current_solution
        return offspring

    def _reset_population(self):
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        

```

### Rank 5 (Overall AOCC Score: 1.7548e-01 |             AOCC Score on Unimodal instances: 1.7548e-01 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveDEwithArchiveAndLocalSearchImproved
# Description: Adaptive Differential Evolution with archive and local search for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithArchiveAndLocalSearchImproved
# Description: Adaptive Differential Evolution with archive and local search for multimodal optimization.
# Code:
class AdaptiveDEwithArchiveAndLocalSearchImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.local_search_prob = 0.1 # Probability of performing local search


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall = population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Combine and select
            combined_population = np.vstack((population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]


            #Update best
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]

            # Archive management
            self._update_archive(population, fitness)

            # Adapt parameters (simple example - more sophisticated adaptation possible)
            self._adapt_parameters(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_F': self.F,
            'final_CR': self.CR
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_individuals(population, i)
            mutant = self._mutate(a, b, c)
            trial = self._crossover(population[i], mutant)
            
            #Local search with probability
            if random.random() < self.local_search_prob:
                trial = self._local_search(trial, objective_function)

            offspring.append(trial)
        return np.array(offspring)

    def _select_individuals(self, population, i):
        indices = np.random.choice(len(population), size=3, replace=False)
        while i in indices: # Ensure that the current individual is not selected as a parent.
            indices = np.random.choice(len(population), size=3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]
    

    def _mutate(self, a, b, c):
        return np.clip(a + self.F * (b - c), self.lower_bounds, self.upper_bounds)

    def _crossover(self, x, v):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, v, x)

    def _local_search(self, x, objective_function):
      # Simple local search (replace with a more sophisticated one if needed)
      step_size = 0.01 * (self.upper_bounds - self.lower_bounds)
      for _ in range(10): # 10 iterations
          for i in range(self.dim):
              temp_x = x.copy()
              temp_x[i] += random.uniform(-1, 1) * step_size[i]
              temp_x = np.clip(temp_x, self.lower_bounds, self.upper_bounds)
              temp_fitness = objective_function(temp_x.reshape(1, -1))[0]
              if temp_fitness < objective_function(x.reshape(1, -1))[0]:
                  x = temp_x
      return x


    def _update_archive(self, population, fitness):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (population[i], fitness[i])

    def _adapt_parameters(self, population, fitness):
        # Simple adaptation: Adjust F and CR based on convergence speed
        if np.std(fitness) < 0.1 * (self.best_fitness_overall): # Check for convergence
            self.F *= 0.9
            self.CR *= 0.9
        else:
            self.F *= 1.1
            self.CR *= 1.1
            self.F = np.clip(self.F, 0.1, 1.0)  #Keep F within bounds
            self.CR = np.clip(self.CR, 0.1, 1.0) #Keep CR within bounds
```

### Rank 6 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: nan |             AOCC Score on Multimodal instances with multiple components: nan)
# Name: AdaptiveMultimodalExplorationOptimizer
# Description: 
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalExplorationOptimizer
# Description: An adaptive evolutionary algorithm combining diverse exploration strategies and an archive for robust multimodal optimization.
# Code:
class AdaptiveMultimodalExplorationOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 911.1905170412372, archive_size: int = 616.2755336475799, mutation_rate: float = 0.6558159400522866,
                 exploration_rate: float = 0.6561979737818846, diversity_threshold: float = 0.5955224523917686):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = population_size  # Initial population size
        self.archive = []  # Archive of diverse solutions
        self.archive_size = archive_size  # Maximum archive size
        self.mutation_rate = mutation_rate  # Initial mutation rate
        self.exploration_rate = exploration_rate  # Initial exploration rate (global vs. local search)
        self.diversity_threshold = diversity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection: Tournament selection
            parents = self._tournament_selection(population, fitness)

            # Genetic Operators: Mutation & Crossover
            offspring = self._generate_offspring(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)


            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Adaptive Parameter Tuning
            self._adapt_parameters()

            # Combine population and offspring
            population = np.vstack((population, offspring))
            fitness = np.concatenate((fitness, offspring_fitness))

            # Select top individuals
            idx = np.argsort(fitness)
            population = population[idx[:self.population_size]]
            fitness = fitness[idx[:self.population_size]]


            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_rate': self.mutation_rate,
            'final_exploration_rate': self.exploration_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _tournament_selection(self, population, fitness, tournament_size=5):
        selected_indices = np.random.choice(len(population), size=self.population_size, replace=True)
        fitness_selected = fitness[selected_indices]

        best_in_tournament = np.argmin(fitness_selected)
        best_index = selected_indices[best_in_tournament]
        return population[[best_index]]


    def _generate_offspring(self, parents):
        offspring = []
        for _ in range(self.population_size):
            parent = parents[0]
            offspring_individual = parent + np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring_individual = np.clip(offspring_individual, self.lower_bounds, self.upper_bounds)
            offspring.append(offspring_individual)

        return np.array(offspring)


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Simple replacement strategy (replace worst in archive)
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _adapt_parameters(self):
        if len(self.archive) > 0:
             diversity = np.std([np.linalg.norm(x) for x, _ in self.archive])
             if diversity < self.diversity_threshold :
                self.mutation_rate *= 1.1 #increase mutation rate
             else:
                 self.mutation_rate *= 0.9 #decrease mutation rate
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 09:00:03 INFO Full response text: **Analysis:**

Comparing (best) `AdaptiveDEwithArchiveAndLocalSearchPlus` vs (worst) `AdaptiveMultimodalExplorationOptimizer`, we see that the best utilizes Differential Evolution (DE), a powerful optimization algorithm known for its efficiency in high-dimensional spaces, incorporating adaptive scaling, an archive for maintaining diversity, and local search to escape local optima.  The worst, on the other hand, uses a simpler evolutionary strategy with basic mutation and lacks sophisticated mechanisms for escaping local optima or managing diversity.  The best also has significantly more robust parameter adaptation strategies than the worst.

(second best) `AdaptiveDEwithClusteringAndLocalSearch` vs (second worst) `AdaptiveDEwithArchiveAndLocalSearchImproved`: The second-best uses clustering to manage diversity in its archive, which is a more sophisticated approach than the simple replacement strategy in the second-worst. The second best also includes adaptive F_scale updates based on population fitness, whereas the second worst has a simpler approach.  Both incorporate local search, but the second best's implementation is slightly more robust.

Comparing (1st) vs (2nd), we see that the top performer uses a more sophisticated archive management strategy, including a diversity check and culling, providing a more balanced exploration and exploitation. The second-best utilizes clustering for archive management, which is less sophisticated and may be less effective in complex landscapes.

(3rd) vs (4th): Both use adaptive archives and local search. The 3rd algorithm features a simpler adaptation strategy for its DE parameters (F_scale and CR). The 4th improves upon this by considering both fitness improvement and population diversity during parameter adaptation, aiming to achieve a better balance between exploration and exploitation.  It also includes a stagnation handling mechanism to prevent getting stuck.

Comparing (second worst) vs (worst), we see a significant difference in the sophistication of their mechanisms. The second-worst uses Differential Evolution with archive and local search, components missing from the worst. The second-worst also incorporates adaptive parameter tuning.

Overall: The top-performing algorithms leverage the power of Differential Evolution, adaptive parameter control, archive management for diversity, and local search to effectively navigate complex multimodal landscapes.  Simpler evolutionary strategies without these components struggle significantly.  The sophistication of archive management and parameter adaptation significantly impact performance.  Stagnation handling is also key.


**Experience:**

Effective high-dimensional optimization requires sophisticated population generation strategies that balance exploration and exploitation. Combining advanced algorithms like Differential Evolution with adaptive mechanisms, archive management, and local search is crucial.  Robust parameter adaptation based on both convergence and diversity is key.

2025-06-23 09:00:05 INFO Full response text: **Keywords:**  Adaptive Parameter Control, Exploration-Exploitation Balance,  Archive Management,  Convergence Diagnostics

**Advice:** Focus on quantifiable metrics for evaluating exploration and exploitation. Develop dynamic strategies that adjust exploration/exploitation based on these metrics (e.g.,  convergence rate, population diversity). Design sophisticated archive management that actively promotes diversity while preventing bloat.  Integrate rigorous convergence diagnostics to guide parameter adaptation.

**Avoid:** Vague terms like "sophisticated," "robust," and "synergistic."  Avoid simply listing techniques without specifying how they interact and are dynamically controlled.  Don't focus on the number of techniques used, but rather their effectiveness and interaction.

**Explanation:** The key is to move beyond simply stating desirable qualities to defining *measurable* criteria and mechanisms for achieving a balanced exploration-exploitation strategy.  The effectiveness of heuristics isn't determined by their complexity but by their ability to efficiently navigate the search space and avoid premature convergence.  Rigorous testing and analysis using these quantifiable metrics are crucial.

2025-06-23 09:00:05 INFO Generating offspring via Crossover...
