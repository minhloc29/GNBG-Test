2025-06-24 08:06:21 INFO Initializing first population
2025-06-24 08:06:21 INFO Initializing population from 9 seed files...
2025-06-24 08:20:39 INFO Started evolutionary loop, best so far: 0.5484245373695569
2025-06-24 08:20:39 INFO Population length is: 20
2025-06-24 08:20:39 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-24 08:20:39 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average weighted AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.4842e-01 |             AOCC Score on Unimodal instances: 1.8516e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 7.5701e-01)
# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 2 (Overall AOCC Score: 1.9752e-02 |             AOCC Score on Unimodal instances: 1.9752e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 3 (Overall AOCC Score: 1.8125e-02 |             AOCC Score on Unimodal instances: 1.8125e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 4 (Overall AOCC Score: 1.7992e-02 |             AOCC Score on Unimodal instances: 1.7992e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random

class EnhancedArchiveGuidedDE: #aocc 0.15
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale  # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 5 (Overall AOCC Score: 1.7887e-02 |             AOCC Score on Unimodal instances: 1.7887e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 6 (Overall AOCC Score: 1.7790e-02 |             AOCC Score on Unimodal instances: 1.7790e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 7 (Overall AOCC Score: 1.7581e-02 |             AOCC Score on Unimodal instances: 1.7581e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 8 (Overall AOCC Score: 1.7491e-02 |             AOCC Score on Unimodal instances: 1.7491e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveNeighborhoodDE
# Description: A Differential Evolution variant with adaptive neighborhood range to balance exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveNeighborhoodDE
# Description: A Differential Evolution variant with adaptive neighborhood range to balance exploration and exploitation in multimodal landscapes.

class AdaptiveNeighborhoodDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50  # Increased pop size
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))

        self.cr = 0.7  # Crossover rate
        self.f = 0.5  # Mutation factor
        self.neighborhood_size = int(self.population_size * 0.2)  # Initial neighborhood size (20%)
        self.neighborhood_adaptation_rate = 0.05 # How fast the neighborhood changes. Larger values are unstable.
        self.min_neighborhood_size = 3 # ensures non-trivial DE operators even in exploitation phase
        self.max_neighborhood_size = self.population_size - 1 # avoids index out of bounds error


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0  # Reset for this run
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim)) # Reinitialize population
        self.fitness = np.full(self.population_size, float('inf')) # Reinitialize fitness
        
        # Initialize fitness values
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.fitness = fitness_values.copy() # prevent potential problems later
        
        best_index = np.argmin(self.fitness)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = self.fitness[best_index]


        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Adaptive Neighborhood Selection
                indices = list(range(self.population_size))
                indices.remove(i)  # Exclude current individual
                random.shuffle(indices)
                
                # Adapt neighborhood size based on current performance
                if self.neighborhood_size > self.min_neighborhood_size:
                    if self.fitness[i] < np.mean(self.fitness): # if the individual is doing well
                        self.neighborhood_size = int(max(self.min_neighborhood_size, self.neighborhood_size * (1 - self.neighborhood_adaptation_rate))) # gradually reduce it
                if self.neighborhood_size < self.max_neighborhood_size:
                    if self.fitness[i] > np.mean(self.fitness): # if the individual is doing poorly
                        self.neighborhood_size = int(min(self.max_neighborhood_size, self.neighborhood_size * (1 + self.neighborhood_adaptation_rate))) # gradually increase it
                
                selected_indices = indices[:self.neighborhood_size]  # Select neighborhood
                a, b, c = selected_indices[:3] # at least 3 individuals required

                # Mutation and Crossover
                mutant = self.population[a] + self.f * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) # keep in search space


                trial_vector = self.population[i].copy()
                for j in range(self.dim):
                    if random.random() < self.cr:
                        trial_vector[j] = mutant[j]

                # Evaluation
                trial_fitness = objective_function(np.array([trial_vector]))[0]
                self.eval_count += 1

                # Selection
                if trial_fitness < self.fitness[i]:
                    self.fitness[i] = trial_fitness
                    self.population[i] = trial_vector

                    # Update overall best
                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector.copy() # Important: copy here!

            # Restarting mechanism to prevent premature convergence. The original proposal involved a condition check
            # on stagnation; it's replaced with a budget check since evaluation budgets are limited in GNBG context.
            # Restart if budget allows, using the restart only for cases which could give improvement on existing fitness.
            if self.eval_count < (self.budget * 0.2) :  # example 20% budget check 
               pass
            elif self.eval_count < self.budget * 0.9 and np.std(self.fitness) < acceptance_threshold: 
               # Re-initialize a few individuals near best solution
               num_restart = 2 if self.eval_count < self.budget else 0
               for k in range(num_restart) :
                    idx = np.random.randint(0, self.population_size) #Pick random spot in population

                    # Replace bad soltion with one slightly different from best_solution
                    pertubation = np.random.uniform(-0.05, 0.05, self.dim) * (self.upper_bounds - self.lower_bounds) # 5% randomness
                    self.population[idx] = np.clip(self.best_solution_overall + pertubation, self.lower_bounds, self.upper_bounds)

                    # Evaluate fitness for the restarted individuals
                    self.fitness[idx] = objective_function(np.array([self.population[idx]]))[0]
                    self.eval_count +=1 #Important: Update evaluation
                    if self.fitness[idx] < self.best_fitness_overall:
                        self.best_fitness_overall = self.fitness[idx]
                        self.best_solution_overall = self.population[idx].copy()




        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'neighborhood_size':self.neighborhood_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 9 (Overall AOCC Score: 1.7033e-02 |             AOCC Score on Unimodal instances: 1.7033e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 10 (Overall AOCC Score: 1.6609e-02 |             AOCC Score on Unimodal instances: 1.6609e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 11 (Overall AOCC Score: 1.6514e-02 |             AOCC Score on Unimodal instances: 1.6514e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveNeighborhoodDifferentialEvolution
# Description: Uses differential evolution with adaptive neighborhood search to balance exploration and exploitation.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveNeighborhoodDifferentialEvolution
# Description: Uses differential evolution with adaptive neighborhood search to balance exploration and exploitation.
# Code:
class AdaptiveNeighborhoodDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 5 * self.dim  # Number of individuals in the population
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf')) # Initialize fitness
        self.crossover_rate = 0.7
        self.mutation_rate_initial = 0.5 # Starting mutation rate.
        self.mutation_rate_final = 0.05   # Target rate near end of budget.
        self.adaptive_neighborhood_size = int(self.population_size * 0.2)  # 20% neighborhood initially


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
            self.fitness = np.full(self.population_size, float('inf'))  # Re-initialize fitness
            
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size
            self.fitness = fitness_values
            best_index = np.argmin(self.fitness)
            self.best_solution_overall = self.population[best_index].copy()
            self.best_fitness_overall = self.fitness[best_index]

        else:
            self.best_solution_overall = np.array([])
            self.best_fitness_overall = float('inf')

        generation = 0
        while self.eval_count < self.budget:
            generation += 1
            mutation_rate = self.mutation_rate_initial + (self.mutation_rate_final - self.mutation_rate_initial) * (self.eval_count / self.budget) # Linearly Annealed
            
            # Adaptive Neighborhood:  Shrink neighborhoood if we're converging, or expand if we're not improving.
            if generation % 10 == 0:
              old_best_fitness = self.best_fitness_overall
              
            # Differential Evolution with Adaptive Neighborhood Search
            for i in range(self.population_size):
                # Select neighbors from an adaptive neighborhood of random size around the current individual
                neighbors_indices = np.random.choice(self.population_size, size=self.adaptive_neighborhood_size, replace=False)

                candidates_indices = random.sample(range(self.population_size), 3) # Not necessarily in the 'neighborhood'.  More diversity.

                a, b, c = self.population[candidates_indices[0]], self.population[candidates_indices[1]], self.population[candidates_indices[2]]

                # Mutation
                mutant = a + mutation_rate * (b - c)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                crossover_mask = np.random.rand(self.dim) < self.crossover_rate
                trial_vector = np.where(crossover_mask, mutant, self.population[i])

                # Evaluate Trial Vector
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0] # Evaluate one solution at a time, reshaped to 2D array.

                self.eval_count += 1

                # Selection
                if trial_fitness < self.fitness[i]:
                    self.fitness[i] = trial_fitness
                    self.population[i] = trial_vector
                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector.copy()

            #Reduce Neighborhood
            if generation % 10 == 0:  # Check every 10 iterations
              if self.best_fitness_overall == old_best_fitness and self.adaptive_neighborhood_size < self.population_size:  #Stagnation
                self.adaptive_neighborhood_size +=1 #Expand search
              elif self.best_fitness_overall < old_best_fitness and self.adaptive_neighborhood_size > 3:
                self.adaptive_neighborhood_size -=1 #Exploit



        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'adaptive_neighborhood_size': self.adaptive_neighborhood_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 12 (Overall AOCC Score: 1.6293e-02 |             AOCC Score on Unimodal instances: 1.6293e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolution
# Description: Implements Differential Evolution with adaptive parameter control, focused on exploration and escaping local optima in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: Implements Differential Evolution with adaptive parameter control, focused on exploration and escaping local optima in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 3 * self.dim  # Initialize population size. This should be tuned for performance
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

        # Differential Evolution parameters (adaptive)
        self.F = 0.5  # Differential weight
        self.CR = 0.7  # Crossover rate
        self.F_memory = [self.F]  # Memory for F values
        self.CR_memory = [self.CR] # Memory for CR values
        self.memory_size = 10    # Length of memory to preserve recent tuning factors

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = self.population[best_index].copy()
            
        while self.eval_count < self.budget:
            #Adaptive F/CR scheme
            F = random.choice(self.F_memory)
            CR = random.choice(self.CR_memory)
           
            new_population = np.zeros_like(self.population)
            for i in range(self.population_size):
                # Mutation
                indices = [j for j in range(self.population_size) if j != i]
                a, b, c = random.sample(indices, 3) # Ensure unique sample indices.
                mutant = self.population[a] + F * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Ensure bounds are respected

                # Crossover
                cross_points = np.random.rand(self.dim) < CR
                if not np.any(cross_points):
                     cross_points[random.randint(0, self.dim - 1)] = True # Ensure that the trial vector gets at least one parameter from the mutant.
                trial = np.where(cross_points, mutant, self.population[i])


                new_population[i] = trial

            # Evaluation
            new_fitness = objective_function(new_population)
            self.eval_count += self.population_size

            # Selection
            for i in range(self.population_size):
                if new_fitness[i] < fitness[i]:
                    fitness[i] = new_fitness[i]
                    self.population[i] = new_population[i]

            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = self.population[best_index].copy()
                
                #Update parameters

            successful_indexes = np.where(new_fitness < fitness)[0]
            if len(successful_indexes) > 0:
                self.F_memory.append(F)
                self.CR_memory.append(CR)
                if len(self.F_memory) > self.memory_size:
                    self.F_memory.pop(0)
                if len(self.CR_memory) > self.memory_size:
                     self.CR_memory.pop(0)
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 13 (Overall AOCC Score: 1.5666e-02 |             AOCC Score on Unimodal instances: 1.5666e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveNeighborhoodDifferentialEvolution
# Description: Differential Evolution with adaptive neighborhood radius and mutation scaling to balance exploration/exploitation.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveNeighborhoodDifferentialEvolution
# Description: Differential Evolution with adaptive neighborhood radius and mutation scaling to balance exploration/exploitation.
# Code:
class AdaptiveNeighborhoodDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 5 * self.dim  # Example population size
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))

        self.mutation_factor = 0.5  # Initial mutation factor
        self.crossover_rate = 0.7
        self.neighborhood_size = min(10, self.population_size // 2)  # Dynamic neighborhood size
        self.neighborhoods = []  # List of neighbors for each solution

        self.adaptive_scaling_enabled = True
        self.success_rate_memory = 10  # Size of the memory for success rate
        self.mutation_success_history = np.zeros(self.success_rate_memory)  # Track mutation success for adaptation
        self.mutation_learning_rate = 0.1

    def initialize_neighborhoods(self):
        """Initializes neighborhoods for each solution."""
        self.neighborhoods = []
        for i in range(self.population_size):
            neighbors = list(range(self.population_size))
            neighbors.remove(i)
            random.shuffle(neighbors)
            self.neighborhoods.append(neighbors[:self.neighborhood_size])

    def update_neighborhoods(self):
        """Re-evaluates and potentially changes neighborhood for each solution."""
        for i in range(self.population_size):
            # Recalculate neighbor ranking (e.g., based on fitness distance)
            neighbor_fitness_distances = []
            for neighbor_index in range(self.population_size):
                if neighbor_index != i:
                    distance = np.linalg.norm(self.population[i] - self.population[neighbor_index])
                    fitness_difference = abs(self.fitness[i] - self.fitness[neighbor_index])
                    neighbor_fitness_distances.append((neighbor_index, distance + fitness_difference * 0.1))  #Combined metric

            neighbor_fitness_distances.sort(key=lambda x: x[1])  #Sort by distance + fitness difference
            
            new_neighbors = [x[0] for x in neighbor_fitness_distances[:self.neighborhood_size]]
            self.neighborhoods[i] = new_neighbors


    def mutate(self, index):
        """Performs differential mutation using neighbors."""
        neighbors = self.neighborhoods[index]
        a, b, c = random.sample(neighbors, 3)

        mutant = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])
        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Boundary handling
        return mutant

    def crossover(self, individual, mutant):
        """Performs binomial crossover."""
        trial_vector = individual.copy()
        for i in range(self.dim):
            if random.random() < self.crossover_rate or i == random.randint(0, self.dim - 1):  #Ensure at least one change
                trial_vector[i] = mutant[i]
        return trial_vector

    def select(self, trial_vector, index, objective_function):
        """Selects between trial vector and current individual."""
        trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
        self.eval_count += 1

        if trial_fitness < self.fitness[index]:
            #Mutation was successful
            if self.adaptive_scaling_enabled:
                self.mutation_success_history = np.roll(self.mutation_success_history, 1)
                self.mutation_success_history[0] = 1

            self.fitness[index] = trial_fitness
            self.population[index] = trial_vector
            if trial_fitness < self.best_fitness_overall:
                self.best_fitness_overall = trial_fitness
                self.best_solution_overall = trial_vector.copy()

        else:
            #Mutation was unsuccessful
             if self.adaptive_scaling_enabled:
                self.mutation_success_history = np.roll(self.mutation_success_history, 1)
                self.mutation_success_history[0] = 0

    def adjust_mutation_scaling(self):
         #Adjust mutation rate using the success history
        success_rate = np.mean(self.mutation_success_history)
        self.mutation_factor = np.clip(self.mutation_factor + self.mutation_learning_rate * (success_rate - 0.5), 0.1, 1.0)

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0  # Reset for this run
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))

        # Initial evaluation
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.fitness = fitness_values
        best_index = np.argmin(self.fitness)
        self.best_fitness_overall = self.fitness[best_index]
        self.best_solution_overall = self.population[best_index].copy()

        self.initialize_neighborhoods()

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                mutant = self.mutate(i)
                trial_vector = self.crossover(self.population[i], mutant)
                self.select(trial_vector, i, objective_function)

            self.update_neighborhoods()
            if self.adaptive_scaling_enabled:
                self.adjust_mutation_scaling()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 14 (Overall AOCC Score: 1.5440e-02 |             AOCC Score on Unimodal instances: 1.5440e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolution
# Description: Adaptive Differential Evolution with population diversity maintenance and crossover adaptation for complex multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: Adaptive Differential Evolution with population diversity maintenance and crossover adaptation for complex multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(10 * self.dim)  # dynamic pop size for scalability
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))
        self.mutation_factor = 0.5
        self.crossover_rate = 0.7  # Start with a higher value, will be adapted
        self.crossover_rate_history = []


    def _evaluate_population(self, objective_function: callable):
        if self.population.size > 0:  # check if population is not empty
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size
            return fitness_values
        else:
            return np.array([])

    def _maintain_diversity(self, min_distance_threshold=0.01):
        """Enforce a minimum distance between population members."""
        for i in range(self.population_size):
            for j in range(i + 1, self.population_size):
                distance = np.linalg.norm(self.population[i] - self.population[j])
                if distance < min_distance_threshold:
                    # Push individuals further apart if too close.  Choose direction randomly.
                    direction = np.random.normal(0, 1, self.dim)
                    direction /= np.linalg.norm(direction) # Normalize to unit vector
                    push_amount = min_distance_threshold - distance
                    self.population[j] += direction * push_amount * 0.5 # push in opposite directions
                    self.population[i] -= direction * push_amount * 0.5

                    # Clip to bounds after moving
                    self.population[i] = np.clip(self.population[i], self.lower_bounds, self.upper_bounds)
                    self.population[j] = np.clip(self.population[j], self.lower_bounds, self.upper_bounds)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0  # Reset for this run
        self.crossover_rate_history = []
        
        # Initialize best solution if not already initialized to a reasonable value
        if self.best_solution_overall is None or self.best_fitness_overall == float('inf'): # or not self.lower_bounds <= self.best_solution_overall <= self.upper_bounds: 
            if self.dim > 0 :
                 self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
            else:
                 self.best_solution_overall = np.array([]) #empty array
        self.best_fitness_overall = float('inf')

        # Initial evaluation of the population
        self.fitness = self._evaluate_population(objective_function)

        if self.fitness.size > 0:
            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness[best_index]
                self.best_solution_overall = self.population[best_index].copy()



        while self.eval_count < self.budget:
            # --- Core Differential Evolution loop ---
            for i in range(self.population_size):
                # Mutation
                indices = list(range(self.population_size))
                indices.remove(i)
                a, b, c = random.sample(indices, 3)  # Use random.sample to avoid replacement

                mutant = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Clip to bounds

                # Crossover
                trial_vector = np.copy(self.population[i]) # Start with the current vector
                for j in range(self.dim):
                    if random.random() < self.crossover_rate or j == random.randint(0, self.dim - 1):  # Ensure at least one element changes
                        trial_vector[j] = mutant[j]

                # Selection
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0] # Ensure the input is a 2D array

                self.eval_count += 1

                if trial_fitness < self.fitness[i]:
                    self.fitness[i] = trial_fitness
                    self.population[i] = trial_vector

                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector.copy() # Store a copy!
            
            # -- Diversity Maintenance and Adaptation --
            self._maintain_diversity()
            
            # Dynamic crossover rate adjustment
            std_dev_fitness = np.std(self.fitness)
            if std_dev_fitness < acceptance_threshold :  # Stagnation detected
                self.crossover_rate *= 0.9   # reduce crossover
            else:
                self.crossover_rate = min(0.9, self.crossover_rate + 0.01)  # mild increase to allow exploration
            
            self.crossover_rate = max(0.1, self.crossover_rate) # bounds check
            self.crossover_rate_history.append(self.crossover_rate)

            # Occasional reset (re-initialization) of worst individuals (helps escape local minima)
            if (self.eval_count // self.population_size) % 50 == 0: # after every X generations, reset the worst
                worst_indices = np.argsort(self.fitness)[-int(0.2 * self.population_size):] #20% worst
                for index in worst_indices:
                    self.population[index] = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                    self.fitness[index] = float('inf') #mark it as invalid, will be updated in next evaluation cycle



        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'crossover_rate_history' : self.crossover_rate_history
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 15 (Overall AOCC Score: 1.5324e-02 |             AOCC Score on Unimodal instances: 1.5324e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolution
# Description: An Adaptive Differential Evolution algorithm utilizing jittering and adaptive parameter control for enhanced exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: An Adaptive Differential Evolution algorithm utilizing jittering and adaptive parameter control for enhanced exploration in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(10 * self.dim)  # Dynamic population size
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))
        self.CR = 0.7  # Initial crossover rate
        self.F = 0.8  # Initial mutation factor
        self.CR_min = 0.1
        self.CR_max = 0.9
        self.F_min = 0.1
        self.F_max = 0.9
        self.adaptive_probability = 0.1

    def _evaluate_population(self, objective_function: callable):
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness_values

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0  # Reset for this run

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))


        self.fitness = self._evaluate_population(objective_function)

        best_index = np.argmin(self.fitness)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = self.fitness[best_index].copy()

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Mutation (DE/rand/1) with jittering
                indices = np.random.choice(self.population_size, 5, replace=False)  # Select 5 distinct indices
                x_r1, x_r2, x_r3, x_r4, x_r5 = self.population[indices]

                # Jittering for exploration
                F_jitter = self.F + np.random.uniform(-0.05, 0.05)
                F_jitter = np.clip(F_jitter, 0.05, 1.0)


                mutant = x_r1 + F_jitter * (x_r2 - x_r3) + F_jitter * (x_r4 - x_r5)  # Ensuring 5 distinct individuals
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)  # Bound handling

                # Crossover
                trial_vector = self.population[i].copy()
                for j in range(self.dim):
                    if random.random() < self.CR or j == random.randint(0, self.dim - 1):
                        trial_vector[j] = mutant[j]

                # Selection
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self.fitness[i]:
                    self.population[i] = trial_vector
                    self.fitness[i] = trial_fitness

                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial_vector.copy()
                        self.best_fitness_overall = trial_fitness

            # Adaptive Parameter Control
            if random.random() < self.adaptive_probability:
                self.CR = np.random.uniform(self.CR_min, self.CR_max)
                self.F = np.random.uniform(self.F_min, self.F_max)
        

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size,
            'CR': self.CR,
            'F': self.F
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 16 (Overall AOCC Score: 1.5129e-02 |             AOCC Score on Unimodal instances: 1.5129e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolution
# Description: Implements Adaptive Differential Evolution with multiple strategies and periodic restarts for improved global exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: Implements Adaptive Differential Evolution with multiple strategies and periodic restarts for improved global exploration in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        # Parameters for DE
        self.pop_size = 10 * self.dim  # Population size
        self.mutation_factors = [0.5, 0.7, 0.9]  # Multiple mutation factors
        self.crossover_rates = [0.6, 0.7, 0.8, 0.9] # Multiple crossover rates
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.pop_size, self.dim))
        self.fitness = np.full(self.pop_size, float('inf'))  # Initialize fitness values

        # Restart mechanism
        self.restart_interval = self.budget // 10  # Restart every 10% of the budget
        self.last_improvement = 0

        # Strategy selection weights (initialized equally)
        num_strategies = len(self.mutation_factors) * len(self.crossover_rates)
        self.strategy_weights = np.ones(num_strategies) / num_strategies

        self.archive = [] #Archive to store unsucessful solution

    def initialize_population(self):
        """Initializes the population."""
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.pop_size, self.dim))
        self.fitness = np.full(self.pop_size, float('inf'))

    def evaluate_population(self, objective_function: callable):
        """Evaluates the fitness of the population."""
        fitness_values = objective_function(self.population)
        self.eval_count += self.pop_size
        self.fitness = fitness_values

        # Update best solution
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = self.fitness[best_index]
            self.best_solution_overall = self.population[best_index].copy()
            self.last_improvement = self.eval_count

    def evolve(self, objective_function: callable):
          """Performs one generation of differential evolution."""
          successful_strategies = np.zeros_like(self.strategy_weights)
          for i in range(self.pop_size):
              # Adaptive strategy selection: sample strategy index based on weights
              strategy_index = np.random.choice(len(self.strategy_weights), p=self.strategy_weights)
              mutation_index = strategy_index // len(self.crossover_rates)
              crossover_index = strategy_index % len(self.crossover_rates)

              mutation_factor = self.mutation_factors[mutation_index]
              crossover_rate = self.crossover_rates[crossover_index]

              # Mutation
              indices = np.random.choice(self.pop_size, 3, replace=False)
              while i in indices: #ensure i is not among chosen indices.
                  indices = np.random.choice(self.pop_size, 3, replace=False)
              x_r1, x_r2, x_r3 = self.population[indices]

              mutant = self.population[i] + mutation_factor * (x_r2 - x_r3)  # Fixed x_r1 as current individual

              # Repair bounds
              mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

              # Crossover
              crossover_mask = np.random.rand(self.dim) < crossover_rate
              trial_vector = np.where(crossover_mask, mutant, self.population[i])

              # Evaluation
              trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
              self.eval_count += 1

              # Selection
              if trial_fitness < self.fitness[i]:
                  self.archive.append(self.population[i].copy()) # Storing the solution.
                  self.population[i] = trial_vector
                  self.fitness[i] = trial_fitness

                  #Update best solution
                  if trial_fitness < self.best_fitness_overall:
                      self.best_fitness_overall = trial_fitness
                      self.best_solution_overall = trial_vector.copy()
                      self.last_improvement = self.eval_count
                  successful_strategies[strategy_index] += 1 # reward strategy


              # Update best solution after each generation

          # Update strategy weights based on success rates
          total_successes = np.sum(successful_strategies)
          if total_successes > 0:
              self.strategy_weights = successful_strategies / total_successes
          else:
             self.strategy_weights = np.ones_like(self.strategy_weights) / len(self.strategy_weights)

          self.strategy_weights = 0.9 * self.strategy_weights + 0.1 / len(self.strategy_weights)
          self.strategy_weights /= np.sum(self.strategy_weights) #Renormalizing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """Main optimization loop."""
        self.eval_count = 0
        self.initialize_population() # Initialize population before each optimization run
        self.evaluate_population(objective_function) #Evaluate initial population

        while self.eval_count < self.budget:
            self.evolve(objective_function)

            # Restart mechanism if no improvement for a while.
            if self.eval_count - self.last_improvement > self.restart_interval:
               self.initialize_population()
               self.evaluate_population(objective_function)
               self.last_improvement = self.eval_count #Reset last improvement.

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 17 (Overall AOCC Score: 1.4937e-02 |             AOCC Score on Unimodal instances: 1.4937e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolution
# Description: Differential Evolution with adaptive parameters and a restarting strategy to escape local optima.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: Differential Evolution with adaptive parameters and a restarting strategy to escape local optima.
# Code:
class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 20 * self.dim  # A common heuristic
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.zeros(self.population_size)

        self.mutation_factor = 0.5
        self.crossover_rate = 0.7
        self.learning_rate_mutation = 0.1
        self.learning_rate_crossover = 0.1
        self.restart_interval = self.budget // 10  # Restart every 10% of the budget
        self.last_restart_eval = 0

    def _evaluate_population(self, objective_function: callable):
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = self.fitness[best_index]
            self.best_solution_overall = self.population[best_index].copy()


    def _restart_population(self):
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        print("Restarting population...")


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = float('inf')

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self._evaluate_population(objective_function)  # Initial evaluation

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                # Mutation
                indices = list(range(self.population_size))
                indices.remove(i)
                a, b, c = random.sample(indices, 3)
                mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])

                # Ensure the mutant vector stays within bounds
                mutant_vector = np.clip(mutant_vector, self.lower_bounds, self.upper_bounds)

                # Crossover
                crossover_mask = np.random.rand(self.dim) < self.crossover_rate
                trial_vector = np.where(crossover_mask, mutant_vector, self.population[i])

                # Evaluation
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
                self.eval_count += 1

                # Selection
                if trial_fitness < self.fitness[i]:
                    self.fitness[i] = trial_fitness
                    self.population[i] = trial_vector
                    # Adjust parameters adaptively
                    self.mutation_factor += self.learning_rate_mutation * (1 if trial_fitness < self.fitness[i] else -1)
                    self.crossover_rate += self.learning_rate_crossover * (1 if trial_fitness < self.fitness[i] else -1)
                    self.mutation_factor = np.clip(self.mutation_factor, 0.1, 0.9)  # Keep mutation factor within reasonable bounds
                    self.crossover_rate = np.clip(self.crossover_rate, 0.1, 0.9)    # Keep crossover rate within reasonable bounds


                if trial_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = trial_fitness
                    self.best_solution_overall = trial_vector.copy()

                if self.eval_count - self.last_restart_eval > self.restart_interval:
                        self._restart_population()
                        self._evaluate_population(objective_function)  # Re-evaluate after restart
                        self.last_restart_eval = self.eval_count


                if self.eval_count >= self.budget:
                    break
        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 18 (Overall AOCC Score: 1.4794e-02 |             AOCC Score on Unimodal instances: 1.4794e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedDiversityEA
# Description: An evolutionary algorithm utilizing Latin Hypercube Initialization, a custom differential mutation operator with dynamic scaling, and restart strategies for enhanced diversity and exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: EnhancedDiversityEA
# Description: An evolutionary algorithm utilizing Latin Hypercube Initialization, a custom differential mutation operator with dynamic scaling, and restart strategies for enhanced diversity and exploration in multimodal landscapes.
# Code:
class EnhancedDiversityEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.range = self.upper_bounds - self.lower_bounds

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(50 + np.sqrt(self.dim))  # Population size scales with dimensionality
        self.population = self.initialize_population_latin_hypercube(self.population_size) # Latin hypercube sampling
        self.fitness = np.zeros(self.population_size)

        self.mutation_rate = 0.1 # Fixed mutation rate
        self.crossover_rate = 0.7 # Fixed crossover rate
        self.scale_factor = 0.5 # Differential evolution scaling factor

        self.restart_threshold = 5000 # Restart if no improvement in this many evaluations
        self.last_improvement = 0

    def initialize_population_latin_hypercube(self, population_size):
        population = np.zeros((population_size, self.dim))
        for i in range(self.dim):
            idx = np.random.permutation(population_size) + 1
            population[:, i] = ((idx - np.random.rand(population_size)) / population_size) * (self.upper_bounds[i] - self.lower_bounds[i]) + self.lower_bounds[i]
        return population
    
    def check_bounds(self, X):
        """Check if individuals are within bounds and repair."""
        X = np.clip(X, self.lower_bounds, self.upper_bounds)
        return X

    def differential_mutation(self):
        """Enhanced Differential Mutation with dynamic scaling."""
        for i in range(self.population_size):
            idxs = random.sample(range(self.population_size), 3)
            while i in idxs:
                idxs = random.sample(range(self.population_size), 3)

            a, b, c = self.population[idxs[0]], self.population[idxs[1]], self.population[idxs[2]]
            
            # Adaptive scaling based on population diversity
            diversity = np.std(self.population) # Calculate pop std dev. Use to tune scale factor.

            mutant = a + (self.scale_factor + 0.1 * diversity) * (b - c) # LLM: Adjust mutation strength by diversity

            #Apply crossover
            cross_points = np.random.rand(self.dim) < self.crossover_rate
            if not np.any(cross_points):
                cross_points[np.random.randint(0, self.dim)] = True # Ensure at least one element changes

            trial_vector = np.where(cross_points, mutant, self.population[i])
            
            self.population[i] = self.check_bounds(trial_vector)  # Apply bounds

    def evaluate_population(self, objective_function: callable):
        """Evaluates the fitness of each individual in the population."""
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        # Update global best
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = self.fitness[best_index]
            self.best_solution_overall = self.population[best_index].copy()
            self.last_improvement = self.eval_count

    def restart_population(self):
        """Restarts the population with new Latin Hypercube samples."""
        self.population = self.initialize_population_latin_hypercube(self.population_size) # Latin hypercube sampling
        self.fitness = np.zeros(self.population_size)
        print("Restarting Population...") #DEBUG

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0  # Reset for this run
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        self.last_improvement = 0

        self.initialize_population_latin_hypercube(self.population_size)

        while self.eval_count < self.budget:
            self.evaluate_population(objective_function)
            self.differential_mutation()

            # Restart mechanism
            if self.eval_count - self.last_improvement > self.restart_threshold:
                self.restart_population()

        if self.best_solution_overall is None and self.dim > 0:  # Fallback
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'mutation_rate': self.mutation_rate,
            'crossover_rate': self.crossover_rate,
            'scale_factor': self.scale_factor
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 19 (Overall AOCC Score: 1.4790e-02 |             AOCC Score on Unimodal instances: 1.4790e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: NovelGlobalScout
# Description: Employs a combination of uniform initialization, a Cauchy mutation for exploration, and a selection mechanism that favors diversity in the initial stage and convergence later.
# Code:
```python
import numpy as np
import random

# Name: NovelGlobalScout
# Description: Employs a combination of uniform initialization, a Cauchy mutation for exploration, and a selection mechanism that favors diversity in the initial stage and convergence later.
# Code:
class NovelGlobalScout:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(min(100, 10 + 4 * np.log(dim)))  # Dynamically adjust pop size
        self.population = None
        self.fitness = None
        self.mutation_rate = 0.1
        self.cauchy_scale = 1.0  # Controls the step size of the Cauchy mutation
        self.diversity_threshold = 0.01  # Threshold for diversity-based selection
        self.diversity_weight = 0.5 # Weight for diversity in the fitness calculation
        self.initial_diversity_focus = 0.8 #How much focus on diversity initially
        self.diversity_decay_rate = 0.995 #Decrease diversity focus linearly over iterations.

        self.current_generation = 0

    def initialize_population(self):
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.zeros(self.population_size)

    def evaluate_population(self, objective_function: callable):
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size
        
        for i in range(self.population_size):
          if self.fitness[i] < self.best_fitness_overall:
            self.best_fitness_overall = self.fitness[i]
            self.best_solution_overall = self.population[i].copy()


    def cauchy_mutation(self, individual):
        new_individual = individual.copy()
        for i in range(self.dim):
            if random.random() < self.mutation_rate:
                step = self.cauchy_scale * random.choice([-1,1]) * np.random.standard_cauchy()
                new_individual[i] += step
                new_individual[i] = np.clip(new_individual[i], self.lower_bounds[i], self.upper_bounds[i])
        return new_individual

    def calculate_diversity(self):
        centroid = np.mean(self.population, axis=0)
        distances = np.linalg.norm(self.population - centroid, axis=1)
        return np.mean(distances)

    def selection(self, objective_function: callable):
        diversity = self.calculate_diversity()
        normalized_fitness = (self.fitness - np.min(self.fitness)) / (np.max(self.fitness) - np.min(self.fitness) + 1e-8)
        if np.max(self.fitness) == np.min(self.fitness):
            normalized_fitness = np.zeros_like(self.fitness)

        #Diversity Fitness
        distances = np.linalg.norm(self.population - self.best_solution_overall, axis=1)
        normalized_distances = distances / (np.max(distances) + 1e-8)
        if np.max(distances) == 0:
            normalized_distances = np.ones_like(distances)
            
        combined_fitness = (1-self.initial_diversity_focus) * (1.0 - normalized_fitness) + self.initial_diversity_focus * normalized_distances # Lower fitness and Farther away.

        selected_indices = np.argsort(combined_fitness)[:self.population_size // 2]
        offspring = []
        for i in selected_indices:
          offspring.append(self.population[i].copy())
        
        while len(offspring) < self.population_size:
            parent = random.choice(self.population[selected_indices])
            mutated_individual = self.cauchy_mutation(parent)
            offspring.append(mutated_individual)

        offspring = np.array(offspring)
        
        self.population = offspring
        fitness = objective_function(self.population)
        self.eval_count += len(offspring)
        self.fitness = fitness
        for i in range(self.population_size):
          if self.fitness[i] < self.best_fitness_overall:
            self.best_fitness_overall = self.fitness[i]
            self.best_solution_overall = self.population[i].copy()

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
             self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
             self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        self.current_generation = 0
        self.initialize_population()
        self.evaluate_population(objective_function)

        while self.eval_count < self.budget:
            self.selection(objective_function)

            self.initial_diversity_focus *= self.diversity_decay_rate
            self.current_generation += 1
        
        if self.best_solution_overall is None and self.dim > 0 : # Fallback
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
            
        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 20 (Overall AOCC Score: 1.4660e-02 |             AOCC Score on Unimodal instances: 1.4660e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: CMAESResilientPopulation
# Description: CMA-ES variant initialized with a resilient population designed to encourage global exploration across multimodal landscapes using Latin Hypercube Sampling and opposition-based learning to enhance diversity and escape local optima.
# Code:
```python
import numpy as np
import random

# Name: CMAESResilientPopulation
# Description: CMA-ES variant initialized with a resilient population designed to encourage global exploration across multimodal landscapes using Latin Hypercube Sampling and opposition-based learning to enhance diversity and escape local optima.
# Code:
class CMAESResilientPopulation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.pop_size = 4 + int(3 * np.log(self.dim)) # Based on CMA-ES recommendations, ensure pop_size is adequate for dimension

        self.mean = np.zeros(self.dim)  # Initialize mean inside valid bounds
        for i in range(self.dim):
            self.mean[i] = np.random.uniform(self.lower_bounds[i], self.upper_bounds[i])

        self.sigma = 0.1 * np.mean(self.upper_bounds - self.lower_bounds) # Global stepsize
        self.C = np.eye(self.dim) # Covariance matrix for adaptive search

        self.eigen_decomposition_needed = True
        self.B = None  # Eigenvectors of C
        self.D = None  # Eigenvalues of C (square roots)
        self.c_sigma = (np.sqrt(self.pop_size)*0.1)/(np.linalg.norm(np.sqrt(self.C)))
        self.c_c = (4+np.mean([self.lower_bounds,self.upper_bounds]))/ self.dim + 1  # Adjust based on bounds
        self.damps = 1 + 2 * max(0, np.sqrt((self.c_c-1)/(self.pop_size+self.dim)) - 1)

        self.ps = np.zeros((self.dim,))
        self.pc = np.zeros((self.dim,))
        self.mu = self.pop_size//2

    def _latin_hypercube_sampling(self, n_samples):
        """Generates samples using Latin Hypercube Sampling (LHS)."""
        samples = np.zeros((n_samples, self.dim))
        for i in range(self.dim):
            bins = np.linspace(self.lower_bounds[i], self.upper_bounds[i], n_samples + 1)
            interval_size = (self.upper_bounds[i] - self.lower_bounds[i]) / n_samples
            permutations = np.random.permutation(n_samples)  # Shuffle bins
            for j in range(n_samples):
                samples[j, i] = bins[permutations[j]] + np.random.uniform(0, interval_size) # select in the interval
        return samples

    def _opposition_based_learning(self, population):
        """Applies opposition-based learning to enhance population diversity."""
        opposites = []
        for x in population:
            opposite = self.lower_bounds + self.upper_bounds - x
            opposites.append(opposite)
        return np.array(opposites)

    def _evaluate_population(self, objective_function, population):
        """Evaluates the population and updates the evaluation count."""
        fitness_values = objective_function(population)
        self.eval_count += len(population)
        return fitness_values

    def _update_eigen_decomposition(self):
        """Updates the eigenvalue decomposition of the covariance matrix."""
        if self.eigen_decomposition_needed:
            self.eigen_decomposition_needed = False
            self.D, self.B = np.linalg.eigh(self.C)  # Eigenvalue decomposition
            self.D = np.sqrt(np.maximum(self.D, 1e-16))  # Ensure positive definite

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0

        # Enhanced population initialization using LHS and opposition-based learning
        initial_population = self._latin_hypercube_sampling(self.pop_size)
        opposition_population = self._opposition_based_learning(initial_population)
        population = np.vstack((initial_population, opposition_population))

        fitness_values = self._evaluate_population(objective_function, population)
        ranked_indices = np.argsort(fitness_values)
        population = population[ranked_indices]
        fitness_values = fitness_values[ranked_indices]

        if fitness_values[0] < self.best_fitness_overall:
            self.best_solution_overall = population[0].copy()
            self.best_fitness_overall = fitness_values[0]

        while self.eval_count < self.budget:
            # Generate offspring
            self._update_eigen_decomposition()

            z = np.random.randn(self.pop_size, self.dim)
            y = self.B.dot(np.diag(self.D)).dot(z.T).T  # y = B * diag(D) * z

            offspring = self.mean + self.sigma * y

            # Handle boundaries (clip to feasible region and/or resample)
            for i in range(self.pop_size):
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

            offspring_fitness = self._evaluate_population(objective_function, offspring)
            ranked_indices = np.argsort(offspring_fitness)
            offspring = offspring[ranked_indices]
            offspring_fitness = offspring_fitness[ranked_indices]

            if offspring_fitness[0] < self.best_fitness_overall:
                self.best_solution_overall = offspring[0].copy()
                self.best_fitness_overall = offspring_fitness[0]

            # Update CMA-ES parameters
            xmean = np.mean(offspring[:self.mu], axis=0)
            y_ = (xmean - self.mean) / self.sigma # Transform step vector
            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2 - self.c_sigma)) * self.B.dot(y_[np.newaxis].T).flatten()

            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma) ** (2 * self.eval_count / self.pop_size)) < (1.4 + 2/(self.dim+1)))

            self.pc = (1-self.c_c)*self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * y_

            self.mean = xmean

            delta = (offspring[:self.mu] - self.mean) / self.sigma
            dC = np.sum([(w * (delta[k][np.newaxis].T * delta[k] )) for k,w in enumerate(np.ones(self.mu)/self.mu)],axis=0)  # Rank- update
            self.C = (1 - self.c_c) * self.C + self.c_c * (self.pc[np.newaxis].T * self.pc + (1-hsig)*dC)
            self.sigma *= np.exp((self.c_sigma/self.damps) * (np.linalg.norm(self.ps) - np.sqrt(self.dim)))

            self.eigen_decomposition_needed = True

            if self.best_fitness_overall <= acceptance_threshold:
                break

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 08:20:45 INFO Full response text: **Analysis:**
Comparing (AdaptiveGaussianArchiveEA - best) vs (CMAESResilientPopulation - worst), we see that the top performer utilizes an archive for diversity and adaptive Gaussian mutation, while the bottom uses CMA-ES principles. Increased archive size and faster sigma decay in the best-performing algorithm possibly improve exploration in complex landscapes. Initializing the population using the Latin Hypercube Sampling from CMAESResilientPopulation could be helpful for other algorithms, but they should not utilize a small value for covariance matrix.

(AdaptiveDifferentialEvolutionWithEnhancedInitialization - second best) vs (NovelGlobalScout - second worst): The second best uses DE with initialization near known optima. In contrast, NovelGlobalScout uses Cauchy mutation and a diversity-focused selection mechanism which does not perform better. EnhancedInitialization may cause local optimum early.

Comparing (AdaptiveGaussianArchiveEA - best) vs (AdaptiveDifferentialEvolutionWithEnhancedInitialization - second best), we see adaptive Gaussian sampling with archive guided by tournament selection is much better than Adaptive DE with enhanced initialization around optima.

Comparing (EnhancedArchiveGuidedDE, EnhancedArchiveGuidedDE) vs (AdaptiveGaussianSamplingEA, AdaptiveGaussianSamplingEA), we see the archive based guided DE is generally better.

Comparing (second worst) vs (worst), we see that cauchy mutation is not as good as Latin Hypercube Sampling (LHS) for initialization.

Overall: the best performing algorithms focus on diversity maintenance through archives and adaptive Gaussian sampling. DE with initialization near known optima can boost local search but may not work well on multi-modal problems. Cauchy mutation performs worse than LHS or gaussian recombination, indicating that GNBG problems might not like to move far away. Archive-guided algorithms perform strongly, showing memory matters. Adaptive parameter control and restarts seem beneficial but have less impact than other techniques.

**Experience:**
Utilizing archive mechanisms is crucial for enhancing diversity. Gaussian sampling and recombination strategies perform well, likely fitting GNBG's landscape better than Cauchy jumps. Initializing with LHS can be efficient in some settings, and parameter adaptation (sigma, CR) should be incorporated, with DE/archive combination being a robust exploration. Adaptive mutation scaling according to the population fitness standard deviation also helps.

2025-06-24 08:20:48 INFO Full response text: Okay, I understand. Let's refine self-reflection for designing better heuristics.

Here's a refined approach, designed to avoid ineffective elements and maximize heuristic improvement potential:

*   **Keywords:** Diversity maintenance, Landscape awareness, Parameter adaptation, Adaptive scaling, Exploration-Exploitation balance, Archive Utilization, Gaussian Processes

*   **Advice:** Explicitly analyze the problem landscape characteristics to inform the choice of search operators (GNBG, DE, etc.). Prioritize adaptive parameter control based on population fitness changes, focusing on convergence rate and diversity metrics. Employ Gaussian Sampling based on proven efficiency but adapt sigma for current location to balance exploration and exploitation.

*   **Avoid:** Blindly applying previously successful strategies without understanding the problem characteristics. Fixed parameters without proper adaptation. Sole reliance on exploration without convergence/exploitation considerations.

*   **Explanation:** Effective heuristics require constant recalibration based on the search process feedback and insights gained from landscape explorations. Focus on building adaptive systems that respond intelligently to the evolving search dynamics. This will make your algorithm adaptive to each instance.

2025-06-24 08:20:48 INFO Generating offspring via Crossover...
2025-06-24 08:29:32 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    

### Better code
AdaptiveDifferentialEvolution
import numpy as np
import random

# Name: AdaptiveDifferentialEvolution
# Description: Implements Adaptive Differential Evolution with multiple strategies and periodic restarts for improved global exploration in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        # Parameters for DE
        self.pop_size = 10 * self.dim  # Population size
        self.mutation_factors = [0.5, 0.7, 0.9]  # Multiple mutation factors
        self.crossover_rates = [0.6, 0.7, 0.8, 0.9] # Multiple crossover rates
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.pop_size, self.dim))
        self.fitness = np.full(self.pop_size, float('inf'))  # Initialize fitness values

        # Restart mechanism
        self.restart_interval = self.budget // 10  # Restart every 10% of the budget
        self.last_improvement = 0

        # Strategy selection weights (initialized equally)
        num_strategies = len(self.mutation_factors) * len(self.crossover_rates)
        self.strategy_weights = np.ones(num_strategies) / num_strategies

        self.archive = [] #Archive to store unsucessful solution

    def initialize_population(self):
        """Initializes the population."""
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.pop_size, self.dim))
        self.fitness = np.full(self.pop_size, float('inf'))

    def evaluate_population(self, objective_function: callable):
        """Evaluates the fitness of the population."""
        fitness_values = objective_function(self.population)
        self.eval_count += self.pop_size
        self.fitness = fitness_values

        # Update best solution
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = self.fitness[best_index]
            self.best_solution_overall = self.population[best_index].copy()
            self.last_improvement = self.eval_count

    def evolve(self, objective_function: callable):
          """Performs one generation of differential evolution."""
          successful_strategies = np.zeros_like(self.strategy_weights)
          for i in range(self.pop_size):
              # Adaptive strategy selection: sample strategy index based on weights
              strategy_index = np.random.choice(len(self.strategy_weights), p=self.strategy_weights)
              mutation_index = strategy_index // len(self.crossover_rates)
              crossover_index = strategy_index % len(self.crossover_rates)

              mutation_factor = self.mutation_factors[mutation_index]
              crossover_rate = self.crossover_rates[crossover_index]

              # Mutation
              indices = np.random.choice(self.pop_size, 3, replace=False)
              while i in indices: #ensure i is not among chosen indices.
                  indices = np.random.choice(self.pop_size, 3, replace=False)
              x_r1, x_r2, x_r3 = self.population[indices]

              mutant = self.population[i] + mutation_factor * (x_r2 - x_r3)  # Fixed x_r1 as current individual

              # Repair bounds
              mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

              # Crossover
              crossover_mask = np.random.rand(self.dim) < crossover_rate
              trial_vector = np.where(crossover_mask, mutant, self.population[i])

              # Evaluation
              trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
              self.eval_count += 1

              # Selection
              if trial_fitness < self.fitness[i]:
                  self.archive.append(self.population[i].copy()) # Storing the solution.
                  self.population[i] = trial_vector
                  self.fitness[i] = trial_fitness

                  #Update best solution
                  if trial_fitness < self.best_fitness_overall:
                      self.best_fitness_overall = trial_fitness
                      self.best_solution_overall = trial_vector.copy()
                      self.last_improvement = self.eval_count
                  successful_strategies[strategy_index] += 1 # reward strategy


              # Update best solution after each generation

          # Update strategy weights based on success rates
          total_successes = np.sum(successful_strategies)
          if total_successes > 0:
              self.strategy_weights = successful_strategies / total_successes
          else:
             self.strategy_weights = np.ones_like(self.strategy_weights) / len(self.strategy_weights)

          self.strategy_weights = 0.9 * self.strategy_weights + 0.1 / len(self.strategy_weights)
          self.strategy_weights /= np.sum(self.strategy_weights) #Renormalizing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """Main optimization loop."""
        self.eval_count = 0
        self.initialize_population() # Initialize population before each optimization run
        self.evaluate_population(objective_function) #Evaluate initial population

        while self.eval_count < self.budget:
            self.evolve(objective_function)

            # Restart mechanism if no improvement for a while.
            if self.eval_count - self.last_improvement > self.restart_interval:
               self.initialize_population()
               self.evaluate_population(objective_function)
               self.last_improvement = self.eval_count #Reset last improvement.

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

### Worse code
AdaptiveMultimodalOptimizerImproved
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability









### Analyze & experience
- Comparing (AdaptiveGaussianArchiveEA - best) vs (CMAESResilientPopulation - worst), we see that the top performer utilizes an archive for diversity and adaptive Gaussian mutation, while the bottom uses CMA-ES principles. Increased archive size and faster sigma decay in the best-performing algorithm possibly improve exploration in complex landscapes. Initializing the population using the Latin Hypercube Sampling from CMAESResilientPopulation could be helpful for other algorithms, but they should not utilize a small value for covariance matrix.

(AdaptiveDifferentialEvolutionWithEnhancedInitialization - second best) vs (NovelGlobalScout - second worst): The second best uses DE with initialization near known optima. In contrast, NovelGlobalScout uses Cauchy mutation and a diversity-focused selection mechanism which does not perform better. EnhancedInitialization may cause local optimum early.

Comparing (AdaptiveGaussianArchiveEA - best) vs (AdaptiveDifferentialEvolutionWithEnhancedInitialization - second best), we see adaptive Gaussian sampling with archive guided by tournament selection is much better than Adaptive DE with enhanced initialization around optima.

Comparing (EnhancedArchiveGuidedDE, EnhancedArchiveGuidedDE) vs (AdaptiveGaussianSamplingEA, AdaptiveGaussianSamplingEA), we see the archive based guided DE is generally better.

Comparing (second worst) vs (worst), we see that cauchy mutation is not as good as Latin Hypercube Sampling (LHS) for initialization.

Overall: the best performing algorithms focus on diversity maintenance through archives and adaptive Gaussian sampling. DE with initialization near known optima can boost local search but may not work well on multi-modal problems. Cauchy mutation performs worse than LHS or gaussian recombination, indicating that GNBG problems might not like to move far away. Archive-guided algorithms perform strongly, showing memory matters. Adaptive parameter control and restarts seem beneficial but have less impact than other techniques.
- Okay, I understand. Let's refine self-reflection for designing better heuristics.

Here's a refined approach, designed to avoid ineffective elements and maximize heuristic improvement potential:

*   **Keywords:** Diversity maintenance, Landscape awareness, Parameter adaptation, Adaptive scaling, Exploration-Exploitation balance, Archive Utilization, Gaussian Processes

*   **Advice:** Explicitly analyze the problem landscape characteristics to inform the choice of search operators (GNBG, DE, etc.). Prioritize adaptive parameter control based on population fitness changes, focusing on convergence rate and diversity metrics. Employ Gaussian Sampling based on proven efficiency but adapt sigma for current location to balance exploration and exploitation.

*   **Avoid:** Blindly applying previously successful strategies without understanding the problem characteristics. Fixed parameters without proper adaptation. Sole reliance on exploration without convergence/exploitation considerations.

*   **Explanation:** Effective heuristics require constant recalibration based on the search process feedback and insights gained from landscape explorations. Focus on building adaptive systems that respond intelligently to the evolving search dynamics. This will make your algorithm adaptive to each instance.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 08:29:32 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    

Current heuristics:
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- Okay, I understand. Let's refine self-reflection for designing better heuristics.

Here's a refined approach, designed to avoid ineffective elements and maximize heuristic improvement potential:

*   **Keywords:** Diversity maintenance, Landscape awareness, Parameter adaptation, Adaptive scaling, Exploration-Exploitation balance, Archive Utilization, Gaussian Processes

*   **Advice:** Explicitly analyze the problem landscape characteristics to inform the choice of search operators (GNBG, DE, etc.). Prioritize adaptive parameter control based on population fitness changes, focusing on convergence rate and diversity metrics. Employ Gaussian Sampling based on proven efficiency but adapt sigma for current location to balance exploration and exploitation.

*   **Avoid:** Blindly applying previously successful strategies without understanding the problem characteristics. Fixed parameters without proper adaptation. Sole reliance on exploration without convergence/exploitation considerations.

*   **Explanation:** Effective heuristics require constant recalibration based on the search process feedback and insights gained from landscape explorations. Focus on building adaptive systems that respond intelligently to the evolving search dynamics. This will make your algorithm adaptive to each instance.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-24 08:42:35 INFO Perform Harmony Search...
2025-06-24 08:42:44 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:44 ERROR Can not run the algorithm
2025-06-24 08:42:44 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1449
2025-06-24 08:42:44 INFO FeHistory: [-183.30892613]
2025-06-24 08:42:44 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:44 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 153.30531226435824,
                 archive_size: int = 428.8608116813744,
                 initial_sigma_ratio: float = 0.4553080633838378,
                 sigma_decay: float = 0.9744505003793262,
                 tournament_size: int = 2.7806982567013954,
                 recombination_sigma_reduction: float = 0.40653379044655324,
                 archive_similarity_threshold: float = 5.1859071753765425e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:44 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:44 ERROR Can not run the algorithm
2025-06-24 08:42:45 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:45 INFO FeHistory: [585520.64175089]
2025-06-24 08:42:45 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:45 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:45 ERROR Can not run the algorithm
2025-06-24 08:42:45 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:45 INFO FeHistory: [102114.68281555]
2025-06-24 08:42:45 INFO Expected Optimum FE: -5000
2025-06-24 08:42:45 INFO Unimodal AOCC mean: 0.1449
2025-06-24 08:42:45 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:45 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:45 INFO AOCC mean: 0.0483
2025-06-24 08:42:45 INFO Weighed AOCC mean: 0.0145
2025-06-24 08:42:45 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:45 ERROR Can not run the algorithm
2025-06-24 08:42:45 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1464
2025-06-24 08:42:45 INFO FeHistory: [-183.42577495]
2025-06-24 08:42:45 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:45 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 71.81816475434309,
                 archive_size: int = 306.1061914322324,
                 initial_sigma_ratio: float = 0.14933361378546423,
                 sigma_decay: float = 0.9196096721753925,
                 tournament_size: int = 2.0397940457873274,
                 recombination_sigma_reduction: float = 0.13756873477979115,
                 archive_similarity_threshold: float = 3.6770688112972095e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:45 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:45 ERROR Can not run the algorithm
2025-06-24 08:42:45 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:45 INFO FeHistory: [1576757.16474506]
2025-06-24 08:42:45 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:45 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:45 ERROR Can not run the algorithm
2025-06-24 08:42:46 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:46 INFO FeHistory: [186433.62686293]
2025-06-24 08:42:46 INFO Expected Optimum FE: -5000
2025-06-24 08:42:46 INFO Unimodal AOCC mean: 0.1464
2025-06-24 08:42:46 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:46 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:46 INFO AOCC mean: 0.0488
2025-06-24 08:42:46 INFO Weighed AOCC mean: 0.0146
2025-06-24 08:42:46 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:46 ERROR Can not run the algorithm
2025-06-24 08:42:46 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1466
2025-06-24 08:42:46 INFO FeHistory: [-183.44749439]
2025-06-24 08:42:46 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:46 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 160.82942108524026,
                 archive_size: int = 181.01431056792072,
                 initial_sigma_ratio: float = 0.9474846461617654,
                 sigma_decay: float = 0.900699392102584,
                 tournament_size: int = 5.128890787271829,
                 recombination_sigma_reduction: float = 0.4116968688167033,
                 archive_similarity_threshold: float = 7.724992426931408e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:46 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:46 ERROR Can not run the algorithm
2025-06-24 08:42:46 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:46 INFO FeHistory: [1355581.30871646]
2025-06-24 08:42:46 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:46 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:46 ERROR Can not run the algorithm
2025-06-24 08:42:46 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:46 INFO FeHistory: [149748.07407519]
2025-06-24 08:42:46 INFO Expected Optimum FE: -5000
2025-06-24 08:42:46 INFO Unimodal AOCC mean: 0.1466
2025-06-24 08:42:46 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:46 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:46 INFO AOCC mean: 0.0489
2025-06-24 08:42:46 INFO Weighed AOCC mean: 0.0147
2025-06-24 08:42:46 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:46 ERROR Can not run the algorithm
2025-06-24 08:42:47 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1454
2025-06-24 08:42:47 INFO FeHistory: [-183.35133404]
2025-06-24 08:42:47 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:47 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 137.75252677495718,
                 archive_size: int = 280.82369086246706,
                 initial_sigma_ratio: float = 0.8018265408838139,
                 sigma_decay: float = 0.9724738083112511,
                 tournament_size: int = 3.8216087490815633,
                 recombination_sigma_reduction: float = 0.5425369884192359,
                 archive_similarity_threshold: float = 4.9700287492559986e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:47 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:47 ERROR Can not run the algorithm
2025-06-24 08:42:47 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:47 INFO FeHistory: [2976523.70065415]
2025-06-24 08:42:47 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:47 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:47 ERROR Can not run the algorithm
2025-06-24 08:42:47 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:47 INFO FeHistory: [169763.64769924]
2025-06-24 08:42:47 INFO Expected Optimum FE: -5000
2025-06-24 08:42:47 INFO Unimodal AOCC mean: 0.1454
2025-06-24 08:42:47 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:47 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:47 INFO AOCC mean: 0.0485
2025-06-24 08:42:47 INFO Weighed AOCC mean: 0.0145
2025-06-24 08:42:47 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:47 ERROR Can not run the algorithm
2025-06-24 08:42:47 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1450
2025-06-24 08:42:47 INFO FeHistory: [-183.31345614]
2025-06-24 08:42:47 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:47 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 129.77741256431432,
                 archive_size: int = 169.95613579057132,
                 initial_sigma_ratio: float = 0.32181227812681545,
                 sigma_decay: float = 0.9964064984929886,
                 tournament_size: int = 3.269445191628198,
                 recombination_sigma_reduction: float = 0.7412820774817207,
                 archive_similarity_threshold: float = 8.595289349731028e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:47 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:47 ERROR Can not run the algorithm
2025-06-24 08:42:48 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:48 INFO FeHistory: [1671529.53782661]
2025-06-24 08:42:48 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:48 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:48 ERROR Can not run the algorithm
2025-06-24 08:42:48 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:48 INFO FeHistory: [105451.29758457]
2025-06-24 08:42:48 INFO Expected Optimum FE: -5000
2025-06-24 08:42:48 INFO Unimodal AOCC mean: 0.1450
2025-06-24 08:42:48 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:48 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:48 INFO AOCC mean: 0.0483
2025-06-24 08:42:48 INFO Weighed AOCC mean: 0.0145
2025-06-24 08:42:48 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:48 ERROR Can not run the algorithm
2025-06-24 08:42:48 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1451
2025-06-24 08:42:48 INFO FeHistory: [-183.32759465]
2025-06-24 08:42:48 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:48 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 140.6840972385447,
                 archive_size: int = 145.76305501969725,
                 initial_sigma_ratio: float = 0.46606780685334803,
                 sigma_decay: float = 0.9196096721753925,
                 tournament_size: int = 3.269445191628198,
                 recombination_sigma_reduction: float = 0.17953270194282073,
                 archive_similarity_threshold: float = 1.874481171833801e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:48 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:48 ERROR Can not run the algorithm
2025-06-24 08:42:48 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:48 INFO FeHistory: [795903.4382385]
2025-06-24 08:42:48 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:48 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:48 ERROR Can not run the algorithm
2025-06-24 08:42:49 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:49 INFO FeHistory: [204868.08658911]
2025-06-24 08:42:49 INFO Expected Optimum FE: -5000
2025-06-24 08:42:49 INFO Unimodal AOCC mean: 0.1451
2025-06-24 08:42:49 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:49 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:49 INFO AOCC mean: 0.0484
2025-06-24 08:42:49 INFO Weighed AOCC mean: 0.0145
2025-06-24 08:42:49 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:49 ERROR Can not run the algorithm
2025-06-24 08:42:49 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1455
2025-06-24 08:42:49 INFO FeHistory: [-183.35501054]
2025-06-24 08:42:49 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:49 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 147.9240122330476,
                 archive_size: int = 183.3974337771112,
                 initial_sigma_ratio: float = 0.5894068693988681,
                 sigma_decay: float = 0.9033441604224083,
                 tournament_size: int = 1.9339636868342844,
                 recombination_sigma_reduction: float = 0.9474522770711478,
                 archive_similarity_threshold: float = 6.811897334253357e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:49 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:49 ERROR Can not run the algorithm
2025-06-24 08:42:49 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:49 INFO FeHistory: [1582964.15879237]
2025-06-24 08:42:49 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:49 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:49 ERROR Can not run the algorithm
2025-06-24 08:42:49 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:49 INFO FeHistory: [107238.0512769]
2025-06-24 08:42:49 INFO Expected Optimum FE: -5000
2025-06-24 08:42:49 INFO Unimodal AOCC mean: 0.1455
2025-06-24 08:42:49 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:49 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:49 INFO AOCC mean: 0.0485
2025-06-24 08:42:49 INFO Weighed AOCC mean: 0.0145
2025-06-24 08:42:49 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:49 ERROR Can not run the algorithm
2025-06-24 08:42:50 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1455
2025-06-24 08:42:50 INFO FeHistory: [-183.35480648]
2025-06-24 08:42:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:50 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 189.06383331647447,
                 archive_size: int = 262.915197538765,
                 initial_sigma_ratio: float = 0.9461148255231275,
                 sigma_decay: float = 0.9609566059284438,
                 tournament_size: int = 1.7409443196524839,
                 recombination_sigma_reduction: float = 0.13756873477979115,
                 archive_similarity_threshold: float = 6.811897334253357e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:50 ERROR Can not run the algorithm
2025-06-24 08:42:50 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:50 INFO FeHistory: [4431928.22351542]
2025-06-24 08:42:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:50 ERROR Can not run the algorithm
2025-06-24 08:42:50 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:50 INFO FeHistory: [112730.59034354]
2025-06-24 08:42:50 INFO Expected Optimum FE: -5000
2025-06-24 08:42:50 INFO Unimodal AOCC mean: 0.1455
2025-06-24 08:42:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:50 INFO AOCC mean: 0.0485
2025-06-24 08:42:50 INFO Weighed AOCC mean: 0.0145
2025-06-24 08:42:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:50 ERROR Can not run the algorithm
2025-06-24 08:42:50 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1452
2025-06-24 08:42:50 INFO FeHistory: [-183.33253287]
2025-06-24 08:42:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:50 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 179.62896697571654,
                 archive_size: int = 197.59283312728675,
                 initial_sigma_ratio: float = 0.01760210729141587,
                 sigma_decay: float = 0.9733035091136143,
                 tournament_size: int = 1.9339636868342844,
                 recombination_sigma_reduction: float = 0.9665315439029717,
                 archive_similarity_threshold: float = 9.503298545982462e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:50 ERROR Can not run the algorithm
2025-06-24 08:42:50 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:50 INFO FeHistory: [2128829.37204791]
2025-06-24 08:42:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:51 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:51 ERROR Can not run the algorithm
2025-06-24 08:42:51 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:51 INFO FeHistory: [108915.01811759]
2025-06-24 08:42:51 INFO Expected Optimum FE: -5000
2025-06-24 08:42:51 INFO Unimodal AOCC mean: 0.1452
2025-06-24 08:42:51 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:51 INFO AOCC mean: 0.0484
2025-06-24 08:42:51 INFO Weighed AOCC mean: 0.0145
2025-06-24 08:42:51 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 08:42:51 ERROR Can not run the algorithm
2025-06-24 08:42:51 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1445
2025-06-24 08:42:51 INFO FeHistory: [-183.27311145]
2025-06-24 08:42:51 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 08:42:51 INFO Good algorithm:
Algorithm Name: ImprovedAdaptiveGaussianArchiveEA
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 171.78827508829227,
                 archive_size: int = 219.35014922023876,
                 initial_sigma_ratio: float = 0.9474846461617654,
                 sigma_decay: float = 0.95101496774268,
                 tournament_size: int = 1.9339636868342844,
                 recombination_sigma_reduction: float = 0.6510083100153915,
                 archive_similarity_threshold: float = 4.998894405904347e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
2025-06-24 08:42:51 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 08:42:51 ERROR Can not run the algorithm
2025-06-24 08:42:51 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:51 INFO FeHistory: [1257346.99797066]
2025-06-24 08:42:51 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 08:42:51 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 08:42:51 ERROR Can not run the algorithm
2025-06-24 08:42:51 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-24 08:42:51 INFO FeHistory: [198472.47660648]
2025-06-24 08:42:51 INFO Expected Optimum FE: -5000
2025-06-24 08:42:51 INFO Unimodal AOCC mean: 0.1445
2025-06-24 08:42:51 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 08:42:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 08:42:51 INFO AOCC mean: 0.0482
2025-06-24 08:42:51 INFO Weighed AOCC mean: 0.0144
2025-06-24 08:42:51 INFO Generation 1, best so far: 0.5484245373695569
2025-06-24 08:42:51 INFO Population length is: 12
2025-06-24 08:42:51 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-24 08:42:51 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average weighted AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.6299e-02 |             AOCC Score on Unimodal instances: 1.6299e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveDE
# Description: Combines DE mutation with a Gaussian archive for exploration, adapting sigma and neighborhood size dynamically.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveGaussianArchiveDE
# Description: Combines DE mutation with a Gaussian archive for exploration, adapting sigma and neighborhood size dynamically.
# Code:
class AdaptiveGaussianArchiveDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 5 * self.dim
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))
        self.crossover_rate = 0.7
        self.mutation_rate_initial = 0.5
        self.mutation_rate_final = 0.05
        self.archive_size = min(2 * self.population_size, 500) # Cap archive size
        self.archive = [] # Archive of solutions, shape (archive_size, dim + 1) last element contains fitness
        self.sigma = 0.5 * (self.upper_bounds[0] - self.lower_bounds[0])
        self.sigma_decay = 0.99
        self.neighborhood_size = int(self.population_size * 0.2)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0

        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
            self.fitness = np.full(self.population_size, float('inf'))
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size
            self.fitness = fitness_values
            best_index = np.argmin(self.fitness)
            self.best_solution_overall = self.population[best_index].copy()
            self.best_fitness_overall = self.fitness[best_index]
            self.archive = self._update_archive(self.population, self.fitness)


        else:
            self.best_solution_overall = np.array([])
            self.best_fitness_overall = float('inf')

        generation = 0
        while self.eval_count < self.budget:
            generation += 1
            mutation_rate = self.mutation_rate_initial + (self.mutation_rate_final - self.mutation_rate_initial) * (self.eval_count / self.budget)

            old_best_fitness = self.best_fitness_overall

            for i in range(self.population_size):
                # DE Mutation with archive guidance.
                candidates_indices = random.sample(range(self.population_size), 3)
                a, b, c = self.population[candidates_indices[0]], self.population[candidates_indices[1]], self.population[candidates_indices[2]]

                # Gaussian Sampling from Archive - adapt sigma based on archive fitness variance.
                if len(self.archive) > 5: #Use archive if not empty
                   archive_fitness = self.archive[:, -1]
                   sigma_archive = np.std(archive_fitness)
                   random_archive_index = random.randint(0, len(self.archive)-1)
                   archive_vector = self.archive[random_archive_index, :-1]
                   gaussian_mutation = np.random.normal(archive_vector, self.sigma + sigma_archive)  # Gaussian sample based on archive fitness

                   #Mix the Gaussian Sample with standard DE Mutation

                   mutant = a + mutation_rate * (b-c)  + 0.1*(gaussian_mutation - a) #Added Gaussian Perturbation to the standard DE

                else: #if the Archive is empty do pure DE
                  mutant = a + mutation_rate * (b-c)

                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                crossover_mask = np.random.rand(self.dim) < self.crossover_rate
                trial_vector = np.where(crossover_mask, mutant, self.population[i])

                # Evaluate
                trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self.fitness[i]:
                    self.fitness[i] = trial_fitness
                    self.population[i] = trial_vector
                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial_vector.copy()

            self.archive = self._update_archive(self.population, self.fitness)

        
            # Adaptive Sigma, reduce exploration if we do not improve best fitnes value
            if generation % 10 == 0:
              if self.best_fitness_overall >= old_best_fitness:
                self.sigma *= 0.9
              else: # Expand sigma
                self.sigma = min(0.5*(self.upper_bounds[0]-self.lower_bounds[0]), self.sigma*1.1)
              

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
             'archive_size': len(self.archive),
             'sigma': self.sigma

        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive) if len(self.archive) > 0 else False
            if not already_present:
                new_archive.append(sol)

        if len(new_archive) > 0:
          if len(self.archive) > 0 :
            combined_archive = np.vstack((self.archive, np.array(new_archive)))
          else:
            combined_archive = np.array(new_archive)
        else:
          combined_archive = self.archive
          
        if len(combined_archive) > 0: # If it has some elements.

          sorted_archive = combined_archive[combined_archive[:, -1].argsort()] # Sort by fitness
          return sorted_archive[:self.archive_size]

        else: # Otherwise return an empty archive
          return np.array([])
```

### Rank 2 (Overall AOCC Score: 1.6257e-02 |             AOCC Score on Unimodal instances: 1.6257e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveDE
# Description: Combines adaptive Gaussian sampling, a diversity archive, and differential evolution for robust global search.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveGaussianArchiveDE
# Description: Combines adaptive Gaussian sampling, a diversity archive, and differential evolution for robust global search.
# Code:
class AdaptiveGaussianArchiveDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 3 * self.dim  # Keep population size dependent on dimension.
        self.archive_size = self.population_size  # Archive size. Increased archive size
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.archive = np.copy(self.population)
        self.archive_fitness = np.full(self.archive_size, float('inf'))

        # DE parameters, made adaptive based on previous design feedback
        self.F = 0.5  # Differential weight
        self.CR = 0.7  # Crossover rate
        self.sigma = 1.0 # Initial sigma for Gaussian Sampling
        self.sigma_decay = 0.995 # Decay the sigma so that smaller adaptive perturbation values are used in later iterations


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
             self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')

        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = self.population[best_index].copy()

        self.archive[:self.population_size] = np.copy(self.population)
        self.archive_fitness[:self.population_size] = np.copy(fitness)

        while self.eval_count < self.budget:
            new_population = np.zeros_like(self.population)

            for i in range(self.population_size):
                # Mutation
                indices = [j for j in range(self.population_size) if j != i]
                a, b, c = random.sample(indices, 3)

                #Adaptive gaussian perturbation
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c]) + np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                cross_points = np.random.rand(self.dim) < self.CR
                if not np.any(cross_points):
                    cross_points[random.randint(0, self.dim - 1)] = True

                trial = np.where(cross_points, mutant, self.population[i])
                new_population[i] = trial

            # Evaluation
            new_fitness = objective_function(new_population)
            self.eval_count += self.population_size

            # Selection and Archive Update
            for i in range(self.population_size):
                if new_fitness[i] < fitness[i]:
                    fitness[i] = new_fitness[i]
                    self.population[i] = new_population[i]

                # Tournament selection for archive update
                rand_index = random.randint(0, self.archive_size - 1)
                if new_fitness[i] < self.archive_fitness[rand_index]:
                    self.archive[rand_index] = np.copy(new_population[i])
                    self.archive_fitness[rand_index] = new_fitness[i]

            # Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = self.population[best_index].copy()

            self.sigma *= self.sigma_decay  #Decay gaussian scaling
            

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 3 (Overall AOCC Score: 1.6156e-02 |             AOCC Score on Unimodal instances: 1.6156e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveExplorationEA
# Description: Exploits adaptive step size control using fitness improvement rate and an archive to balance exploration and exploitation.
# Code:
```python
import numpy as np


# Name: AdaptiveExplorationEA
# Description: Exploits adaptive step size control using fitness improvement rate and an archive to balance exploration and exploitation.
# Code:
class AdaptiveExplorationEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.learning_rate = 0.1  # Learning rate for sigma adaptation
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)  # Initial step size
        self.archive = []
        self.fitness_history = []
        self.population = None
        self.fitness_values = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        self.population = self._initialize_population()
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(self.population, self.fitness_values)
        self.fitness_history.append(np.min(self.fitness_values))

        while self.eval_count < self.budget:
            parents = self._tournament_selection(self.population, self.fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.population, self.fitness_values = self._select_next_generation(
                self.population, self.fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((self.population, offspring)),
                np.concatenate((self.fitness_values, offspring_fitness))
            )
            self._update_best(offspring, offspring_fitness)
            self._adapt_sigma()
            self.fitness_history.append(np.min(self.fitness_values))

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _adapt_sigma(self):
        """
        Adapt the step size (sigma) based on the recent fitness improvement.
        If there's significant improvement, increase sigma to explore further.
        If improvement is stagnating, decrease sigma to exploit the current region.
        """
        if len(self.fitness_history) < 5:
            return  # Not enough data to adapt

        recent_fitness = self.fitness_history[-5:]
        improvement = recent_fitness[0] - recent_fitness[-1] # Compare the first fitness of the batch to the current best
        
        if improvement > 0:
            self.sigma *= (1 + self.learning_rate) # Increase step size
        else:
            self.sigma *= (1 - self.learning_rate) # Decrease step size
        
        self.sigma = np.clip(self.sigma, 0.01 * (self.upper_bounds - self.lower_bounds),
                              0.5 * (self.upper_bounds - self.lower_bounds)) # Avoid extremes

```

### Rank 4 (Overall AOCC Score: 1.5718e-02 |             AOCC Score on Unimodal instances: 1.5718e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianDEWithArchive
# Description: Combines adaptive Gaussian mutation with Differential Evolution, guided by an archive for diversity.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveGaussianDEWithArchive
# Description: Combines adaptive Gaussian mutation with Differential Evolution, guided by an archive for diversity.
# Code:
class AdaptiveGaussianDEWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # Common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

        self.F = 0.5       # Differential weight.
        self.CR = 0.7       # Crossover rate.
        self.sigma = 1.0 # Initial sigma for Gaussian mutation, adaptively scaled

        self.sigma_decay_rate = 0.995  # Decay rate for sigma, important for convergence

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = self.population[best_index]

                #Adapt the Gaussian Noise to best solution change rate.
                self.sigma *= self.sigma_decay_rate # global decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            # DE Mutation
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            # Gaussian perturbation to maintain diversity
            gaussian_noise = np.random.normal(0, self.sigma, self.dim)

            offspring[i] = mutant + gaussian_noise
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

            # Crossover: Trial vector generation
            cross_points = np.random.rand(self.dim) < self.CR
            if not np.any(cross_points):
                cross_points[random.randint(0, self.dim - 1)] = True

            offspring[i] = np.where(cross_points, offspring[i], population[i])
        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive (crowding distance or fitness proportionate selection can be used.)
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]: #or np.random.rand() < 0.1 : #with probablity to include different candidate

                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 5 (Overall AOCC Score: 1.5348e-02 |             AOCC Score on Unimodal instances: 1.5348e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianDifferentialEvolutionArchive
# Description: Combines DE mutation with adaptive Gaussian sampling and archive-based fitness sharing for global exploration.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveGaussianDifferentialEvolutionArchive
# Description: Combines DE mutation with adaptive Gaussian sampling and archive-based fitness sharing for global exploration.
# Code:
class AdaptiveGaussianDifferentialEvolutionArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8, archive_size_factor: float = 4, gaussian_sigma_scale: float = 0.1):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)
        self.archive_size = int(archive_size_factor * self.dim)
        self.archive = []  # List to store (solution, fitness) tuples
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness = np.full(self.population_size, float('inf'))
        self.mutation_factor = 0.5
        self.crossover_rate = 0.7
        self.gaussian_sigma_scale = gaussian_sigma_scale  # Scales the Gaussian noise
        self.fitness_history_length = 10
        self.fitness_history = np.full(self.fitness_history_length, float('inf'))

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.fitness = fitness

        best_index = np.argmin(fitness)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness[best_index]
        self.fitness_history = np.full(self.fitness_history_length, self.best_fitness_overall)

        while self.eval_count < self.budget:
            for i in range(self.population_size):
                mutant = self.create_mutant(i)
                trial = self.crossover(self.population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                self.select(trial, trial_fitness, i)
                self.update_archive(trial, trial_fitness)

            self.adapt_parameters()

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def create_mutant(self, index):
        """Combines DE mutation with Gaussian sampling."""
        # Differential Evolution Mutation
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index:
            a, b, c = random.sample(range(self.population_size), 3)
        mutant = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])

        # Gaussian Sampling around the mutant (landscape aware)
        sigma = self.gaussian_sigma_scale * (self.upper_bounds - self.lower_bounds)  #Dim-wise sigma

        gaussian_noise = np.random.normal(0, sigma, self.dim)
        mutant += gaussian_noise


        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return mutant

    def crossover(self, individual, mutant):
        """Binomial Crossover."""
        trial = individual.copy()
        for i in range(self.dim):
            if random.random() < self.crossover_rate or i == random.randint(0, self.dim - 1):
                trial[i] = mutant[i]
        return trial

    def select(self, trial, trial_fitness, index):
        """Selection and Fitness Sharing with Archive."""
        if trial_fitness < self.fitness[index]:
            self.fitness[index] = trial_fitness
            self.population[index] = trial
            if trial_fitness < self.best_fitness_overall:
                self.best_fitness_overall = trial_fitness
                self.best_solution_overall = trial.copy()

    def update_archive(self, solution, fitness):
        """Maintains a diverse archive."""
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            # Replace the worst with some probability
            worst_index = np.argmax([f for _, f in self.archive])
            if random.random() < 0.5 or fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def adapt_parameters(self):
        """Adapts mutation and crossover rates based on recent fitness history."""
        self.fitness_history = np.roll(self.fitness_history, 1)
        self.fitness_history[0] = self.best_fitness_overall
        fitness_change = np.abs(self.fitness_history[0] - self.fitness_history[-1])

        #If little change, increase exploration by boosting mutation
        if fitness_change < 1e-3:
            self.mutation_factor = min(1.0, self.mutation_factor * 1.1)
            self.crossover_rate = max(0.1, self.crossover_rate * 0.9) # Also reduce crossover to let bigger jumps occur
        else:
            self.mutation_factor = max(0.1, self.mutation_factor * 0.9)  # Reduce to exploit if improving
            self.crossover_rate = min(0.9, self.crossover_rate * 1.1)
```

### Rank 6 (Overall AOCC Score: 1.5165e-02 |             AOCC Score on Unimodal instances: 1.5165e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchivalAdaptiveGaussianDifferentialEvolution
# Description: Integrates archive-guided DE with adaptive Gaussian mutation for enhanced diversity and exploitation.
# Code:
```python
import numpy as np
import random

# Name: ArchivalAdaptiveGaussianDifferentialEvolution
# Description: Integrates archive-guided DE with adaptive Gaussian mutation for enhanced diversity and exploitation.
# Code:
class ArchivalAdaptiveGaussianDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        """
        Initializes the ArchivalAdaptiveGaussianDifferentialEvolution optimizer.

        Args:
            budget (int): The maximum number of function evaluations.
            dim (int): The dimensionality of the problem.
            lower_bounds (list[float]): A list of lower bounds for each dimension.
            upper_bounds (list[float]): A list of upper bounds for each dimension.
        """
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        # DE parameters
        self.pop_size = 10 * self.dim
        self.mutation_factor = 0.5  # Initial mutation factor, adaptively tuned
        self.crossover_rate = 0.7 # Crossover rate, not tuned directly, but influenced via archive
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.pop_size, self.dim))
        self.fitness = np.full(self.pop_size, float('inf'))

        # Archive for storing diverse solutions
        self.archive = []
        self.archive_size = self.pop_size
        self.archive_fitness = [] # Store fitnesses for archive members

        # Adaptive Gaussian parameters
        self.sigma = 0.1 * (self.upper_bounds - self.lower_bounds)  # Initial sigma, element-wise
        self.sigma_decay = 0.995
        self.sigma_min = 0.0001 * (self.upper_bounds - self.lower_bounds)
        self.gaussian_prob = 0.1  # Probability of applying Gaussian mutation

        self.improvement_threshold = 1e-6 # Threshold of improvement before adpative updates

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        """
        Optimizes the given objective function using Archival Adaptive Gaussian Differential Evolution.

        Args:
            objective_function (callable): The objective function to minimize.
            acceptance_threshold (float): The acceptance threshold.

        Returns:
            tuple: A tuple containing the best solution, its fitness, and optimization information.
        """

        self.eval_count = 0
        self.initialize_population()
        self.evaluate_population(objective_function)

        while self.eval_count < self.budget:
            self.evolve(objective_function)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def initialize_population(self):
         """Initializes the population randomly within the bounds."""
         self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.pop_size, self.dim))
         self.fitness = np.full(self.pop_size, float('inf'))


    def evaluate_population(self, objective_function: callable):
        """Evaluates the fitness of the entire population."""
        fitness_values = objective_function(self.population)
        self.eval_count += self.pop_size
        self.fitness = fitness_values

        # Update best solution
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = self.fitness[best_index]
            self.best_solution_overall = self.population[best_index].copy()


    def evolve(self, objective_function: callable):
        """Performs one generation of the evolutionary process."""
        for i in range(self.pop_size):
            # Mutation (DE with archive and Gaussian component)
            mutant = self.mutate(i)

            # Crossover
            trial_vector = self.crossover(i, mutant)

            # Repair bounds
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            # Evaluation
            trial_fitness = objective_function(trial_vector.reshape(1, -1))[0]
            self.eval_count += 1

            # Selection
            if trial_fitness < self.fitness[i]:
                # Add replaced solution to archive
                if len(self.archive) < self.archive_size:
                    self.archive.append(self.population[i].copy())
                    self.archive_fitness.append(self.fitness[i])  # Store fitness of archived solution
                else:
                    # Replace worst solution in archive
                    worst_archive_index = np.argmax(self.archive_fitness)
                    if self.fitness[i] < self.archive_fitness[worst_archive_index]:
                        self.archive[worst_archive_index] = self.population[i].copy()
                        self.archive_fitness[worst_archive_index] = self.fitness[i]

                # Replace current individual
                self.population[i] = trial_vector
                self.fitness[i] = trial_fitness

                # Update best solution
                if trial_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = trial_fitness
                    self.best_solution_overall = trial_vector.copy()


            # Adaptive sigma decay.
            if trial_fitness < self.fitness[i] - self.improvement_threshold :
                self.sigma = np.maximum(self.sigma * self.sigma_decay, self.sigma_min) # Element-wise decay


    def mutate(self, i: int) -> np.ndarray:
        """Generates a mutant vector using DE with archive guidance and Gaussian mutation."""
        # DE mutation with archive
        if len(self.archive) > 0:
            # Choose random individuals from population and archive
            indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)
            x_r1 = self.population[indices[0]] if indices[0] < self.pop_size else self.archive[indices[0] - self.pop_size]
            x_r2 = self.population[indices[1]] if indices[1] < self.pop_size else self.archive[indices[1] - self.pop_size]
            x_r3 = self.population[indices[2]] if indices[2] < self.pop_size else self.archive[indices[2] - self.pop_size]
        else:
            # If archive is empty, use standard DE mutation
            indices = np.random.choice(self.pop_size, 3, replace=False)
            while i in indices:
                 indices = np.random.choice(self.pop_size, 3, replace=False)
            x_r1, x_r2, x_r3 = self.population[indices]

        mutant = self.population[i] + self.mutation_factor * (x_r2 - x_r3)

        # Gaussian mutation
        if random.random() < self.gaussian_prob:
            mutant += np.random.normal(0, self.sigma) # Apply element-wise

        return mutant

    def crossover(self, i: int, mutant: np.ndarray) -> np.ndarray:
        """Performs crossover between the current individual and the mutant."""
        crossover_mask = np.random.rand(self.dim) < self.crossover_rate
        trial_vector = np.where(crossover_mask, mutant, self.population[i])
        return trial_vector
```

### Rank 7 (Overall AOCC Score: 1.4881e-02 |             AOCC Score on Unimodal instances: 1.4881e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDispersalArchiveEA
# Description: This algorithm employs an adaptive dispersal mechanism based on population diversity, coupled with an archive, to aggressively explore and exploit multimodal landscapes, escaping local optima and maintaining solution diversity.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDispersalArchiveEA
# Description: This algorithm employs an adaptive dispersal mechanism based on population diversity, coupled with an archive, to aggressively explore and exploit multimodal landscapes, escaping local optima and maintaining solution diversity.
# Code:
class AdaptiveDispersalArchiveEA:
    """
    An evolutionary algorithm that uses an archive to maintain diversity and an adaptive dispersal mechanism
    to escape local optima, balancing exploration and exploitation effectively.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.range = self.upper_bounds - self.lower_bounds

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.1 * self.range  # Initial sigma scaled to the range
        self.sigma_decay = 0.99 # Slightly slower decay
        self.archive = []
        self.population = None  # To store the current population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0

        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        self.population = self._initialize_population()  # Moved population initialization here
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(self.population, fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Dispersal Mechanism
            if self._needs_dispersal(fitness_values):
                self.population = self._dispersal(self.population)
                fitness_values = objective_function(self.population)
                self.eval_count += self.population_size
                self.archive = self._update_archive(self.population, fitness_values)  # Update archive immediately after dispersal

            parents = self._tournament_selection(self.population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.population, fitness_values = self._select_next_generation(
                self.population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((self.population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        #Latin Hypercube Sampling for Improved Initial Coverage
        population = np.zeros((self.population_size, self.dim))
        for i in range(self.dim):
            population[:, i] = np.random.uniform(low=self.lower_bounds[i], high=self.upper_bounds[i], size=self.population_size)
            indices = np.arange(self.population_size)
            np.random.shuffle(indices)
            population[:, i] = population[indices, i] #Shuffle so that one point in the hypercube per dimension
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        # Retain potentially better solutions and reduce redundant ones
        archive_subset = []
        for new_solution in new_archive:
            is_dominated = False
            for arch_solution in self.archive:
                if new_solution[-1] > arch_solution[-1] and np.all(new_solution[:-1] >= arch_solution[:-1]):
                     is_dominated = True
                     break
            if not is_dominated:
              archive_subset.append(new_solution)

        self.archive.extend(archive_subset)

        self.archive.sort(key=lambda x: x[-1])  # Sorted by fitness

        self.archive = np.array(self.archive[:self.archive_size]) # Keep top

        return self.archive

    def _needs_dispersal(self, fitness_values):
        # Check for premature convergence using fitness variance
        fitness_std = np.std(fitness_values)
        if fitness_std < 1e-4 :  #Dynamic thresholding (adjusted to problem scale
            return True #Trigger Dispersal

        #Diversity Check, check crowding distance between particles
        distances = []
        for i in range(self.population_size):
            dist = 0
            for j in range(i+1, self.population_size):
                 dist += np.linalg.norm(self.population[i] - self.population[j])
            distances.append(dist)
        average_distance = np.mean(distances)

        if average_distance < 0.0001:
            return True
        return False

    def _dispersal(self, population):
        #Adaptive Dispersal
        center = np.mean(population, axis=0)
        dispersal_factor = 2 # More Aggressive dispersal for quicker escapes
        new_population = np.random.uniform(low=self.lower_bounds, high=self.upper_bounds, size=population.shape) # Re initialize around bounds
        for i in range(self.population_size):
                direction = population[i] - center # Direction away from cluster
                magnitude = np.linalg.norm(direction) #Magnitude of direction
                new_location = population[i] + dispersal_factor*direction/magnitude # New Location
                new_location = np.clip(new_location, self.lower_bounds, self.upper_bounds)
                new_population[i] = new_location

        return new_population
```

### Rank 8 (Overall AOCC Score: 1.4707e-02 |             AOCC Score on Unimodal instances: 1.4707e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCovarianceArchiveEA
# Description: Employs an adaptive covariance matrix, an archive with a dynamic radius and restart mechanism for enhanced exploration and exploitation in difficult multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveCovarianceArchiveEA
# Description: Employs an adaptive covariance matrix, an archive with a dynamic radius and restart mechanism for enhanced exploration and exploitation in difficult multimodal landscapes.

class AdaptiveCovarianceArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.bounds_range = self.upper_bounds - self.lower_bounds

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 50  # Reduced for faster iteration
        self.archive_size = 100    # Adjusted size

        self.mean = 0.5 * (self.lower_bounds + self.upper_bounds)
        self.covariance = np.diag(0.1 * self.bounds_range**2) # Smaller initial covariance
        self.learning_rate = 0.1 # Adaptive learning rate
        self.mutation_rate = 0.05 # Probability of perturbing individuals

        self.archive = []
        self.archive_radius = 0.1 * np.linalg.norm(self.bounds_range)  #Dynamic radius
        self.restart_trigger = 500 # Number of iterations before potential restart
        self.stagnation_counter = 0


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_best(population, fitness_values)

        self.archive = self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._recombination(parents)
            offspring = self._mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_best(offspring, offspring_fitness)

            population, fitness_values = self._selection(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            # Adaptive covariance adjustment based on success
            self._adapt_covariance(population, fitness_values)

            # Dynamic Radius Decay
            #self.archive_radius *= 0.995
            #Adaptive Stagnation/Restart Mechanism
            if np.std(fitness_values) < acceptance_threshold:
                 self.stagnation_counter +=1
            else:
                 self.stagnation_counter = 0

            if self.stagnation_counter > self.restart_trigger:
                 self._restart_population()
                 self.stagnation_counter = 0




        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):

        population = np.random.multivariate_normal(self.mean, self.covariance, self.population_size)
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 3
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            alpha = np.random.rand(self.dim) # Uniform blending
            child1 = alpha * parent1 + (1 - alpha) * parent2
            child2 = (1 - alpha) * parent1 + alpha * parent2

            offspring.extend([child1, child2]) # Adding both children

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _mutation(self, offspring):
        mutated = offspring.copy() # Deep copy
        for i in range(len(mutated)):
            if random.random() < self.mutation_rate:  # Apply mutation based on mutation rate
                mutation_vector = np.random.normal(0, 0.1 * self.bounds_range, self.dim)
                mutated[i] += mutation_vector

        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
         archive_limit = self.archive_size * 2 # Check individuals against a larger subset to increase diversity.
         combined = np.column_stack((population, fitness_values))
         np.random.shuffle(combined) # Shuffle for greater randomness in sampling.
         candidates = combined[:archive_limit]

         for candidate in candidates:
               sol = candidate[:-1]
               fitness = candidate[-1]
               is_duplicate = False
               for arch_sol in self.archive:
                 if np.allclose(sol, arch_sol[:-1], atol=1e-06):
                    is_duplicate = True
                    break
               if not is_duplicate: # Ensure candidate is not already in the archive.
                self.archive.append(candidate) # Add the entire combined solution
                self.archive.sort(key=lambda x: x[-1])

         return np.array(self.archive[:self.archive_size]) # Truncate to archive size

    def _adapt_covariance(self, population, fitness_values):
        #Select top 50%
        num_elites = len(population) // 2
        elites = population[np.argsort(fitness_values)[:num_elites]]

        #Recalculate
        new_mean = np.mean(elites, axis=0)
        #Add damping term to covariance
        new_covariance = np.cov(elites, rowvar=False) + np.eye(self.dim) * 1e-6

        #Leaky integration
        self.mean = (1 - self.learning_rate) * self.mean + self.learning_rate * new_mean
        self.covariance = (1- self.learning_rate) * self.covariance + self.learning_rate * new_covariance

    def _restart_population(self):
         #Option to either use only the archive or the entire bounds
         if len(self.archive) > self.population_size:
           archive_solutions = self.archive[:, :-1] # Archive minus the fitness values

           indices = np.random.choice(len(archive_solutions), self.population_size, replace = False)
           self.population = archive_solutions[indices]

         else:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size = (self.population_size, self.dim)) #Full Population Restart

         self.mean = np.mean(self.population, axis = 0) #Reset the parameters.
         self.covariance = np.diag(0.1 * self.bounds_range**2)
```

### Rank 9 (Overall AOCC Score: 1.4664e-02 |             AOCC Score on Unimodal instances: 1.4664e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ImprovedAdaptiveGaussianArchiveEA
# Description: 
# Code:
```python
import numpy as np
class ImprovedAdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 160.82942108524026,
                 archive_size: int = 181.01431056792072,
                 initial_sigma_ratio: float = 0.9474846461617654,
                 sigma_decay: float = 0.900699392102584,
                 tournament_size: int = 5.128890787271829,
                 recombination_sigma_reduction: float = 0.4116968688167033,
                 archive_similarity_threshold: float = 7.724992426931408e-05):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size  #Increased archive size for better diversity
        self.sigma = initial_sigma_ratio * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = sigma_decay # Slightly faster decay
        self.archive = []
        self.tournament_size = tournament_size
        self.recombination_sigma_reduction = recombination_sigma_reduction
        self.archive_similarity_threshold = archive_similarity_threshold

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma * self.recombination_sigma_reduction, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=self.archive_similarity_threshold) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 10 (Overall AOCC Score: 1.4658e-02 |             AOCC Score on Unimodal instances: 1.4658e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AMPArchiveEnhancedEA
# Description: Employs Adaptive Mutation Probabilities and an enhanced Archive strategy to dynamically balance exploration and exploitation in complex multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AMPArchiveEnhancedEA
# Description: Employs Adaptive Mutation Probabilities and an enhanced Archive strategy to dynamically balance exploration and exploitation in complex multimodal landscapes.
# Code:
class AMPArchiveEnhancedEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.3 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []
        self.mutation_probability = 0.1
        self.mutation_probability_decay = 0.995

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay
            self.mutation_probability *= self.mutation_probability_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
       mutated_offspring = []
       for individual in offspring:
           if random.random() < self.mutation_probability:
               # Apply mutation
               mutation = np.random.normal(0, self.sigma, size=self.dim)
               mutated_individual = individual + mutation
               mutated_offspring.append(np.clip(mutated_individual, self.lower_bounds, self.upper_bounds))
           else:
               mutated_offspring.append(individual)
       return np.array(mutated_offspring)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        
        # Keep best and most diverse
        num_to_select = min(self.archive_size, len(new_archive))
        
        if num_to_select==0 and len(self.archive)>0: return np.array(self.archive[:self.archive_size])

        if num_to_select > 0 :
          best_from_new = new_archive[:num_to_select//2]

          if len(self.archive) > 0:
              archive_pop_only = np.array([x[:-1] for x in self.archive])
              new_archive_pop_only = np.array([x[:-1] for x in new_archive])
              
              from scipy.spatial import distance_matrix
              dm = distance_matrix(new_archive_pop_only, archive_pop_only)
              min_distances = np.min(dm, axis=1)
              diversity_indices = np.argsort(min_distances)[::-1]
              diverse_from_new = [new_archive[i] for i in diversity_indices[:num_to_select - len(best_from_new)]]
          else: 
              diverse_from_new = [] if num_to_select - len(best_from_new)<=0 else new_archive[num_to_select - len(best_from_new)]

          final_archive = best_from_new + diverse_from_new
          final_archive.sort(key=lambda x: x[-1])
          return np.array(final_archive[:self.archive_size])

        return np.array(self.archive[:self.archive_size])
```

### Rank 11 (Overall AOCC Score: 1.4638e-02 |             AOCC Score on Unimodal instances: 1.4638e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: GaussianAdaptiveArchiveEvolution
# Description: Adaptive Gaussian mutation with an archive and landscape-aware sigma scaling for enhanced exploration and exploitation.
# Code:
```python
import numpy as np

# Name: GaussianAdaptiveArchiveEvolution
# Description: Adaptive Gaussian mutation with an archive and landscape-aware sigma scaling for enhanced exploration and exploitation.
# Code:
class GaussianAdaptiveArchiveEvolution:
    """
    Adaptive Gaussian mutation with an archive and landscape-aware sigma scaling.
    Employs an archive for diversity, adapts sigma based on fitness variance, and uses tournament selection.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.98
        self.sigma_min = 0.01 * (self.upper_bounds[0] - self.lower_bounds[0])  # Min sigma to maintain exploration
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        generation = 0
        while self.eval_count < self.budget:
            # Landscape-aware sigma adjustment
            fitness_std = np.std(fitness_values)
            if fitness_std < acceptance_threshold:  # Population converging
                self.sigma *= 1.1  # Increase exploration
            else:
                self.sigma *= self.sigma_decay
            self.sigma = max(self.sigma, self.sigma_min) # Ensure minimal exploration

            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 08:42:57 INFO Full response text: **Analysis:**
Comparing AdaptiveGaussianArchiveDE (Rank 1) vs AMPArchiveEnhancedEA (Rank 10), we see AdaptiveGaussianArchiveDE (Rank 1) incorporates a Gaussian archive into the DE mutation process and adapts sigma dynamically based on archive fitness variance, which aids exploration. Conversely, AMPArchiveEnhancedEA (Rank 10) focuses on adapting mutation probabilities. AdaptiveGaussianArchiveDE updates the archive by keeping better archive fitness where AMPArchiveEnhancedEA (Rank 10) keep a balance between quality and diverse candidates by shortest distance.

Comparing AdaptiveGaussianArchiveDE (Rank 2) vs AMPArchiveEnhancedEA (Rank 10), AdaptiveGaussianArchiveDE adapt initial parameter and sigma for diversity differently, it includes tournament selection which is missing from AMPArchiveEnhancedEA (Rank 10).

Comparing AdaptiveExplorationEA (Rank 3) vs AdaptiveCovarianceArchiveEA (Rank 8),AdaptiveExplorationEA adapt the improvement fitness rate to control exploration where AdaptiveCovarianceArchiveEA adaptive covariance adjustment based on success. Also AdaptiveCovarianceArchiveEA contains a restart mechanism not available in AdaptiveExplorationEA. Also AdaptiveExplorationEA adapt mutation as np.random.normal(0, self.sigma, size=offspring.shape) against to AdaptiveCovarianceArchiveEA gaussian sampling with self.covariance as the parameter.

Comparing AdaptiveGaussianDEWithArchive (Rank 4) vs ImprovedAdaptiveGaussianArchiveEA (Rank 9), AdaptiveGaussianDEWithArchive implements diversity using a probability threshold. Meanwhile, ImprovedAdaptiveGaussianArchiveEA adapt different parameters and update weights. It also implements tournament selection in its processing.

Comparing AdaptiveGaussianArchiveDE (Rank 1) vs AdaptiveGaussianArchiveDE (Rank 2) which includes adaptive Gaussian sampling, a diversity archive, and differential evolution. The population size in (Rank 2) is based dimension against to Rank (1) static one.

Comparing ArchivalAdaptiveGaussianDifferentialEvolution (Rank 6) vs AdaptiveDispersalArchiveEA (Rank 7), we can see that (Rank 7) contains LH initial sample for the population, also adaptive dispersal is incorporated in addition to diversity for population quality. Additionally, Archive in (Rank 7) takes in subset after filtering for domination.

Overall: Key successful strategies involve adapting mutation parameters (sigma, probability), using archives to maintain population diversity and guide search, and integrating mechanisms to escape local optima (e.g., restarts, adaptive dispersal). Adaptations according to success are better than static configuration.

**Experience:**
Adaptive parameter control significantly improves evolutionary algorithm performance. Hybrid approaches that combine multiple exploration strategies (DE mutation, Gaussian sampling, archives) often outperform simpler methods. The population should be initialized well to improve population quality (LH sampling).

2025-06-24 08:43:00 INFO Full response text: Okay, I understand. We need to craft a *useful* form of self-reflection to generate actionable insights for designing better heuristics for evolutionary algorithms (EAs), specifically avoiding the pitfalls demonstrated in the "Ineffective self-reflection" example. This means moving beyond simply listing observed successes and failures. Instead, we need to analyze *why* certain approaches worked and translate that understanding into design principles. Let's break it down:

**Here's my response, aiming to maximize actionability and minimize vague observations:**

*   **Keywords:** Landscape characterization, exploitation/exploration balance, parameter sensitivity analysis, problem-specific heuristic tailoring.

*   **Advice:** Focus on understanding *why* a heuristic works (or doesn't) in the context of the problem's landscape. Use exploratory data analysis to map out characteristics like multimodality, separability, and ruggedness. Analyze parameter sensitivity to understand how heuristic performance changes across various problem instances. Strive to design heuristics that adapt their behavior based on problem characteristics. Look for patterns in which heuristics work best on certain types of problems.

*   **Avoid:** Simply stating "X performs well" without providing a rationale. Vague generalizations (e.g., "archives are crucial for diversity"). Listing parameters that "should be incorporated" without addressing *how* to incorporate them effectively or the conditions under which they should be used. Presenting findings without quantifying the evidence supporting them.

*   **Explanation:** The "Ineffective self-reflection" example is flawed because it focuses on surface-level observations rather than causal relationships. The advice above advocates for deeper investigation into the interplay between the heuristic's behavior, problem features, and the resulting performance. Heuristics should be designed through an iterative problem characterization, sensitivity analysis, hypothesis generation, and validation loop.

This approach shifts the focus to problem-centric heuristic design rather than blindly adopting successful methods, leading to truly better heuristics tailored to specific problem types. Let me know if you want to dive deeper into specific areas!

2025-06-24 08:43:00 INFO Generating offspring via Crossover...
