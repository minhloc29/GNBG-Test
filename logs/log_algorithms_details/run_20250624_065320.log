2025-06-24 06:53:21 INFO Initializing first population
2025-06-24 06:53:21 INFO Initializing population from 9 seed files...
2025-06-24 07:05:51 INFO Started evolutionary loop, best so far: 0.14616794743172618
2025-06-24 07:05:51 INFO Population length is: 20
2025-06-24 07:05:51 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-24 07:05:51 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average weighted AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.4617e-01 |             AOCC Score on Unimodal instances: 1.7933e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 1.8319e-01)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score: 1.9979e-02 |             AOCC Score on Unimodal instances: 1.9979e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 3 (Overall AOCC Score: 1.8605e-02 |             AOCC Score on Unimodal instances: 1.8605e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 4 (Overall AOCC Score: 1.8022e-02 |             AOCC Score on Unimodal instances: 1.8022e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 5 (Overall AOCC Score: 1.7920e-02 |             AOCC Score on Unimodal instances: 1.7920e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random

class EnhancedArchiveGuidedDE: #aocc 0.15
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale  # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 6 (Overall AOCC Score: 1.7728e-02 |             AOCC Score on Unimodal instances: 1.7728e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 7 (Overall AOCC Score: 1.7574e-02 |             AOCC Score on Unimodal instances: 1.7574e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 8 (Overall AOCC Score: 1.6744e-02 |             AOCC Score on Unimodal instances: 1.6744e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 9 (Overall AOCC Score: 1.6623e-02 |             AOCC Score on Unimodal instances: 1.6623e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 10 (Overall AOCC Score: 1.6122e-02 |             AOCC Score on Unimodal instances: 1.6122e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm using adaptive mutation and population diversification to escape local optima in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100 # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_rate = 0.1  # Initial mutation rate
        self.mutation_decay = 0.99 # Decay factor for mutation rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        self.fitness_values = np.full(self.population_size, float('inf'))

        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        while self.eval_count < self.budget:
            self.fitness_values = objective_function(self.population)
            self.eval_count += self.population_size

            for i, fitness in enumerate(self.fitness_values):
                if fitness < self.best_fitness_overall:
                    self.best_fitness_overall = fitness
                    self.best_solution_overall = self.population[i]

            # Selection (tournament selection)
            parents = self.tournament_selection(self.fitness_values, self.population_size//2)

            # Recombination (uniform crossover)
            offspring = self.uniform_crossover(parents)

            # Mutation (adaptive)
            offspring = self.adaptive_mutation(offspring)

            #Population Diversification (adding random solutions to avoid premature convergence)
            num_diverse = int(0.1 * self.population_size) #10% diverse solutions
            diverse_solutions = np.random.uniform(self.lower_bounds, self.upper_bounds, (num_diverse, self.dim))
            self.population = np.vstack((parents, offspring, diverse_solutions))
            self.mutation_rate *= self.mutation_decay

        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'mutation_rate_final': self.mutation_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, num_parents):
        parents = []
        for _ in range(num_parents):
            competitors = random.sample(range(len(fitnesses)), 5) #Tournament size 5
            winner = min(competitors, key=lambda i: fitnesses[i])
            parents.append(self.population[winner])
        return np.array(parents)

    def uniform_crossover(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = np.where(np.random.rand(self.dim) < 0.5, parent1, parent2)
            child2 = np.where(np.random.rand(self.dim) < 0.5, parent2, parent1)
            offspring.extend([child1, child2])
        return np.array(offspring)

    def adaptive_mutation(self, offspring):
        for i in range(len(offspring)):
            for j in range(self.dim):
                if np.random.rand() < self.mutation_rate:
                    offspring[i, j] += np.random.normal(0, (self.upper_bounds[j] - self.lower_bounds[j]) * 0.05) #Adaptive step size
                    offspring[i, j] = np.clip(offspring[i, j], self.lower_bounds[j], self.upper_bounds[j])
        return offspring
```

### Rank 11 (Overall AOCC Score: 1.5659e-02 |             AOCC Score on Unimodal instances: 1.5659e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A Differential Evolution algorithm enhanced with adaptive mutation and clustering to escape local optima and improve exploration in multimodal landscapes.
# Code:
```python
import numpy as np
from sklearn.cluster import KMeans

class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.F = 0.8 # Differential weight (can be adapted)
        self.CR = 0.9 # Crossover rate (can be adapted)
        self.cluster_count = 5 # Number of clusters for analysis

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        generation = 0
        while self.eval_count < self.budget:
            generation += 1
            offspring = []
            offspring_fitness = []
            
            for i in range(self.population_size):
                # Differential Evolution mutation
                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)
                while a == i or b == i or c == i:  # Ensure different individuals
                    a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)

                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Adaptive Mutation: Adjust F based on success rate
                
                # Boundary handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)


                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])

                offspring.append(trial)


            offspring = np.array(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))
            
            sorted_indices = np.argsort(combined_fitness)
            self.population = combined_population[sorted_indices[:self.population_size]]
            fitness_values = combined_fitness[sorted_indices[:self.population_size]]
            

            #Clustering Analysis (Adaptive Strategy)
            if generation % 10 == 0: #check clustering every 10 generations. Adjust as needed
                kmeans = KMeans(n_clusters=self.cluster_count, random_state=0).fit(self.population)
                cluster_centers = kmeans.cluster_centers_
                
                if np.min(objective_function(cluster_centers)) < self.best_fitness_overall:
                   self.best_solution_overall = cluster_centers[np.argmin(objective_function(cluster_centers))]
                   self.best_fitness_overall = np.min(objective_function(cluster_centers))
                   
            
            self.best_solution_overall = self.population[np.argmin(fitness_values)]
            self.best_fitness_overall = np.min(fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'generations': generation
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 12 (Overall AOCC Score: 1.5311e-02 |             AOCC Score on Unimodal instances: 1.5311e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with a niching strategy and adaptive mutation to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100 # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_rate = 0.5 # Initial mutation rate
        self.niche_radius = 10.0 # Initial niche radius

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, self.fitness_values)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.population, self.fitness_values = self._selection(self.population, self.fitness_values, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, self.fitness_values)

            # Adaptive mechanisms
            self._adapt_mutation_rate()
            self._adapt_niche_radius()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_parents(3)
            mutant = self._mutate(a, b, c)
            offspring.append(mutant)
        return np.array(offspring)


    def _select_parents(self, num_parents):
        return random.sample(range(self.population_size), num_parents)

    def _mutate(self, a, b, c):
        mutant = self.population[a] + self.mutation_rate * (self.population[b] - self.population[c])
        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return mutant

    def _selection(self, population, fitnesses, offspring, offspring_fitnesses):
        combined_population = np.vstack((population, offspring))
        combined_fitnesses = np.concatenate((fitnesses, offspring_fitnesses))
        
        #Niching
        selected_population = []
        selected_fitnesses = []
        
        while len(selected_population) < self.population_size:
            best_index = np.argmin(combined_fitnesses)
            best_solution = combined_population[best_index]
            best_fitness = combined_fitnesses[best_index]

            is_unique = True
            for sol in selected_population:
                if np.linalg.norm(best_solution - sol) < self.niche_radius:
                    is_unique = False
                    break

            if is_unique:
                selected_population.append(best_solution)
                selected_fitnesses.append(best_fitness)

            combined_population = np.delete(combined_population, best_index, 0)
            combined_fitnesses = np.delete(combined_fitnesses, best_index)


        return np.array(selected_population), np.array(selected_fitnesses)

    def _update_best(self, population, fitnesses):
        best_index = np.argmin(fitnesses)
        best_solution = population[best_index]
        best_fitness = fitnesses[best_index]
        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution
        return best_solution, best_fitness


    def _adapt_mutation_rate(self):
        # Simple adaptation: reduce mutation rate if many evaluations without improvement
        if self.eval_count > 1000 and self.best_fitness_overall == float('inf'):
            self.mutation_rate *= 0.9 # reduce


    def _adapt_niche_radius(self):
        # Adjust niche radius based on exploration/exploitation balance
        # (More sophisticated adaptation could be implemented here)
        if self.eval_count > self.budget/2:
            self.niche_radius *= 0.8 # Reduce radius in later stages to focus exploitation
```

### Rank 13 (Overall AOCC Score: 1.5240e-02 |             AOCC Score on Unimodal instances: 1.5240e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a niching strategy and adaptive mutation to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Differential Evolution crossover rate
        self.niche_radius = 0.5 # Initial niche radius, adaptive later.
        self.mutation_rate = 0.1 # Initial mutation rate.

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)

        while self.eval_count < self.budget:
            # Differential Evolution
            offspring = np.zeros_like(self.population)
            for i in range(self.population_size):
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Bound checking

                trial = np.zeros_like(self.population[i])
                for j in range(self.dim):
                    if random.random() < self.CR:
                        trial[j] = mutant[j]
                    else:
                        trial[j] = self.population[i][j]
                offspring[i] = trial


            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Selection
            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness_values[i]:
                    self.population[i] = offspring[i]
                    self.fitness_values[i] = offspring_fitness[i]

            # Adaptive Niching and Mutation
            self.update_niche_and_mutation()

            # Update best solution
            best_index = np.argmin(self.fitness_values)
            if self.fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness_values[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def update_niche_and_mutation(self):
        #Simple niching: reduce niche radius if many solutions are close, increase mutation rate
        distances = np.linalg.norm(self.population[:, np.newaxis, :] - self.population[np.newaxis, :, :], axis=2)
        close_pairs = np.sum(distances < self.niche_radius)

        if close_pairs > 0.8 * self.population_size * (self.population_size-1) / 2: # Many close solutions
            self.niche_radius *= 0.9
            self.mutation_rate *= 1.1 # Increase exploration
        else:
            self.niche_radius *= 1.1
            self.mutation_rate *= 0.9 # Reduce exploration



```

### Rank 14 (Overall AOCC Score: 1.5237e-02 |             AOCC Score on Unimodal instances: 1.5237e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with adaptive mutation and a local search to effectively tackle multimodal landscapes.
# Code:
```python
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with adaptive mutation and a local search to effectively tackle multimodal landscapes.

import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.adaptation_rate = 0.1 #Rate of adapting mutation strength
        self.local_search_radius = 0.1 # parameter controlling local search intensity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        self.fitness_values = np.full(self.population_size, float('inf'))


        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


        #Initial Fitness Evaluation
        for i in range(self.population_size):
          self.fitness_values[i] = objective_function(self.population[i].reshape(1,-1))[0]
          self.eval_count += 1
          if self.fitness_values[i] < self.best_fitness_overall:
              self.best_fitness_overall = self.fitness_values[i]
              self.best_solution_overall = np.copy(self.population[i])


        mutation_strength = 1.0 # Initialize mutation strength

        while self.eval_count < self.budget:
            new_population = np.zeros_like(self.population)
            for i in range(self.population_size):
                #Differential Evolution Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                #Clamp to bounds
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])


                #Adaptive Mutation
                trial += np.random.normal(0, mutation_strength, self.dim) #Add gaussian noise
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                #Evaluation and Selection
                fitness_trial = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if fitness_trial < self.fitness_values[i]:
                    new_population[i] = trial
                    self.fitness_values[i] = fitness_trial
                    if fitness_trial < self.best_fitness_overall:
                        self.best_fitness_overall = fitness_trial
                        self.best_solution_overall = np.copy(trial)
                else:
                    new_population[i] = self.population[i]

            self.population = new_population

            #Local Search (periodically)
            if self.eval_count % (self.budget // 10) == 0:
                self.local_search(objective_function)

            #Adaptive Mutation Strength Adjustment
            mutation_strength *= (1 - self.adaptation_rate) + self.adaptation_rate * np.random.rand()



        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def local_search(self, objective_function):
        neighbor = self.best_solution_overall + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        fitness_neighbor = objective_function(neighbor.reshape(1, -1))[0]
        self.eval_count += 1
        if fitness_neighbor < self.best_fitness_overall:
            self.best_fitness_overall = fitness_neighbor
            self.best_solution_overall = np.copy(neighbor)

```

### Rank 15 (Overall AOCC Score: 1.5190e-02 |             AOCC Score on Unimodal instances: 1.5190e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with a local search and adaptive mutation to escape local optima and explore diverse multimodal landscapes efficiently.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Differential Evolution crossover rate
        self.mutation_rate = 0.1 # Initial mutation rate. This will be adapted.

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]


        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Boundary handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.copy(self.population[i])
                crossover_points = np.random.rand(self.dim) < self.CR
                trial[crossover_points] = mutant[crossover_points]

                # Adaptive Mutation to escape local optima (more likely when stuck)
                if self.eval_count > self.budget * 0.5: #increase mutation after half the budget
                    if random.random() < self.mutation_rate:
                        mutation_index = np.random.randint(0, self.dim)
                        trial[mutation_index] = np.random.uniform(self.lower_bounds[mutation_index], self.upper_bounds[mutation_index])


                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = trial_fitness
                        self.best_solution_overall = trial.copy()
                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)

            #Adapt Mutation Rate based on progress (very basic adaptation for example)
            if self.eval_count > self.budget * 0.7 and self.best_fitness_overall > acceptance_threshold:
              if self.best_fitness_overall < 0.9 * self.best_fitness_overall:
                  self.mutation_rate *=1.2
              else:
                  self.mutation_rate *= 0.8
                  self.mutation_rate = max(0.01, self.mutation_rate) #clamp mutation to avoid 0


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 16 (Overall AOCC Score: 1.4761e-02 |             AOCC Score on Unimodal instances: 1.4761e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with a Levy flight mutation strategy for enhanced exploration of multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8 # Differential evolution scaling factor
        self.CR = 0.9 # Differential evolution crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]


        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Levy Flight Mutation for Exploration (with probability 0.1)
                if random.random() < 0.1:
                    levy_step = self.levy_flight(self.dim)
                    mutant = mutant + levy_step

                # Crossover
                trial = np.zeros(self.dim)
                for j in range(self.dim):
                    if random.random() < self.CR:
                        trial[j] = mutant[j]
                    else:
                        trial[j] = self.population[i][j]

                #Boundary Handling
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
                
                trial_fitness = objective_function(trial.reshape(1,-1))
                self.eval_count += 1
                
                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness[0]
                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial.copy()
                        self.best_fitness_overall = trial_fitness[0]
                else:
                    new_population.append(self.population[i])


            self.population = np.array(new_population)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
    
    def levy_flight(self, dim):
        beta = 3/2
        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1/beta)
        u = np.random.normal(0, 1, dim)
        v = np.random.normal(0, 1, dim)
        step = u / (np.abs(v)**(1/beta))
        return step


```

### Rank 17 (Overall AOCC Score: 1.4739e-02 |             AOCC Score on Unimodal instances: 1.4739e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with adaptive mutation and a niching strategy for efficient multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.niche_radius = 0.1 * (np.max(self.upper_bounds) - np.min(self.lower_bounds)) #Initial niche radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)


        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.selection(offspring, offspring_fitness)
            self.adapt_parameters()
            self.niche_radius *= 0.99  # Gradually reduce niche radius

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

            # Bound handling
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            for j in range(self.dim):
                if random.random() < self.CR:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = self.population[i, j]

        return offspring


    def selection(self, offspring, offspring_fitness):
        combined_population = np.concatenate((self.population, offspring))
        combined_fitness = np.concatenate((self.fitness_values, offspring_fitness))

        # Niching: Select diverse solutions
        selected_indices = []
        for i in range(self.population_size):
            best_index = np.argmin(combined_fitness)
            selected_indices.append(best_index)
            combined_fitness[best_index] = np.inf
            # Remove solutions in the niche of the selected solution
            for j in range(len(combined_fitness)):
                if combined_fitness[j] != np.inf and np.linalg.norm(combined_population[best_index] - combined_population[j]) < self.niche_radius:
                    combined_fitness[j] = np.inf


        self.population = combined_population[selected_indices]
        self.fitness_values = combined_fitness[selected_indices]
        
        if np.min(self.fitness_values) < self.best_fitness_overall:
            self.best_fitness_overall = np.min(self.fitness_values)
            self.best_solution_overall = self.population[np.argmin(self.fitness_values)]

    def adapt_parameters(self):
        #Simple adaptive strategy: Reduce F and increase CR if convergence is slow.
        if self.eval_count > self.budget * 0.5 and self.best_fitness_overall > 1e-2: #Adjust threshold as needed
            self.F *= 0.95
            self.CR *= 1.05

            self.F = max(0.2, self.F) #Keep F within reasonable bounds
            self.CR = min(0.99, self.CR)
```

### Rank 18 (Overall AOCC Score: 1.4689e-02 |             AOCC Score on Unimodal instances: 1.4689e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a Levy flight mutation strategy for escaping local optima and adaptive weighting to prioritize difficult multi-component problems.
# Code:
```python
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a Levy flight mutation strategy for escaping local optima and adaptive weighting to prioritize difficult multi-component problems.

import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])

        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index]
        self.best_fitness_overall = fitness_values[best_index]


        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Levy Flight Mutation for exploration
                if random.random() < 0.1:  # Probability of Levy flight
                    levy_step = self._levy_flight(self.dim)
                    mutant += levy_step

                # Boundary handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])

                # Evaluation
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                
                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial
                        self.best_fitness_overall = trial_fitness
                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _levy_flight(self, dim):
        # Levy flight using Mantegna's algorithm
        beta = 1.5
        sigma_u = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)
        sigma_v = 1
        u = np.random.normal(0, sigma_u, dim)
        v = np.random.normal(0, sigma_v, dim)
        step = u / (np.abs(v)**(1 / beta))
        return step * 0.01  # Scale the step to avoid overly large jumps

```

### Rank 19 (Overall AOCC Score: 1.4683e-02 |             AOCC Score on Unimodal instances: 1.4683e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalExploration
# Description: A hybrid evolutionary algorithm combining Differential Evolution with adaptive mutation and a niching strategy for efficient multimodal exploration.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalExploration:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.niche_radius = 0.1 * (self.upper_bounds[0] - self.lower_bounds[0]) # Initial niche radius. Adaptive later
        self.niches = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
        self.best_fitness_overall = np.min(self.fitness_values)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Selection with niching:
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((self.fitness_values, offspring_fitness))

            # Simple niching: only add if it's not too close to an existing niche
            new_niches = []
            for i in range(len(combined_population)):
                too_close = False
                for j in range(len(self.niches)):
                    if np.linalg.norm(combined_population[i] - self.niches[j][0]) < self.niche_radius:
                        too_close = True
                        break
                if not too_close:
                    new_niches.append( (combined_population[i], combined_fitness[i]) )
            
            #Adaptive Niche Radius
            if len(new_niches) > 0 :
                self.niche_radius = 0.5 * self.niche_radius + 0.5 * np.mean([np.linalg.norm(x[0]-y[0]) for x in new_niches for y in new_niches if np.any(x != y)])
            self.niches.extend(new_niches)

            #Keep best solutions, update population
            sorted_niches = sorted(self.niches, key=lambda x: x[1])
            self.niches = sorted_niches[:self.population_size]
            self.population = np.array([x[0] for x in self.niches])
            self.fitness_values = np.array([x[1] for x in self.niches])

            self.best_solution_overall = self.population[np.argmin(self.fitness_values)]
            self.best_fitness_overall = np.min(self.fitness_values)



        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'niches_found': len(self.niches)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            v = self.population[a] + self.F * (self.population[b] - self.population[c])
            for j in range(self.dim):
                if random.random() < self.CR:
                    offspring[i, j] = v[j]
                else:
                    offspring[i, j] = self.population[i, j]
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Bounds handling

        return offspring

```

### Rank 20 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: UnnamedAlgorithm
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive mutation and a niching strategy for multimodal optimization.
# Code:
```python
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive mutation and a niching strategy for multimodal optimization.
# Code:
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 07:05:58 INFO Full response text: **Analysis:**

Comparing `EnhancedArchiveGuidedDE` (Rank 1) vs `AdaptiveMultimodalOptimizer` (Rank 10), we see that incorporating an archive significantly improves performance, particularly on multi-component problems.  `EnhancedArchiveGuidedDE` leverages past successful solutions, guiding the search towards promising regions, unlike `AdaptiveMultimodalOptimizer`, which lacks this mechanism.

`(second best)` `AdaptiveDifferentialEvolutionWithEnhancedInitialization` (Rank 2) vs `AdaptiveGaussianSamplingEA` (Rank 4): The enhanced initialization of Rank 2 near known optima gives it an advantage over Rank 4 in unimodal landscapes, which lacks this targeted initialization. The local search further boosts performance in unimodal cases.

Comparing `EnhancedArchiveGuidedDE` (Rank 1) vs `AdaptiveDifferentialEvolutionWithEnhancedInitialization` (Rank 2), we observe that the archive mechanism in Rank 1 is more robust across all problem types than the local search of Rank 2, which is highly specialized to unimodal problems.

`AdaptiveGaussianSamplingEAwithArchive` (Rank 3) vs `AdaptiveGaussianSamplingEA` (Rank 4): The addition of an archive in Rank 3 helps to retain diversity and prevents premature convergence, leading to better exploration and therefore slightly improved performance compared to Rank 4.

Comparing `AdaptiveMultimodalOptimizerImproved` (Rank 8) vs `AdaptiveGaussianMutationDE` (Rank 9), we see that a tabu list and simulated annealing in Rank 8 improve exploration, whereas Rank 9 focuses solely on differential evolution and Gaussian mutation.  Rank 8s strategy prevents revisiting explored regions, leading to a slightly better outcome.

Comparing `AdaptiveDifferentialEvolutionWithClustering` (Rank 11) vs `AdaptiveMultimodalOptimizer` (Rank 12): The clustering strategy in Rank 11 helps identify promising regions in the search space, but this does not significantly improve the performance compared to the simpler niching technique and adaptive mutation of Rank 12.

Overall: The heuristics that maintain an archive of solutions and incorporate adaptive strategies for mutation or scaling factors generally perform better.  Simple adaptations and mechanisms such as incorporating a tabu list and local search offer advantages for unimodal problems but fail to generalize well to multimodal problems.

**Experience:**

Effective heuristics for high-dimensional multimodal optimization need sophisticated exploration and exploitation mechanisms.  Maintaining diversity and selectively focusing on promising regions by using archives and adaptive parameter tuning seems crucial for general performance across different problem landscapes.  Combining multiple techniques like DE, Gaussian sampling, and niching strategies is likely more effective than relying on a single approach.

2025-06-24 07:06:00 INFO Full response text: * **Keywords:**  High-dimensional, multimodal, exploration-exploitation, diversity, adaptation, archive, niching, hybrid methods.

* **Advice:** Focus on designing hybrid algorithms combining strengths of diverse optimization techniques (e.g., DE, Gaussian processes, simulated annealing).  Emphasize adaptive mechanisms that dynamically adjust exploration/exploitation balance based on search progress.  Rigorous testing on diverse benchmark problems is crucial.

* **Avoid:**  Overly simplistic heuristics; relying on a single optimization method;  lack of adaptive parameter tuning; neglecting diversity maintenance; insufficient testing.

* **Explanation:**  High-dimensional multimodal problems require sophisticated strategies to balance exploration (finding new areas) and exploitation (refining promising regions).  A hybrid approach, dynamically adapting to the problem landscape, and maintaining solution diversity are key to success.  Thorough testing ensures robustness.

2025-06-24 07:06:00 INFO Generating offspring via Crossover...
2025-06-24 07:27:57 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    

### Better code
AdaptiveGaussianMutationDE
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

### Worse code
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

### Analyze & experience
- Comparing `EnhancedArchiveGuidedDE` (Rank 1) vs `AdaptiveMultimodalOptimizer` (Rank 10), we see that incorporating an archive significantly improves performance, particularly on multi-component problems.  `EnhancedArchiveGuidedDE` leverages past successful solutions, guiding the search towards promising regions, unlike `AdaptiveMultimodalOptimizer`, which lacks this mechanism.

`(second best)` `AdaptiveDifferentialEvolutionWithEnhancedInitialization` (Rank 2) vs `AdaptiveGaussianSamplingEA` (Rank 4): The enhanced initialization of Rank 2 near known optima gives it an advantage over Rank 4 in unimodal landscapes, which lacks this targeted initialization. The local search further boosts performance in unimodal cases.

Comparing `EnhancedArchiveGuidedDE` (Rank 1) vs `AdaptiveDifferentialEvolutionWithEnhancedInitialization` (Rank 2), we observe that the archive mechanism in Rank 1 is more robust across all problem types than the local search of Rank 2, which is highly specialized to unimodal problems.

`AdaptiveGaussianSamplingEAwithArchive` (Rank 3) vs `AdaptiveGaussianSamplingEA` (Rank 4): The addition of an archive in Rank 3 helps to retain diversity and prevents premature convergence, leading to better exploration and therefore slightly improved performance compared to Rank 4.

Comparing `AdaptiveMultimodalOptimizerImproved` (Rank 8) vs `AdaptiveGaussianMutationDE` (Rank 9), we see that a tabu list and simulated annealing in Rank 8 improve exploration, whereas Rank 9 focuses solely on differential evolution and Gaussian mutation.  Rank 8s strategy prevents revisiting explored regions, leading to a slightly better outcome.

Comparing `AdaptiveDifferentialEvolutionWithClustering` (Rank 11) vs `AdaptiveMultimodalOptimizer` (Rank 12): The clustering strategy in Rank 11 helps identify promising regions in the search space, but this does not significantly improve the performance compared to the simpler niching technique and adaptive mutation of Rank 12.

Overall: The heuristics that maintain an archive of solutions and incorporate adaptive strategies for mutation or scaling factors generally perform better.  Simple adaptations and mechanisms such as incorporating a tabu list and local search offer advantages for unimodal problems but fail to generalize well to multimodal problems.
- * **Keywords:**  High-dimensional, multimodal, exploration-exploitation, diversity, adaptation, archive, niching, hybrid methods.

* **Advice:** Focus on designing hybrid algorithms combining strengths of diverse optimization techniques (e.g., DE, Gaussian processes, simulated annealing).  Emphasize adaptive mechanisms that dynamically adjust exploration/exploitation balance based on search progress.  Rigorous testing on diverse benchmark problems is crucial.

* **Avoid:**  Overly simplistic heuristics; relying on a single optimization method;  lack of adaptive parameter tuning; neglecting diversity maintenance; insufficient testing.

* **Explanation:**  High-dimensional multimodal problems require sophisticated strategies to balance exploration (finding new areas) and exploitation (refining promising regions).  A hybrid approach, dynamically adapting to the problem landscape, and maintaining solution diversity are key to success.  Thorough testing ensures robustness.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 07:27:57 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  High-dimensional, multimodal, exploration-exploitation, diversity, adaptation, archive, niching, hybrid methods.

* **Advice:** Focus on designing hybrid algorithms combining strengths of diverse optimization techniques (e.g., DE, Gaussian processes, simulated annealing).  Emphasize adaptive mechanisms that dynamically adjust exploration/exploitation balance based on search progress.  Rigorous testing on diverse benchmark problems is crucial.

* **Avoid:**  Overly simplistic heuristics; relying on a single optimization method;  lack of adaptive parameter tuning; neglecting diversity maintenance; insufficient testing.

* **Explanation:**  High-dimensional multimodal problems require sophisticated strategies to balance exploration (finding new areas) and exploitation (refining promising regions).  A hybrid approach, dynamically adapting to the problem landscape, and maintaining solution diversity are key to success.  Thorough testing ensures robustness.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-24 07:31:10 INFO Perform Harmony Search...
2025-06-24 07:31:20 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:31:29 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1529
2025-06-24 07:31:29 INFO FeHistory: [-183.37076715 -183.35353397 -183.40805637 ... -184.02779642 -183.96979812
 -183.95140796]
2025-06-24 07:31:29 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:31:29 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 95.4528959434633, archive_size: int = 490.10875251093415, initial_F_scale: float = 0.33556332754176355):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:31:29 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:31:38 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:31:38 INFO FeHistory: [1374437.2517515  1204455.32269462  800266.48310319 ... 1607024.28092777
 1596935.3583436   558567.37779481]
2025-06-24 07:31:38 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:31:38 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:32:04 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:32:04 INFO FeHistory: [138081.7212598  171880.09857673 249853.78056426 ...  22316.41367781
  30863.17376094  26540.42994185]
2025-06-24 07:32:04 INFO Expected Optimum FE: -5000
2025-06-24 07:32:04 INFO Unimodal AOCC mean: 0.1529
2025-06-24 07:32:04 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:32:04 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:32:04 INFO AOCC mean: 0.0510
2025-06-24 07:32:04 INFO Weighed AOCC mean: 0.0153
2025-06-24 07:32:04 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:32:12 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1546
2025-06-24 07:32:12 INFO FeHistory: [-183.30877325 -183.30803179 -183.28602586 ... -184.198474   -184.21847937
 -184.206128  ]
2025-06-24 07:32:12 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:32:12 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 50.670758576139875, archive_size: int = 213.7627648117131, initial_F_scale: float = 0.18898442035664353):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:32:12 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:32:20 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:32:20 INFO FeHistory: [3075851.90165587 1410917.6265548  1070362.87173317 ... 1801780.79583969
  639334.55897573  802669.98237915]
2025-06-24 07:32:20 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:32:20 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:32:45 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:32:45 INFO FeHistory: [172930.70092056 179455.32556905  64084.98551773 ...  -1103.40456823
   1829.64908354  -2357.15299383]
2025-06-24 07:32:45 INFO Expected Optimum FE: -5000
2025-06-24 07:32:45 INFO Unimodal AOCC mean: 0.1546
2025-06-24 07:32:45 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:32:45 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:32:45 INFO AOCC mean: 0.0515
2025-06-24 07:32:45 INFO Weighed AOCC mean: 0.0155
2025-06-24 07:32:45 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:32:55 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1537
2025-06-24 07:32:55 INFO FeHistory: [-183.3604335  -183.32001121 -183.30800502 ... -184.01193326 -184.0775958
 -184.07257425]
2025-06-24 07:32:55 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:32:55 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 61.01151511839553, archive_size: int = 576.9770959672314, initial_F_scale: float = 0.2831256941894712):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:32:55 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:33:05 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:33:05 INFO FeHistory: [1512359.30112262 1210680.83590442 1550383.56446402 ...  823911.12140637
  424584.38248526 1740595.55290246]
2025-06-24 07:33:05 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:33:05 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:33:31 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:33:31 INFO FeHistory: [217423.39868579 182548.37858259 172953.43063694 ...   2362.55760376
   4714.477182     1565.71748577]
2025-06-24 07:33:31 INFO Expected Optimum FE: -5000
2025-06-24 07:33:31 INFO Unimodal AOCC mean: 0.1537
2025-06-24 07:33:31 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:33:31 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:33:31 INFO AOCC mean: 0.0512
2025-06-24 07:33:31 INFO Weighed AOCC mean: 0.0154
2025-06-24 07:33:31 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:33:41 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1603
2025-06-24 07:33:41 INFO FeHistory: [-183.31615628 -183.41400854 -183.31226348 ... -184.74056825 -184.73797772
 -184.75798829]
2025-06-24 07:33:41 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:33:41 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 15.175621645376637, archive_size: int = 699.1954153101478, initial_F_scale: float = 0.6296290777317092):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:33:41 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:33:51 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:33:51 INFO FeHistory: [1718281.79393526 2290603.27101032 1159720.5152642  ...  324853.04399349
  220480.90656542  817099.24854535]
2025-06-24 07:33:51 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:33:51 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:34:19 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:34:19 INFO FeHistory: [170553.9564996  114103.17602708 202054.47294833 ...  -4350.54600275
  -4418.02484936  -4421.47441437]
2025-06-24 07:34:19 INFO Expected Optimum FE: -5000
2025-06-24 07:34:19 INFO Unimodal AOCC mean: 0.1603
2025-06-24 07:34:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:34:19 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:34:19 INFO AOCC mean: 0.0534
2025-06-24 07:34:19 INFO Weighed AOCC mean: 0.0160
2025-06-24 07:34:19 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:34:29 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1521
2025-06-24 07:34:29 INFO FeHistory: [-183.398888   -183.30170493 -183.31632372 ... -183.88645576 -183.85279578
 -183.90515441]
2025-06-24 07:34:29 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:34:29 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 79.9307040001833, archive_size: int = 887.1562632549774, initial_F_scale: float = 0.6785639466856551):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:34:29 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:34:40 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:34:40 INFO FeHistory: [1560655.12856696 2442128.51435116 1159901.0296234  ...  338416.74392101
 1035299.00835853 2670256.79925764]
2025-06-24 07:34:40 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:34:40 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:35:08 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:35:08 INFO FeHistory: [161947.64515081 202298.03084932 142273.77493778 ...  23465.55790012
  49545.40827074  17430.1087151 ]
2025-06-24 07:35:08 INFO Expected Optimum FE: -5000
2025-06-24 07:35:08 INFO Unimodal AOCC mean: 0.1521
2025-06-24 07:35:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:35:08 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:35:08 INFO AOCC mean: 0.0507
2025-06-24 07:35:08 INFO Weighed AOCC mean: 0.0152
2025-06-24 07:35:08 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:35:17 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1542
2025-06-24 07:35:17 INFO FeHistory: [-183.36750897 -183.34485755 -183.33257747 ... -184.20153713 -184.13623628
 -184.03811173]
2025-06-24 07:35:17 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:35:17 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 55.99885515122248, archive_size: int = 321.88017175830987, initial_F_scale: float = 0.6296290777317092):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:35:17 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:35:26 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:35:26 INFO FeHistory: [1347892.94573844 1500129.56831519 2507805.7141673  ... 1595298.7764024
  828063.17287148 1118323.92952411]
2025-06-24 07:35:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:35:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:35:52 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:35:52 INFO FeHistory: [186951.93563861 166459.5628909  211211.70936787 ...   6529.68609911
   5692.58620991   4775.2490928 ]
2025-06-24 07:35:52 INFO Expected Optimum FE: -5000
2025-06-24 07:35:52 INFO Unimodal AOCC mean: 0.1542
2025-06-24 07:35:52 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:35:52 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:35:52 INFO AOCC mean: 0.0514
2025-06-24 07:35:52 INFO Weighed AOCC mean: 0.0154
2025-06-24 07:35:52 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:36:01 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1569
2025-06-24 07:36:01 INFO FeHistory: [-183.38822849 -183.29202345 -183.32588879 ... -184.48180669 -184.44113027
 -184.53531564]
2025-06-24 07:36:01 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:36:01 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 35.64595192994583, archive_size: int = 412.6244628184969, initial_F_scale: float = 0.13178264343444202):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:36:01 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:36:11 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:36:11 INFO FeHistory: [ 847308.13157815 1179782.80288258  960441.5978575  ... 3150126.15929815
  694149.82363772 2012998.40229744]
2025-06-24 07:36:11 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:36:11 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:36:37 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:36:37 INFO FeHistory: [164454.3032696  146372.93345553 127495.78143156 ...  -3103.25280998
  -3728.64297005  -3228.65403954]
2025-06-24 07:36:37 INFO Expected Optimum FE: -5000
2025-06-24 07:36:37 INFO Unimodal AOCC mean: 0.1569
2025-06-24 07:36:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:36:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:36:37 INFO AOCC mean: 0.0523
2025-06-24 07:36:37 INFO Weighed AOCC mean: 0.0157
2025-06-24 07:36:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:36:48 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1577
2025-06-24 07:36:48 INFO FeHistory: [-183.32633672 -183.35144069 -183.34399206 ... -184.59874483 -184.58989804
 -184.59469504]
2025-06-24 07:36:48 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:36:48 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 24.764051902421482, archive_size: int = 921.5716077437673, initial_F_scale: float = 0.6296290777317092):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:36:48 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:36:59 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:36:59 INFO FeHistory: [ 339309.09893317 1461255.90825695 2665238.26948312 ...  258146.17159394
 1184471.09599052  947673.13104777]
2025-06-24 07:36:59 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:36:59 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:37:28 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:37:28 INFO FeHistory: [127581.75407725 123518.84708954 114529.84389501 ...  -1280.96788953
   -641.98116819  -1672.92128911]
2025-06-24 07:37:28 INFO Expected Optimum FE: -5000
2025-06-24 07:37:28 INFO Unimodal AOCC mean: 0.1577
2025-06-24 07:37:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:37:28 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:37:28 INFO AOCC mean: 0.0526
2025-06-24 07:37:28 INFO Weighed AOCC mean: 0.0158
2025-06-24 07:37:28 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:37:39 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1558
2025-06-24 07:37:39 INFO FeHistory: [-183.35819938 -183.30996305 -183.34864758 ... -184.41959022 -184.43878598
 -184.41189497]
2025-06-24 07:37:39 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:37:39 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 40.012299192826795, archive_size: int = 598.4747867664576, initial_F_scale: float = 0.36342253364923527):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:37:39 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:37:49 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:37:49 INFO FeHistory: [2023652.61870533 1174750.16923821 2230823.05127396 ... 1131483.59615646
  567573.53916093 1013653.35523981]
2025-06-24 07:37:49 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:37:49 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:38:16 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:38:16 INFO FeHistory: [ 97068.65781596 126630.03319043 189977.00812929 ...   4868.05928008
   2056.33766508   2456.43307201]
2025-06-24 07:38:16 INFO Expected Optimum FE: -5000
2025-06-24 07:38:16 INFO Unimodal AOCC mean: 0.1558
2025-06-24 07:38:16 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:38:16 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:38:16 INFO AOCC mean: 0.0519
2025-06-24 07:38:16 INFO Weighed AOCC mean: 0.0156
2025-06-24 07:38:16 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:38:25 INFO Run function 6 complete. FEHistory len: 100000, AOCC: 0.1538
2025-06-24 07:38:25 INFO FeHistory: [-183.2879211  -183.31366792 -183.37718846 ... -184.14162381 -184.20125065
 -184.17337846]
2025-06-24 07:38:25 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:38:25 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 52.55604482638023, archive_size: int = 525.8796543739448, initial_F_scale: float = 0.6296290777317092):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:38:25 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:38:35 INFO Run function 13 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:38:35 INFO FeHistory: [3832702.56798755  628315.48444257 1954208.39668404 ...  541059.00108629
  733022.82190232  366758.96333742]
2025-06-24 07:38:35 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:38:35 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:39:01 INFO Run function 18 complete. FEHistory len: 100000, AOCC: 0.0000
2025-06-24 07:39:01 INFO FeHistory: [177763.76917612 134970.88953588 167758.15513141 ...   3191.31703127
   7392.6417548    4194.66142022]
2025-06-24 07:39:01 INFO Expected Optimum FE: -5000
2025-06-24 07:39:01 INFO Unimodal AOCC mean: 0.1538
2025-06-24 07:39:01 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:39:01 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:39:01 INFO AOCC mean: 0.0513
2025-06-24 07:39:01 INFO Weighed AOCC mean: 0.0154
2025-06-24 07:39:01 INFO Generation 1, best so far: 0.14616794743172618
2025-06-24 07:39:01 INFO Population length is: 12
2025-06-24 07:39:01 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-24 07:39:01 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average weighted AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.6026e-02 |             AOCC Score on Unimodal instances: 1.6026e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_multiplier: float = 15.175621645376637, archive_size: int = 699.1954153101478, initial_F_scale: float = 0.6296290777317092):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_multiplier * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation:float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 2 (Overall AOCC Score: 1.5792e-02 |             AOCC Score on Unimodal instances: 1.5792e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE algorithm using an archive to enhance exploration and adaptive mutation for exploitation.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE algorithm using an archive to enhance exploration and adaptive mutation for exploitation.

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution (DE) with an archive and adaptive mutation 
    to efficiently explore and exploit multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.8  # Differential weight (adaptive)
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(np.vstack((population, offspring)), 
                                                np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different_individuals(population, i)
            mutant = a + self.F * (b - c)
            offspring[i] = self._crossover(population[i], mutant)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_different_individuals(self, population, i):
        indices = list(range(self.population_size))
        indices.remove(i)
        a, b, c = random.sample(indices, 3)
        return population[a], population[b], population[c]

    def _crossover(self, x, v):
        jrand = random.randint(0, self.dim - 1)
        y = np.copy(x)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive)[:self.archive_size]

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptive scheme: Reduce F if convergence is detected
        avg_fitness_diff = np.mean(np.diff(np.sort(fitness_values)))
        if avg_fitness_diff < 0.1: # Adjust threshold as needed
            self.F *= 0.95
```

### Rank 3 (Overall AOCC Score: 1.5269e-02 |             AOCC Score on Unimodal instances: 1.5269e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE with an archive to enhance exploration and adaptive mutation for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE with an archive to enhance exploration and adaptive mutation for multimodal optimization.
# Code:

class ArchiveGuidedAdaptiveDE:
    """
    Combines adaptive Differential Evolution (DE) with an archive to enhance exploration and exploitation in multimodal landscapes.  
    Uses an adaptive mutation strategy and tournament selection for efficiency.  The archive helps maintain diversity and guides exploration towards promising areas.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Mutation
            a, b, c = self._select_mutants(i, len(population))
            mutant = population[a] + self.F * (population[b] - population[c])

            # Crossover
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
            offspring.append(trial)

        return np.array(offspring)

    def _select_mutants(self, i, pop_size):
       
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 4 (Overall AOCC Score: 1.5264e-02 |             AOCC Score on Unimodal instances: 1.5264e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid Differential Evolution with an archive for enhanced exploration and adaptive mutation.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution (DE) with an archive to enhance exploration and exploitation in multimodal landscapes.  
    Adaptive mutation rate adjusts exploration based on diversity.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.mutation_rate = 0.1 # Initial mutation rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self.mutation_rate = self._adaptive_mutation_rate(population)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            trial = np.zeros_like(population[i])
            for j in range(self.dim):
                if random.random() < self.CR:
                    trial[j] = mutant[j]
                else:
                    trial[j] = population[i][j]
            offspring[i] = trial
            #Adaptive Mutation
            if random.random() < self.mutation_rate:
                offspring[i] += np.random.normal(0, 0.1 * (self.upper_bounds - self.lower_bounds), self.dim) # Gaussian mutation
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])


    def _adaptive_mutation_rate(self, population):
        #Simple diversity measure: average distance to nearest neighbor. High distance implies high diversity
        distances = np.linalg.norm(population[:, np.newaxis, :] - population[np.newaxis, :, :], axis=2)
        avg_dist = np.mean(np.min(distances[np.arange(distances.shape[0]) != np.arange(distances.shape[1])], axis=1))
        if avg_dist > 50:
            return 0.05 # Decrease exploration if already diverse
        elif avg_dist < 20:
            return 0.2  # Increase exploration if not enough diversity
        else:
            return self.mutation_rate # Maintain current rate

```

### Rank 5 (Overall AOCC Score: 1.5193e-02 |             AOCC Score on Unimodal instances: 1.5193e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE with archive and adaptive mutation for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE with archive and adaptive mutation for multimodal optimization.
class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution (DE) with an archive and adaptive mutation 
    to enhance exploration and exploitation in high-dimensional multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds) #Adaptive mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self.sigma *= 0.99 #Adaptive Mutation Scaling

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_distinct(population, i, 3)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Keep within bounds
            trial = self._crossover(population[i], mutant)
            trial = self._adaptive_mutation(trial)
            offspring[i] = trial
        return offspring
    
    def _adaptive_mutation(self, solution):
        return solution + np.random.normal(0, self.sigma, size=solution.shape)

    def _select_distinct(self, population, exclude_index, num_vectors):
      indices = np.random.choice(len(population), num_vectors, replace=False)
      while exclude_index in indices:
          indices = np.random.choice(len(population), num_vectors, replace=False)
      return population[indices]

    def _crossover(self, x, v):
        u = np.copy(x)
        indices = np.random.rand(self.dim) < self.CR
        u[indices] = v[indices]
        return u

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 6 (Overall AOCC Score: 1.5131e-02 |             AOCC Score on Unimodal instances: 1.5131e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveDE
# Description: Combines Differential Evolution with an archive for enhanced multimodal exploration and adaptive mutation.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an archive to enhance exploration in multimodal landscapes.  Adaptive mutation adjusts step size.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = 100  # Size of the solution archive
        self.archive = []
        self.population_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.mutation_rate = 0.2 #Initial mutation rate
        self.mutation_decay = 0.99 # Decay for mutation rate


        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += self.population_size

        self.best_solution_overall = population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            # Differential Evolution
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < fitness[i]:
                    offspring[i] = trial
                    fitness[i] = trial_fitness
                else:
                    offspring[i] = population[i]

            # Archive Management
            self.update_archive(offspring, fitness)

            #Adaptive Mutation
            offspring = self.adaptive_mutation(offspring)

            population = offspring
            
            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]
            self.mutation_rate *= self.mutation_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size_final':len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def update_archive(self, population, fitness):
        for i in range(len(population)):
            is_better = True
            for j in range(len(self.archive)):
                if fitness[i] > self.archive[j][1]:
                    is_better = False
                    break

            if is_better and len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness[i]))
            elif is_better and len(self.archive) >= self.archive_size:
                worst_index = np.argmax([f for _, f in self.archive])
                if fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (population[i], fitness[i])

    def adaptive_mutation(self, offspring):
        for i in range(len(offspring)):
            for j in range(self.dim):
                if np.random.rand() < self.mutation_rate:
                    offspring[i, j] += np.random.normal(0, (self.upper_bounds[j] - self.lower_bounds[j]) * 0.05)
                    offspring[i, j] = np.clip(offspring[i, j], self.lower_bounds[j], self.upper_bounds[j])
        return offspring

```

### Rank 7 (Overall AOCC Score: 1.4897e-02 |             AOCC Score on Unimodal instances: 1.4897e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveHybridDE_SA
# Description: A hybrid Differential Evolution and Simulated Annealing algorithm with adaptive parameters for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDE_SA
# Description: A hybrid Differential Evolution and Simulated Annealing algorithm with adaptive parameters for multimodal optimization.

class AdaptiveHybridDE_SA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 20 * self.dim  # Increased population size for better exploration
        self.population = None
        self.archive = []  # Archive to store diverse solutions
        self.archive_size = 200

        self.F = 0.5  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.T = 100.0  # Initial temperature for Simulated Annealing
        self.cooling_rate = 0.95  # Cooling rate for Simulated Annealing


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adapt parameters
            self.adapt_parameters(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

            # Simulated Annealing perturbation
            perturbation = np.random.normal(0, self.T/10, self.dim) #scale perturbation by temperature
            mutant = mutant + perturbation
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)


            crosspoints = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crosspoints, mutant, self.population[i])

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def adapt_parameters(self, fitness):
        # Simple adaptive strategy: Reduce temperature and adjust F based on convergence
        self.T *= self.cooling_rate
        avg_fitness_diff = np.mean(np.diff(np.sort(fitness)))
        if avg_fitness_diff < 0.1 : #adjust F if convergence is slow
            self.F = min(1.0, self.F + 0.05)  #increase F for further exploration
        else:
            self.F = max(0.1, self.F - 0.02) #decrease F for exploitation

```

### Rank 8 (Overall AOCC Score: 1.4762e-02 |             AOCC Score on Unimodal instances: 1.4762e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE algorithm combining an archive for exploration and adaptive scaling factor for exploitation.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE algorithm combining an archive for exploration and adaptive scaling factor for exploitation.
class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution with an archive to enhance exploration and an adaptive scaling factor for exploitation in multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 200 # Increased archive size for better exploration
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive (improved diversity handling)
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation (elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            if np.min(fitness) < self.best_fitness_overall:
                self.best_solution_overall = self.population[np.argmin(fitness)]
                self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor with noise for enhanced exploration
        self.F_scale = 0.5 + 0.3 * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity and quality in archive using a distance metric and fitness
                distances = np.linalg.norm(self.archive[:, 0] - offspring[i], axis=1)
                closest_index = np.argmin(distances)
                if offspring_fitness[i] < self.archive[closest_index][1]: #replace if better
                    self.archive[closest_index] = (offspring[i], offspring_fitness[i])
                elif np.mean(distances) > 20: #add if diverse enough
                    worst_index = np.argmax([f for _, f in self.archive])
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


```

### Rank 9 (Overall AOCC Score: 1.4759e-02 |             AOCC Score on Unimodal instances: 1.4759e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveHybridOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution, Gaussian Processes, and local search for efficient multimodal optimization.
# Code:
```python
import numpy as np
import random
from scipy.optimize import minimize

# Name: AdaptiveHybridOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution, Gaussian Processes, and local search for efficient multimodal optimization.

class AdaptiveHybridOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 #crossover rate for DE
        self.exploration_rate = 0.8 # Initial exploration rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt exploration rate based on progress
            if self.eval_count > self.budget * 0.2 :
                progress = (self.best_fitness_overall - np.min(fitness))/self.best_fitness_overall if self.best_fitness_overall != 0 else 1.0
                self.exploration_rate = max(0.1, self.exploration_rate * (1 - progress) + 0.1)  #Reduce if good progress.

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros((int(self.population_size * self.exploration_rate), self.dim))
        for i in range(int(self.population_size * self.exploration_rate)):
            #Global Exploration using DE
            a, b, c = random.sample(range(self.population_size), 3)
            offspring[i] = self.population[a] + self.F_scale * (self.population[b] - self.population[c])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        #Local Exploitation using local search around best solutions
        remaining_offspring = int(self.population_size * (1 - self.exploration_rate))
        if remaining_offspring > 0:
          local_offspring = np.zeros((remaining_offspring, self.dim))
          for i in range(remaining_offspring):
              best_index = np.argmin(np.linalg.norm(self.population - self.best_solution_overall, axis=1))
              x0 = self.population[best_index]
              res = minimize(lambda x: objective_function(np.array([x])), x0, bounds = list(zip(self.lower_bounds, self.upper_bounds)), method = "L-BFGS-B")
              local_offspring[i] = res.x
          offspring = np.concatenate((offspring, local_offspring))
          
        return offspring


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 10 (Overall AOCC Score: 1.4689e-02 |             AOCC Score on Unimodal instances: 1.4689e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveHybridOptimizer
# Description: 
# Code:
```python
import numpy as np
import random
from scipy.optimize import minimize

class AdaptiveHybridOptimizer:
    """Hybrid algorithm combining Differential Evolution (DE), Gaussian Processes (GP), and Simulated Annealing (SA) for multimodal optimization."""

    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        # DE parameters
        self.population_size = 10 * self.dim
        self.F = 0.5  # scaling factor
        self.CR = 0.9  # crossover rate

        # SA parameters
        self.T0 = 100.0  # initial temperature
        self.alpha = 0.95  # cooling rate

        # GP parameters (simplified for demonstration)
        self.gp_samples = 10 # number of samples for GP exploration


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)


        while self.eval_count < self.budget:
            # Differential Evolution step
            offspring = self.differential_evolution(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Simulated Annealing step - focus on best solution from DE
            sa_solution, sa_fitness = self.simulated_annealing(self.best_solution_overall, objective_function, self.T0, self.alpha)
            if sa_fitness < self.best_fitness_overall:
                self.best_solution_overall = sa_solution
                self.best_fitness_overall = sa_fitness


            # Gaussian Process exploration (periodically)
            if self.eval_count % (self.population_size * 2) == 0:
                 self.gaussian_process_exploration(objective_function)


            # Combine and select
            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def differential_evolution(self, population, fitness):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = population[a] + self.F * (population[b] - population[c])
            trial = np.clip(np.where(np.random.rand(self.dim) < self.CR, mutant, population[i]), self.lower_bounds, self.upper_bounds)
            trial_fitness = objective_function(trial.reshape(1, -1))
            if trial_fitness < fitness[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring

    def simulated_annealing(self, initial_solution, objective_function, T0, alpha):
        current_solution = initial_solution.copy()
        current_fitness = objective_function(current_solution.reshape(1, -1))
        best_solution = current_solution.copy()
        best_fitness = current_fitness

        T = T0
        while T > 1e-6:
            neighbor = current_solution + np.random.normal(0, T, self.dim)
            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
            neighbor_fitness = objective_function(neighbor.reshape(1, -1))
            delta_e = neighbor_fitness - current_fitness
            if delta_e < 0 or random.random() < np.exp(-delta_e / T):
                current_solution = neighbor
                current_fitness = neighbor_fitness
            if current_fitness < best_fitness:
                best_solution = current_solution.copy()
                best_fitness = current_fitness
            T *= alpha
            self.eval_count += 1
            if self.eval_count >= self.budget:
                break
        return best_solution, best_fitness

    def gaussian_process_exploration(self, objective_function):
        # Simplified GP exploration (replace with a proper GP library for better performance)
        # This example just generates random samples around the current best
        for _ in range(self.gp_samples):
            sample = self.best_solution_overall + np.random.normal(0, 20, self.dim)  # Adjust variance as needed
            sample = np.clip(sample, self.lower_bounds, self.upper_bounds)
            fitness = objective_function(sample.reshape(1,-1))
            self.eval_count +=1
            if fitness < self.best_fitness_overall:
                self.best_solution_overall = sample
                self.best_fitness_overall = fitness

```

### Rank 11 (Overall AOCC Score: 1.4665e-02 |             AOCC Score on Unimodal instances: 1.4665e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE with archive and adaptive mutation for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE with archive and adaptive mutation for robust multimodal optimization.
# Code:
class ArchiveGuidedAdaptiveDE:
    """
    A hybrid Differential Evolution algorithm that uses an archive to store promising solutions 
    and adapts its mutation strategy based on the search progress.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99
        self.population = None
        self.fitness_values = None


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation with Archive Guidance
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                # Incorporate archive into mutation
                if len(self.archive) > 0:
                    archive_index = random.randint(0, len(self.archive) - 1)
                    mutant += 0.2 * (self.archive[archive_index] - self.population[i])  # Influence from archive


                # Adaptive Gaussian Perturbation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                # Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_solution_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_solution_index][1]:
                self.archive[worst_solution_index] = (solution, fitness)

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 07:39:09 INFO Full response text: **Analysis:**

Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveHybridOptimizer` (Rank 10), we see that `EnhancedArchiveGuidedDE` uses an adaptive scaling factor (`F_scale`) which is adjusted in each iteration adding a stochastic element to the search, improving exploration.  `AdaptiveHybridOptimizer` uses a fixed `F` and `CR` for DE, making exploration less dynamic and potentially less effective on complex landscapes.  `EnhancedArchiveGuidedDE` also has a more sophisticated archive update strategy, prioritizing both fitness and diversity. `AdaptiveHybridOptimizer` uses only fitness for archive updating.

`(second best)` `ArchiveGuidedAdaptiveDE` (Rank 2) vs `AdaptiveHybridDE_SA` (Rank 7): `ArchiveGuidedAdaptiveDE`  adapts parameters (`F`, `CR`) based on convergence speed, balancing exploration and exploitation. `AdaptiveHybridDE_SA` combines DE with Simulated Annealing but may suffer from slow cooling rate resulting in premature convergence. The archive update in `ArchiveGuidedAdaptiveDE` is more efficient, discarding solutions based on similarity rather than pure fitness.

Comparing (1st) `EnhancedArchiveGuidedDE` vs (2nd) `ArchiveGuidedAdaptiveDE`: `EnhancedArchiveGuidedDE` shows superior performance due to its adaptive scaling factor with slight variation, adding a more stochastic element into exploration.  Archive update mechanism in `EnhancedArchiveGuidedDE` dynamically adjusts based on the proportion of the archive filled.

(3rd) `ArchiveGuidedAdaptiveDE` (Rank 3) vs (4th) `ArchiveGuidedAdaptiveDE` (Rank 4): The minor differences in the code structure, adaptive mutation and the archive update in these two similar algorithms lead to marginally different performance results.  The Rank 3 algorithm slightly edges out Rank 4.

Comparing (second worst) `AdaptiveHybridOptimizer` (Rank 9) vs (worst) `AdaptiveHybridOptimizer` (Rank 10): Rank 9 algorithm incorporates local search around best solutions via `scipy.optimize.minimize`, which improves exploitation compared to the pure DE and SA approach of Rank 10.

Overall: The best-performing algorithms consistently utilize adaptive parameter control, sophisticated archive management prioritizing both diversity and fitness, and incorporate strategies that balance global exploration and local exploitation. Simple adaptive schemes, like decaying mutation rates,  show promise but lack the robustness of more nuanced strategies.

**Experience:**

Adaptive parameter tuning, coupled with sophisticated archive management that considers diversity, and hybridized approaches combining global and local search methods, are crucial for high performance on diverse multimodal optimization problems.  Further research should focus on more sophisticated diversity measures and adaptive strategies for parameter control.

2025-06-24 07:39:10 INFO Full response text: * **Keywords:**  Adaptive parameter control, diversity metrics, archive management, hybrid search, multimodal optimization.

* **Advice:** Focus on quantifiable metrics for diversity and adaptation.  Develop rigorous experiments comparing different diversity measures and adaptive parameter strategies across diverse benchmark problems. Explore novel hybrid search methods combining the strengths of different global and local optimizers, including theoretical analysis of their convergence properties.

* **Avoid:** Vague statements like "sophisticated exploration/exploitation,"  repetitive phrasing of existing methods (DE, Gaussian sampling, niching), and unsubstantiated claims of effectiveness without empirical evidence.

* **Explanation:** The current self-reflection lacks concrete, actionable steps.  The revised approach prioritizes measurable progress and rigorous validation, moving beyond general observations to specific research directions backed by formal analysis and empirical evaluation.  This ensures the investment ($999K) yields demonstrably improved heuristics.

2025-06-24 07:39:10 INFO Generating offspring via Crossover...
2025-06-24 07:53:48 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    

### Better code
ArchiveGuidedAdaptiveDE
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveDE
# Description: Hybrid DE algorithm using an archive to enhance exploration and adaptive mutation for exploitation.

class ArchiveGuidedAdaptiveDE:
    """
    Combines Differential Evolution (DE) with an archive and adaptive mutation 
    to efficiently explore and exploit multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.8  # Differential weight (adaptive)
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(np.vstack((population, offspring)), 
                                                np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different_individuals(population, i)
            mutant = a + self.F * (b - c)
            offspring[i] = self._crossover(population[i], mutant)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_different_individuals(self, population, i):
        indices = list(range(self.population_size))
        indices.remove(i)
        a, b, c = random.sample(indices, 3)
        return population[a], population[b], population[c]

    def _crossover(self, x, v):
        jrand = random.randint(0, self.dim - 1)
        y = np.copy(x)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive)[:self.archive_size]

    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptive scheme: Reduce F if convergence is detected
        avg_fitness_diff = np.mean(np.diff(np.sort(fitness_values)))
        if avg_fitness_diff < 0.1: # Adjust threshold as needed
            self.F *= 0.95

### Worse code
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

### Analyze & experience
- Comparing (best) `EnhancedArchiveGuidedDE` vs (worst) `AdaptiveHybridOptimizer` (Rank 10), we see that `EnhancedArchiveGuidedDE` uses an adaptive scaling factor (`F_scale`) which is adjusted in each iteration adding a stochastic element to the search, improving exploration.  `AdaptiveHybridOptimizer` uses a fixed `F` and `CR` for DE, making exploration less dynamic and potentially less effective on complex landscapes.  `EnhancedArchiveGuidedDE` also has a more sophisticated archive update strategy, prioritizing both fitness and diversity. `AdaptiveHybridOptimizer` uses only fitness for archive updating.

`(second best)` `ArchiveGuidedAdaptiveDE` (Rank 2) vs `AdaptiveHybridDE_SA` (Rank 7): `ArchiveGuidedAdaptiveDE`  adapts parameters (`F`, `CR`) based on convergence speed, balancing exploration and exploitation. `AdaptiveHybridDE_SA` combines DE with Simulated Annealing but may suffer from slow cooling rate resulting in premature convergence. The archive update in `ArchiveGuidedAdaptiveDE` is more efficient, discarding solutions based on similarity rather than pure fitness.

Comparing (1st) `EnhancedArchiveGuidedDE` vs (2nd) `ArchiveGuidedAdaptiveDE`: `EnhancedArchiveGuidedDE` shows superior performance due to its adaptive scaling factor with slight variation, adding a more stochastic element into exploration.  Archive update mechanism in `EnhancedArchiveGuidedDE` dynamically adjusts based on the proportion of the archive filled.

(3rd) `ArchiveGuidedAdaptiveDE` (Rank 3) vs (4th) `ArchiveGuidedAdaptiveDE` (Rank 4): The minor differences in the code structure, adaptive mutation and the archive update in these two similar algorithms lead to marginally different performance results.  The Rank 3 algorithm slightly edges out Rank 4.

Comparing (second worst) `AdaptiveHybridOptimizer` (Rank 9) vs (worst) `AdaptiveHybridOptimizer` (Rank 10): Rank 9 algorithm incorporates local search around best solutions via `scipy.optimize.minimize`, which improves exploitation compared to the pure DE and SA approach of Rank 10.

Overall: The best-performing algorithms consistently utilize adaptive parameter control, sophisticated archive management prioritizing both diversity and fitness, and incorporate strategies that balance global exploration and local exploitation. Simple adaptive schemes, like decaying mutation rates,  show promise but lack the robustness of more nuanced strategies.
- * **Keywords:**  Adaptive parameter control, diversity metrics, archive management, hybrid search, multimodal optimization.

* **Advice:** Focus on quantifiable metrics for diversity and adaptation.  Develop rigorous experiments comparing different diversity measures and adaptive parameter strategies across diverse benchmark problems. Explore novel hybrid search methods combining the strengths of different global and local optimizers, including theoretical analysis of their convergence properties.

* **Avoid:** Vague statements like "sophisticated exploration/exploitation,"  repetitive phrasing of existing methods (DE, Gaussian sampling, niching), and unsubstantiated claims of effectiveness without empirical evidence.

* **Explanation:** The current self-reflection lacks concrete, actionable steps.  The revised approach prioritizes measurable progress and rigorous validation, moving beyond general observations to specific research directions backed by formal analysis and empirical evaluation.  This ensures the investment ($999K) yields demonstrably improved heuristics.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 07:53:48 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    

Current heuristics:
EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Adaptive parameter control, diversity metrics, archive management, hybrid search, multimodal optimization.

* **Advice:** Focus on quantifiable metrics for diversity and adaptation.  Develop rigorous experiments comparing different diversity measures and adaptive parameter strategies across diverse benchmark problems. Explore novel hybrid search methods combining the strengths of different global and local optimizers, including theoretical analysis of their convergence properties.

* **Avoid:** Vague statements like "sophisticated exploration/exploitation,"  repetitive phrasing of existing methods (DE, Gaussian sampling, niching), and unsubstantiated claims of effectiveness without empirical evidence.

* **Explanation:** The current self-reflection lacks concrete, actionable steps.  The revised approach prioritizes measurable progress and rigorous validation, moving beyond general observations to specific research directions backed by formal analysis and empirical evaluation.  This ensures the investment ($999K) yields demonstrably improved heuristics.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-24 07:58:39 INFO Perform Harmony Search...
2025-06-24 07:58:48 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:48 ERROR Can not run the algorithm
2025-06-24 07:58:48 INFO Run function 6 complete. FEHistory len: 2530, AOCC: 0.1479
2025-06-24 07:58:48 INFO FeHistory: [-183.368635   -183.34666755 -183.33819324 ... -183.37124609 -183.40492734
 -183.35221286]
2025-06-24 07:58:48 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:48 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 84.33830973638973, archive_size: int = 67.99155490337043,
                 initial_F_scale: float = 0.8813955494880837, F_scale_variation: float = 0.5869878269477009,
                 acceptance_threshold: float = 8.139965793029053e-06, archive_update_threshold: float = 0.3136099622830315):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:48 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:49 ERROR Can not run the algorithm
2025-06-24 07:58:49 INFO Run function 13 complete. FEHistory len: 2530, AOCC: 0.0000
2025-06-24 07:58:49 INFO FeHistory: [2295801.76224513 2855535.70505901 1621849.19663879 ... 1955483.22333416
  838433.23870149 3860281.03571739]
2025-06-24 07:58:49 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:49 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:49 ERROR Can not run the algorithm
2025-06-24 07:58:50 INFO Run function 18 complete. FEHistory len: 2530, AOCC: 0.0000
2025-06-24 07:58:50 INFO FeHistory: [168811.95883209 159399.97129864 137804.85864262 ... 129956.81051902
 211487.03341258 177896.64182249]
2025-06-24 07:58:50 INFO Expected Optimum FE: -5000
2025-06-24 07:58:50 INFO Unimodal AOCC mean: 0.1479
2025-06-24 07:58:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:50 INFO AOCC mean: 0.0493
2025-06-24 07:58:50 INFO Weighed AOCC mean: 0.0148
2025-06-24 07:58:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:50 ERROR Can not run the algorithm
2025-06-24 07:58:50 INFO Run function 6 complete. FEHistory len: 112, AOCC: 0.1470
2025-06-24 07:58:50 INFO FeHistory: [-183.39689368 -183.35030833 -183.31353451 -183.41881851 -183.33623383
 -183.32342131 -183.47431933 -183.35596003 -183.38097282 -183.44179779
 -183.31339676 -183.43799866 -183.30694691 -183.26228914 -183.31183851
 -183.36862843 -183.39436006 -183.44984586 -183.35487049 -183.38209218
 -183.33081035 -183.43823895 -183.35720107 -183.27943489 -183.33617702
 -183.36849359 -183.33132496 -183.39178988 -183.30706647 -183.31385628
 -183.32522706 -183.35170545 -183.36155669 -183.35029109 -183.37287476
 -183.37541865 -183.35810028 -183.37510315 -183.40473883 -183.35525074
 -183.36687653 -183.31385467 -183.34575203 -183.38128899 -183.29615417
 -183.44050267 -183.32587046 -183.39773177 -183.46302902 -183.44031297
 -183.39692153 -183.40148045 -183.42920487 -183.27241012 -183.28119624
 -183.33809086 -183.26979629 -183.35298381 -183.26472234 -183.29109044
 -183.35274185 -183.31923405 -183.4096869  -183.312837   -183.28639306
 -183.34861253 -183.26655637 -183.34462297 -183.36389193 -183.30214816
 -183.40181455 -183.33163883 -183.43332421 -183.31129573 -183.34883429
 -183.31019192 -183.35347258 -183.27136401 -183.36088777 -183.33507892
 -183.31343827 -183.34679306 -183.3390301  -183.3994053  -183.37737671
 -183.47313159 -183.34181991 -183.41951558 -183.38066708 -183.34341193
 -183.34847237 -183.41793074 -183.37011399 -183.3588585  -183.38662449
 -183.32992798 -183.29411207 -183.42256252 -183.3554275  -183.26265324
 -183.29179801 -183.39026542 -183.31333639 -183.31081861 -183.29864734
 -183.38630719 -183.30966097 -183.32487868 -183.42252661 -183.34444713
 -183.27364219 -183.30658748]
2025-06-24 07:58:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:50 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 3.7616878356401227, archive_size: int = 699.7399933925976,
                 initial_F_scale: float = 0.7878150456620839, F_scale_variation: float = 0.9423397426190482,
                 acceptance_threshold: float = 2.3154469144639937e-05, archive_update_threshold: float = 0.6139360922100783):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:50 ERROR Can not run the algorithm
2025-06-24 07:58:50 INFO Run function 13 complete. FEHistory len: 112, AOCC: 0.0000
2025-06-24 07:58:50 INFO FeHistory: [ 722584.08706482 2631604.2946597  3335362.95702607 3000375.58784661
  998215.8056449  1047182.54732262 1563440.53449728 1319571.90488883
 1631270.21973865 1553804.6768408   717767.31579417 2860490.28502451
 1717260.76007949 3097656.0207199  2199027.82072912 2106417.87303125
 1436352.9589219  1469318.28744723 1249400.48125983 1898088.93312392
 1414620.44654199 1186037.52640098  990627.32467948 3023382.04668094
  841016.54391947 1186283.81440053 2614308.25814182 2013792.00774235
  105372.0474667  2581485.26296566 2271878.09021222 1275030.93026068
  847180.69954524 3888861.34097116 1012526.78464308 3086376.08481205
 2855661.80304841  554196.61543726  498113.25412421  824002.73561301
 1324655.38703864 1841842.8315105  1988620.90946711 1150188.54477543
 1979348.65812879  688008.91698615 4525495.14556207 2449814.50346039
 1712481.50164567  822017.3782682  2470618.31101788 3590883.16350833
 1929366.98767136 2149543.78018521 2453604.55585466 3430303.98572004
 2106556.20446767  840585.827739   1761201.58912186 1027890.47947172
 2562094.43388919 3562320.0699879   961656.48848896  653433.41229853
 2967831.9200584  2848677.13420501  877806.32455432 2638674.17451855
  904120.71446335 1171377.40878894 1252207.04118158 2365085.03952036
  627227.4545071  1357513.94397817 1876446.01575717 1170600.84359286
 1572499.05175622 2427314.47349605 1635948.97768022 1465804.16303893
 2061542.35803382  594377.31646328  708536.90159465 1803884.68990257
 2679680.86886506 2059099.43115572 2659384.15385691 1792953.69016713
  729068.82591136 2371308.29701449  775154.16765838  762662.11750929
  865998.91830925  570416.77876249 2289718.79736233 1761944.67871297
 1481237.60172304 1741151.56607905  708673.12468821 1263083.47344002
 2749542.72067731 1940253.35809048 1953137.47748273 4262919.89986724
 2122591.59271132 1604923.59504269 1250016.60794235 2272970.72352231
 1340021.47480669 2503020.45363293 1735882.01291257 1684867.80623575]
2025-06-24 07:58:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:50 ERROR Can not run the algorithm
2025-06-24 07:58:50 INFO Run function 18 complete. FEHistory len: 112, AOCC: 0.0000
2025-06-24 07:58:50 INFO FeHistory: [116764.94921389 103470.41257146 200804.27774427 142039.39534557
 202997.79681296 168234.72620203 114886.19084926 165088.35979646
 188358.55233666 183559.83359988 187558.97438285 150592.75030528
 184173.79559405 135603.74889596 123442.17414645 121777.4567719
 135477.38085489 193878.53192183 103882.09546083 148110.543616
 182359.40001902 120220.01606449 162914.07821315 197547.00479294
 130521.92004413 118380.26230521 154771.68613387 166472.45392847
 137252.67339699 176905.69041083 163377.72559627 116647.33624538
 111189.94586843 115331.14411843 178893.18318759 163780.89566446
 161057.15890875 170789.4944276  157495.68029996 132861.12962231
 182605.24138025 186436.06380657 153340.87035201 200733.0392496
 195014.80646728 153021.70507051 111834.90478154 157060.21728832
 123892.17468937 152571.55705782 182522.86961255 139766.19210352
 168568.2063458  137822.04221058 157914.20448319 140458.14157733
 143958.4502363  128107.43236655 218138.3089415  114732.69352116
 123107.56225824 166105.73377754 142615.35020045 103192.27655802
 160385.73880816  85975.8973893  203070.45940676 122211.33983583
 136402.47847916 160790.00192282 196563.00229781 221555.4745738
 195407.07853687 205921.45302159 132609.64685603 132526.37676574
 113117.9721281  157624.33712631  97580.87192743 109740.29381165
 213437.78334208 112922.21471111 148372.76964795 165158.41332559
 188537.97599329 182194.12229872 158747.99196675 153186.76655722
 183833.08602341 168250.05560273 215840.81240465  84683.26197518
  92447.73697342 195176.5988303  146211.78154121 190575.16819874
 112540.45811785 129466.91049688 173439.45578723 136994.60626841
  81292.12122875 203697.57040908  89648.98485121 101398.88558916
 148529.93795452 157626.41297526 138689.03217326 262700.84617389
 108744.94613311 164583.60098718 150439.08752229 152626.67526165]
2025-06-24 07:58:50 INFO Expected Optimum FE: -5000
2025-06-24 07:58:50 INFO Unimodal AOCC mean: 0.1470
2025-06-24 07:58:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:50 INFO AOCC mean: 0.0490
2025-06-24 07:58:50 INFO Weighed AOCC mean: 0.0147
2025-06-24 07:58:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:50 ERROR Can not run the algorithm
2025-06-24 07:58:51 INFO Run function 6 complete. FEHistory len: 1307, AOCC: 0.1474
2025-06-24 07:58:51 INFO FeHistory: [-183.37031204 -183.30244    -183.28467964 ... -183.37136073 -183.26988976
 -183.33111064]
2025-06-24 07:58:51 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:51 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 43.572266593564805, archive_size: int = 413.4983786383707,
                 initial_F_scale: float = 0.20267128385673228, F_scale_variation: float = 0.23117537070187055,
                 acceptance_threshold: float = 3.937222153171903e-06, archive_update_threshold: float = 0.9456584164018393):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:51 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:51 ERROR Can not run the algorithm
2025-06-24 07:58:51 INFO Run function 13 complete. FEHistory len: 1307, AOCC: 0.0000
2025-06-24 07:58:51 INFO FeHistory: [2273457.91241167 1661045.75916141  857684.30396398 ...  870622.22753955
 3830576.56880675 2053781.60615317]
2025-06-24 07:58:51 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:51 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:51 ERROR Can not run the algorithm
2025-06-24 07:58:51 INFO Run function 18 complete. FEHistory len: 1307, AOCC: 0.0000
2025-06-24 07:58:51 INFO FeHistory: [220160.22748731 166023.79034477 148644.59642798 ... 110707.35647904
 179001.50445319 229080.11407495]
2025-06-24 07:58:51 INFO Expected Optimum FE: -5000
2025-06-24 07:58:51 INFO Unimodal AOCC mean: 0.1474
2025-06-24 07:58:51 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:51 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:51 INFO AOCC mean: 0.0491
2025-06-24 07:58:51 INFO Weighed AOCC mean: 0.0147
2025-06-24 07:58:51 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:51 ERROR Can not run the algorithm
2025-06-24 07:58:52 INFO Run function 6 complete. FEHistory len: 1521, AOCC: 0.1479
2025-06-24 07:58:52 INFO FeHistory: [-183.40917315 -183.35272747 -183.41106237 ... -183.38735127 -183.413838
 -183.34129323]
2025-06-24 07:58:52 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:52 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 50.70129152988721, archive_size: int = 430.6706551202469,
                 initial_F_scale: float = 0.025713667827453657, F_scale_variation: float = 0.3912954791901705,
                 acceptance_threshold: float = 8.581358959599647e-05, archive_update_threshold: float = 0.2093386896282226):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:52 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:52 ERROR Can not run the algorithm
2025-06-24 07:58:52 INFO Run function 13 complete. FEHistory len: 1521, AOCC: 0.0000
2025-06-24 07:58:52 INFO FeHistory: [1898407.26299724 2171694.5879298  1748361.87645257 ...  946873.7119147
 1087902.55820118 2578121.53711102]
2025-06-24 07:58:52 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:52 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:52 ERROR Can not run the algorithm
2025-06-24 07:58:53 INFO Run function 18 complete. FEHistory len: 1521, AOCC: 0.0000
2025-06-24 07:58:53 INFO FeHistory: [147998.3090888  161676.00075967 155395.47047284 ... 109528.59415041
 113998.71576664 133505.37589804]
2025-06-24 07:58:53 INFO Expected Optimum FE: -5000
2025-06-24 07:58:53 INFO Unimodal AOCC mean: 0.1479
2025-06-24 07:58:53 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:53 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:53 INFO AOCC mean: 0.0493
2025-06-24 07:58:53 INFO Weighed AOCC mean: 0.0148
2025-06-24 07:58:53 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:53 ERROR Can not run the algorithm
2025-06-24 07:58:53 INFO Run function 6 complete. FEHistory len: 2461, AOCC: 0.1480
2025-06-24 07:58:53 INFO FeHistory: [-183.41967009 -183.34157947 -183.37112651 ... -183.32414234 -183.40125273
 -183.38858381]
2025-06-24 07:58:53 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:53 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 82.05466941828251, archive_size: int = 986.1939197826593,
                 initial_F_scale: float = 0.07809316667934407, F_scale_variation: float = 0.8649858442356303,
                 acceptance_threshold: float = 4.500513537814433e-05, archive_update_threshold: float = 0.14388929768598294):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:53 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:53 ERROR Can not run the algorithm
2025-06-24 07:58:53 INFO Run function 13 complete. FEHistory len: 2461, AOCC: 0.0000
2025-06-24 07:58:53 INFO FeHistory: [1592270.51719318 2918182.20998743  836090.13889891 ... 3058725.07871218
 4727515.63427206 3696947.41547861]
2025-06-24 07:58:53 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:53 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:54 ERROR Can not run the algorithm
2025-06-24 07:58:54 INFO Run function 18 complete. FEHistory len: 2461, AOCC: 0.0000
2025-06-24 07:58:54 INFO FeHistory: [131109.39602439 146387.24574157 123337.3186133  ... 138217.13262224
 135011.94320845 134542.9821285 ]
2025-06-24 07:58:54 INFO Expected Optimum FE: -5000
2025-06-24 07:58:54 INFO Unimodal AOCC mean: 0.1480
2025-06-24 07:58:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:54 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:54 INFO AOCC mean: 0.0493
2025-06-24 07:58:54 INFO Weighed AOCC mean: 0.0148
2025-06-24 07:58:54 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:54 ERROR Can not run the algorithm
2025-06-24 07:58:54 INFO Run function 6 complete. FEHistory len: 1525, AOCC: 0.1479
2025-06-24 07:58:54 INFO FeHistory: [-183.36364495 -183.36592282 -183.29056085 ... -183.31671637 -183.34723567
 -183.36585678]
2025-06-24 07:58:54 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:54 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 50.85040421911731, archive_size: int = 699.7399933925976,
                 initial_F_scale: float = 0.7727849364883296, F_scale_variation: float = 0.23117537070187055,
                 acceptance_threshold: float = 4.500513537814433e-05, archive_update_threshold: float = 0.6139360922100783):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:54 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:54 ERROR Can not run the algorithm
2025-06-24 07:58:55 INFO Run function 13 complete. FEHistory len: 1525, AOCC: 0.0000
2025-06-24 07:58:55 INFO FeHistory: [4081699.65209287 1193708.50573761 2148431.23454421 ... 1319548.03797272
 1269151.49284915  829138.50884675]
2025-06-24 07:58:55 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:55 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:55 ERROR Can not run the algorithm
2025-06-24 07:58:55 INFO Run function 18 complete. FEHistory len: 1525, AOCC: 0.0000
2025-06-24 07:58:55 INFO FeHistory: [151650.207672   128539.24623806 190381.09541316 ... 159270.0011548
  87041.46547253 165841.42040506]
2025-06-24 07:58:55 INFO Expected Optimum FE: -5000
2025-06-24 07:58:55 INFO Unimodal AOCC mean: 0.1479
2025-06-24 07:58:55 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:55 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:55 INFO AOCC mean: 0.0493
2025-06-24 07:58:55 INFO Weighed AOCC mean: 0.0148
2025-06-24 07:58:55 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:55 ERROR Can not run the algorithm
2025-06-24 07:58:56 INFO Run function 6 complete. FEHistory len: 1299, AOCC: 0.1473
2025-06-24 07:58:56 INFO FeHistory: [-183.36741508 -183.38154585 -183.32996499 ... -183.36800426 -183.36886625
 -183.35931202]
2025-06-24 07:58:56 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:56 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 43.302960751663896, archive_size: int = 699.7399933925976,
                 initial_F_scale: float = 0.025713667827453657, F_scale_variation: float = 0.01640652341128379,
                 acceptance_threshold: float = 4.197585493811349e-05, archive_update_threshold: float = 0.9384160082349688):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:56 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:56 ERROR Can not run the algorithm
2025-06-24 07:58:56 INFO Run function 13 complete. FEHistory len: 1299, AOCC: 0.0000
2025-06-24 07:58:56 INFO FeHistory: [ 545193.26627712 2283555.89880078 1285490.58999804 ... 3030008.15165651
 1706253.48837151 3568542.5264913 ]
2025-06-24 07:58:56 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:56 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:56 ERROR Can not run the algorithm
2025-06-24 07:58:56 INFO Run function 18 complete. FEHistory len: 1299, AOCC: 0.0000
2025-06-24 07:58:56 INFO FeHistory: [236356.62128312 163075.44273257 188880.88643269 ... 160514.68497076
 127919.69468062 204331.45346961]
2025-06-24 07:58:56 INFO Expected Optimum FE: -5000
2025-06-24 07:58:56 INFO Unimodal AOCC mean: 0.1473
2025-06-24 07:58:56 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:56 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:56 INFO AOCC mean: 0.0491
2025-06-24 07:58:56 INFO Weighed AOCC mean: 0.0147
2025-06-24 07:58:56 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:57 ERROR Can not run the algorithm
2025-06-24 07:58:57 INFO Run function 6 complete. FEHistory len: 2733, AOCC: 0.1477
2025-06-24 07:58:57 INFO FeHistory: [-183.34712153 -183.33169272 -183.33868506 ... -183.2946434  -183.3679558
 -183.27808058]
2025-06-24 07:58:57 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:57 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 91.11186063250432, archive_size: int = 699.7399933925976,
                 initial_F_scale: float = 0.9425654593084307, F_scale_variation: float = 0.5869878269477009,
                 acceptance_threshold: float = 1.7869359400058523e-05, archive_update_threshold: float = 0.592044910511913):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:57 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:57 ERROR Can not run the algorithm
2025-06-24 07:58:57 INFO Run function 13 complete. FEHistory len: 2733, AOCC: 0.0000
2025-06-24 07:58:57 INFO FeHistory: [2635421.78490276 1918777.04716267 1168928.26566735 ... 2483464.94790385
 1768004.52643308 2658795.68290519]
2025-06-24 07:58:57 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:57 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:58 ERROR Can not run the algorithm
2025-06-24 07:58:58 INFO Run function 18 complete. FEHistory len: 2733, AOCC: 0.0000
2025-06-24 07:58:58 INFO FeHistory: [152446.5080429   94721.9316881  163087.82471819 ... 163677.05714117
 138741.63751335 141324.9661059 ]
2025-06-24 07:58:58 INFO Expected Optimum FE: -5000
2025-06-24 07:58:58 INFO Unimodal AOCC mean: 0.1477
2025-06-24 07:58:58 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:58 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:58 INFO AOCC mean: 0.0492
2025-06-24 07:58:58 INFO Weighed AOCC mean: 0.0148
2025-06-24 07:58:58 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:58 ERROR Can not run the algorithm
2025-06-24 07:58:58 INFO Run function 6 complete. FEHistory len: 783, AOCC: 0.1476
2025-06-24 07:58:58 INFO FeHistory: [-183.3261211  -183.33393329 -183.35211974 -183.36247937 -183.34223681
 -183.31320912 -183.34601523 -183.31181215 -183.28682657 -183.40237909
 -183.48845274 -183.28793107 -183.32418194 -183.25543181 -183.32757201
 -183.42783447 -183.35228776 -183.33522264 -183.42655942 -183.36821798
 -183.43407437 -183.34760642 -183.25382376 -183.35958161 -183.37187213
 -183.31058971 -183.32200776 -183.33998271 -183.32318293 -183.39710576
 -183.38731017 -183.34037174 -183.32677584 -183.39115678 -183.35276346
 -183.27340723 -183.35963464 -183.4414394  -183.35613819 -183.26314722
 -183.38885116 -183.31682147 -183.28911444 -183.31766731 -183.29722222
 -183.3084786  -183.35997869 -183.39609299 -183.31025874 -183.3482383
 -183.52428454 -183.31564522 -183.33584491 -183.32388735 -183.32380301
 -183.35861867 -183.3211366  -183.3777094  -183.3095006  -183.34063028
 -183.31464947 -183.31190067 -183.32257776 -183.44095366 -183.35923804
 -183.42502519 -183.35757946 -183.41683301 -183.34695234 -183.34127025
 -183.32220121 -183.31437927 -183.31589365 -183.39946034 -183.3187358
 -183.32125437 -183.33952669 -183.28866346 -183.33248959 -183.39303871
 -183.39842073 -183.40925986 -183.3535238  -183.35917855 -183.3795219
 -183.42913444 -183.36193516 -183.3480716  -183.37611107 -183.37916634
 -183.36092113 -183.28470124 -183.32829921 -183.29415621 -183.39639481
 -183.36461262 -183.30842307 -183.41690245 -183.41695556 -183.36160847
 -183.43088848 -183.30013689 -183.32792617 -183.44777149 -183.40075141
 -183.40435835 -183.31047507 -183.33787804 -183.33075684 -183.37321368
 -183.29455452 -183.38315164 -183.3568976  -183.39652675 -183.38390142
 -183.32842361 -183.34697166 -183.29977045 -183.33495828 -183.39753311
 -183.32659031 -183.29324765 -183.35239784 -183.38734502 -183.32072866
 -183.25766882 -183.40587006 -183.33514586 -183.31955006 -183.37792875
 -183.32063223 -183.25110926 -183.31732997 -183.39530972 -183.34394521
 -183.36088301 -183.4073505  -183.38924619 -183.29083375 -183.30191285
 -183.37907429 -183.31533419 -183.32569464 -183.36371893 -183.46073398
 -183.3155892  -183.38839647 -183.44616088 -183.4241104  -183.34621895
 -183.31167861 -183.40150065 -183.34781617 -183.32491432 -183.29708954
 -183.30029715 -183.34443995 -183.34647184 -183.35678819 -183.40926928
 -183.33689118 -183.34507913 -183.29693697 -183.33265115 -183.37066537
 -183.31139268 -183.44332675 -183.30948746 -183.30308162 -183.46436702
 -183.33164844 -183.33444735 -183.29346221 -183.35778417 -183.38156306
 -183.33635303 -183.39558362 -183.27620359 -183.41235223 -183.3092005
 -183.32881291 -183.38449499 -183.34242574 -183.34705605 -183.36216815
 -183.3303651  -183.38602528 -183.30742279 -183.40889849 -183.28882364
 -183.32968123 -183.32703643 -183.36233759 -183.33458976 -183.36614933
 -183.4209145  -183.40408669 -183.41214262 -183.33105165 -183.37775795
 -183.367973   -183.37241185 -183.36711322 -183.27215552 -183.38248923
 -183.32538213 -183.29170255 -183.31987777 -183.36269162 -183.37529286
 -183.38458869 -183.30510559 -183.27452347 -183.36232596 -183.32923497
 -183.38239557 -183.4062817  -183.30421814 -183.38589913 -183.32950303
 -183.37654529 -183.32706178 -183.26575311 -183.35304841 -183.30326268
 -183.37463837 -183.32763767 -183.30371322 -183.31121803 -183.3509196
 -183.33781485 -183.37244558 -183.32277517 -183.31926964 -183.32298305
 -183.42177723 -183.33703785 -183.34496191 -183.40288291 -183.294604
 -183.34416434 -183.3309884  -183.35338389 -183.32118484 -183.25179455
 -183.34766234 -183.33596549 -183.42387305 -183.33723997 -183.32514752
 -183.33296841 -183.33931731 -183.41527531 -183.29812821 -183.400975
 -183.33017851 -183.36295015 -183.39390796 -183.40467185 -183.34199758
 -183.32420643 -183.4039439  -183.40701661 -183.44660123 -183.30422209
 -183.33597836 -183.30892738 -183.31040694 -183.34632252 -183.39096009
 -183.39599791 -183.3893285  -183.4839826  -183.38501268 -183.32251366
 -183.3502662  -183.29644315 -183.33297758 -183.3494911  -183.39751004
 -183.28348557 -183.3639661  -183.41155031 -183.37455958 -183.45908968
 -183.3660169  -183.33383131 -183.45783099 -183.33671636 -183.29916566
 -183.37519696 -183.4384096  -183.40061566 -183.362584   -183.25895522
 -183.34963437 -183.28050431 -183.42037438 -183.34313017 -183.3040724
 -183.40654195 -183.42751954 -183.30978769 -183.32357517 -183.32255552
 -183.33240231 -183.27115856 -183.30842258 -183.37203409 -183.34250208
 -183.34179477 -183.41876383 -183.32631739 -183.25747721 -183.49902962
 -183.34288504 -183.38940757 -183.3742206  -183.38780441 -183.31152858
 -183.34969912 -183.40222823 -183.32169904 -183.32354214 -183.28613526
 -183.3765336  -183.33998785 -183.33273858 -183.36277902 -183.35141907
 -183.42892964 -183.29914764 -183.36659969 -183.39141375 -183.2895077
 -183.32896701 -183.45767427 -183.39580137 -183.3535257  -183.29386044
 -183.38372765 -183.33940592 -183.35544779 -183.32996072 -183.39991884
 -183.40455952 -183.35054854 -183.40680042 -183.46241693 -183.4121651
 -183.44841466 -183.36571626 -183.33305598 -183.33329742 -183.30912871
 -183.29662192 -183.38978768 -183.39750135 -183.32491405 -183.28318926
 -183.36378454 -183.44086983 -183.32888123 -183.34216325 -183.43417389
 -183.30791935 -183.38959029 -183.37542929 -183.34035643 -183.24921908
 -183.28836302 -183.29416115 -183.29980663 -183.3410375  -183.32921171
 -183.3178934  -183.44272583 -183.31967266 -183.30367665 -183.4940478
 -183.29887496 -183.32694142 -183.31174433 -183.36518567 -183.41262295
 -183.35803704 -183.32726109 -183.35640013 -183.37773507 -183.34830162
 -183.37032706 -183.32357524 -183.43346745 -183.39044562 -183.36216655
 -183.2619935  -183.31795901 -183.32448178 -183.32464216 -183.29467192
 -183.33596828 -183.29583297 -183.30864198 -183.3886202  -183.39450901
 -183.38143417 -183.32749348 -183.34612979 -183.40979921 -183.31956379
 -183.35824367 -183.33427999 -183.37422651 -183.49495058 -183.35151652
 -183.27715223 -183.38097698 -183.2724874  -183.32797087 -183.33823075
 -183.30493842 -183.40016903 -183.32922295 -183.39833669 -183.31030953
 -183.36370977 -183.32052781 -183.35355404 -183.37104086 -183.3124087
 -183.38015647 -183.30620057 -183.33587999 -183.35269791 -183.38948123
 -183.32977506 -183.35527344 -183.29767821 -183.33250094 -183.34206219
 -183.33923041 -183.3326181  -183.34293837 -183.27241562 -183.31484998
 -183.38700424 -183.2990436  -183.35402653 -183.29024415 -183.33982149
 -183.3655583  -183.38079454 -183.35770608 -183.38677307 -183.37910217
 -183.3927853  -183.38873307 -183.33371657 -183.29830613 -183.40709788
 -183.35794091 -183.38345298 -183.37142609 -183.39335871 -183.37122211
 -183.32358748 -183.32133601 -183.29578886 -183.35151159 -183.31172734
 -183.31407281 -183.47227274 -183.36041486 -183.30086083 -183.31047566
 -183.40395599 -183.3711507  -183.28577413 -183.33991947 -183.400702
 -183.37102169 -183.3890977  -183.35675545 -183.34259581 -183.33547677
 -183.32402764 -183.34007534 -183.44842416 -183.35771745 -183.30815829
 -183.33540515 -183.31551502 -183.38537423 -183.28986096 -183.34704425
 -183.30894041 -183.32959427 -183.41778591 -183.32651652 -183.33875433
 -183.29500998 -183.32588888 -183.2413918  -183.3318032  -183.37561003
 -183.33740708 -183.35491011 -183.37955667 -183.3771668  -183.37970768
 -183.38966879 -183.39008231 -183.33358195 -183.3197404  -183.32947815
 -183.31633331 -183.26101027 -183.39279557 -183.32604987 -183.3068852
 -183.40472508 -183.37058124 -183.37006381 -183.29960919 -183.36428057
 -183.32436835 -183.39835261 -183.34676188 -183.34623742 -183.34429506
 -183.33404215 -183.34510006 -183.29056972 -183.48492671 -183.39952547
 -183.38674726 -183.31132268 -183.37215647 -183.36847268 -183.39096783
 -183.44694345 -183.40988697 -183.37956635 -183.37009725 -183.34152648
 -183.36841538 -183.41779067 -183.33114251 -183.34621893 -183.29742338
 -183.35361245 -183.33490086 -183.41016632 -183.35827714 -183.37249545
 -183.37841852 -183.25839061 -183.4044025  -183.38236449 -183.40231068
 -183.35941796 -183.38158522 -183.29057545 -183.39131895 -183.40047712
 -183.38628277 -183.38697617 -183.29080825 -183.3039981  -183.38314312
 -183.37276486 -183.29428588 -183.35561772 -183.30456107 -183.33362884
 -183.3897612  -183.43624888 -183.33356777 -183.34486989 -183.29504515
 -183.33089304 -183.36109972 -183.39100276 -183.33362665 -183.37364338
 -183.38964172 -183.25333973 -183.3056274  -183.31815101 -183.32464051
 -183.38801018 -183.36221472 -183.3558469  -183.30861032 -183.30833398
 -183.34502741 -183.29792572 -183.35512148 -183.29126503 -183.39048483
 -183.30607592 -183.34075523 -183.36796347 -183.36126219 -183.38267069
 -183.35945531 -183.34341665 -183.4246536  -183.3098055  -183.31761909
 -183.32069038 -183.35185005 -183.40608107 -183.30957282 -183.39903301
 -183.25967182 -183.34559651 -183.34615413 -183.36311281 -183.45383697
 -183.30920007 -183.31817244 -183.39100587 -183.41203678 -183.31085747
 -183.30610648 -183.38639286 -183.38844222 -183.30131149 -183.27915583
 -183.39887813 -183.2789705  -183.3103708  -183.37877161 -183.36459694
 -183.26594234 -183.28566339 -183.36061356 -183.34972442 -183.36392243
 -183.30925899 -183.30692364 -183.31173697 -183.40689287 -183.38206367
 -183.36345062 -183.30492929 -183.34818475 -183.29964027 -183.28903126
 -183.28027014 -183.36248391 -183.29716189 -183.38196319 -183.35249736
 -183.35050193 -183.2978351  -183.36726781 -183.39519657 -183.38353753
 -183.32639592 -183.34134389 -183.32828688 -183.41580023 -183.3988042
 -183.28934614 -183.3235485  -183.41862321 -183.32516779 -183.32203517
 -183.26404285 -183.3531346  -183.30671534 -183.3892735  -183.4054296
 -183.35792171 -183.33010563 -183.39067866 -183.30319532 -183.31286843
 -183.29012219 -183.41335362 -183.33032594 -183.34314979 -183.32482586
 -183.27774857 -183.32051115 -183.35010893 -183.37663472 -183.38089432
 -183.37150182 -183.37329825 -183.3292499  -183.37957788 -183.28555356
 -183.38352308 -183.42465076 -183.2804811  -183.36955089 -183.39507988
 -183.4585038  -183.33322989 -183.34728972 -183.38884676 -183.27825563
 -183.34241541 -183.34759049 -183.39557094 -183.35453945 -183.42674685
 -183.36348422 -183.3083132  -183.31608814 -183.33292016 -183.3503403
 -183.33444218 -183.31578492 -183.30597164 -183.32670482 -183.34884107
 -183.3211687  -183.37287052 -183.32870608 -183.40621315 -183.42523913
 -183.40191528 -183.28673889 -183.28838075 -183.37321502 -183.35502411
 -183.38738034 -183.37564008 -183.28681802 -183.35116543 -183.40544398
 -183.35293278 -183.33748547 -183.30183778 -183.35005815 -183.39258432
 -183.38935116 -183.3670052  -183.36144608 -183.28769284 -183.2934077
 -183.35546334 -183.38495744 -183.29653847 -183.38143418 -183.34219796
 -183.29054526 -183.3761505  -183.35121241 -183.28216404 -183.32058957
 -183.38113447 -183.31019403 -183.30056462 -183.46377763 -183.418633
 -183.45693048 -183.33922742 -183.36594679 -183.39594214 -183.32810032
 -183.30468935 -183.41077705 -183.39359956 -183.39703377 -183.34624485
 -183.34157808 -183.34415612 -183.36032465 -183.33291618 -183.38781675
 -183.33405969 -183.34222289 -183.35143823 -183.30724114 -183.26162484
 -183.31309204 -183.41038533 -183.38596721]
2025-06-24 07:58:58 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:58 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 26.106594657857567, archive_size: int = -71.61190235601714,
                 initial_F_scale: float = 0.8813955494880837, F_scale_variation: float = 0.8393219070786871,
                 acceptance_threshold: float = 2.4218082181744473e-05, archive_update_threshold: float = 0.6139360922100783):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:58 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:58 ERROR Can not run the algorithm
2025-06-24 07:58:59 INFO Run function 13 complete. FEHistory len: 783, AOCC: 0.0000
2025-06-24 07:58:59 INFO FeHistory: [2217329.51561728 4701613.28588272 1339853.06962573  836310.77780414
 1013504.62681545 2418310.57085788 1506478.59124641 2764634.74167947
  616476.37926731 1876121.09360549 1771414.22843028 1561884.49168178
 2312944.98409102 1691259.81911864  722731.27348114 1261053.59477302
 2962249.01431621 2451100.12231502 3815320.92899052 2759538.56873661
 2345496.34511872 2537328.99022825 2366098.1056566  3059111.7038202
 1227360.44036112 1164811.40829752 2557927.83087886 2023817.31127411
  229186.67797422 2538136.91799915 2685322.15015664  930956.22202595
 1871059.08267239 1890490.2487327  2789321.79655198  797023.76550624
 2414046.27896326 2538145.57014282  435362.22431759 1043122.7237545
 3032885.77077007 1543455.12118323 2040229.81109884 1229312.07418121
 1485092.13865996  555602.66195028  712962.0413059  1905144.62276945
 1485350.8169579  1098475.31601609 2270882.28347882  946211.48651805
 2541979.07727176 1600071.99940692 1978761.76856107 2389045.23823281
 1224049.119881   2095787.56481431 1509756.28373069 2419733.26878048
 2820477.12838697 2864406.24246075  986284.31958302 3449812.66463319
 1402626.23188343 1817978.4533333   861064.2893528  3732304.83084964
 2177892.52608682 1439212.33658464 1095804.0702969   852887.33064864
 1166646.62066727  401046.83101317 1460096.2931804  2279776.69639234
 1401007.11322642 2363214.92488392 1994088.84600062 1776253.42552323
 1409332.77309597 1998605.58094333 1556987.78455508 1437934.69988486
 1523525.6317195  1141994.25695669 3704980.7277004  2214902.91103732
 3942588.73839866  722090.52613108 1804396.37884794 2222983.89095887
 2617524.07931374 1670158.86894907 1447411.80655986 1701461.17948969
 1218244.3941251  1179228.24155943 2934862.35237723 2082519.27856723
 2335580.38048525 1195037.07865854 1307935.80376011 2049738.50850399
 2505252.06765874 2691167.47990399 1171191.98311415 1750089.04379169
 1741768.93129237 4783392.05244607  587480.18809475 3502683.9509545
 2129979.45819146 1004693.57389605 1866447.94076312  739816.25109783
 2570460.07937051  635676.86405977 1340349.08346188 1916679.55686376
  560627.03915898  724019.07508705 1683370.4532788  3249803.10992324
 2308925.02777786 1023160.55805168 1848777.61048039 1175572.33770582
 2190215.12410888 1267221.77349905 2032775.44981242 3332698.88563879
 1180746.44930521 2456873.80859939 1188652.22662076 2020952.38177334
 2718236.13301754  715575.72451001 1589219.49684581 1393751.22746749
 2427103.8169362  3064789.92088327 3113458.75295842 1477520.91490862
 1671668.56733668 1300791.70734117 2060148.86450214 1916918.60139375
 1090223.21805601 2094184.35922102 1131226.03671512 1079951.63259985
 3019085.60244833 1172706.70523045  798519.22125696  754044.65594499
 4058803.08112482 4884303.18640455 2140495.47995294 1080977.49531148
 1699822.5656505  1215278.25676237 1826340.77223097  488579.93337112
 1637855.73754422 1454423.88423492 1675993.71693797 2315301.09043004
 1597559.28072213 2303592.17731336 1800637.93338118  250458.93969955
 1364917.48126446  746804.04356868 1672855.80520441 2001840.80844583
 3243186.16888445  279892.30389853 2430378.04511325  997654.45136942
 1751175.24665255 1304037.55617228 3459803.96890342 2296441.23163291
 1153746.40007302  816965.9660235  3250338.20252208 2318009.21544314
 2319180.4025265  1710884.47591427 1899657.33468598 1892542.46839583
  911911.13829851 1777722.72509447 1906299.78122057 1746005.25178374
 1199890.3100695  3385491.15066229 1646021.35039147  230770.69575648
 1181133.32404811 1751444.38822477 1467803.76330234 3726904.71054776
 1836816.99095246 1954298.09692248 1437233.45675348 3578509.51751253
  838825.30186066 2603853.84506105 1454289.60596227 3308780.00983778
  917436.03586704  992038.83179329 1078444.13418482 1600077.7165478
  626334.25435111 1443790.34760234 1237997.10943104 1628550.5036702
 1161844.37745016  514133.46156159 1174709.44370525 2415813.53232171
 3334187.10174364  701395.94501669 3197661.06744438  615076.92024472
 2956606.57662275 1828998.14073116 2462233.76839915 2113102.76604316
 1710913.32646156 1266907.63391295 1711004.70260472 2160236.39009922
 1012114.21568098 4510285.78282494 1294684.66161155 1160971.64952985
 3149728.74772224 1297604.1166724   513437.68513647 2552993.32239175
 2647120.20746452 1943762.72213651 1262242.67192427 2933044.79850274
 2864343.44694368 2575125.53496675  771417.1138917   833778.67992611
 1935096.37516623 1009100.90598416 2890380.1491462  2108968.03119802
  951423.46345414 1134557.94184084 1802408.01424002  857376.69667858
  831864.74090412 3713741.16855224  409152.41036841 1884517.26153384
 3128719.7039122  1230868.37069801 1350963.39794399 1613602.66080878
  680521.11008416  980543.99203192 3458020.51807722  635794.9313075
 1730775.57917826 1040264.18720934 1667798.1601065   948359.53319815
 2829238.17056974 2118703.67236973 2217843.15796008 2326814.32466379
 2959607.15650959 3321155.38450065 1930551.72294893 4576082.5492913
  722389.08174559  657033.18645968 1635895.2321864  1241035.0242098
  956947.44316571 1528388.84734757 1779737.11018265  921538.71917876
 1636472.7174728  1480378.46285159  821843.07553069 1179615.82779158
 1163425.5259579  2041932.62910204  890007.08243494 1628998.03548542
 2462097.03867636 2115012.62749675 1972590.88767522 2450574.94046394
 1212646.47857793 2142168.31553852 1458393.3300376  2675133.10479449
  851400.72610125 1215040.05679064  826230.5961304  3360810.95860855
 3232145.18348846 1299771.76781575 2001580.70675275 3015776.00323815
  946674.54461329  505692.01374848 3466884.13993065 1576662.81714371
 1698112.85538404 3779149.09155617 1448894.73585881  976980.72187595
 1801513.54559049 2327999.96917228 1816854.73643158 2404754.29081695
 2854602.60294271 1500745.92002379 1035482.93617587 2616154.91620844
 2122145.44075288 1263873.29076004 3877686.1105117  1346663.26639857
  490005.16970236 2131507.39520206 2540980.9429904  1536580.87162846
  779652.29945448  589143.25451578 1210093.19241409 1779578.25378497
 2477694.02735335  515499.45568044  591901.43699075  450515.36155254
 1446149.7157007  4077048.12594462 2812970.65898983 4043084.27721902
 1389249.32760778 4052881.14442088 3738105.4562947  1173646.43146759
 2001467.42053766 2385348.6156008  2261359.4097794  3601526.92586388
 2583999.6282769  1495838.36952374 2280531.50176675 1350231.39596666
 1642849.60274206 1096434.72090371 2484502.50412362 3160531.49489108
 2456103.58237159 2231795.77743618 1556311.35486934 1725964.64385537
 1321083.84443896 1435764.94568551 1262248.47307056 1850521.70488013
 1756535.77046992 3105656.39629667 2675150.14230229  165957.69334487
  516554.98312378 3624277.33024578 3179243.90643183 4200329.70162874
 1412297.04712476 1673647.95106636  686783.48445199 1751792.28458918
 1004983.64647053 2355366.49313073 2120465.65168493 2237091.99919262
 6222150.08104239 2128792.12913821 1346297.10488808 1842190.61614482
 2903847.41392354 2409812.39897468 4607607.81991926 2706915.78516799
  720174.19092612  585564.73830882 2500124.09914766 2575454.36407666
 1242689.48395022  960255.9711884  1388572.54346176 2048366.82799867
 2555272.10725663 1493680.14194442 3240786.93827594 1443774.60652118
 2254044.20739545 2118577.45054213 1221364.38730902 1402549.10117142
  891879.11774771  686159.97493466 2128043.57803831  204946.31544948
  869874.74566533 3410787.66023688 2319724.06948602 1332284.5788885
 2766745.16186784 2404646.24609712 1578429.10804929 1471884.58062076
 3070649.21895156 3444362.91885527 2826266.96390316  895405.29136171
  711752.3999974  2446676.73972482 2220757.87483688 2325031.13950401
 1776237.34164909 1731033.39498783 1354056.39168775 1045788.92790488
 2501675.72494704  446964.02764923 1321908.43654656 1470240.18099057
 1472102.64466774 2810430.85138637  663265.73093744 2461233.4101278
 3486395.23859429 1946357.36903532 5647096.53090505  739959.03458449
 1021875.18832911 1078373.51198755 3957252.47477038 1427712.96507845
 1133280.43091164 3598852.93761771 1848891.30439946 1501563.98925028
 1568001.16466303 1023899.4347133  1494402.1328506  3129496.2375176
 3145732.206079   3662063.01764288 1844897.49617092 1573844.61798804
 1554533.37453269  894509.27526374 2741112.2051645  1924737.9712348
 1278735.48940355 1051303.00451613  585551.16571239  744769.11547685
  412569.93664485  610502.87429408 1994693.74194129 1360238.31263789
  798415.58243314 1455426.33991237  855230.26362753 1220478.06664606
 1281661.59137151 2405881.63297764  709877.25416853 2299118.78182863
 1360880.54152138 2003569.48937568 1735098.9025126  2583082.04193238
  281894.27862479  987960.01454891 3474108.57810344 1273811.01647287
 1490945.84743358 1107779.77964711 1612192.26625707 2482664.31711351
  447989.50274601 2775314.8872215   389009.11022822 1908569.56516376
 1926707.54465917  953028.33892517 1127850.89733898 1498215.8989664
 1414007.02880469 3465120.27805614 2405861.31545753 1405013.85655254
 2414594.59243926 1494796.09992963  970707.13998171 4028040.47216379
 1920015.61170927 5600944.80150977 2635562.05427049  661953.21566456
 1596449.54321167  367595.76044657  903510.81019844 1000517.36637688
 1105345.84378827 2490667.90640596 3481884.54141261 1575534.17400013
 3022141.31655965 1045528.28107615 1857264.42182301  886343.32492972
  976122.12249298 2857876.38123084  909936.80635682 1397211.83414884
 2002734.82940993 2521518.29337468 3587500.35028682 1035670.13855518
 2997886.06495742  412071.08508187 1749094.43485199 1464153.61811524
 2286017.5560871  5645041.3870376   732579.99936587 2737699.18999986
 2273729.15005228 1340409.59856671 1072912.23218269 2196706.59301713
 2208234.5426599  2130901.99455506 4173089.86808892 2562463.46054614
 1343629.86737757 1125327.37767597 1751514.20580892 2270891.04021397
 1219205.07316472 2826868.52744417 2288777.07735003 3037297.68775155
 2495130.4105278  1959444.89318216  323510.20425812 2346173.05687157
 2884062.96161048 1189118.2571173  2517415.33605728 3389159.4588111
 2019501.24420077 1218746.47806702 1245405.50096557 1537816.44664356
 1957146.01428282 2307367.17916879 1787072.95648747 1741421.1247541
 1142314.9133346  2998448.89426492 1041633.26371    2788019.28873202
 4750728.59887089 3455238.3360751  1583216.70288939  806494.21697447
 1291314.15050636 4931215.49648839 2027260.73998191 2317652.40114365
 3321060.79789017 2221334.10839484 2723999.91723501 1037736.09779142
 1376646.38320644 1977983.20599282 1869479.16325051  833309.5957904
  605895.05010768 1740186.31870292 2217362.10690314 3040818.87522454
 2140961.67569846 1300084.17471473  606030.80616285 2588344.53571551
 1141455.48846419 2376255.5954312  2256037.00563553 1287327.68713464
  625442.93151371  688938.1200527  1854313.08468952 3511819.99793574
 1081021.81193599 4064490.03907451 1396517.1809339  2644005.10399502
  381778.70814336 2781613.75808396  808355.95309455  713232.1256957
 1418716.00657345 2312917.78066701 1303621.14458804 1952798.11072071
 1864002.36188709 1417916.69581567 1467295.88189911 3198382.81244574
  277209.51557202 2415244.11517137  976359.85282613 2550233.68888872
 1203055.21092244 3099585.88902576 1051186.76754323 1172313.11293848
 4436694.67270572 2428637.72279086  890571.26703748 1014556.34072446
 1578784.6990057  1737668.81330847 1868338.0147567  1679102.6081861
 1690021.35355722 1349407.57837586 3066399.76683117 3531407.90950109
 2562869.12611068 1549654.90185199 1139063.07739727  691867.18233767
 1986341.19718882 2707438.51193872 1269175.87450408  700649.20512972
  669112.83158368 1625663.88745825 1135318.05960093 2200750.91658162
  514831.69818571 2760782.85097681 1811316.36984527 1630683.16036323
 1492514.82595174 1024889.15970242 1576726.71025569 2406304.24707686
 2547187.90980732 1290509.63545629 2080513.94224652 1512301.10082726
 2316931.13164962 5246512.494653   1238965.71861373 1253232.90735521
 1571754.89842313 1815232.06300932  833169.5704164   957752.68585544
 1277717.15581633 1524831.65060454 1737653.978253   2017301.73514505
 1097145.11477056  981188.81938764  935582.35159088 1350240.22223404
 4491104.10059475 2306940.18106715  654640.11743786 1361387.09055023
  570999.91818405 3440135.08352095 2187704.38017112 1785959.96122482
 3958303.43824363  606830.79365531 2534644.4758847  1224497.38294452
  924008.07801789 3751138.26202587  428799.82180586 2410282.1931691
 1645389.46582498 2554868.47591927 2038464.71711346 1052554.60430105
 1219894.70409803  574214.49763829 3752293.75668868 1821104.09063683
 1906747.37966638 1028552.83334967 2715551.37995387 3621433.64590184
 1324385.11145108 1432276.1438371  2101336.38813321  704792.71677047
 3142542.72469382  599375.67035536 1662644.04017443 1317898.6497997
 3809877.08952294 1343081.43167544 2131477.15874816 2372200.80170132
 4737417.05061237 1521677.28690538 1668433.50309128 2256233.23704322
 1497201.36570514 2922883.02992106  920704.38752135 1319947.24086645
 1537055.15947845 1894091.76566741 1241931.2166746  1469863.05991173
 2885347.38061378  478217.09060294 1702909.91585457 3037833.22481435
 1786219.28954972 1113928.89952303  960321.67456447 2522992.65463631
 1909456.42831182  921037.28633618 2794802.30336921  969587.19922636
 2299824.40224926 2347935.43896363 2958325.79110628 2005554.08001397
  729529.89191262 1047770.65370037  974895.71839144 2462768.8193577
  926037.37261464 1927525.05230196 3375561.31593741  993224.06682597
 1485362.03482749 1542442.05263933 1668778.4280062  1924433.03217096
 1264770.81817582 2544686.56564442 1741011.87208873 2505379.48222932
 2335410.73531411 1320528.82010315 2117224.23135328  791105.61878558
 2509256.56600109 2117539.38239406 3059179.7472951 ]
2025-06-24 07:58:59 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:58:59 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:58:59 ERROR Can not run the algorithm
2025-06-24 07:58:59 INFO Run function 18 complete. FEHistory len: 783, AOCC: 0.0000
2025-06-24 07:58:59 INFO FeHistory: [152383.38192997 114327.52008532 198828.25978081 100742.22131867
 157783.90697972 131939.46359317 125180.31946414 162359.75779305
 153335.23185905  86256.03791047 136723.25219717 142029.05274412
 145669.35509928 181304.22622358 109383.82243538 126179.09924912
 118392.61672146 159781.03474002 185774.21562784  74821.41096546
 130139.84051749  91220.62552209 120200.44359311 191853.46086071
 231218.84056469 123378.09912562 120430.46391457 158402.21235885
 204317.6486114  168666.03759075 147423.59407136 192557.77816987
 173649.45934608 132849.45729382 145373.45046707 203739.5276501
 178547.14447795 154303.08679839 170449.28940652 149121.79099477
 154307.9645903  101211.14346241 202737.75903852 248930.65786052
 127010.04427886 148121.81211159 163492.08354649 170791.38357212
 141467.49931608 129562.29197401 132574.57581317 165112.54971963
  96227.21372939 157919.56280392 136711.63781007 128547.78748445
 152617.12381722 139991.36404439 122915.66507373 111647.83827089
 158646.61833     98461.52928831 147547.57353006 107367.35337519
 114337.32195757 186367.19115027 143141.36358252 237928.30074373
 194409.71467775 135648.02598269 139873.76684906 121681.04893013
  99249.74305721 192899.38830344 108794.55297101 156611.18324683
 121840.62022847 121611.03221402 170604.82876094  88757.87338481
 130777.36661894 121383.18740633 197687.00788301 123815.25753564
 122726.84953018 159131.05700921 165594.25063636 149171.72628908
 138913.47359973 126855.80099056 100224.99383155 132230.09163434
  80383.64711848 112014.01340541 167604.73961246 209435.9261552
 173434.87522203 121444.76088382 205933.16769421 117679.55152586
 256427.79331245 173386.0432521  103287.05448955 154513.84118284
 149801.85423278 173738.64476549 104393.89791587 156541.93417144
 140671.64654366 163300.34851411 175883.95003466 170226.78590834
 157892.52582292 125588.92061236 136893.7992893  155002.23722424
 160820.2090888  133051.64009366 140461.73955253 232179.95206657
 139792.37807317 113365.47285306 114805.18631897 133103.6035707
 149015.75485849 133273.46620239 202653.93708291 173780.35693431
 190988.73843794 124296.33345689 110559.5977772  185078.84608839
 125851.24848224 159823.80198727 119188.76431328 170230.85966191
  99780.87072461 163293.59744138 187907.387684   149240.06773483
 195711.04336197 150094.70891538 173291.18260635  91145.14331286
 149128.76667912 134828.78488096 115404.30976313 180816.53335105
 164758.26343594 133662.14179212 145658.90526136 151846.06731401
 185732.69055538 245755.52550236 147475.46723658 111998.9859903
 213327.18866917 107421.04871103 124762.54885928 117471.60095021
 157477.47536126 197386.49604516 131494.27719414 139303.30602995
 235788.8734108  209966.78441036 171766.44573951 141769.70673252
 167078.37737066 130877.59901706 128878.2448169  102112.39723708
 113983.79762077 245006.70293237  96121.01360927 178121.18454586
  96903.7686833  184206.25331519 166693.91409506 170126.00737102
 102509.96392471  94411.51171052 110622.51738815 108091.32242212
 261217.6048158  169699.4149714  221754.38055226 134007.41565345
 102496.8371175  244273.69488145 114326.22379007 126805.13724631
 146765.7758929  128002.13029897 142401.15928933 170522.30862193
 120097.61449916 101509.55801897 101793.52128195 102198.44631294
 218757.0921468  156104.64643045 237185.01599928 111564.57919743
 131593.88775245 168403.20115342 175464.41703678 140607.8422436
 109640.99786459 120911.3928509   97957.89154671 182360.48473963
 162780.10963519 144047.20152731 123462.63285851 138136.69579144
 155501.47036586 140567.56046905 197363.85213236 105489.63111186
 208474.57791602  94221.12423996 136579.77264304 208907.56593761
  86143.21599004  94637.33346386 127747.53898699 113060.21899998
 136439.99726605 106952.72863104 133581.3233814  112073.99911292
 158885.79043268 121420.12033117 139288.7730096  130762.80739268
 120805.2504317  157359.23285683 165369.28694311 142858.49549955
 154729.62537169 139638.90797753 167740.06253602 195519.66357617
 105851.38891706 138375.66272838 113805.66156765 145744.24049837
 181878.96912945 218360.24903213 110670.47428314 105851.26041845
 172730.13629737 118478.69040956 202478.65052054 115433.72517856
  94358.18216471 181728.21548406 140386.57813468 132632.33868828
 112102.46137145 177899.07377784 149565.31535704 142265.2284619
 148605.55627745 121143.22432981 163453.91936385 223363.41974943
 126141.70475624 131657.70300309 166631.27460242  90124.47398732
 127524.09321523 120641.77726992 114535.32594203 175373.51647502
 125925.23139516 148854.98019632 190561.30496261 113635.69862583
 163011.18534437 102169.60025037 174045.41534325 149077.24116298
 137143.22091699 202514.5402069  177828.64730623 178068.89377266
 129074.42525788 123652.43139    115573.56628311 225273.26721643
 173511.50985128 202313.74966632 132384.73011277 179769.33665384
 127897.45706533 123774.80699141 170405.69525905 194386.6427748
 209203.61604601 150742.22243199 175312.02503416 137212.43129711
 197246.11981969 123639.27495738 157043.96674011 252280.40373095
 193265.26973784 155226.38941406 125759.24383305 197021.48383874
 110292.9365152  155253.96363421 127263.31365785 181951.41872186
 211199.29004374 199582.07832882 150384.85353284 127517.85562098
 162184.83720982 156988.16641818 103636.38430287 141075.59885968
 184871.41357463  65543.06739157 170023.02216529 137035.06685888
 223037.03773324 171172.47038063 209646.37098816 161631.8292259
 209572.86796693  94915.795933   129860.06840762 218915.63897208
 173973.51657627 132794.68265321 120105.02667649  93053.91830231
 138596.53491992 170496.12673903 199981.42715089 122157.59924507
 120020.79391125 173253.41677868 175506.00575381 156689.54027072
 193649.6186851  139891.73685669 158585.32865159 138932.88598257
 177900.41494461 185560.45235738 191245.71844171 212912.5731146
  88491.65285611 130282.04414427 160723.84527527 118698.71674684
 142705.99636895 131797.40146803 114749.89574455 107207.14531024
 166154.92284674  96303.26076777 159057.61344758  89980.57240393
 100815.92607407 115200.9249499  106998.59255202  97192.09822772
 159252.55259484 103594.46037105 213227.14560534 105071.01550868
 146763.29241035 136702.44712772 137956.54944294 136570.41913943
 131493.79015597 143676.39666317 156061.59156885 100406.48594843
 163553.52925052 128759.95013562 119409.89099251 235089.16524862
 230448.34687132 120492.07783118  67061.42572412 139523.18173373
 114372.01332316 158322.70148883 125847.69388964 182716.30329994
 111249.03385606 134286.67176872 228624.12099399 141658.14161578
 133155.5352064  156556.99161879 214106.38251749 168647.70619639
 160777.53119314 231059.64445757  92719.04685938 126951.56624747
  73016.73139149 140296.41365915 156821.90645645 208081.56692758
 151666.86140399 152462.66425154 176561.12327589 248450.22501772
  67410.62240469 154442.54195248 159295.37386996 233366.54613638
 129853.30987192 141471.46759204 151018.01625958 144041.27621423
 156432.57267233 164338.32822405 211918.97979121 202347.91225088
 119766.35168796 179094.60167516 185688.5917759  189915.07301947
 173356.86225418 112381.2000501  268261.46406543  97988.27604513
 160384.3407587  122861.46048778  87247.845644   178942.24317821
 126765.6872399  110756.00718769 181449.94107698 145686.29454258
 167668.52861926 136278.59110321 121079.93244702 151602.45063425
 121901.39687873  98907.75354816 213494.28467966 113977.19014541
 241323.88854991 150638.84044733 172549.92521329 265083.63846383
 148416.66444729 173507.64734194 117673.15011466 147641.28854138
 104215.2802114  179113.38857477 298528.45526551 130517.5361404
 183479.58708224 158261.42401865 170678.05746119 138935.11523524
 118520.25420254 165463.18142374 164985.88565531 115229.64046692
  97977.97218504 178533.05197394 152618.80119833 142813.02670233
 111528.37556981 154125.37009803 133190.81178487 227439.02170466
 206001.85865539 172993.99306041 205950.79468879 160819.95984596
 158767.20961923 155540.08427713 208165.57813133 201119.67216526
  80845.191763   220525.07683335 203504.76934091 203127.94073339
 110361.08700983 149690.74287468 144485.11388688 185165.02038691
  94799.17569276 142616.70692494 196653.60090881 134337.0650119
 166272.30684881 137823.06529336 210802.89390839 151946.10995231
  99751.35361559 114131.7140599  147589.2516022  148998.56826681
 105975.02539852 109220.98607093 168497.97627332 107771.45190461
 163447.06995312 335747.15951739 116581.01019935  98049.58192749
 157226.71752135 156370.01461156 153865.34729605 155848.59485446
 131257.56264072 135140.34847722 120136.78778252 127660.11120393
 224255.09518695 161892.56887809  91717.10602522 160434.01443327
 107069.83591318 134143.40546528 119641.29286291 102473.54252977
 151805.14737791 209098.11085862 193468.82974815 131470.45630681
 118935.88369598 126745.75034471 221643.34224861 170193.0612712
 104336.4422375   82736.61800393  92257.06917721 169255.79311086
 191003.45405453  97761.89826625 114868.40292817 215268.70048622
 189502.4053024  157132.74513011 197342.91249235 124730.99911818
 161909.22506254 181563.50284465 194374.06729035 122996.23654136
 146039.35925018 146234.31625072 122650.32821413 173356.68447385
 135233.51654717 104022.98311969  98842.21168134 133664.48137951
 148480.50121645 109065.50868679 153478.89289585 158197.45234906
 107599.93346004 197618.43556918 121515.56558213 147881.63573547
 179832.29759591 126648.1855135  139162.43500144 117115.19245698
 149960.99427303 132551.78271878 157231.78971489 169917.68911208
 117356.35306259 119140.98676947 158544.29984533 120126.05176105
 104540.64483523 148203.99902569 160125.68235249 127190.68994304
 169906.13067878  92555.31067323 230674.22289734 159798.77045568
 134894.34729631 129045.87023111 143214.0596892  120346.54390929
  87496.89495284 125375.66222336 139020.9318038  192773.32880485
 113032.232465   151148.7574094  176317.54958558 170944.7658401
 187145.64430141 117433.37674429 182700.24354299 129995.04892623
 101626.82310582 141295.19830966 100440.03112979 175952.48974597
 158091.16745232 179834.31977213 103793.19181703 164815.1239616
 158283.79022245 225326.73017414 196917.34418919 204219.40529153
 168981.14912082 176635.61503811 121014.27971627 107909.42040877
 160165.8128006   83136.42765789 203481.9485042  121688.58584384
 159359.07090694 121648.3080189  104539.0645755  145063.69778554
 163319.90469804 158167.55984277  85363.92222932 164521.48269764
 127878.02378209 139215.84289899 106711.02183388  94494.11340913
 185125.30438083  78217.22863676 183064.19933127 152383.28647779
 104850.13620895 164301.41212467 137555.42115123 174944.86216835
 176022.61438726 180872.13597802 165443.91716596 222039.38706665
 127583.41566628 174326.69422927 118817.3801292  180453.58431564
 134490.99888736 101926.99185255 180071.2619167  192516.18721642
 178601.58867015 156660.73426108 167038.14716446 122357.12097223
  53033.73745019 152831.14185438 113939.66979839 241981.26168798
 177208.80107573 184055.57306111 147853.22014576 125091.93921938
 143233.95359147 139089.85421184  97450.64005949 144934.22538109
 139939.26069699 226380.91401652 157597.48938288 116734.5696333
 121135.22184314 117487.06163814  99939.14969267 139990.8728666
 117314.29006347 130607.55407182 132708.920009   174491.19705854
 106486.44054846 239078.34397857  80836.40214546 141904.05450679
 171179.96715166 150477.050254   203896.01341646 100383.63257931
  97033.03723808 148393.11037039 187700.51266798 224836.39481466
 145291.30891858  98933.78291453 124885.15953174 128726.08722393
 147961.91896133 179870.21608874 229417.83830641 162625.96520086
 209646.62605473 139570.95739294 134643.52504334 147186.92879863
 207935.93921539 147247.84899456 122084.29412457 155064.15314056
 195261.3230839   99124.04762488 129607.16902633 109692.48178572
 173854.03741311 156141.2387698  118611.03458031 203288.47294723
 150229.74129096 203539.11976639 179836.64774955 195228.81033746
 154181.0137342  124188.71143184 179427.27400972 108769.5990203
 135621.43424481 112268.85723106 130697.87507783 135998.01798288
 101173.1235135  170233.9953976  161645.93539234 142124.28919951
 139887.68097739  98401.4207227  132777.20322782 164453.12699189
 152090.0394822  253033.26785895 207830.52976431 138840.15112753
 147111.56161567 139814.76805642  98997.48117864 136961.01761534
 193402.58586573 177461.33340765 127542.59545205 146676.35013578
 203452.36625504 190657.59344519 198201.02802354 154011.92437804
 114592.78161252 197196.7187474  133923.84085646 172738.50149485
 151147.84130205 164899.16674908 128704.54573536 113643.1163006
 150201.1674492  153293.14635849 183554.99349665 154501.22709878
 148283.04087934  85757.92346212 170828.97571418 100210.82150665
 166117.13000827 173620.7978092  168525.3894643  185195.84645206
 124068.3676414  156526.56757726 118895.73316724]
2025-06-24 07:58:59 INFO Expected Optimum FE: -5000
2025-06-24 07:58:59 INFO Unimodal AOCC mean: 0.1476
2025-06-24 07:58:59 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:58:59 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:58:59 INFO AOCC mean: 0.0492
2025-06-24 07:58:59 INFO Weighed AOCC mean: 0.0148
2025-06-24 07:58:59 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-24 07:58:59 ERROR Can not run the algorithm
2025-06-24 07:58:59 INFO Run function 6 complete. FEHistory len: 2004, AOCC: 0.1481
2025-06-24 07:58:59 INFO FeHistory: [-183.33208745 -183.25615989 -183.45019196 ... -183.36266169 -183.3319804
 -183.41908405]
2025-06-24 07:58:59 INFO Expected Optimum FE: -186.86405320391498
2025-06-24 07:58:59 INFO Good algorithm:
Algorithm Name: EnhancedArchiveGuidedDE
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 66.8205344574657, archive_size: int = 430.6706551202469,
                 initial_F_scale: float = 1.070672425901928, F_scale_variation: float = 0.3912954791901705,
                 acceptance_threshold: float = 4.500513537814433e-05, archive_update_threshold: float = 0.7670352679183965):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
2025-06-24 07:58:59 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-24 07:58:59 ERROR Can not run the algorithm
2025-06-24 07:59:00 INFO Run function 13 complete. FEHistory len: 2004, AOCC: 0.0000
2025-06-24 07:59:00 INFO FeHistory: [1357482.14367334 2407590.78307212 1953464.51243088 ... 1602738.11176633
  742170.16548038 1450165.28701888]
2025-06-24 07:59:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-24 07:59:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-24 07:59:00 ERROR Can not run the algorithm
2025-06-24 07:59:00 INFO Run function 18 complete. FEHistory len: 2004, AOCC: 0.0000
2025-06-24 07:59:00 INFO FeHistory: [149013.84053212 136589.08973152 141579.69140994 ... 150504.21461836
 103835.17641827 171810.29961156]
2025-06-24 07:59:00 INFO Expected Optimum FE: -5000
2025-06-24 07:59:00 INFO Unimodal AOCC mean: 0.1481
2025-06-24 07:59:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-24 07:59:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-24 07:59:00 INFO AOCC mean: 0.0494
2025-06-24 07:59:00 INFO Weighed AOCC mean: 0.0148
2025-06-24 07:59:00 INFO Generation 2, best so far: 0.14616794743172618
2025-06-24 07:59:00 INFO Population length is: 12
2025-06-24 07:59:00 INFO --- Performing Long-Term Reflection at Generation 3 ---
2025-06-24 07:59:00 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

A simple algorithm might do well on one group but will fail completely on others. To guide the evolution towards a true generalist, our evaluation metric is a weighted AOCC fitness score, where performance on the most difficult Multi-Component problems (Group 3) is weighted most heavily.

Therefore, an algorithm that makes even small progress on the hard, multi-component problems will be considered superior to one that is only good at the easier problems. Your primary goal is to design an algorithm with powerful global exploration capabilities, as this is the key to achieving a high weighted score.
    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average weighted AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 1.5417e-02 |             AOCC Score on Unimodal instances: 1.5417e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive guided exploration for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive guided exploration for multimodal optimization.
# Code:
class AdaptiveArchiveDE:
    """
    Combines adaptive Differential Evolution (DE) with an archive to enhance exploration and exploitation in multimodal landscapes.
    Uses an adaptive mutation strategy and tournament selection for efficiency. The archive helps maintain diversity and guides exploration.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F_scale = 0.5  # Initial scaling factor
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Adaptive Mutation
            self.F_scale = 0.5 + 0.3 * np.random.rand()  # Adaptive scaling factor with variation

            #Select pbest from archive (if available), else use current best
            if self.archive.size > 0:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index, :-1]
            else:
                pbest = population[np.argmin(fitness_values)]

            a, b, c = self._select_mutants(i, len(population))
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring.append(mutant)

        return np.array(offspring)

    def _select_mutants(self, i, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        #Efficient archive update, removing duplicates based on similarity and fitness
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        self.archive = np.array(new_archive[:self.archive_size]) if len(new_archive) > 0 else np.array([])
        return self.archive

```

### Rank 2 (Overall AOCC Score: 1.5176e-02 |             AOCC Score on Unimodal instances: 1.5176e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalDE
# Description: A Differential Evolution algorithm with adaptive mutation and archive-based diversity management for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveMultimodalDE
# Description: A Differential Evolution algorithm with adaptive mutation and archive-based diversity management for multimodal optimization.

class AdaptiveMultimodalDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  #Increased archive size for better diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive with diversity check
            self.update_archive(offspring, offspring_fitness)

            # Selection with elitism
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adaptive Parameter Control (Adjust F and CR based on progress)
            self.adapt_parameters(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            # Select pbest from archive (if available), prioritizing diversity
            if self.archive:
                pbest = self.select_diverse_pbest(population[i])
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            #Differential mutation
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])

            # Binomial Crossover
            crosspoints = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crosspoints, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity and fitness
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or self.diversity_check(offspring[i]) :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def select_diverse_pbest(self, current_solution):
        # Prioritize pbest from the archive that is most distant from the current solution
        distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - current_solution, axis=1)
        return self.archive[np.argmax(distances)][0]


    def diversity_check(self, solution):
        #Simple diversity check: Check distance to existing solutions in the archive.
        distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - solution, axis=1)
        return np.all(distances > 0.1 * (self.upper_bounds - self.lower_bounds).mean())


    def adapt_parameters(self, fitness):
        # Adapt F and CR based on the convergence rate.
        # Simpler adaptive scheme for demonstration;  more sophisticated methods are possible.

        std_fitness = np.std(fitness)
        if std_fitness < 0.1 * (np.max(fitness) - np.min(fitness)):  #if convergence is detected
            self.F_scale = min(self.F_scale + 0.1, 1.0)
            self.CR = max(self.CR-0.1, 0.1) #Increase exploration
        else:
            self.F_scale = max(self.F_scale - 0.05, 0.2)
            self.CR = min(self.CR + 0.05, 0.95) # Increase exploitation


```

### Rank 3 (Overall AOCC Score: 1.5168e-02 |             AOCC Score on Unimodal instances: 1.5168e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided exploration for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided exploration for multimodal optimization.
# Code:
class AdaptiveArchiveDE:
    """
    Combines Differential Evolution with an adaptive scaling factor and archive management 
    to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100  # Adjust as needed
        self.archive_size = 500 #Larger archive for better exploration
        self.archive = []
        self.F_scale = 0.5 #Initial scaling factor
        self.F_scale_variation = 0.3 # Variation range for F
        self.CR = 0.9  # Crossover rate (can be adaptive too)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall = population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            best_index = np.argmin(fitness)
            if fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness[best_index]
                self.best_solution_overall = population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand() #Adaptive scaling factor

        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 4 (Overall AOCC Score: 1.5114e-02 |             AOCC Score on Unimodal instances: 1.5114e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveArchiveGuidedDE
# Description: Hybrid DE algorithm with adaptive scaling factor and archive guided search for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveGuidedDE
# Description: Hybrid DE algorithm with adaptive scaling factor and archive guided search for multimodal optimization.
class AdaptiveArchiveGuidedDE:
    """
    Hybrid Differential Evolution (DE) algorithm with adaptive scaling factor and archive-guided search for efficient multimodal optimization.  Combines features of ArchiveGuidedAdaptiveDE and EnhancedArchiveGuidedDE.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # Initial scaling factor
        self.CR = 0.9 #Initial crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)
            
            #Adapt CR based on convergence
            self.adapt_CR(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand() #Adaptive scaling factor

        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            #Differential mutation with crossover
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            crosspoints = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crosspoints, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adapt_CR(self, fitness):
      # Simple CR adaptation: increase CR if convergence is slow, decrease otherwise
      std_fitness = np.std(fitness)
      if std_fitness > 0.1: #Threshold for slow convergence
          self.CR = min(self.CR + 0.05, 1.0) #Increase CR
      else:
          self.CR = max(self.CR - 0.05, 0.0) #Decrease CR

```

### Rank 5 (Overall AOCC Score: 1.4934e-02 |             AOCC Score on Unimodal instances: 1.4934e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveHybridDE
# Description: A hybrid Differential Evolution algorithm with adaptive scaling factor and population diversification using Gaussian perturbations.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridDE
# Description: A hybrid Differential Evolution algorithm with adaptive scaling factor and population diversification using Gaussian perturbations.

class AdaptiveHybridDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.F_scale = 0.5  # Initial scaling factor
        self.CR = 0.9 #Crossover rate
        self.population = None


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            # Adaptive parameter control
            self.adapt_parameters(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = self.population[a] + self.F_scale * (self.population[b] - self.population[c])
            
            # Binomial crossover
            jrand = random.randint(0, self.dim - 1)
            for j in range(self.dim):
                if random.random() < self.CR or j == jrand:
                    offspring[i, j] = mutant[j]
                else:
                    offspring[i, j] = self.population[i, j]

            #Gaussian perturbation for diversity
            offspring[i] += np.random.normal(0, 0.1, size=self.dim) # Adjust scale as needed.
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring


    def adapt_parameters(self, fitness):
        # Simple adaptation: Increase F if the population is converging too fast, decrease otherwise.
        std_fitness = np.std(fitness)
        if std_fitness < 0.1:  # Adjust threshold as needed.
            self.F_scale = min(1.0, self.F_scale + 0.1)
        else:
            self.F_scale = max(0.1, self.F_scale - 0.05)


```

### Rank 6 (Overall AOCC Score: 1.4929e-02 |             AOCC Score on Unimodal instances: 1.4929e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveHybridSearch
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a local search, using adaptive parameter control and a diversity-aware archive.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveHybridSearch
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a local search, using adaptive parameter control and a diversity-aware archive.

class AdaptiveHybridSearch:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.archive_size = 200  # Increased archive size for diversity
        self.archive = []
        self.population = None
        self.F_scale = 0.5
        self.CR = 0.9 # Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Local Search Enhancement
            for i in range(len(offspring)):
                improved = self.local_search(offspring[i], offspring_fitness[i], objective_function)
                if improved[1] < offspring_fitness[i]:
                    offspring[i] = improved[0]
                    offspring_fitness[i] = improved[1]

            # Update archive (diversity-aware)
            self.update_archive(offspring, offspring_fitness)

            # Selection (tournament selection)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            self.population = self.tournament_selection(combined_population, combined_fitness, self.population_size)
            fitness = objective_function(self.population) # Re-evaluate after selection
            self.eval_count += self.population_size


            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adaptive Parameter Control
            self.adapt_parameters(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            #pbest selection from archive
            if self.archive:
                pbest = random.choice(self.archive)[0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            v = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            u = np.zeros(self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR:
                    u[j] = v[j]
                else:
                    u[j] = population[i][j]
            offspring[i] = np.clip(u, self.lower_bounds, self.upper_bounds)
        return offspring
    
    def local_search(self, solution, fitness, objective_function):
        step_size = 0.1
        improved = False
        for i in range(10):  #limit iterations to avoid excess computation
            neighbor = solution + np.random.uniform(-step_size, step_size, self.dim)
            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
            neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
            if neighbor_fitness < fitness:
                solution = neighbor
                fitness = neighbor_fitness
                improved = True
            step_size *= 0.9
        return solution, fitness


    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Diversity-aware replacement (replace least diverse)
                distances = np.array([np.linalg.norm(offspring[i] - sol) for sol, _ in self.archive])
                worst_index = np.argmin(distances) # replace the closest solution
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])


    def tournament_selection(self, population, fitness, num_to_select):
        selected_population = []
        for i in range(num_to_select):
            tournament = random.sample(range(len(population)), 5) #tournament size 5
            winner_index = tournament[np.argmin(fitness[tournament])]
            selected_population.append(population[winner_index])
        return np.array(selected_population)

    def adapt_parameters(self, fitness):
        std_fitness = np.std(fitness)
        if std_fitness < 0.1: #increase exploration if the fitness values are too similar
            self.F_scale = min(1.0, self.F_scale + 0.1)
        else:
             self.F_scale = max(0.1, self.F_scale - 0.05) #decrease exploration otherwise


```

### Rank 7 (Overall AOCC Score: 1.4846e-02 |             AOCC Score on Unimodal instances: 1.4846e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with an archive for enhanced exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with an archive for enhanced exploration in multimodal landscapes.
# Code:
class AdaptiveArchiveDE:
    """
    Combines adaptive Differential Evolution (DE) with an archive to enhance exploration and exploitation in multimodal landscapes.
    Uses an adaptive mutation strategy and tournament selection for efficiency. The archive helps maintain diversity and guides exploration.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.F_scale = 0.5 #initial scaling factor
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            #Adaptive scaling factor
            self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

            # Select pbest from archive (if available)
            if self.archive.size > 0:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness_values)]

            a, b, c = self._select_mutants(i, len(population))
            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])

            #simple crossover, no CR
            trial = mutant 
            trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
            offspring.append(trial)

        return np.array(offspring)

    def _select_mutants(self, i, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 8 (Overall AOCC Score: 1.4808e-02 |             AOCC Score on Unimodal instances: 1.4808e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: 
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 66.8205344574657, archive_size: int = 430.6706551202469,
                 initial_F_scale: float = 1.070672425901928, F_scale_variation: float = 0.3912954791901705,
                 acceptance_threshold: float = 4.500513537814433e-05, archive_update_threshold: float = 0.7670352679183965):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale #initial scaling factor
        self.acceptance_threshold = acceptance_threshold
        self.archive_update_threshold = archive_update_threshold
        self.F_scale_variation = F_scale_variation


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = self.initial_F_scale + self.F_scale_variation * np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * self.archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 9 (Overall AOCC Score: 1.4757e-02 |             AOCC Score on Unimodal instances: 1.4757e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-based diversity preservation.
# Code:
```python
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-based diversity preservation.

import numpy as np
import random

class AdaptiveArchiveDE:
    """
    Combines Differential Evolution (DE) with an adaptive scaling factor and 
    an archive to enhance exploration and exploit multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * dim  # Heuristic: population size proportional to dimension
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5 # Initial scaling factor
        self.population = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)
        
        while self.eval_count < self.budget:
            offspring = self._generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            self._update_archive(offspring, offspring_fitness)
            self.population, fitness = self._select_next_generation(self.population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness)
            self.F_scale = self._adapt_F(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            pbest = self._select_pbest()
            a, b, c = self._select_different_individuals(population, i)
            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_pbest(self):
        if self.archive:
            return random.choice(self.archive)[:,0] #select random solution from archive
        else:
            return self.best_solution_overall

    def _select_different_individuals(self, population, i):
        indices = list(range(self.population_size))
        indices.remove(i)
        a, b, c = random.sample(indices, 3)
        return population[a], population[b], population[c]

    def _select_next_generation(self, population, fitness, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness, offspring_fitness))
        sorted_indices = np.argsort(combined_fitness)
        return combined_population[sorted_indices[:self.population_size]], combined_fitness[sorted_indices[:self.population_size]]

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            return population[best_index], fitness_values[best_index]
        return self.best_solution_overall, self.best_fitness_overall
    
    def _update_archive(self, offspring, offspring_fitness):
      combined = np.column_stack((offspring, offspring_fitness))
      for sol in combined:
          already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
          if not already_present:
              if len(self.archive) < self.archive_size:
                  self.archive.append(sol)
              else: #Prioritize diversity in archive
                  worst_index = np.argmax([f for _, f in self.archive])
                  if sol[-1] < self.archive[worst_index][-1]:
                    self.archive[worst_index] = sol

    def _adapt_F(self, fitness):
        #Adaptive scaling factor: Increase exploration if convergence is slow
        avg_fitness_diff = np.mean(np.diff(np.sort(fitness))) if len(fitness)>1 else 1
        if avg_fitness_diff < 0.1: # Adjust threshold as needed
            return max(0.05, self.F_scale * 0.9) # prevents F from becoming too small
        return min(1, self.F_scale * 1.1) # prevents F from becoming too large

```

### Rank 10 (Overall AOCC Score: 1.4719e-02 |             AOCC Score on Unimodal instances: 1.4719e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided exploration for multimodal optimization.
# Code:
```python
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive-guided exploration for multimodal optimization.
# Code:
import numpy as np
import random

class AdaptiveArchiveDE:
    """
    Combines adaptive Differential Evolution (DE) with an archive to enhance exploration and exploitation in multimodal landscapes.
    Uses an adaptive mutation strategy and tournament selection for efficiency. The archive helps maintain diversity and guides exploration.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5  # Initial scaling factor
        self.CR = 0.9

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)

        optimization_info = {'function_evaluations_used': self.eval_count, 'final_best_fitness': self.best_fitness_overall}
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros((self.population_size, self.dim))
        self.F_scale = 0.5 + 0.3 * np.random.rand() #Adaptive scaling factor
        for i in range(self.population_size):
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness_values)]
            a, b, c = self._select_mutants(i, len(population))
            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
            #Crossover (optional addition for further enhancement)
            trial = np.where(np.random.rand(self.dim) < self.CR, offspring[i], population[i])
            offspring[i] = trial

        return offspring

    def _select_mutants(self, i, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

```

### Rank 11 (Overall AOCC Score: 1.4665e-02 |             AOCC Score on Unimodal instances: 1.4665e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive management for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveArchiveDE
# Description: Adaptive Differential Evolution with archive management for multimodal optimization.

class AdaptiveArchiveDE:
    """
    Combines Differential Evolution (DE) with an adaptive scaling factor and 
    archive management to efficiently explore and exploit multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F_scale = 0.5 # Initial scaling factor
        self.F_scale_variation = 0.3 # Variation for stochasticity


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(np.vstack((population, offspring)), 
                                                np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor with variation
        self.F_scale = 0.5 + self.F_scale_variation * np.random.rand()

        for i in range(self.population_size):
            # Select pbest from archive (if available), otherwise from current population.
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness_values)]

            a, b, c = self._select_different_individuals(population, i)
            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling
        return offspring

    def _select_different_individuals(self, population, i):
        indices = list(range(self.population_size))
        indices.remove(i)
        a, b, c = random.sample(indices, 3)
        return population[a], population[b], population[c]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive)[:self.archive_size]

    def _adapt_parameters(self, population, fitness_values):
        # Simple adaptive scheme: Adjust F_scale_variation based on convergence
        avg_fitness_diff = np.mean(np.diff(np.sort(fitness_values)))
        if avg_fitness_diff < 0.1:
            self.F_scale_variation *= 0.95 #Reduce variation if converging
        else:
            self.F_scale_variation *= 1.05 #Increase variation if not converging (up to a limit)
        self.F_scale_variation = np.clip(self.F_scale_variation, 0.1, 0.6) #Keep variation within bounds

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 07:59:07 INFO Full response text: **Analysis:**

Comparing AdaptiveArchiveDE (Rank 1) vs AdaptiveHybridSearch (Rank 6), we see that AdaptiveArchiveDE uses a more sophisticated archive update mechanism, efficiently removing duplicates based on similarity and fitness, while AdaptiveHybridSearch only replaces the closest solution, potentially hindering diversity.  AdaptiveArchiveDE also incorporates adaptive mutation, adjusting the scaling factor F dynamically for better exploration and exploitation. AdaptiveHybridSearch, while incorporating local search, lacks the refinement of AdaptiveArchiveDE's adaptive strategy and archive management.

Comparing AdaptiveMultimodalDE (Rank 2) vs AdaptiveArchiveDE (Rank 9), both use archives for diversity but AdaptiveMultimodalDE prioritizes diversity in pbest selection and archive updates, resulting in better exploration of diverse optima. AdaptiveMultimodalDE also implements adaptive parameter control (F and CR) for fine-tuning the balance between exploration and exploitation based on convergence rate. AdaptiveArchiveDE (Rank 9), however, employs a simpler adaptive mechanism only adjusting F.

Comparing AdaptiveArchiveDE (Rank 3) vs AdaptiveHybridDE (Rank 5), we observe that AdaptiveArchiveDE (Rank 3) benefits from a larger archive size for enhanced exploration and has more carefully tuned parameter values. While AdaptiveHybridDE uses Gaussian perturbations for diversification, it lacks the focused exploration strategies present in AdaptiveArchiveDE (Rank 3). Its adaptive parameter control is also simpler.

Comparing AdaptiveArchiveGuidedDE (Rank 4) vs EnhancedArchiveGuidedDE (Rank 8),  AdaptiveArchiveGuidedDE shows improved performance. The heuristic parameters in EnhancedArchiveGuidedDE appear less effective based on the evaluation metrics. Both leverage archives and adaptive scaling factors, but AdaptiveArchiveGuidedDE's strategy for adapting the crossover rate (CR) shows a clearer advantage.

Comparing AdaptiveArchiveDE (Rank 7) vs AdaptiveArchiveDE (Rank 10), the difference is subtle. Rank 7 has simpler adaptive parameters and lacks the crossover implementation present in Rank 10.   However, the performance difference is not significant.

Comparing AdaptiveArchiveDE (Rank 11) vs AdaptiveArchiveDE (Rank 7), Rank 11 shows similar performance despite a more adaptive F_scale_variation parameter, which seems to not provide a significant advantage in this case.  Both use simple archive updates and lack sophisticated diversity preservation mechanisms.

Overall: The top-performing algorithms consistently utilize adaptive scaling factors, effectively manage archives to maintain diversity, and employ more sophisticated archive update strategies than the lower-ranked algorithms.  Simple adaptive parameter control schemes without considering diversity seem to have less effect.


**Experience:**

Prioritizing diversity management through effective archive mechanisms and adaptive parameter control, particularly for the scaling factor in DE, is crucial for solving high-dimensional multimodal problems.  Simple adaptive strategies may not sufficiently address complex landscapes.

2025-06-24 07:59:09 INFO Full response text: **Keywords:**  Adaptive Parameter Control, Diversity Management, Archive Mechanisms, High-Dimensional Multimodal Optimization

**Advice:** Focus on novel adaptive strategies for the DE scaling factor that go beyond simple adjustments.  Explore less common archive management techniques prioritizing diversity using metrics beyond simple distance measures.  Rigorously test on benchmark problems with diverse characteristics.  Quantify diversity and performance gains clearly.

**Avoid:**  Generic statements about "sophisticated" methods. Vague claims of improved performance without empirical evidence.  Combining multiple disparate methods without a clear rationale or synergistic benefit.  Overly broad research directions.

**Explanation:** The current self-reflection correctly identifies key challenges. The ineffective reflection lacks concrete actionable steps. The advice emphasizes specific improvements to existing DE mechanisms rather than proposing a broad, untested combination of techniques.  The focus on quantifiable results is crucial for demonstrating actual progress and justifying the substantial investment.

2025-06-24 07:59:09 INFO Generating offspring via Crossover...
