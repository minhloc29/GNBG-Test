2025-06-23 11:46:04 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:46:04 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:46:04 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:46:05 ERROR Can not run the algorithm
2025-06-23 11:46:05 INFO Run function 2 complete. FEHistory len: 501, AOCC: 0.1753
2025-06-23 11:46:05 INFO FeHistory: [-701.29234043 -701.29871325 -701.28771399 -701.26917864 -701.34181857
 -701.2924217  -701.29909726 -701.28565072 -701.28225842 -701.32872441
 -701.36566351 -701.2557439  -701.31700083 -701.30247329 -701.33150914
 -701.34330908 -701.29452094 -701.30518716 -701.29654271 -701.31109103
 -701.30621017 -701.32294284 -701.29498461 -701.33046124 -701.28156665
 -701.30475125 -701.29405555 -701.33970244 -701.28826257 -701.31998993
 -701.33060942 -701.30810617 -701.31057879 -701.28887657 -701.35625334
 -701.30812833 -701.33240877 -701.30736266 -701.30885583 -701.28268885
 -701.28789374 -701.315447   -701.32362656 -701.31518058 -701.29635014
 -701.34846847 -701.31206018 -701.28753433 -701.31240656 -701.3110981
 -701.33489604 -701.30393161 -701.3133364  -701.31033001 -701.30645028
 -701.3010794  -701.29843799 -701.32274758 -701.2935956  -701.31186909
 -701.31941264 -701.30066685 -701.29512007 -701.31824577 -701.27031891
 -701.33067578 -701.33810251 -701.32245544 -701.3533367  -701.30863257
 -701.3197194  -701.31243964 -701.31268137 -701.27808381 -701.30572256
 -701.32273854 -701.3188269  -701.30952566 -701.3224072  -701.30872926
 -701.34885087 -701.28034619 -701.29947685 -701.32566941 -701.29689971
 -701.30658887 -701.2886725  -701.32911798 -701.29499103 -701.32655568
 -701.32101197 -701.28125518 -701.28800249 -701.29794668 -701.29498615
 -701.29288674 -701.32209419 -701.33342592 -701.30209899 -701.30431864
 -701.31801361 -701.27753753 -701.27474638 -701.31661549 -701.32189955
 -701.2680848  -701.28890212 -701.28270909 -701.29299825 -701.30857512
 -701.35681309 -701.25366731 -701.30673535 -701.28994905 -701.32555928
 -701.33310532 -701.27891836 -701.29679789 -701.30840298 -701.30788708
 -701.29035649 -701.31441297 -701.2925178  -701.31382417 -701.28755647
 -701.29592739 -701.29186339 -701.31445991 -701.27425201 -701.30660267
 -701.32289142 -701.31244404 -701.30298046 -701.28153028 -701.33269654
 -701.29112711 -701.30169314 -701.30143756 -701.2961664  -701.24636282
 -701.28880484 -701.31998278 -701.31681032 -701.30782415 -701.29822799
 -701.33460727 -701.2683319  -701.28556836 -701.26994538 -701.31269938
 -701.32236161 -701.31011807 -701.31358997 -701.2808054  -701.29748942
 -701.28343414 -701.28859552 -701.32254632 -701.29153874 -701.30451869
 -701.31193309 -701.29586094 -701.28701753 -701.31099136 -701.26628687
 -701.33172778 -701.26618036 -701.32068277 -701.33893614 -701.30811236
 -701.33220908 -701.31910134 -701.29816861 -701.27358463 -701.30871346
 -701.32228318 -701.31091055 -701.30710435 -701.30620467 -701.30789627
 -701.33068862 -701.25816854 -701.30797426 -701.31911621 -701.29141025
 -701.32072431 -701.28087447 -701.3287895  -701.28888046 -701.3164142
 -701.31438273 -701.3035335  -701.28574018 -701.28246805 -701.29151531
 -701.2784718  -701.28576615 -701.27535681 -701.29249457 -701.30030178
 -701.30673109 -701.32829387 -701.33404217 -701.34773464 -701.32813043
 -701.33862803 -701.32172207 -701.32341731 -701.34874775 -701.33235003
 -701.3189098  -701.32211744 -701.31935354 -701.31006213 -701.32224773
 -701.33505506 -701.32939674 -701.32245477 -701.32756423 -701.31257995
 -701.33095475 -701.31890211 -701.3264182  -701.31711052 -701.32332998
 -701.31725641 -701.32549127 -701.33026983 -701.31492505 -701.29816763
 -701.30859973 -701.30038326 -701.32814362 -701.32591759 -701.30760392
 -701.32322908 -701.29406932 -701.30201455 -701.31298748 -701.31057711
 -701.32187189 -701.3083159  -701.30187075 -701.29561819 -701.32183776
 -701.3182964  -701.31914672 -701.31250978 -701.32038499 -701.31294672
 -701.33279026 -701.30151799 -701.3313838  -701.31215689 -701.30376259
 -701.31704737 -701.3013341  -701.30749622 -701.31606718 -701.30757713
 -701.31008794 -701.31353049 -701.31695112 -701.30233743 -701.28557861
 -701.30468515 -701.30900834 -701.33386588 -701.31654883 -701.30946991
 -701.31080315 -701.31493615 -701.30715608 -701.30893107 -701.30205925
 -701.30620802 -701.30515486 -701.30077887 -701.30718293 -701.30059994
 -701.29130923 -701.28181318 -701.28510998 -701.30458276 -701.3057998
 -701.2957514  -701.30277542 -701.30551729 -701.32233971 -701.30172016
 -701.3143668  -701.2984005  -701.297847   -701.31319685 -701.30759025
 -701.29427003 -701.2986914  -701.28472924 -701.30563529 -701.30341301
 -701.29955655 -701.34671899 -701.33570819 -701.33545624 -701.33272557
 -701.34588237 -701.31986003 -701.30467801 -701.29855727 -701.3018473
 -701.32989407 -701.33882074 -701.32063119 -701.3180495  -701.3422244
 -701.32797125 -701.31914998 -701.27882416 -701.32646261 -701.31999565
 -701.29976282 -701.31660262 -701.33083346 -701.31745348 -701.2955324
 -701.31204356 -701.31842993 -701.32554557 -701.31742429 -701.30195478
 -701.31841511 -701.31097638 -701.32625686 -701.32937767 -701.31724972
 -701.31632179 -701.31065049 -701.31632694 -701.32372256 -701.31363929
 -701.31803126 -701.34303622 -701.29078454 -701.31228148 -701.32541711
 -701.32234319 -701.30173736 -701.31887079 -701.32523968 -701.30601663
 -701.305926   -701.32474803 -701.29329664 -701.31278301 -701.3232863
 -701.29817542 -701.3206137  -701.32215281 -701.30647396 -701.31830987
 -701.3302155  -701.31515741 -701.29583896 -701.31788479 -701.34167062
 -701.29201431 -701.31005535 -701.30516015 -701.30932982 -701.30519296
 -701.31731552 -701.30436334 -701.29262397 -701.31749968 -701.32334887
 -701.31577396 -701.31035607 -701.31389882 -701.30063036 -701.30814459
 -701.31772138 -701.3130643  -701.32364899 -701.32093285 -701.32620472
 -701.31468439 -701.30950137 -701.31243416 -701.31134891 -701.30442102
 -701.30523346 -701.30849542 -701.29094672 -701.312332   -701.30750697
 -701.30987171 -701.29974432 -701.29816383 -701.3163405  -701.31429949
 -701.29658498 -701.34190219 -701.30128336 -701.36319042 -701.31636623
 -701.33643796 -701.33793446 -701.34053499 -701.30735654 -701.30699241
 -701.34596615 -701.33934045 -701.29047669 -701.35932046 -701.33739601
 -701.32324891 -701.32579261 -701.31738472 -701.31638876 -701.33038268
 -701.28779503 -701.31761488 -701.32598589 -701.33166389 -701.32172971
 -701.33049087 -701.31955546 -701.33589374 -701.32775788 -701.33213429
 -701.33060402 -701.32859445 -701.30141714 -701.31512029 -701.31474903
 -701.30650265 -701.3231819  -701.316109   -701.32645522 -701.32031985
 -701.30772109 -701.30044299 -701.30057042 -701.31256375 -701.33666534
 -701.32124657 -701.32558217 -701.33266073 -701.32942682 -701.32907359
 -701.32343371 -701.30856807 -701.31224245 -701.31407113 -701.32531233
 -701.31401248 -701.32627602 -701.35618821 -701.31606313 -701.31470843
 -701.31829068 -701.31352185 -701.29101884 -701.32549605 -701.31090273
 -701.30969532 -701.3150844  -701.30358272 -701.32125135 -701.30831563
 -701.32476062 -701.31712514 -701.31409682 -701.31328172 -701.313402
 -701.3031968  -701.32201272 -701.31566463 -701.28717241 -701.32874467
 -701.31258307 -701.3317617  -701.30334443 -701.32065952 -701.29233947
 -701.32865908 -701.31275199 -701.31652972 -701.30161804 -701.31509973
 -701.32499987 -701.30787373 -701.32364587 -701.31084994 -701.31878383
 -701.30498246 -701.27537318 -701.31344714 -701.32632171 -701.3039679
 -701.31928759]
2025-06-23 11:46:05 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:46:05 INFO Good algorithm:
Algorithm Name: AdaptiveCovarianceDEArchiveEA
import numpy as np
from scipy.stats import levy, multivariate_normal
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveCovarianceDEArchiveEA
# Description: Combines adaptive covariance DE, LÃ©vy flights, and a novelty archive for multimodal optimization.
# Code:
class AdaptiveCovarianceDEArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.levy_alpha = 1.5 # Levy flight parameter
        self.exploration_rate = 0.8 # Balance between DE and Levy
        self.novelty_threshold = 0.1
        self.covariance_matrix = np.eye(self.dim) #Initial covariance matrix

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self._adapt_covariance(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                a, b, c = self._select_different(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _levy_flight(self, x):
        step = levy.rvs(self.levy_alpha, size=self.dim)
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:min(len(combined), self.archive_size)]
            return self.archive

        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)]) if len(self.archive)>0 else np.inf
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])

        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

    def _adapt_covariance(self, population, fitness_values):
        # Update covariance matrix based on top performing individuals
        top_performers = population[:self.population_size//2]
        self.covariance_matrix = np.cov(top_performers.T) + 0.1 * np.eye(self.dim) #Regularization


2025-06-23 11:46:05 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:46:05 ERROR Can not run the algorithm
2025-06-23 11:46:05 INFO Run function 15 complete. FEHistory len: 701, AOCC: 0.1055
2025-06-23 11:46:05 INFO FeHistory: [-221.69420015 -221.08671195 -222.48365181 -222.74413687 -222.67888735
 -222.01589859 -219.54545295 -221.33473132 -222.8659207  -221.86662734
 -220.75113095 -224.12325786 -224.4040194  -223.16877175 -222.35760401
 -221.30914765 -221.40188506 -220.58912797 -220.71394936 -220.79253504
 -220.68971534 -222.57196687 -223.99590578 -220.97281964 -222.18055905
 -223.15768903 -221.04201525 -222.80583586 -222.41585439 -221.58400099
 -222.41753714 -222.7459474  -222.05299727 -220.73208593 -221.65298567
 -222.92569716 -223.63234234 -221.26675226 -220.43456234 -222.90665863
 -223.1582426  -221.87048998 -222.01464363 -220.86135073 -223.40784064
 -222.19921128 -222.2943273  -222.98118437 -221.18032094 -222.42059871
 -221.35818068 -220.58015829 -222.28691802 -222.76617054 -221.68087021
 -222.18467513 -223.2385783  -221.6648929  -222.83957064 -222.55690536
 -222.71899954 -222.99869029 -221.76355393 -221.63003038 -221.22408885
 -220.12461495 -221.41559975 -221.33695071 -223.1118169  -221.14750851
 -221.99502771 -222.70223    -221.66771923 -221.63112437 -221.89880611
 -221.81340827 -222.20758503 -224.33478201 -223.46498423 -223.20097636
 -221.28817743 -222.03441642 -220.80638673 -222.24477766 -221.53159028
 -221.46631415 -222.99884641 -222.53677805 -223.60777271 -222.51114684
 -222.10250456 -221.78628213 -222.10156009 -222.64443782 -221.48279267
 -222.24319428 -221.10402556 -220.07267183 -220.73294492 -221.19619116
 -223.28770704 -222.50460654 -222.54163358 -220.77460024 -220.98844898
 -220.81748138 -220.71238644 -223.67061874 -221.76445633 -220.68546676
 -221.71458577 -223.67437434 -221.52244234 -223.23884541 -220.87991513
 -222.26709543 -220.61686211 -221.097588   -220.43479023 -220.50020295
 -220.94109208 -223.52314769 -224.02283121 -222.01773865 -221.45829619
 -223.05413909 -220.64124479 -221.78388961 -221.80078361 -221.66993957
 -222.6622979  -220.05959106 -223.583435   -220.33557127 -221.59076367
 -222.43768113 -221.5155296  -222.21680927 -220.4873428  -221.29841861
 -222.93852261 -221.45286199 -221.56604298 -221.45418494 -222.66675584
 -221.79730631 -222.78876317 -221.15205891 -221.58402756 -221.74198373
 -221.84819676 -221.82533548 -220.6235629  -221.7093522  -220.66929221
 -223.6741945  -219.97756559 -221.50317552 -222.41198301 -220.5019659
 -224.70447032 -220.89441035 -220.83406868 -221.6677644  -221.11845011
 -220.34804225 -222.12676661 -220.40861052 -222.37180035 -220.15716229
 -222.70999141 -222.21464531 -221.20965999 -223.4400852  -221.53250112
 -221.53914154 -222.25457371 -223.51662058 -222.60295728 -222.42051488
 -221.28557783 -222.4381679  -219.98079849 -222.92056707 -221.28230073
 -221.44957007 -221.73604869 -223.66370162 -224.13638606 -222.44702087
 -222.31136422 -221.84621453 -220.53262278 -223.94956108 -221.35793473
 -221.98805094 -225.26119685 -220.79724041 -221.43587368 -221.33713503
 -223.44344712 -222.36799234 -222.45229067 -222.34572038 -222.49016114
 -223.85104907 -224.22220944 -225.48172383 -223.89376537 -222.75075401
 -221.911294   -223.97631672 -223.91054065 -222.17469766 -223.03027115
 -220.73521864 -223.08539935 -222.29087779 -221.61376426 -222.33525531
 -222.74928945 -220.76206828 -220.59471191 -221.688686   -222.2581557
 -221.5081149  -223.3031784  -221.5481329  -222.06546535 -221.78558089
 -223.1783611  -223.67141545 -222.40652869 -222.72244038 -221.13034
 -221.6272501  -222.26370416 -220.53491589 -221.24479041 -221.40684977
 -223.00209931 -222.49999248 -222.86716342 -222.84436536 -221.98466295
 -221.96154258 -221.76344788 -221.70478221 -221.19372049 -222.45448788
 -221.00296425 -222.6754115  -222.08050531 -222.34621101 -222.65407577
 -222.28936924 -223.70107001 -221.70018336 -222.1000321  -222.23380038
 -221.63790726 -221.81633549 -221.89042222 -221.83214345 -222.47521874
 -221.65567144 -222.96692869 -221.71110601 -222.92206415 -223.07395994
 -221.89336622 -222.82023583 -221.49713772 -221.37053707 -220.78159616
 -220.56987102 -221.5886091  -221.48238394 -222.56917513 -221.91080678
 -221.01306574 -222.33735065 -222.16373392 -221.24983857 -221.88704986
 -221.36516219 -222.29871146 -221.97196237 -221.52032538 -223.50217583
 -222.10707069 -222.76756661 -221.722999   -222.6347232  -221.18734692
 -222.60317227 -222.96276228 -221.88676106 -220.99136555 -221.67696137
 -221.41784619 -221.54101917 -223.02648751 -224.05462131 -221.50895311
 -221.7995369  -222.25544371 -220.33346943 -222.1621913  -223.04661926
 -222.65558155 -223.84111546 -223.8262057  -223.87907904 -222.09502428
 -222.62810316 -222.16646514 -222.77975006 -223.08187772 -222.37030301
 -223.17521351 -222.04399273 -223.08607721 -223.77541751 -222.43365487
 -222.8058018  -222.11578033 -223.50210848 -223.16076036 -224.42371218
 -221.88950305 -221.57889293 -222.73811567 -222.80836086 -221.80718491
 -220.76574772 -222.46547337 -222.52310413 -221.4894397  -222.01585123
 -222.03874187 -222.3837027  -220.59585892 -222.71839113 -223.80409652
 -221.52261049 -222.97084935 -223.28716076 -220.87743462 -222.12508367
 -224.24110679 -223.04479213 -221.71337703 -220.94035924 -222.42364042
 -220.9131609  -222.07952508 -223.03731497 -222.5182798  -221.62174675
 -222.22746376 -221.96708039 -220.6935658  -222.5833071  -221.54928723
 -222.51644914 -221.69124938 -223.22684441 -222.7393474  -222.06658467
 -221.26922495 -223.79989871 -222.85201463 -222.14667834 -223.60558957
 -223.05917334 -220.91035901 -221.42678009 -222.02006184 -221.88865409
 -222.30314363 -222.09536614 -221.64601442 -222.73053364 -223.10916219
 -223.46317288 -222.68958905 -222.29645653 -222.70585856 -220.55497367
 -222.66595747 -222.09193564 -222.67254894 -222.20397721 -222.4058205
 -221.81573537 -223.18935118 -221.53253001 -222.68834922 -222.95684408
 -222.82225412 -221.91831378 -223.55990637 -221.97276991 -222.08713745
 -222.03142199 -222.41571504 -222.52140555 -223.48464553 -222.48533923
 -223.79941077 -220.17942457 -222.67765712 -222.13251671 -221.86405708
 -222.59235992 -222.5508077  -223.80869946 -221.20579499 -221.07605649
 -223.67192973 -221.27239406 -222.67569663 -222.17322302 -222.20767942
 -221.59396802 -221.72237858 -223.2811793  -222.39197266 -223.23676749
 -221.97264354 -222.98291055 -220.94984436 -222.54891995 -223.01354304
 -222.46679326 -222.92441689 -222.20715364 -222.89409096 -222.34763964
 -221.66943853 -221.99644198 -222.52425275 -221.3313083  -222.15618475
 -221.15472211 -222.44281472 -221.96314985 -221.48443135 -223.5790418
 -222.78628307 -222.68351932 -222.37469458 -222.70178877 -222.36704524
 -222.67060303 -220.91813035 -223.41896482 -223.67641457 -220.18721927
 -223.91292926 -222.38419679 -222.93969685 -222.98075341 -223.07336687
 -221.90721043 -222.39124868 -222.41781434 -221.04784306 -223.98211474
 -223.66709367 -222.67439739 -222.13793727 -222.24687448 -223.50990048
 -221.54826261 -222.29984602 -221.58071293 -222.26490003 -223.33877395
 -222.21496947 -222.51145659 -222.49952761 -220.59912894 -220.9547447
 -221.44602035 -221.52074658 -222.02525344 -222.68824834 -221.51937111
 -221.65290477 -224.5204017  -223.44537501 -221.30269936 -222.11036801
 -222.8729354  -220.86397013 -222.65811121 -221.95970186 -222.43858954
 -222.96159712 -223.35122225 -221.08120308 -223.38175754 -222.61005626
 -222.02764449 -222.25969989 -223.56832153 -222.84202155 -222.20056306
 -222.21997296 -223.8526338  -221.95519019 -223.56749912 -221.83130983
 -223.79359182 -223.17697899 -222.8041384  -221.06409206 -221.3777593
 -221.59913803 -222.56849421 -223.24345949 -223.02196017 -223.28554599
 -223.57609191 -223.74756132 -222.5378496  -223.14122569 -223.17472696
 -223.00261189 -224.13277209 -222.13412988 -222.18360365 -223.11092072
 -222.35832195 -222.07603187 -222.52235212 -223.55918504 -223.72155416
 -222.65753435 -222.98918643 -221.65282655 -222.49054157 -222.67576618
 -223.92384936 -222.24989189 -223.46377242 -222.8875054  -223.68106415
 -224.54986264 -221.7416932  -221.47098309 -224.63310015 -223.91316638
 -222.87946094 -223.15924864 -222.34019747 -223.89637799 -222.36752508
 -222.62987958 -223.2870989  -221.84619405 -221.80166051 -220.74979745
 -221.63514654 -222.68152204 -222.44713275 -221.93192489 -221.25324823
 -223.53532559 -222.59453499 -222.42801768 -220.77020328 -222.08862556
 -222.04251104 -222.98763887 -224.18136387 -223.22300265 -221.82007789
 -220.88917696 -223.070753   -223.02255883 -222.63143963 -222.20000141
 -221.75022708 -222.29724604 -222.19203122 -223.02433137 -222.54180334
 -221.59035045 -223.54333725 -221.41198682 -222.59751196 -222.7481721
 -220.60414078 -222.77866154 -223.2146815  -220.76418096 -222.5263549
 -222.41180448 -223.19176467 -222.3549699  -223.32013023 -221.37943235
 -222.45283325 -223.58658677 -222.17472678 -221.43298109 -221.93073012
 -222.63634725 -220.74208061 -222.73880061 -221.24050471 -223.18051194
 -221.70180437 -224.04811522 -222.57900927 -223.13991415 -221.83385278
 -222.57668593 -223.78821652 -222.48073341 -222.28969688 -225.34170099
 -223.83657206 -221.62432721 -222.00309888 -223.12467124 -222.41676614
 -222.7008628  -222.68712733 -222.38965165 -221.0311686  -223.43327736
 -222.30089732 -222.19328722 -222.72285168 -222.47813355 -222.20037165
 -223.82813163 -221.34961722 -222.33292434 -222.44931872 -222.07899599
 -220.18408043 -221.53737701 -223.02014841 -222.35164914 -221.84378299
 -221.11290767 -222.64167784 -221.70401725 -222.09864435 -222.10334026
 -222.93512447 -223.49343353 -222.33246303 -222.03925826 -224.09355502
 -224.06767968 -222.55836702 -223.48182228 -222.1444074  -222.36733894
 -223.51652768 -222.32721862 -220.9631337  -221.92377898 -224.33743329
 -222.28629305 -221.69788163 -222.62566397 -222.72072456 -222.3384003
 -223.02187869 -222.5729561  -222.83246735 -222.77230131 -220.41803771
 -221.29094845 -223.38452752 -221.15124566 -220.76936985 -223.32878565
 -223.30658428 -222.32811349 -222.60666959 -221.69946454 -223.33313098
 -221.44110201 -220.87935628 -222.07747082 -221.61842814 -222.97563217
 -221.58094727 -224.3001123  -221.526667   -221.56018254 -222.76184165
 -222.7643139 ]
2025-06-23 11:46:05 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:46:05 INFO Good algorithm:
Algorithm Name: AdaptiveCovarianceDEArchiveEA
import numpy as np
from scipy.stats import levy, multivariate_normal
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveCovarianceDEArchiveEA
# Description: Combines adaptive covariance DE, LÃ©vy flights, and a novelty archive for multimodal optimization.
# Code:
class AdaptiveCovarianceDEArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.levy_alpha = 1.5 # Levy flight parameter
        self.exploration_rate = 0.8 # Balance between DE and Levy
        self.novelty_threshold = 0.1
        self.covariance_matrix = np.eye(self.dim) #Initial covariance matrix

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self._adapt_covariance(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            if np.random.rand() < self.exploration_rate:
                offspring[i] = self._levy_flight(population[i])
            else:
                a, b, c = self._select_different(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _levy_flight(self, x):
        step = levy.rvs(self.levy_alpha, size=self.dim)
        step = (self.upper_bounds - self.lower_bounds) * step / np.max(np.abs(step))
        return np.clip(x + step, self.lower_bounds, self.upper_bounds)

    def _select_different(self, exclude):
        candidates = list(range(self.population_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:min(len(combined), self.archive_size)]
            return self.archive

        distances = squareform(pdist(combined[:, :-1]))
        novel_solutions = []
        for i in range(len(combined)):
            min_distance = np.min(distances[i, :len(self.archive)]) if len(self.archive)>0 else np.inf
            if min_distance > self.novelty_threshold:
                novel_solutions.append(combined[i])

        if len(novel_solutions) + len(self.archive) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))

    def _adapt_covariance(self, population, fitness_values):
        # Update covariance matrix based on top performing individuals
        top_performers = population[:self.population_size//2]
        self.covariance_matrix = np.cov(top_performers.T) + 0.1 * np.eye(self.dim) #Regularization


2025-06-23 11:46:05 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:46:05 ERROR Can not run the algorithm
2025-06-23 11:46:05 INFO Run function 24 complete. FEHistory len: 601, AOCC: 0.0000
2025-06-23 11:46:05 INFO FeHistory: [159.69576984 199.46495802 173.68916607 154.36524189 156.94132924
 155.23095353 206.67774058 181.9259373  215.11548111 186.77601993
 185.75460051 182.56993891 225.16690532 183.02950024 179.26420756
 168.2270111  199.60483908 191.76825751 172.30947765 157.42032982
 176.93749032 204.57792529 205.27217997 186.03296172 215.91539428
 189.15172548 194.72742448 194.08633012 172.27097627 192.39704542
 194.54403718 159.61355572 167.25013527 208.70605821 135.41323441
 197.62077687 189.58553241 194.51727289 162.46412755 138.55639985
 191.44470129 212.24078012 169.992778   206.44670482 199.10888549
 188.67931591 180.7968197  198.7746674  200.29508584 155.31899673
 202.03208745 173.17984003 220.88159156 186.97171399 187.46524955
 227.09077288 176.92166671 177.19921171 160.30613767 188.96770056
 191.16934406 155.09301941 157.08370602 163.72903379 180.2041211
 181.94611257 195.62852575 214.16240772 214.52599442 178.93322134
 218.18787551 196.46956388 180.79928535 191.28978063 212.01882963
 218.30022108 209.2326461  217.62658251 194.75240299 175.6342013
 188.48881072 211.08407107 209.27084953 147.2717415  203.11041823
 179.74731829 169.33628099 206.14360274 205.30222156 126.26054846
 161.72423531 194.80244068 181.70871442 200.28493312 190.6262169
 203.50550972 219.40400243 186.82882403 198.92270981 168.59846815
 202.61977529 182.08473535 199.02068122 150.6211092  145.22626608
 165.57137925 197.91171478 195.24043279 194.10876813 211.11721984
 185.40880882 176.93884104 214.36734154 178.65793912 211.56704414
 173.13151791 187.1873965  213.0183406  188.63885436 153.3449855
 205.76000874 199.8119457  192.83249147 201.82020417 203.60388309
 190.96303743 214.08451875 202.79035576 216.90169826 214.32005555
 183.62853569 220.82601891 168.53063783 209.22395615 146.43917944
 174.86615407 205.61089931 226.63800492 196.60942284 145.07203946
 190.89237065 191.98543381 207.34252577 198.37393416 204.34934302
 192.09455417 186.01011012 202.39563258 222.63304706 164.38210824
 200.6693555  164.01202242 237.54993628 196.20570131 187.92264013
 203.11356558 183.83565378 181.74201727 176.86723747 166.58107058
 211.44041795 214.45138238 175.46990846 185.58906471 188.91694736
 201.71866627 196.00006941 204.79428482 204.00896673 175.88238449
 191.0485555  218.43322306 184.58899544 208.75192732 205.24188351
 193.97306975 189.83217971 203.7487576  187.80470596 147.05855092
 182.11765992 198.16540838 177.67076306 155.66353245 226.08207705
 189.58872762 149.74983383 202.56955836 193.29188117 178.06957254
 196.73755026 202.26296292 161.60696339 251.62496134 198.75439931
 200.78006711 186.92417481 187.70821441 195.52239029 181.94754159
 191.40021173 140.77509899 184.15140404 223.40567412 179.86245789
 159.97133966 181.67845574 182.56975317 177.25218185 167.56764294
 152.47572208 167.54946215 180.895645   152.63960781 199.66688856
 181.55877533 182.54269506 141.54781298 175.16409204 179.54513822
 200.26957122 145.46623742 173.53651915 160.70223354 208.451458
 191.44592851 193.22529866 165.50090928 152.46590508 179.52051278
 177.45595763 166.67915437 179.09367876 192.32345004 206.65282253
 196.92151152 196.63217658 199.00353423 223.26490797 189.34338435
 211.96093062 178.50384471 214.45822845 190.89184297 209.51413876
 170.38211501 178.57846132 180.46119573 190.90743995 188.35318599
 197.4311743  184.05845622 175.85921422 164.18649064 180.56024273
 173.79967044 183.81278178 163.95333723 180.28321831 181.97354629
 180.59664198 217.66907081 181.28102612 183.73592205 220.35921877
 178.74404583 181.11045647 229.31495429 210.96312128 222.1099249
 189.31928423 186.34866338 186.73876887 191.01842921 141.50072957
 176.49587169 179.06374526 200.4599648  160.66598007 175.43404576
 204.01925501 191.48633923 234.40821736 140.93402394 195.46738936
 171.30797284 186.35223416 187.10623192 198.39388135 210.33739838
 168.56181071 206.36697527 217.74752544 203.99264958 181.30825947
 208.91416369 167.55388422 167.93391278 205.3880629  210.34731399
 195.12115137 135.70044561 178.15979583 177.19597784 155.93346236
 149.71222984 188.80100314 185.40829957 152.06125032 169.49363468
 162.9797598  205.60486283 196.04360059 179.77442789 178.81826147
 182.8274648  150.25487687 163.44056635 184.90822793 159.91990165
 156.28828903 183.35762764 171.03229036 161.17230752 154.97197162
 162.35737893 181.26199909 207.72474854 197.07802715 172.16962506
 168.16262609 213.16571206 169.57880324 175.56748992 196.44826062
 214.47444469 196.08144628 165.10553214 173.82262019 159.33523741
 199.25395078 183.09137368 157.92415405 182.0859168  191.76375139
 181.83866591 189.94852142 178.52627999 195.15666605 188.20189702
 183.45356051 178.03660379 194.37682617 201.87392644 154.5294342
 216.09788581 161.0886305  181.21769488 241.2650596  192.97251371
 213.5005462  189.57671068 164.18381671 169.10437901 166.649305
 173.73262489 205.72072309 203.28534    190.3643711  174.87967627
 215.3763726  195.66691181 201.87900533 159.89153529 196.81605929
 153.72303173 202.70752677 194.57377568 194.30560265 197.57368559
 160.30226465 185.06677608 184.31119019 180.70314037 167.83611989
 241.75823259 185.69960503 202.7888202  186.36655373 189.29332796
 197.08315096 198.0149631  163.5781738  187.53556708 191.50710206
 155.54044364 172.79770177 191.33490005 162.48952386 187.0314336
 189.50227481 147.84456345 196.32068383 164.31111354 146.68605157
 133.17651604 155.31592961 210.81257015 164.02523093 176.47057704
 184.0627422  144.76545332 207.79127067 162.75988267 146.25889842
 154.81677688 190.68484891 208.05063289 212.42782753 214.18355694
 202.21548884 149.39070202 199.06474478 129.67198673 151.14099149
 197.21598381 200.17016792 233.74924357 200.59608812 171.77368795
 190.26599236 166.20452552 164.31993488 176.32878937 155.38937563
 173.84883994 176.34842025 232.3375252  170.08504673 173.33471955
 189.6464464  173.81525978 180.19902384 151.90591234 195.93482774
 173.01136824 187.94135076 180.07372366 172.7434118  210.32465201
 158.04965004 207.5466471  138.26223912 193.09928181 176.62511963
 171.7851106  183.78004587 216.08856985 209.8365976  182.0259485
 174.4775248  165.53060133 183.44168342 180.92740365 192.09779432
 200.11966631 159.40628483 193.32659753 201.07365808 167.96084538
 182.29788947 162.3373659  189.96089937 197.11959489 176.3112925
 217.56987488 148.03465339 166.55581848 179.6975863  186.11633642
 196.67463553 186.80332339 177.64564199 181.69342857 180.16369656
 193.39342546 228.37484566 193.94384832 170.80190248 156.75583633
 219.10484887 186.42075515 172.82747466 175.91021363 174.46018683
 157.64693491 207.93056335 170.717122   186.01700877 189.86035584
 175.51128794 144.50563979 173.83665958 159.56289022 199.57511349
 129.27230085 168.82426681  99.38822665 167.92451332 136.23225855
 172.0522123  156.83167915 170.71282889 162.60891818 179.13073183
 183.20611207 155.30185984 170.1723508  184.49212892 196.50936807
 165.99403601 174.98668315 182.43813842 197.87746435 162.40693207
 174.7632172  174.69475196 204.33504055 155.1416879  155.20791925
 161.37117995 163.69391094 158.11529732 192.08709407 189.79408844
 149.61463539 188.37956341 175.67935677 188.44231991 166.70723399
 201.89755675 133.30597656 163.18075474 160.03713734 164.74795681
 168.14392246 194.4095059  193.1904933  171.07863275 161.9338387
 156.13703731 183.79751426 162.34022124 158.77246295 173.519989
 132.8574088  204.38501607 161.97438802 186.94772043 184.28543316
 193.0494956  185.78267055 175.97030539 170.23197889 164.69685992
 217.95904671 193.59718971 180.34889207 168.34860798 161.14431365
 174.90672754 179.877202   189.20731966 166.55898149 160.69823832
 156.91524779 190.59938613 184.122402   180.21828556 164.66840724
 174.55527239 168.10213204 175.11089011 155.9430208  192.20484931
 162.78962148 177.66668578 202.06402713 208.02138447 178.82866522
 172.29951824 172.75673906 176.57984078 176.85346287 169.92070778
 196.68636062 185.7719238  171.31710814 155.71364442 195.94448018
 186.33929313]
2025-06-23 11:46:05 INFO Expected Optimum FE: -100
2025-06-23 11:46:05 INFO Unimodal AOCC mean: 0.1753
2025-06-23 11:46:05 INFO Multimodal (single component) AOCC mean: 0.1055
2025-06-23 11:46:05 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:46:05 INFO AOCC mean: 0.0936
2025-06-23 11:46:10 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.2040
2025-06-23 11:46:10 INFO FeHistory: [-701.31791896 -701.30489001 -701.30734708 ... -702.62717007 -702.62698218
 -702.63034177]
2025-06-23 11:46:10 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:46:10 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCovarianceAdaptation
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDEwithCovarianceAdaptation
# Description: Adaptive Differential Evolution incorporating covariance matrix adaptation for efficient multimodal exploration.
# Code:
class AdaptiveDEwithCovarianceAdaptation:
    """
    Combines adaptive Differential Evolution (DE) with covariance matrix adaptation 
    for efficient exploration of multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200,  F_init: float = 0.5, CR_init: float = 0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.F = F_init
        self.CR = CR_init
        self.archive = []
        self.covariance_matrix = np.eye(self.dim) # Initialize covariance matrix


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self._adapt_covariance(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population.shape[0])
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.archive_size)]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

    def _adapt_covariance(self, population, fitness_values):
        #Simple covariance adaptation -  replace with more sophisticated methods if needed.
        #This example updates based on the top performing individuals.
        top_performers = population[np.argsort(fitness_values)[:int(0.2*self.population_size)]] # Top 20%
        self.covariance_matrix = np.cov(top_performers, rowvar=False) + 0.1 * np.eye(self.dim) #Regularization

2025-06-23 11:46:10 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:46:10 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.1865
2025-06-23 11:46:10 INFO FeHistory: [-701.35082797 -701.31417946 -701.31422436 ... -701.81542268 -701.79302644
 -701.80399046]
2025-06-23 11:46:10 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:46:10 INFO Good algorithm:
Algorithm Name: AdaptiveDE_GaussianArchiveEA
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDE_GaussianArchiveEA
# Description: Combines adaptive DE with Gaussian mutation and a novelty archive for multimodal optimization.

class AdaptiveDE_GaussianArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian sigma
        self.sigma_decay = 0.99 # Gaussian sigma decay rate
        self.novelty_threshold = 0.1 # Minimum distance for novelty


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_gaussian = self._generate_offspring_gaussian(population)
            offspring = np.vstack((offspring_de, offspring_gaussian))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._selection(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self.sigma *= self.sigma_decay # Adapt Gaussian mutation strength

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population[:self.population_size//2])
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_gaussian(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            new_solution = population[i] + np.random.normal(0, self.sigma, self.dim)
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        distances = np.linalg.norm(population[:, np.newaxis, :] - self.archive[:, :-1], axis=2)
        min_distances = np.min(distances, axis=1)

        novel_indices = np.where(min_distances > self.novelty_threshold)[0]
        novel_solutions = combined[novel_indices]

        if len(self.archive) + len(novel_solutions) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

2025-06-23 11:46:10 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:46:16 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1108
2025-06-23 11:46:16 INFO FeHistory: [-221.26763767 -222.58214464 -222.1519448  ... -223.24678627 -222.42814809
 -221.83583973]
2025-06-23 11:46:16 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:46:16 INFO Good algorithm:
Algorithm Name: AdaptiveDEwithCovarianceAdaptation
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDEwithCovarianceAdaptation
# Description: Adaptive Differential Evolution incorporating covariance matrix adaptation for efficient multimodal exploration.
# Code:
class AdaptiveDEwithCovarianceAdaptation:
    """
    Combines adaptive Differential Evolution (DE) with covariance matrix adaptation 
    for efficient exploration of multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200,  F_init: float = 0.5, CR_init: float = 0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.F = F_init
        self.CR = CR_init
        self.archive = []
        self.covariance_matrix = np.eye(self.dim) # Initialize covariance matrix


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self._adapt_covariance(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population.shape[0])
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different(self, exclude, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_data = combined[combined[:, -1].argsort()]
        return sorted_data[:min(len(sorted_data), self.archive_size)]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

    def _adapt_covariance(self, population, fitness_values):
        #Simple covariance adaptation -  replace with more sophisticated methods if needed.
        #This example updates based on the top performing individuals.
        top_performers = population[np.argsort(fitness_values)[:int(0.2*self.population_size)]] # Top 20%
        self.covariance_matrix = np.cov(top_performers, rowvar=False) + 0.1 * np.eye(self.dim) #Regularization

2025-06-23 11:46:16 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:46:16 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1125
2025-06-23 11:46:16 INFO FeHistory: [-220.39850634 -221.77251384 -220.5902262  ... -226.09930842 -226.35576722
 -226.72552039]
2025-06-23 11:46:16 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:46:16 INFO Good algorithm:
Algorithm Name: AdaptiveDE_GaussianArchiveEA
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDE_GaussianArchiveEA
# Description: Combines adaptive DE with Gaussian mutation and a novelty archive for multimodal optimization.

class AdaptiveDE_GaussianArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.F = 0.5  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian sigma
        self.sigma_decay = 0.99 # Gaussian sigma decay rate
        self.novelty_threshold = 0.1 # Minimum distance for novelty


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring_de = self._generate_offspring_de(population)
            offspring_gaussian = self._generate_offspring_gaussian(population)
            offspring = np.vstack((offspring_de, offspring_gaussian))
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population = self._selection(population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(population)
            self.eval_count += len(population)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)
            self.sigma *= self.sigma_decay # Adapt Gaussian mutation strength

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring_de(self, population):
        offspring = np.zeros_like(population[:self.population_size//2])
        for i in range(self.population_size // 2):
            a, b, c = self._select_three(population, i)
            offspring[i] = population[i] + self.F * (b - c)
            offspring[i] = self._crossover(population[i], offspring[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _generate_offspring_gaussian(self, population):
        offspring = []
        for i in range(self.population_size // 2):
            new_solution = population[i] + np.random.normal(0, self.sigma, self.dim)
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
            offspring.append(new_solution)
        return np.array(offspring)

    def _select_three(self, population, i):
        indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        while i in indices:
            indices = np.random.choice(np.arange(self.population_size), 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) == 0:
            self.archive = combined[:self.archive_size]
            return self.archive

        distances = np.linalg.norm(population[:, np.newaxis, :] - self.archive[:, :-1], axis=2)
        min_distances = np.min(distances, axis=1)

        novel_indices = np.where(min_distances > self.novelty_threshold)[0]
        novel_solutions = combined[novel_indices]

        if len(self.archive) + len(novel_solutions) <= self.archive_size:
            self.archive = np.vstack((self.archive, novel_solutions))
        else:
            combined_archive = np.vstack((self.archive, novel_solutions))
            sorted_indices = np.argsort(combined_archive[:, -1])
            self.archive = combined_archive[sorted_indices][:self.archive_size]
        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values < np.median(fitness_values))
        self.F = max(0.1, min(1, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0, min(1, self.CR + 0.1 * (success_rate - 0.5)))

2025-06-23 11:46:16 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:46:34 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0362
2025-06-23 11:46:34 INFO FeHistory: [173.05907364 179.56295802 140.84419919 ... -69.74642695 -67.15474351
 -73.07689249]
2025-06-23 11:46:34 INFO Expected Optimum FE: -100
2025-06-23 11:46:34 INFO Unimodal AOCC mean: 0.2040
2025-06-23 11:46:34 INFO Multimodal (single component) AOCC mean: 0.1108
2025-06-23 11:46:34 INFO Multimodal (multiple components) AOCC mean: 0.0362
2025-06-23 11:46:34 INFO AOCC mean: 0.1170
2025-06-23 11:46:34 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0085
2025-06-23 11:46:34 INFO FeHistory: [195.12300582 182.10073808 194.86446893 ... -22.41858649 -20.20501745
 -15.39306689]
2025-06-23 11:46:34 INFO Expected Optimum FE: -100
2025-06-23 11:46:34 INFO Unimodal AOCC mean: 0.1865
2025-06-23 11:46:34 INFO Multimodal (single component) AOCC mean: 0.1125
2025-06-23 11:46:34 INFO Multimodal (multiple components) AOCC mean: 0.0085
2025-06-23 11:46:34 INFO AOCC mean: 0.1025
2025-06-23 11:46:56 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:49:58 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.1756
2025-06-23 11:49:58 INFO FeHistory: [-701.27216401 -701.24672567 -701.26420342 ... -701.33096566 -701.33096566
 -701.32757489]
2025-06-23 11:49:58 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:49:58 INFO Good algorithm:
Algorithm Name: AdaptiveNoveltyMultimodalEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveNoveltyMultimodalEA
# Description: An evolutionary algorithm using adaptive Gaussian mutation, novelty search, and archive management for multimodal optimization.
# Code:
class AdaptiveNoveltyMultimodalEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.98
        self.archive = []
        self.novelty_weight = 0.1  # Initial weight for novelty
        self.novelty_weight_increase_rate = 0.001 #Adaptive Novelty Weight

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            novelty_scores = self._calculate_novelty(offspring)
            combined_scores = offspring_fitness + self.novelty_weight * novelty_scores

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, combined_scores
            )

            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay
            self.novelty_weight = min(1, self.novelty_weight + self.novelty_weight_increase_rate) #Adaptive Novelty increase

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, combined_scores):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, combined_scores))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit[:self.population_size]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _calculate_novelty(self, offspring):
        if not self.archive.size:
            return np.zeros(offspring.shape[0])
        
        archive_solutions = self.archive[:, :-1]
        distances = np.min(squareform(pdist(np.vstack((offspring, archive_solutions)))), axis=0)[:offspring.shape[0]]
        return 1.0 / (distances + 1e-10) #Avoid division by zero

2025-06-23 11:49:58 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:52:50 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1061
2025-06-23 11:52:50 INFO FeHistory: [-222.34847718 -221.33376398 -222.59509495 ... -221.91690536 -221.91690536
 -222.60400281]
2025-06-23 11:52:50 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:52:50 INFO Good algorithm:
Algorithm Name: AdaptiveNoveltyMultimodalEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveNoveltyMultimodalEA
# Description: An evolutionary algorithm using adaptive Gaussian mutation, novelty search, and archive management for multimodal optimization.
# Code:
class AdaptiveNoveltyMultimodalEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.98
        self.archive = []
        self.novelty_weight = 0.1  # Initial weight for novelty
        self.novelty_weight_increase_rate = 0.001 #Adaptive Novelty Weight

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            novelty_scores = self._calculate_novelty(offspring)
            combined_scores = offspring_fitness + self.novelty_weight * novelty_scores

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, combined_scores
            )

            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay
            self.novelty_weight = min(1, self.novelty_weight + self.novelty_weight_increase_rate) #Adaptive Novelty increase

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, combined_scores):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, combined_scores))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit[:self.population_size]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _calculate_novelty(self, offspring):
        if not self.archive.size:
            return np.zeros(offspring.shape[0])
        
        archive_solutions = self.archive[:, :-1]
        distances = np.min(squareform(pdist(np.vstack((offspring, archive_solutions)))), axis=0)[:offspring.shape[0]]
        return 1.0 / (distances + 1e-10) #Avoid division by zero

2025-06-23 11:52:50 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:55:58 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-23 11:55:58 INFO FeHistory: [196.42311322 240.81760013 219.86096115 ... 199.83169833 199.83169833
 187.82995549]
2025-06-23 11:55:58 INFO Expected Optimum FE: -100
2025-06-23 11:55:58 INFO Unimodal AOCC mean: 0.1756
2025-06-23 11:55:58 INFO Multimodal (single component) AOCC mean: 0.1061
2025-06-23 11:55:58 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:55:58 INFO AOCC mean: 0.0939
2025-06-23 11:57:40 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 11:57:40 ERROR Can not run the algorithm
2025-06-23 11:57:41 INFO Run function 2 complete. FEHistory len: 101, AOCC: 0.1761
2025-06-23 11:57:41 INFO FeHistory: [-701.29166496 -701.25723613 -701.29276733 -701.31116297 -701.30944838
 -701.30298268 -701.29748437 -701.30900195 -701.29062958 -701.29556108
 -701.30805086 -701.32587868 -701.31682591 -701.3606288  -701.28915089
 -701.33535872 -701.28587267 -701.34362413 -701.31747037 -701.29723004
 -701.3121947  -701.29904486 -701.37540244 -701.29011015 -701.30130179
 -701.27578279 -701.30433092 -701.30182364 -701.30132561 -701.30118846
 -701.30005389 -701.30618765 -701.31292606 -701.30600699 -701.3259053
 -701.31678257 -701.34119223 -701.29489705 -701.33771459 -701.30589142
 -701.29304788 -701.26870868 -701.40038051 -701.30452829 -701.33372898
 -701.30353588 -701.31271557 -701.34614808 -701.34618088 -701.30793956
 -701.29258428 -701.32690143 -701.29184817 -701.33250195 -701.27895879
 -701.30089217 -701.29326782 -701.27893059 -701.31519217 -701.32745414
 -701.28599958 -701.29043483 -701.26976263 -701.32017524 -701.31296448
 -701.28027457 -701.29028683 -701.34178853 -701.30335928 -701.30860386
 -701.2609673  -701.32025663 -701.29304781 -701.30391176 -701.30618705
 -701.31013008 -701.33628206 -701.29801363 -701.29410979 -701.32142829
 -701.33906901 -701.31427813 -701.30625734 -701.30636686 -701.34737095
 -701.31881407 -701.31328431 -701.32143932 -701.31973376 -701.31626336
 -701.32308177 -701.2875724  -701.30186425 -701.36486314 -701.29728636
 -701.29670879 -701.27949517 -701.31046437 -701.34705051 -701.28455258
 -701.28638198]
2025-06-23 11:57:41 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 11:57:41 INFO Good algorithm:
Algorithm Name: AdaptiveDE_GaussianArchiveEA
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDE_GaussianArchiveEA
# Description: Combines adaptive DE, Gaussian mutation, and an archive for efficient multimodal optimization.
# Code:
class AdaptiveDE_GaussianArchiveEA:
    """
    Combines adaptive differential evolution (DE) with Gaussian mutation and an archive 
    to enhance exploration and exploitation in multimodal optimization problems.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, F: float = 0.5, CR: float = 0.9, sigma_multiplier: float = 0.3):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.F = F
        self.CR = CR
        self.sigma = sigma_multiplier * (self.upper_bounds - self.lower_bounds)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            offspring[i] = self._differential_evolution(population, i)
            offspring[i] = self._gaussian_mutation(offspring[i]) #add gaussian mutation
        return offspring

    def _gaussian_mutation(self, x):
        return np.clip(x + np.random.normal(0, self.sigma, size=self.dim), self.lower_bounds, self.upper_bounds)


    def _differential_evolution(self, population, i):
        a, b, c = self._select_different(i, population.shape[0])
        mutant = population[a] + self.F * (population[b] - population[c])
        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return self._crossover(population[i], mutant)

    def _select_different(self, exclude, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.vstack((self.archive, combined))
        else:
            self.archive = np.vstack((self.archive, combined))
            sorted_indices = np.argsort(self.archive[:, -1])
            self.archive = self.archive[sorted_indices][:self.archive_size]

        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))
        self.sigma *= 0.9 #decay sigma


2025-06-23 11:57:41 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 11:57:41 ERROR Can not run the algorithm
2025-06-23 11:57:41 INFO Run function 15 complete. FEHistory len: 101, AOCC: 0.1039
2025-06-23 11:57:41 INFO FeHistory: [-223.30271088 -221.03525788 -223.60354706 -222.15897738 -222.60526497
 -222.68836557 -222.38341149 -221.19654118 -221.90178563 -223.127095
 -219.75382072 -222.88948884 -222.95866569 -222.77250673 -221.0771507
 -220.6393639  -220.74276605 -220.59835653 -221.77202819 -221.95162634
 -222.97050381 -222.09797847 -221.36928756 -222.2973315  -222.16795129
 -223.00358582 -223.03666236 -222.73556209 -220.96950424 -220.92640037
 -220.70801581 -221.92922157 -222.40440808 -223.87142156 -221.75108619
 -221.64624291 -222.09406132 -223.02414314 -222.02707605 -221.84882889
 -222.13379704 -222.62412711 -222.57615166 -222.5714414  -223.08231694
 -220.24698544 -223.33315611 -220.60904589 -221.91156377 -224.15624386
 -222.55911949 -222.52813819 -221.8402301  -222.3134288  -222.14601211
 -221.227226   -221.1731101  -222.51000632 -222.55011472 -222.38100425
 -222.30939357 -222.09937586 -221.19299536 -222.27670326 -221.02284391
 -221.86335178 -221.93805386 -222.33478695 -222.00045033 -220.72259252
 -220.01847034 -222.48101425 -220.76992464 -220.40692578 -221.96803911
 -221.50729995 -221.69302988 -224.39707123 -222.15162053 -222.75115515
 -220.78041608 -222.38758512 -225.14505637 -223.55658099 -223.16055658
 -220.78982523 -221.88640131 -221.43722571 -222.21275083 -222.19791359
 -222.66070294 -224.65428265 -222.31577366 -223.79855199 -222.7095503
 -221.48518909 -222.57409425 -222.49971556 -222.28764066 -222.68922962
 -220.92380647]
2025-06-23 11:57:41 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 11:57:41 INFO Good algorithm:
Algorithm Name: AdaptiveDE_GaussianArchiveEA
import numpy as np
from scipy.stats import levy

# Name: AdaptiveDE_GaussianArchiveEA
# Description: Combines adaptive DE, Gaussian mutation, and an archive for efficient multimodal optimization.
# Code:
class AdaptiveDE_GaussianArchiveEA:
    """
    Combines adaptive differential evolution (DE) with Gaussian mutation and an archive 
    to enhance exploration and exploitation in multimodal optimization problems.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 100, archive_size: int = 200, F: float = 0.5, CR: float = 0.9, sigma_multiplier: float = 0.3):
        self.budget = budget
        self.dim = dim
        self.lower_bounds = np.array(lower_bounds)
        self.upper_bounds = np.array(upper_bounds)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.F = F
        self.CR = CR
        self.sigma = sigma_multiplier * (self.upper_bounds - self.lower_bounds)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            offspring[i] = self._differential_evolution(population, i)
            offspring[i] = self._gaussian_mutation(offspring[i]) #add gaussian mutation
        return offspring

    def _gaussian_mutation(self, x):
        return np.clip(x + np.random.normal(0, self.sigma, size=self.dim), self.lower_bounds, self.upper_bounds)


    def _differential_evolution(self, population, i):
        a, b, c = self._select_different(i, population.shape[0])
        mutant = population[a] + self.F * (population[b] - population[c])
        mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return self._crossover(population[i], mutant)

    def _select_different(self, exclude, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(exclude)
        np.random.shuffle(candidates)
        return candidates[:3]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        if len(self.archive) < self.archive_size:
            self.archive = np.vstack((self.archive, combined))
        else:
            self.archive = np.vstack((self.archive, combined))
            sorted_indices = np.argsort(self.archive[:, -1])
            self.archive = self.archive[sorted_indices][:self.archive_size]

        return self.archive

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
        success_rate = np.mean(fitness_values[:self.population_size // 2] < fitness_values[self.population_size // 2:])
        self.F = max(0.1, min(1.0, self.F + 0.1 * (success_rate - 0.5)))
        self.CR = max(0.1, min(1.0, self.CR + 0.1 * (success_rate - 0.5)))
        self.sigma *= 0.9 #decay sigma


2025-06-23 11:57:41 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 11:57:41 ERROR Can not run the algorithm
2025-06-23 11:57:41 INFO Run function 24 complete. FEHistory len: 101, AOCC: 0.0000
2025-06-23 11:57:41 INFO FeHistory: [189.91194683 179.04265213 181.56173942 190.1170314  182.72089851
 196.89745894 193.97070517 188.34546229 184.3397112  188.80388247
 196.28051036 156.70590882 212.91395195 192.0034054  191.19040262
 192.25587445 184.44242262 189.45205712 213.96202009 180.13090238
 170.97128178 130.48921876 189.66598314 153.91801096 218.4751179
 176.83422455 219.484889   172.11756597 194.13010408 161.50159426
 180.59075667 196.23758777 180.34051026 175.113712   218.21661704
 197.1547833  191.64592885 192.31729433 198.14978782 172.40531546
 192.67191574 151.07659913 179.98584127 193.88515776 215.40901587
 226.9562938  238.69961601 207.99731333 215.3867029  142.62829077
 204.19464587 217.18535159 197.16772886 194.9810997  182.77628113
 194.633438   165.34255652 230.87732463 186.85774809 195.38370976
 206.06094856 193.5005084  155.32384576 170.15576294 199.01066645
 188.39943314 132.88087464 166.4930514  185.6368872  198.565687
 182.64135132 197.46884385 199.53997515 215.421078   191.49391751
 189.03092849 183.08094104 224.07998969 157.74147059 202.20507082
 217.62172397 199.56811041 177.33525604 161.73138929 167.0641335
 179.7314232  177.18779043 208.16195454 184.36617023 210.58748713
 211.49932341 158.74984336 161.34480607 161.34425045 186.72938673
 173.0105559  158.30166969 168.6084568  178.45601801 196.02272899
 195.38777975]
2025-06-23 11:57:41 INFO Expected Optimum FE: -100
2025-06-23 11:57:41 INFO Unimodal AOCC mean: 0.1761
2025-06-23 11:57:41 INFO Multimodal (single component) AOCC mean: 0.1039
2025-06-23 11:57:41 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 11:57:41 INFO AOCC mean: 0.0934
2025-06-23 11:57:41 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 12:00:36 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.1761
2025-06-23 12:00:36 INFO FeHistory: [-701.27924807 -701.30298858 -701.33867755 ... -701.27566588 -701.28089798
 -701.34248051]
2025-06-23 12:00:36 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 12:00:36 INFO Good algorithm:
Algorithm Name: AdaptiveDE_NoveltyArchiveEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDE_NoveltyArchiveEA
# Description: Combines Differential Evolution, novelty search, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDE_NoveltyArchiveEA:
    """
    Combines Differential Evolution (DE), novelty search, and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 100, archive_size: int = 200, F: float = 0.5, CR: float = 0.9, novelty_weight: float = 0.1):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.F = F
        self.CR = CR
        self.archive = []
        self.novelty_weight = novelty_weight

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            novelty_scores = self._calculate_novelty(offspring)
            combined_scores = offspring_fitness + self.novelty_weight * novelty_scores

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, combined_scores
            )

            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_random_individuals(population, i)
            mutant = a + self.F * (b - c)
            trial = self._crossover(population[i], mutant)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_random_individuals(self, population, exclude_index):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial
    
    def _select_next_generation(self, population, fitness_values, offspring, combined_scores):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, combined_scores))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit[:self.population_size]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _calculate_novelty(self, offspring):
        if not self.archive.size:
            return np.zeros(offspring.shape[0])

        archive_solutions = self.archive[:, :-1]
        distances = np.min(squareform(pdist(np.vstack((offspring, archive_solutions)))), axis=0)[:offspring.shape[0]]
        return 1.0 / (distances + 1e-10)  # Avoid division by zero

2025-06-23 12:00:36 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 12:03:33 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1078
2025-06-23 12:03:33 INFO FeHistory: [-222.45522806 -222.34504311 -221.54378224 ... -221.25540134 -223.17283156
 -222.06474219]
2025-06-23 12:03:33 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 12:03:33 INFO Good algorithm:
Algorithm Name: AdaptiveDE_NoveltyArchiveEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDE_NoveltyArchiveEA
# Description: Combines Differential Evolution, novelty search, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDE_NoveltyArchiveEA:
    """
    Combines Differential Evolution (DE), novelty search, and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 100, archive_size: int = 200, F: float = 0.5, CR: float = 0.9, novelty_weight: float = 0.1):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.archive_size = archive_size
        self.F = F
        self.CR = CR
        self.archive = []
        self.novelty_weight = novelty_weight

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            novelty_scores = self._calculate_novelty(offspring)
            combined_scores = offspring_fitness + self.novelty_weight * novelty_scores

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, combined_scores
            )

            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_random_individuals(population, i)
            mutant = a + self.F * (b - c)
            trial = self._crossover(population[i], mutant)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_random_individuals(self, population, exclude_index):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial
    
    def _select_next_generation(self, population, fitness_values, offspring, combined_scores):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, combined_scores))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit[:self.population_size]

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

    def _calculate_novelty(self, offspring):
        if not self.archive.size:
            return np.zeros(offspring.shape[0])

        archive_solutions = self.archive[:, :-1]
        distances = np.min(squareform(pdist(np.vstack((offspring, archive_solutions)))), axis=0)[:offspring.shape[0]]
        return 1.0 / (distances + 1e-10)  # Avoid division by zero

2025-06-23 12:03:33 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
2025-06-23 12:06:42 INFO Run function 24 complete. FEHistory len: 70000, AOCC: 0.0000
2025-06-23 12:06:42 INFO FeHistory: [190.74044279 195.95065113 168.52553091 ... 186.48321956 210.00242939
 165.41573052]
2025-06-23 12:06:42 INFO Expected Optimum FE: -100
2025-06-23 12:06:42 INFO Unimodal AOCC mean: 0.1761
2025-06-23 12:06:42 INFO Multimodal (single component) AOCC mean: 0.1078
2025-06-23 12:06:42 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 12:06:42 INFO AOCC mean: 0.0946
2025-06-23 12:07:06 INFO --- GNBG Problem Parameters for f2 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -703.132815
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 12:09:52 INFO Run function 2 complete. FEHistory len: 70000, AOCC: 0.1920
2025-06-23 12:09:52 INFO FeHistory: [-701.28605742 -701.25750312 -701.26708219 ... -701.94155559 -701.90253078
 -701.91268255]
2025-06-23 12:09:52 INFO Expected Optimum FE: -703.1328146165181
2025-06-23 12:09:52 INFO Good algorithm:
Algorithm Name: AdaptiveTopologyEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveTopologyEA
# Description: An evolutionary algorithm using adaptive topology-based exploration and exploitation for multimodal landscapes.
# Code:

class AdaptiveTopologyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.initial_sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma = self.initial_sigma.copy()
        self.archive = []
        self.topology_radius = 0.25 * np.linalg.norm(self.upper_bounds - self.lower_bounds)
        self.mutation_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._topological_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(np.vstack((population, offspring)),
                                                np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_topology()
            self._adapt_sigma()

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _topological_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            diff = parent2 - parent1
            alpha = np.random.rand()
            child = parent1 + alpha * diff
            offspring.append(child)
            child2 = parent2 + (1-alpha)*diff
            offspring.append(child2)
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma * self.mutation_rate, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])


    def _adapt_topology(self):
        if len(self.archive) > self.population_size:
            distances = pdist(self.archive[:, :-1])
            avg_distance = np.mean(distances)
            self.topology_radius = min(max(0.1 * avg_distance, 0.01 * np.linalg.norm(self.upper_bounds - self.lower_bounds)),
                                       0.5 * np.linalg.norm(self.upper_bounds - self.lower_bounds))

    def _adapt_sigma(self):
        if len(self.archive) > 0:
            std_dev = np.std(self.archive[:, :-1], axis=0)
            self.sigma = np.clip(0.1 * std_dev + 0.1 * self.initial_sigma, 0.01 * self.initial_sigma, 10 * self.initial_sigma)

2025-06-23 12:09:52 INFO --- GNBG Problem Parameters for f15 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -234.280428
  Lambda (Curvature): [0.1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 12:48:02 INFO Run function 15 complete. FEHistory len: 70000, AOCC: 0.1161
2025-06-23 12:48:02 INFO FeHistory: [-221.17690562 -221.28331771 -221.5530583  ... -227.39674783 -227.3912613
 -227.40243832]
2025-06-23 12:48:02 INFO Expected Optimum FE: -234.28042789139022
2025-06-23 12:48:02 INFO Good algorithm:
Algorithm Name: AdaptiveTopologyEA
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveTopologyEA
# Description: An evolutionary algorithm using adaptive topology-based exploration and exploitation for multimodal landscapes.
# Code:

class AdaptiveTopologyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.initial_sigma = 0.5 * (self.upper_bounds - self.lower_bounds)
        self.sigma = self.initial_sigma.copy()
        self.archive = []
        self.topology_radius = 0.25 * np.linalg.norm(self.upper_bounds - self.lower_bounds)
        self.mutation_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._topological_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )
            self.archive = self._update_archive(np.vstack((population, offspring)),
                                                np.concatenate((fitness_values, offspring_fitness)))
            self._update_best(offspring, offspring_fitness)
            self._adapt_topology()
            self._adapt_sigma()

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _topological_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            diff = parent2 - parent1
            alpha = np.random.rand()
            child = parent1 + alpha * diff
            offspring.append(child)
            child2 = parent2 + (1-alpha)*diff
            offspring.append(child2)
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma * self.mutation_rate, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])


    def _adapt_topology(self):
        if len(self.archive) > self.population_size:
            distances = pdist(self.archive[:, :-1])
            avg_distance = np.mean(distances)
            self.topology_radius = min(max(0.1 * avg_distance, 0.01 * np.linalg.norm(self.upper_bounds - self.lower_bounds)),
                                       0.5 * np.linalg.norm(self.upper_bounds - self.lower_bounds))

    def _adapt_sigma(self):
        if len(self.archive) > 0:
            std_dev = np.std(self.archive[:, :-1], axis=0)
            self.sigma = np.clip(0.1 * std_dev + 0.1 * self.initial_sigma, 0.01 * self.initial_sigma, 10 * self.initial_sigma)

2025-06-23 12:48:02 INFO --- GNBG Problem Parameters for f24 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -100.000000
  Lambda (Curvature): [0.25 0.25 0.25 0.25 0.25]
  Mu (Asymmetry/Depth): [0.44142637 0.27898903 0.25803028 0.21978833 0.39183826 0.42051979
 0.35740109 0.43165341 0.47744239 0.47234476]
----------------------------------------
