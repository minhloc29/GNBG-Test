2025-06-23 21:42:33 INFO Initializing first population
2025-06-23 21:42:33 INFO Initializing population from 9 seed files...
2025-06-23 21:56:32 INFO Started evolutionary loop, best so far: 0.24747886597801494
2025-06-23 21:56:32 INFO Population length is: 20
2025-06-23 21:56:32 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-23 21:56:32 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 2.4748e-01 |             AOCC Score on Unimodal instances: 1.7997e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 5.6246e-01)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 2 (Overall AOCC Score: 1.2568e-01 |             AOCC Score on Unimodal instances: 1.7593e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 2.0111e-01)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random

class EnhancedArchiveGuidedDE: #aocc 0.15
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale  # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 3 (Overall AOCC Score: 1.0839e-01 |             AOCC Score on Unimodal instances: 1.7552e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 1.4964e-01)
# Name: AdaptiveGaussianMutationDE
# Description: Seed from AdaptiveGaussianMutationDE
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]
```

### Rank 4 (Overall AOCC Score: 6.4491e-02 |             AOCC Score on Unimodal instances: 1.9347e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Description: Seed from AdaptiveDifferentialEvolutionWithEnhancedInitialization
# Code:
```python
import numpy as np
from scipy.optimize import minimize

class AdaptiveDifferentialEvolutionWithEnhancedInitialization:
    """
    Combines Differential Evolution with enhanced initialization near known optima and local search for multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], known_optimum=None):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.known_optimum = known_optimum  # Allow for None if no known optimum

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.local_search_freq = 5 # Perform local search every 5 generations

    def initialize_population(self, num_samples):
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(num_samples, self.dim))
        
        if self.known_optimum is not None:
            num_near_optimum = int(0.3 * num_samples) # 30% near the optimum
            noise_scale = 20 # Adjust noise scale as needed. Experiment with this!
            noise = np.random.normal(scale=noise_scale, size=(num_near_optimum, self.dim))
            population[:num_near_optimum, :] = self.known_optimum + noise
            population[:num_near_optimum, :] = np.clip(population[:num_near_optimum, :], self.lower_bounds, self.upper_bounds)

        return population

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self.initialize_population(self.population_size)
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        best_solution = population[np.argmin(fitness)]
        best_fitness = np.min(fitness)
        self.best_solution_overall = best_solution
        self.best_fitness_overall = best_fitness

        generation = 0
        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    new_population[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    new_population[i] = population[i]

            population = new_population
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

            # Local Search
            if generation % self.local_search_freq == 0:
                result = minimize(objective_function, best_solution, method='L-BFGS-B', bounds=list(zip(self.lower_bounds, self.upper_bounds)))
                if result.fun < best_fitness:
                    best_fitness = result.fun
                    best_solution = result.x
                    self.eval_count += result.nfev

                    if best_fitness < self.best_fitness_overall:
                        self.best_fitness_overall = best_fitness
                        self.best_solution_overall = best_solution

            generation += 1

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info









```

### Rank 5 (Overall AOCC Score: 5.9826e-02 |             AOCC Score on Unimodal instances: 1.7948e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random
class EnhancedArchiveGuidedDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5 #initial scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8 :
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 6 (Overall AOCC Score: 5.9113e-02 |             AOCC Score on Unimodal instances: 1.7734e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEAwithArchive
# Description: Seed from AdaptiveGaussianSamplingEAwithArchive
# Code:
```python
import numpy as np
import random
class AdaptiveGaussianSamplingEAwithArchive:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []

        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []

        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)

        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 7 (Overall AOCC Score: 5.8687e-02 |             AOCC Score on Unimodal instances: 1.7606e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 8 (Overall AOCC Score: 5.7368e-02 |             AOCC Score on Unimodal instances: 1.7210e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 9 (Overall AOCC Score: 5.5829e-02 |             AOCC Score on Unimodal instances: 1.6749e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizerImproved
# Description: Seed from AdaptiveMultimodalOptimizerImproved
# Code:
```python
import numpy as np
import random
class AdaptiveMultimodalOptimizerImproved:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tabu_list = []  # Tabu list to avoid revisiting recent solutions
        self.tabu_length = 10 # Length of the tabu list

        self.perturbation_strength = 0.5 # Initial perturbation strength, adaptive
        self.local_search_iterations = 10 # Number of iterations for local search
        self.temperature = 1.0 # Initial temperature for simulated annealing

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])

        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        while self.eval_count < self.budget:
            current_solution = self.best_solution_overall.copy()
                                
            # Local Search
            for _ in range(self.local_search_iterations):
                neighbor = self._generate_neighbor(current_solution)
                neighbor_fitness = objective_function(neighbor.reshape(1, -1))[0]
                self.eval_count += 1

                if self._accept(neighbor_fitness, self._fitness(current_solution, objective_function), self.temperature):
                    current_solution = neighbor

                if neighbor_fitness < self.best_fitness_overall:
                    self.best_fitness_overall = neighbor_fitness
                    self.best_solution_overall = neighbor
                    self.tabu_list = [] # Reset tabu list upon finding a new global best

            # Check for stagnation and apply perturbation
            if self._is_stagnant(current_solution):
                current_solution = self._perturb(current_solution)
            self.temperature *= 0.95 # Cool down the temperature

            # Add solution to tabu list
            self._update_tabu_list(current_solution)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'perturbation_strength': self.perturbation_strength,
            'final_temperature': self.temperature
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_neighbor(self, solution):
        neighbor = solution.copy()
        index = random.randint(0, self.dim - 1)
        neighbor[index] += np.random.normal(0, 0.1 * (self.upper_bounds[index] - self.lower_bounds[index]))  # Small Gaussian perturbation
        neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
        return neighbor

    def _perturb(self, solution):
        perturbation = np.random.uniform(-self.perturbation_strength, self.perturbation_strength, self.dim) * (self.upper_bounds - self.lower_bounds)
        new_solution = solution + perturbation
        new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)
        self.perturbation_strength *= 1.1 # Increase perturbation strength adaptively
        return new_solution

    def _is_stagnant(self, solution):
        return np.allclose(solution, self.best_solution_overall, atol=1e-4)


    def _update_tabu_list(self, solution):
        self.tabu_list.append(tuple(solution))
        if len(self.tabu_list) > self.tabu_length:
            self.tabu_list.pop(0)

    def _fitness(self, solution, objective_function):
        return objective_function(solution.reshape(1, -1))[0]

    def _accept(self, new_fitness, current_fitness, temperature):
        if new_fitness < current_fitness:
            return True
        else:
            delta_e = new_fitness - current_fitness
            acceptance_probability = np.exp(-delta_e / temperature)
            return random.random() < acceptance_probability








```

### Rank 10 (Overall AOCC Score: 5.0982e-02 |             AOCC Score on Unimodal instances: 1.5295e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalEvolutionaryStrategy
# Description: A hybrid evolutionary strategy incorporating adaptive mutation and a local search to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.mutation_rate = 0.1  # Initial mutation rate
        self.mutation_decay = 0.99 #Decay rate for mutation
        self.local_search_radius = 10.0 # Radius for local search
        self.population = self.initialize_population()

    def initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def mutate(self, solution):
        mutated_solution = solution + np.random.normal(0, self.mutation_rate * (self.upper_bounds-self.lower_bounds), self.dim)
        mutated_solution = np.clip(mutated_solution, self.lower_bounds, self.upper_bounds)
        return mutated_solution


    def local_search(self, solution, objective_function):
        best_local_solution = solution.copy()
        best_local_fitness = objective_function(best_local_solution.reshape(1,-1))[0]

        for _ in range(10):  # Limited local search iterations
            neighbor = best_local_solution + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)
            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
            neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
            if neighbor_fitness < best_local_fitness:
                best_local_solution = neighbor
                best_local_fitness = neighbor_fitness

        return best_local_solution, best_local_fitness

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')


        while self.eval_count < self.budget:
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size


            for i, fitness in enumerate(fitness_values):
                if fitness < self.best_fitness_overall:
                    self.best_fitness_overall = fitness
                    self.best_solution_overall = self.population[i].copy()

            # Selection (Tournament Selection)
            parents = []
            for _ in range(self.population_size):
                tournament = random.sample(range(self.population_size), 5)
                winner = min(tournament, key=lambda i: fitness_values[i])
                parents.append(self.population[winner])

            # Reproduction (Mutation & Local Search)
            offspring = []
            for parent in parents:
                mutated_solution = self.mutate(parent)
                local_solution, local_fitness = self.local_search(mutated_solution, objective_function)
                offspring.append(local_solution)
                self.eval_count += 1 # Account for local search evaluations

            self.population = np.array(offspring)
            self.mutation_rate *= self.mutation_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
```

### Rank 11 (Overall AOCC Score: 5.0798e-02 |             AOCC Score on Unimodal instances: 1.5239e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive Gaussian mutation to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.5 # Initial standard deviation for Gaussian mutation
        self.mutation_factor = 0.8 # Factor for differential evolution mutation
        self.crossover_rate = 0.9 # Crossover rate for differential evolution

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Evolution Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])

                # Adaptive Gaussian Mutation
                mutant = np.clip(mutant + np.random.normal(0, self.sigma, self.dim), self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.population[i])

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                    if trial_fitness < self.best_fitness_overall:
                        self.best_solution_overall = trial.copy()
                        self.best_fitness_overall = trial_fitness
                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)

            #Adaptive Sigma Adjustment (reduce sigma if convergence is detected)
            fitness_std = np.std(fitness_values)
            if fitness_std < 0.1 : # Adjust threshold as needed
                self.sigma *= 0.9


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 12 (Overall AOCC Score: 5.0652e-02 |             AOCC Score on Unimodal instances: 1.5196e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive mutation strength and a niching strategy to handle multimodal landscapes effectively.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.mutation_strength = 0.5 # Initial mutation strength
        self.niche_radius = 5 # Radius for niching

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = np.full(self.population_size, np.inf)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.fitness_values = np.full(self.population_size, np.inf)


        # Initial evaluation
        self.evaluate_population(objective_function)

        while self.eval_count < self.budget:
            new_population = np.copy(self.population)
            for i in range(self.population_size):
                a, b, c = self.select_different_individuals(i)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                trial = self.crossover(self.population[i], mutant)
                trial = self.bound_solution(trial) # Ensure solution stays within bounds

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self.fitness_values[i]:
                    new_population[i] = trial
                    self.fitness_values[i] = trial_fitness


            self.population = new_population
            self.adapt_mutation_strength() # Adapt mutation strength based on convergence
            self.apply_niching() # Apply niching to maintain diversity

            # Update overall best solution
            best_index = np.argmin(self.fitness_values)
            if self.fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness_values[best_index]
                self.best_solution_overall = self.population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def evaluate_population(self, objective_function):
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size


    def select_different_individuals(self, i):
        while True:
            a, b, c = random.sample(range(self.population_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c


    def crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u


    def bound_solution(self, solution):
        solution = np.clip(solution, self.lower_bounds, self.upper_bounds)
        return solution


    def adapt_mutation_strength(self):
        # Simple adaptation: Reduce mutation strength if population is converging, increase otherwise
        avg_fitness_diff = np.mean(np.abs(np.diff(np.sort(self.fitness_values))))
        if avg_fitness_diff < 1e-2: #Example threshold. Adjust as needed
            self.mutation_strength *= 0.9
        else:
            self.mutation_strength *= 1.1
        self.mutation_strength = np.clip(self.mutation_strength, 0.1, 2)  # Keep within reasonable bounds


    def apply_niching(self):
        # Simple niching: Remove solutions that are too close to each other
        for i in range(self.population_size):
            for j in range(i + 1, self.population_size):
                distance = np.linalg.norm(self.population[i] - self.population[j])
                if distance < self.niche_radius and self.fitness_values[i] > self.fitness_values[j]:
                    self.population[i] = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                    self.fitness_values[i] = objective_function(self.population[i].reshape(1,-1))[0] # Re-evaluate
                    self.eval_count +=1

                elif distance < self.niche_radius and self.fitness_values[j] > self.fitness_values[i]:
                    self.population[j] = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
                    self.fitness_values[j] = objective_function(self.population[j].reshape(1,-1))[0] # Re-evaluate
                    self.eval_count +=1

```

### Rank 13 (Overall AOCC Score: 5.0646e-02 |             AOCC Score on Unimodal instances: 1.5194e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a local search and adaptive mutation rate to handle multimodal landscapes efficiently.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100 # Adjust as needed
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.mutation_rate = 0.5 # Initial mutation rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall, self.best_fitness_overall = self.get_best(self.population, fitness_values)
        
        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self.select_three_different(i)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                trial = self.crossover(self.population[i], mutant)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds) # Boundary handling

                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                
                if trial_fitness[0] < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness[0]
                    if trial_fitness[0] < self.best_fitness_overall:
                        self.best_solution_overall = trial
                        self.best_fitness_overall = trial_fitness[0]
                else:
                    new_population.append(self.population[i])

            self.population = np.array(new_population)
            self.mutation_rate = max(0.01, self.mutation_rate * 0.95) # Adaptive mutation rate decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def select_three_different(self, i):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == i or b == i or c == i:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
        return u

    def get_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]


```

### Rank 14 (Overall AOCC Score: 4.9435e-02 |             AOCC Score on Unimodal instances: 1.4830e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalEvolutionaryStrategy
# Description: An evolutionary strategy employing adaptive mutation and a niching mechanism to handle multimodal landscapes efficiently.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness = None
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) # Initial mutation standard deviation
        self.niche_radius = 0.2 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Initial niche radius

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        self.fitness = np.full(self.population_size, float('inf'))

        while self.eval_count < self.budget:
            self.fitness = self._evaluate_population(self.population, objective_function)

            # Update best solution
            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness[best_index]
                self.best_solution_overall = self.population[best_index]


            # Selection and Reproduction with Adaptive Mutation and Niching
            offspring = self._create_offspring(self.population, self.sigma)
            offspring_fitness = self._evaluate_population(offspring, objective_function)


            combined_population = np.vstack((self.population, offspring))
            combined_fitness = np.concatenate((self.fitness, offspring_fitness))

            # Niching: Select individuals based on fitness and distance from existing solutions
            selected_indices = self._niching_selection(combined_population, combined_fitness, self.niche_radius)
            self.population = combined_population[selected_indices]
            self.fitness = combined_fitness[selected_indices]
            
            # Adaptive Sigma: Adjust mutation strength based on success rate
            self.sigma = self._adaptive_sigma(self.sigma)


        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _evaluate_population(self, population, objective_function):
        fitness = objective_function(population)
        self.eval_count += len(fitness)
        return fitness

    def _create_offspring(self, population, sigma):
        offspring = population + np.random.normal(0, sigma, population.shape)
        offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)  #Handle boundary constraints
        return offspring

    def _niching_selection(self, population, fitness, niche_radius):
        selected = []
        for i, (individual, fit) in enumerate(zip(population, fitness)):
            is_unique = True
            for j, (other_individual, other_fit) in enumerate(zip(population, fitness)):
                if i != j and np.linalg.norm(individual - other_individual) < niche_radius and fit > other_fit :
                    is_unique = False
                    break
            if is_unique:
                selected.append(i)

        #Ensure Population Size 
        selected = random.sample(selected, min(len(selected),self.population_size))
        return selected

    def _adaptive_sigma(self, sigma):
        #Simple adaptive mechanism.  More sophisticated methods exist.
        improvement_rate = np.mean(self.fitness < self.best_fitness_overall)
        if improvement_rate > 0.2:
            sigma *= 1.1  # Increase sigma if many improvements
        elif improvement_rate < 0.1 :
            sigma *= 0.9  # Decrease sigma if few improvements
        return sigma
```

### Rank 15 (Overall AOCC Score: 4.9116e-02 |             AOCC Score on Unimodal instances: 1.4735e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalEvolutionaryStrategy
# Description: An evolutionary strategy that adapts mutation strength based on exploration success and uses a diverse initial population and niching to handle multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalEvolutionaryStrategy:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.mutation_rate = 0.1 # initial mutation rate
        self.mutation_strength = 5.0 # initial mutation strength
        self.niche_radius = 20.0 # for niching

        self.population = self.initialize_population()


    def initialize_population(self):
        # Create a diverse initial population using latin hypercube sampling
        population = np.zeros((self.population_size, self.dim))
        for i in range(self.dim):
            values = np.linspace(self.lower_bounds[i], self.upper_bounds[i], self.population_size)
            random.shuffle(values)
            population[:, i] = values
        return population


    def mutate(self, individual):
        # Adaptive mutation based on recent success
        mutation = np.random.normal(0, self.mutation_strength, self.dim)
        return np.clip(individual + mutation, self.lower_bounds, self.upper_bounds)

    def select(self, fitness_values):
       #Tournament Selection
       selected_indices = np.random.choice(range(self.population_size), size=self.population_size, replace=True)
       return selected_indices


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population = self.initialize_population()


        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]


        while self.eval_count < self.budget:
            # Selection (Tournament)
            selected_indices = self.select(fitness_values)
            offspring = self.population[selected_indices].copy()

            # Mutation with Adaptive Mutation Strength
            for i in range(self.population_size):
                offspring[i] = self.mutate(offspring[i])


            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Merge and replace (Elitism)
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))

            sorted_indices = np.argsort(combined_fitness)
            self.population = combined_population[sorted_indices[:self.population_size]]
            fitness_values = combined_fitness[sorted_indices[:self.population_size]]


            #Update best solution
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index].copy()
                self.best_fitness_overall = fitness_values[best_index]


            # Adapt mutation strength (crude example, can be more sophisticated)
            improvement = (self.best_fitness_overall - np.mean(fitness_values))
            if improvement > 0:
                self.mutation_strength *= 1.1  #Increase on success
            else:
                self.mutation_strength *= 0.9 #Decrease on failure
            self.mutation_strength = max(0.01, min(10, self.mutation_strength)) #keep within bounds


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            "mutation_strength": self.mutation_strength
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 16 (Overall AOCC Score: 4.9054e-02 |             AOCC Score on Unimodal instances: 1.4716e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a local search and adaptive mutation strength to efficiently explore and exploit multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate
        self.mutation_strength = 0.5 # Initial mutation strength, adaptive later


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        best_index = np.argmin(fitness_values)
        self.best_solution_overall = self.population[best_index].copy()
        self.best_fitness_overall = fitness_values[best_index]

        while self.eval_count < self.budget:
            # Differential Evolution
            new_population = np.zeros_like(self.population)
            for i in range(self.population_size):
                # Mutation
                a, b, c = random.sample(range(self.population_size), 3)
                while a == i or b == i or c == i:
                    a, b, c = random.sample(range(self.population_size), 3)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

                # Boundary handling
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                
                # Crossover
                trial = np.zeros_like(self.population[i])
                j_rand = random.randint(0, self.dim -1)
                for j in range(self.dim):
                    if random.random() < self.CR or j == j_rand:
                        trial[j] = mutant[j]
                    else:
                        trial[j] = self.population[i][j]
                
                # Local Search (Simple hill climbing)
                for _ in range(5): # Limited local search iterations
                    neighbor = trial + np.random.normal(0, self.mutation_strength, self.dim)
                    neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                    neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]
                    self.eval_count += 1
                    if neighbor_fitness < fitness_values[i]:
                        trial = neighbor
                        fitness_values[i] = neighbor_fitness
                
                new_population[i] = trial

            self.population = new_population
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size
            
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index].copy()
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Mutation Strength
            self.mutation_strength *= 0.98 # Gradually decrease to focus exploitation
            if self.mutation_strength < 0.01: # Avoid getting stuck
                self.mutation_strength = 0.1
            
        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

```

### Rank 17 (Overall AOCC Score: 4.8984e-02 |             AOCC Score on Unimodal instances: 1.4695e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A Differential Evolution algorithm enhanced with adaptive mutation and population clustering to escape local optima and explore diverse regions efficiently in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.cluster.vq import kmeans2

class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        
        self.population_size = 100 # Example value - can be tuned
        self.F = 0.8 # Differential weight - can be tuned
        self.CR = 0.9 # Crossover rate - can be tuned
        self.cluster_k = 5 # Number of clusters - can be tuned


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness_values)


        while self.eval_count < self.budget:
            #Clustering
            centroids, labels = kmeans2(self.population, self.cluster_k)

            offspring = []
            offspring_fitness = []
            for i in range(self.population_size):
                cluster_indices = np.where(labels == labels[i])[0]
                cluster = self.population[cluster_indices]
                
                a, b, c = np.random.choice(cluster, size=3, replace=False)
                mutant = a + self.F * (b - c)
                
                trial = np.clip(np.random.rand(self.dim) < self.CR, 0, 1) * mutant + (1 - trial) * self.population[i]
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count +=1
                offspring.append(trial)
                offspring_fitness.append(trial_fitness[0])

            offspring = np.array(offspring)
            offspring_fitness = np.array(offspring_fitness)
            
            #Selection
            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, offspring, offspring_fitness)
            fitness_values = objective_function(self.population)
            self.eval_count += self.population_size


            #Adaptive Mutation (adjust F based on success rate)
            #Implementation of Adaptive Mutation strategy is omitted for brevity.
            #A typical approach could be to increase F if many successful mutations are observed,
            #and decrease F if mutation frequently leads to worse solutions.

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
    
    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]

        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution

        return best_solution, best_fitness

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        indices = np.argsort(combined_fitness)
        selected_population = combined_population[indices[:self.population_size]]
        selected_fitness = combined_fitness[indices[:self.population_size]]

        best_solution, best_fitness = self._update_best(selected_population, selected_fitness)

        return selected_population, best_solution, best_fitness

```

### Rank 18 (Overall AOCC Score: 4.8957e-02 |             AOCC Score on Unimodal instances: 1.4687e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a local search and adaptive mutation to escape local optima efficiently in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Differential Evolution crossover rate
        self.mutation_rate = 0.2 #Initial mutation rate
        self.population = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness_values)

        while self.eval_count < self.budget:
            new_population = self._differential_evolution()
            new_fitness_values = objective_function(new_population)
            self.eval_count += self.population_size

            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, new_population, new_fitness_values)
            fitness_values = np.concatenate((fitness_values,new_fitness_values))
            #Adaptive mutation rate adjustment: increase mutation rate if progress is slow
            if self.eval_count > self.budget * 0.1 and (self.best_fitness_overall > self.best_fitness_overall*0.999): #Check for lack of improvement
                self.mutation_rate += 0.02
                if self.mutation_rate > 0.5:
                    self.mutation_rate = 0.5

        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_mutation_rate' : self.mutation_rate
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _differential_evolution(self):
        new_population = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])

            #Clamp values to bounds
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            trial = np.zeros_like(self.population[i])
            for j in range(self.dim):
                if random.random() < self.CR:
                    trial[j] = mutant[j]
                else:
                    trial[j] = self.population[i][j]

            #Add adaptive mutation
            trial += np.random.normal(0, self.mutation_rate * (self.upper_bounds - self.lower_bounds), self.dim)
            trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
            new_population[i] = trial
        return new_population


    def _selection(self, pop1, fit1, pop2, fit2):
        combined_pop = np.concatenate((pop1, pop2))
        combined_fit = np.concatenate((fit1, fit2))
        sorted_indices = np.argsort(combined_fit)
        selected_pop = combined_pop[sorted_indices[:self.population_size]]
        selected_fit = combined_fit[sorted_indices[:self.population_size]]
        best_solution, best_fitness = self._update_best(selected_pop, selected_fit)
        return selected_pop, best_solution, best_fitness

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]
        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution
        return best_solution, best_fitness

```

### Rank 19 (Overall AOCC Score: 4.8955e-02 |             AOCC Score on Unimodal instances: 1.4686e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining differential evolution with adaptive mutation and a local search to escape local optima effectively in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Differential Evolution crossover rate
        self.mutation_rate = 0.1 # Adaptive mutation rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(self.population, fitness_values)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, offspring, offspring_fitness)
            fitness_values = np.concatenate((fitness_values,offspring_fitness))
            self.mutation_rate = self._adapt_mutation_rate()
            
        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'mutation_rate_history': self._get_mutation_rate_history()
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info
    
    def _generate_offspring(self):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            v = self.population[a] + self.F * (self.population[b] - self.population[c])
            
            #Bound constraints
            v = np.clip(v, self.lower_bounds, self.upper_bounds)
            
            for j in range(self.dim):
                if random.random() < self.CR:
                    offspring[i, j] = v[j]
                else:
                    offspring[i, j] = self.population[i, j]
            
            #Adaptive Mutation
            if random.random() < self.mutation_rate:
                offspring[i] += np.random.normal(0, 0.1, self.dim) #Gaussian Mutation
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
                
        return offspring

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fitness)
        
        new_population = combined_population[sorted_indices[:self.population_size]]
        new_fitness = combined_fitness[sorted_indices[:self.population_size]]
        
        best_solution, best_fitness = self._update_best(new_population, new_fitness)
        
        return new_population, best_solution, best_fitness
        

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]

        if best_fitness < self.best_fitness_overall:
            self.best_fitness_overall = best_fitness
            self.best_solution_overall = best_solution

        return best_solution, best_fitness

    def _adapt_mutation_rate(self):
        #Example: Simple adaptation - increase mutation rate if not improving
        if self.eval_count % (self.population_size * 5) == 0: #Check every 5 generations
            if self.best_fitness_overall > self.best_fitness_overall:
                return min(self.mutation_rate + 0.01, 0.5) #Cap at 0.5
            else:
                return max(self.mutation_rate -0.005, 0.01) #Cap at 0.01
        return self.mutation_rate
    
    def _get_mutation_rate_history(self):
      # Placeholder for mutation rate history - implement a logging mechanism if needed.
      return []

```

### Rank 20 (Overall AOCC Score: 4.8936e-02 |             AOCC Score on Unimodal instances: 1.4681e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: A hybrid evolutionary algorithm combining Differential Evolution with a local search and adaptive mutation strategy for efficient multimodal optimization.
# Code:
```python
import numpy as np
import random

class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential Evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.mutation_scale = 1.0 # Initial mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        else:
            self.population = np.array([])
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall, self.best_fitness_overall = self._get_best(self.population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring()
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.population, self.best_solution_overall, self.best_fitness_overall = self._selection(self.population, fitness_values, offspring, offspring_fitness)
            fitness_values = np.concatenate((fitness_values, offspring_fitness))
            #Adaptive Mutation: reduce mutation if stuck in local minima
            if self.eval_count > self.budget * 0.3 and self.best_fitness_overall > acceptance_threshold:
                self.mutation_scale *= 0.9


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            "final_mutation_scale": self.mutation_scale
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self):
        offspring = np.zeros_like(self.population)
        for i in range(self.population_size):
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Keep within bounds

            #Add a local search step with a probability of 20%
            if random.random() < 0.2:
                mutant = self._local_search(mutant,objective_function)
                
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, self.population[i])
            
            #Add a small random perturbation to encourage exploration
            offspring[i] += np.random.normal(0,self.mutation_scale/10,self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

        return offspring

    def _local_search(self,x,objective_function):
        #Simple local search (replace with more sophisticated method if needed)
        step_size = 0.1
        for _ in range(10): #Number of steps to search
            for i in range(self.dim):
                neighbor = x.copy()
                neighbor[i] += random.uniform(-step_size,step_size)
                neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)
                fitness_neighbor = objective_function(np.array([neighbor]))[0]
                fitness_x = objective_function(np.array([x]))[0]
                if fitness_neighbor < fitness_x:
                  x = neighbor
        return x
    

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.concatenate((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fitness)
        selected_population = combined_population[sorted_indices[:self.population_size]]
        best_solution, best_fitness = self._get_best(selected_population, combined_fitness[sorted_indices[:self.population_size]])
        return selected_population, best_solution, best_fitness

    def _get_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        best_solution = population[best_index]
        best_fitness = fitness_values[best_index]
        return best_solution, best_fitness
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 21:56:45 INFO Full response text: **Analysis:**

Comparing AdaptiveGaussianSamplingEA (best) vs AdaptiveMultimodalOptimizer (worst), we see that the best utilizes adaptive Gaussian sampling and tournament selection, focusing on efficient exploration and exploitation in a unimodal landscape.  The worst uses a hybrid approach with differential evolution and adaptive mutation, but lacks the focused efficiency of the best.  AdaptiveGaussianSamplingEA shows strong exploitation capabilities, while AdaptiveMultimodalOptimizer struggles, indicated by the zero AOCC score on multimodal problems.

(second best) EnhancedArchiveGuidedDE vs (second worst) AdaptiveMultimodalEvolutionaryStrategy: EnhancedArchiveGuidedDE incorporates an archive to maintain diversity and guide exploration, showing better performance in multimodal problems compared to AdaptiveMultimodalEvolutionaryStrategy, which relies solely on adaptive mutation and a rudimentary local search.  EnhancedArchiveGuidedDE adapts scaling factors while AdaptiveMultimodalEvolutionaryStrategy focuses on the mutation rate.

Comparing (1st) AdaptiveGaussianSamplingEA vs (2nd) EnhancedArchiveGuidedDE, we see that AdaptiveGaussianSamplingEA has a simpler structure and focuses on Gaussian mutation to exploit the unimodal aspects of the GNBG, resulting in a higher AOCC score for unimodal instances but comparatively worse on multimodal functions. EnhancedArchiveGuidedDE balances exploration and exploitation better with its archive and adaptive scaling factors, yielding competitive results across multiple GNBG problem groups.

(3rd) AdaptiveGaussianMutationDE vs (4th) AdaptiveDifferentialEvolutionWithEnhancedInitialization:  AdaptiveGaussianMutationDE combines DE with adaptive Gaussian mutation, showing some success in unimodal problems but falling short on multimodal ones.  AdaptiveDifferentialEvolutionWithEnhancedInitialization adds enhanced initialization and a local search but has poor results overall. The adaptive Gaussian mutation in the 3rd seems to be more effective than the local search in the 4th.

Comparing (second worst) AdaptiveMultimodalOptimizer vs (worst) AdaptiveMultimodalOptimizer, the slight differences in approaches, especially local search strategies and mutation adaptation, didn't create a noticeable change in performance; both struggle with multimodal problems.  The differences are subtle in implementation detail, not fundamental design.

Overall: The top-performing algorithms prioritize either efficient exploitation in unimodal landscapes (AdaptiveGaussianSamplingEA) or effective exploration coupled with exploitation using archives or adaptive parameter tuning for multimodal landscapes (EnhancedArchiveGuidedDE). Simpler, more focused algorithms perform better on unimodal functions.  Multimodal success depends heavily on mechanisms for exploration and maintaining solution diversity.


**Experience:**

Effective population initialization and adaptive mechanisms are critical for navigating high-dimensional spaces.  Balancing exploration and exploitation is key, with archives and adaptive parameter tuning proving crucial for success on multimodal problems. Simple, focused algorithms can outperform more complex hybrids on unimodal problems.

2025-06-23 21:56:47 INFO Full response text: * **Keywords:**  Exploration-exploitation,  multimodality, dimensionality, adaptation, archive, parameter tuning, simplicity.

* **Advice:** Focus on designing heuristics that dynamically adjust exploration/exploitation based on problem characteristics (e.g., detected multimodality).  Prioritize simple, efficient mechanisms for low-dimensional or unimodal problems. Leverage archives to retain useful information and guide future searches.

* **Avoid:** Overly complex hybrid approaches unless strong justification exists.  Avoid heuristics that are computationally expensive without commensurate gains in performance.  Don't neglect the importance of adaptive parameter tuning.

* **Explanation:** Effective heuristics adapt to the problem's structure.  Simplicity and efficiency are valued, with complexity introduced only when necessary to address challenging characteristics like high dimensionality or multimodality.  Adaptive parameter tuning allows the heuristic to self-optimize for the specific problem instance.

2025-06-23 21:56:47 INFO Generating offspring via Crossover...
2025-06-23 22:14:01 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveGaussianArchiveEA
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])

### Worse code
AdaptiveGaussianMutationDE
import numpy as np
import random

class AdaptiveGaussianMutationDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.fitness_values = None
        self.mutation_scale = 0.8 # Initial mutation scale
        self.mutation_scale_decay = 0.99 #decay factor for the mutation scale

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population,self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                #Adaptive Gaussian perturbation to escape local optima
                mutant += np.random.normal(0, self.mutation_scale/2, self.dim)  

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])
                
                best_solution,best_fitness = self._find_best(np.array(new_population), np.array(new_fitness_values))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness


            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay #Decay mutation scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        population_reshaped = self.population.reshape(-1, self.dim)
        fitness = objective_function(population_reshaped)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self,population,fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

### Analyze & experience
- Comparing AdaptiveGaussianSamplingEA (best) vs AdaptiveMultimodalOptimizer (worst), we see that the best utilizes adaptive Gaussian sampling and tournament selection, focusing on efficient exploration and exploitation in a unimodal landscape.  The worst uses a hybrid approach with differential evolution and adaptive mutation, but lacks the focused efficiency of the best.  AdaptiveGaussianSamplingEA shows strong exploitation capabilities, while AdaptiveMultimodalOptimizer struggles, indicated by the zero AOCC score on multimodal problems.

(second best) EnhancedArchiveGuidedDE vs (second worst) AdaptiveMultimodalEvolutionaryStrategy: EnhancedArchiveGuidedDE incorporates an archive to maintain diversity and guide exploration, showing better performance in multimodal problems compared to AdaptiveMultimodalEvolutionaryStrategy, which relies solely on adaptive mutation and a rudimentary local search.  EnhancedArchiveGuidedDE adapts scaling factors while AdaptiveMultimodalEvolutionaryStrategy focuses on the mutation rate.

Comparing (1st) AdaptiveGaussianSamplingEA vs (2nd) EnhancedArchiveGuidedDE, we see that AdaptiveGaussianSamplingEA has a simpler structure and focuses on Gaussian mutation to exploit the unimodal aspects of the GNBG, resulting in a higher AOCC score for unimodal instances but comparatively worse on multimodal functions. EnhancedArchiveGuidedDE balances exploration and exploitation better with its archive and adaptive scaling factors, yielding competitive results across multiple GNBG problem groups.

(3rd) AdaptiveGaussianMutationDE vs (4th) AdaptiveDifferentialEvolutionWithEnhancedInitialization:  AdaptiveGaussianMutationDE combines DE with adaptive Gaussian mutation, showing some success in unimodal problems but falling short on multimodal ones.  AdaptiveDifferentialEvolutionWithEnhancedInitialization adds enhanced initialization and a local search but has poor results overall. The adaptive Gaussian mutation in the 3rd seems to be more effective than the local search in the 4th.

Comparing (second worst) AdaptiveMultimodalOptimizer vs (worst) AdaptiveMultimodalOptimizer, the slight differences in approaches, especially local search strategies and mutation adaptation, didn't create a noticeable change in performance; both struggle with multimodal problems.  The differences are subtle in implementation detail, not fundamental design.

Overall: The top-performing algorithms prioritize either efficient exploitation in unimodal landscapes (AdaptiveGaussianSamplingEA) or effective exploration coupled with exploitation using archives or adaptive parameter tuning for multimodal landscapes (EnhancedArchiveGuidedDE). Simpler, more focused algorithms perform better on unimodal functions.  Multimodal success depends heavily on mechanisms for exploration and maintaining solution diversity.
- * **Keywords:**  Exploration-exploitation,  multimodality, dimensionality, adaptation, archive, parameter tuning, simplicity.

* **Advice:** Focus on designing heuristics that dynamically adjust exploration/exploitation based on problem characteristics (e.g., detected multimodality).  Prioritize simple, efficient mechanisms for low-dimensional or unimodal problems. Leverage archives to retain useful information and guide future searches.

* **Avoid:** Overly complex hybrid approaches unless strong justification exists.  Avoid heuristics that are computationally expensive without commensurate gains in performance.  Don't neglect the importance of adaptive parameter tuning.

* **Explanation:** Effective heuristics adapt to the problem's structure.  Simplicity and efficiency are valued, with complexity introduced only when necessary to address challenging characteristics like high dimensionality or multimodality.  Adaptive parameter tuning allows the heuristic to self-optimize for the specific problem instance.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:14:01 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Exploration-exploitation,  multimodality, dimensionality, adaptation, archive, parameter tuning, simplicity.

* **Advice:** Focus on designing heuristics that dynamically adjust exploration/exploitation based on problem characteristics (e.g., detected multimodality).  Prioritize simple, efficient mechanisms for low-dimensional or unimodal problems. Leverage archives to retain useful information and guide future searches.

* **Avoid:** Overly complex hybrid approaches unless strong justification exists.  Avoid heuristics that are computationally expensive without commensurate gains in performance.  Don't neglect the importance of adaptive parameter tuning.

* **Explanation:** Effective heuristics adapt to the problem's structure.  Simplicity and efficiency are valued, with complexity introduced only when necessary to address challenging characteristics like high dimensionality or multimodality.  Adaptive parameter tuning allows the heuristic to self-optimize for the specific problem instance.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 22:15:47 INFO Perform Harmony Search...
2025-06-23 22:16:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:00 ERROR Can not run the algorithm
2025-06-23 22:16:00 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1448
2025-06-23 22:16:00 INFO FeHistory: [-183.30063456]
2025-06-23 22:16:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:00 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 648.6098320422105, sigma_decay: float = 0.9522728357348608, initial_sigma_multiplier: float = 0.33012821731273484):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:00 ERROR Can not run the algorithm
2025-06-23 22:16:00 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:00 INFO FeHistory: [3510412.47094852]
2025-06-23 22:16:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:00 ERROR Can not run the algorithm
2025-06-23 22:16:01 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:01 INFO FeHistory: [233335.7487103]
2025-06-23 22:16:01 INFO Expected Optimum FE: -5000
2025-06-23 22:16:01 INFO Unimodal AOCC mean: 0.1448
2025-06-23 22:16:01 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:01 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:01 INFO AOCC mean: 0.0483
2025-06-23 22:16:01 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:01 ERROR Can not run the algorithm
2025-06-23 22:16:01 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1449
2025-06-23 22:16:01 INFO FeHistory: [-183.30978347]
2025-06-23 22:16:01 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:01 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 726.4727378432084, sigma_decay: float = 0.9211081569953448, initial_sigma_multiplier: float = 0.07737394257231274):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:01 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:01 ERROR Can not run the algorithm
2025-06-23 22:16:01 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:01 INFO FeHistory: [1479986.09956502]
2025-06-23 22:16:01 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:01 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:01 ERROR Can not run the algorithm
2025-06-23 22:16:01 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:01 INFO FeHistory: [147444.70338762]
2025-06-23 22:16:01 INFO Expected Optimum FE: -5000
2025-06-23 22:16:01 INFO Unimodal AOCC mean: 0.1449
2025-06-23 22:16:01 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:01 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:01 INFO AOCC mean: 0.0483
2025-06-23 22:16:01 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:01 ERROR Can not run the algorithm
2025-06-23 22:16:02 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1459
2025-06-23 22:16:02 INFO FeHistory: [-183.38824404]
2025-06-23 22:16:02 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:02 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 829.1673217213768, sigma_decay: float = 0.9001009957141733, initial_sigma_multiplier: float = 0.26274729062255925):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:02 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:02 ERROR Can not run the algorithm
2025-06-23 22:16:02 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:02 INFO FeHistory: [2194828.29203573]
2025-06-23 22:16:02 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:02 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:02 ERROR Can not run the algorithm
2025-06-23 22:16:02 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:02 INFO FeHistory: [126892.19606404]
2025-06-23 22:16:02 INFO Expected Optimum FE: -5000
2025-06-23 22:16:02 INFO Unimodal AOCC mean: 0.1459
2025-06-23 22:16:02 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:02 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:02 INFO AOCC mean: 0.0486
2025-06-23 22:16:02 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:02 ERROR Can not run the algorithm
2025-06-23 22:16:03 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1447
2025-06-23 22:16:03 INFO FeHistory: [-183.28986304]
2025-06-23 22:16:03 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:03 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 578.2218154454515, sigma_decay: float = 0.834477168299181, initial_sigma_multiplier: float = 0.060604167982961914):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:03 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:03 ERROR Can not run the algorithm
2025-06-23 22:16:03 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:03 INFO FeHistory: [1469337.85787439]
2025-06-23 22:16:03 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:03 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:03 ERROR Can not run the algorithm
2025-06-23 22:16:03 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:03 INFO FeHistory: [182897.0620546]
2025-06-23 22:16:03 INFO Expected Optimum FE: -5000
2025-06-23 22:16:03 INFO Unimodal AOCC mean: 0.1447
2025-06-23 22:16:03 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:03 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:03 INFO AOCC mean: 0.0482
2025-06-23 22:16:03 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:03 ERROR Can not run the algorithm
2025-06-23 22:16:03 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1456
2025-06-23 22:16:03 INFO FeHistory: [-183.36610704]
2025-06-23 22:16:03 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:03 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 679.1562948433109, sigma_decay: float = 0.9424264829188305, initial_sigma_multiplier: float = 0.696961892953316):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:03 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:03 ERROR Can not run the algorithm
2025-06-23 22:16:04 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:04 INFO FeHistory: [4529359.03795267]
2025-06-23 22:16:04 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:04 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:04 ERROR Can not run the algorithm
2025-06-23 22:16:04 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:04 INFO FeHistory: [119259.38186532]
2025-06-23 22:16:04 INFO Expected Optimum FE: -5000
2025-06-23 22:16:04 INFO Unimodal AOCC mean: 0.1456
2025-06-23 22:16:04 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:04 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:04 INFO AOCC mean: 0.0485
2025-06-23 22:16:04 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:04 ERROR Can not run the algorithm
2025-06-23 22:16:04 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1454
2025-06-23 22:16:04 INFO FeHistory: [-183.34934683]
2025-06-23 22:16:04 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:04 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 827.6396874227084, sigma_decay: float = 0.9375506577423389, initial_sigma_multiplier: float = 0.23280934181493215):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:04 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:04 ERROR Can not run the algorithm
2025-06-23 22:16:05 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:05 INFO FeHistory: [4068396.58491628]
2025-06-23 22:16:05 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:05 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:05 ERROR Can not run the algorithm
2025-06-23 22:16:05 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:05 INFO FeHistory: [185726.10839838]
2025-06-23 22:16:05 INFO Expected Optimum FE: -5000
2025-06-23 22:16:05 INFO Unimodal AOCC mean: 0.1454
2025-06-23 22:16:05 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:05 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:05 INFO AOCC mean: 0.0485
2025-06-23 22:16:05 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:05 ERROR Can not run the algorithm
2025-06-23 22:16:05 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1458
2025-06-23 22:16:05 INFO FeHistory: [-183.38127234]
2025-06-23 22:16:05 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:05 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 726.4727378432084, sigma_decay: float = 0.9424264829188305, initial_sigma_multiplier: float = 0.7045779887810116):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:05 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:05 ERROR Can not run the algorithm
2025-06-23 22:16:05 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:05 INFO FeHistory: [1264120.56024463]
2025-06-23 22:16:05 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:05 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:05 ERROR Can not run the algorithm
2025-06-23 22:16:06 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:06 INFO FeHistory: [150230.60280645]
2025-06-23 22:16:06 INFO Expected Optimum FE: -5000
2025-06-23 22:16:06 INFO Unimodal AOCC mean: 0.1458
2025-06-23 22:16:06 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:06 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:06 INFO AOCC mean: 0.0486
2025-06-23 22:16:06 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:06 ERROR Can not run the algorithm
2025-06-23 22:16:06 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1451
2025-06-23 22:16:06 INFO FeHistory: [-183.32305772]
2025-06-23 22:16:06 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:06 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 670.0738004725148, sigma_decay: float = 0.9001009957141733, initial_sigma_multiplier: float = 0.26274729062255925):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:06 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:06 ERROR Can not run the algorithm
2025-06-23 22:16:06 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:06 INFO FeHistory: [1974350.81103292]
2025-06-23 22:16:06 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:06 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:06 ERROR Can not run the algorithm
2025-06-23 22:16:07 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:07 INFO FeHistory: [168240.90010298]
2025-06-23 22:16:07 INFO Expected Optimum FE: -5000
2025-06-23 22:16:07 INFO Unimodal AOCC mean: 0.1451
2025-06-23 22:16:07 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:07 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:07 INFO AOCC mean: 0.0484
2025-06-23 22:16:07 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:07 ERROR Can not run the algorithm
2025-06-23 22:16:07 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1458
2025-06-23 22:16:07 INFO FeHistory: [-183.37882781]
2025-06-23 22:16:07 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:07 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 727.9788277367732, sigma_decay: float = 0.9001009957141733, initial_sigma_multiplier: float = 0.9265585999612301):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:07 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:07 ERROR Can not run the algorithm
2025-06-23 22:16:07 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:07 INFO FeHistory: [2220962.44985913]
2025-06-23 22:16:07 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:07 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:07 ERROR Can not run the algorithm
2025-06-23 22:16:07 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:07 INFO FeHistory: [153602.96914086]
2025-06-23 22:16:07 INFO Expected Optimum FE: -5000
2025-06-23 22:16:07 INFO Unimodal AOCC mean: 0.1458
2025-06-23 22:16:07 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:07 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:07 INFO AOCC mean: 0.0486
2025-06-23 22:16:07 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:16:07 ERROR Can not run the algorithm
2025-06-23 22:16:08 INFO Run function 6 complete. FEHistory len: 1, AOCC: 0.1463
2025-06-23 22:16:08 INFO FeHistory: [-183.42072116]
2025-06-23 22:16:08 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:16:08 INFO Good algorithm:
Algorithm Name: AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 726.4727378432084, sigma_decay: float = 0.861395124804767, initial_sigma_multiplier: float = 0.5542077618767173):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
2025-06-23 22:16:08 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:16:08 ERROR Can not run the algorithm
2025-06-23 22:16:08 INFO Run function 13 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:08 INFO FeHistory: [1062675.21308252]
2025-06-23 22:16:08 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:16:08 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:16:08 ERROR Can not run the algorithm
2025-06-23 22:16:08 INFO Run function 18 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-23 22:16:08 INFO FeHistory: [190260.41028518]
2025-06-23 22:16:08 INFO Expected Optimum FE: -5000
2025-06-23 22:16:08 INFO Unimodal AOCC mean: 0.1463
2025-06-23 22:16:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:16:08 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:16:08 INFO AOCC mean: 0.0488
2025-06-23 22:16:08 INFO Generation 1, best so far: 0.24747886597801494
2025-06-23 22:16:08 INFO Population length is: 12
2025-06-23 22:16:08 INFO --- Performing Long-Term Reflection at Generation 2 ---
2025-06-23 22:16:08 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.0894e-02 |             AOCC Score on Unimodal instances: 1.5268e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchySamplingWithArchive
# Description: An evolutionary algorithm using adaptive Cauchy sampling and an archive to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchySamplingWithArchive
# Description: An evolutionary algorithm using adaptive Cauchy sampling and an archive to escape local optima in multimodal landscapes.
# Code:
class AdaptiveCauchySamplingWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.mutation_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Cauchy mutation)
            offspring = self._cauchy_recombination(parents)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self._update_archive(offspring, offspring_fitness)

            # Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)

            # Adapt Cauchy scale parameter
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.gamma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 2 (Overall AOCC Score: 5.0702e-02 |             AOCC Score on Unimodal instances: 1.5211e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveGaussianDE
# Description: Combines Differential Evolution with an archive and adaptive Gaussian mutation for efficient multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveGaussianDE:
    """
    Combines Differential Evolution (DE) with an archive and adaptive Gaussian mutation for efficient multimodal optimization.  The archive helps maintain diversity and guide exploration, while adaptive Gaussian mutation allows for fine-tuned exploitation.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.mutation_strength = 0.1 #initial mutation strength

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt mutation strength based on progress
            self.mutation_strength = max(0.01, self.mutation_strength * (1 + 0.1 * (self.best_fitness_overall > 0.01) ) )  # Reduce if close to 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_mutation_strength': self.mutation_strength
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            
            #Gaussian Mutation
            gaussian_noise = np.random.normal(0, self.mutation_strength * (self.upper_bounds - self.lower_bounds), self.dim)
            offspring[i] = mutant + gaussian_noise

            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 3 (Overall AOCC Score: 5.0667e-02 |             AOCC Score on Unimodal instances: 1.5200e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedGaussianDE
# Description: Combines Differential Evolution with Gaussian mutation and an archive for enhanced exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedGaussianDE:
    """
    Combines Differential Evolution with Gaussian mutation and an archive to enhance exploration and exploitation in multimodal optimization problems.  The archive stores promising solutions encountered so far, promoting diversity and preventing premature convergence.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian width
        self.sigma_decay = 0.99 # Decay rate for sigma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += len(fitness)

        self.best_solution_overall = population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        self.update_archive(population, fitness)

        while self.eval_count < self.budget:
            # Differential Evolution with Gaussian Mutation
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                
                #Gaussian Mutation
                mutant += np.random.normal(0, self.sigma, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    offspring[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    offspring[i] = population[i]

            population = offspring
            self.sigma *= self.sigma_decay
            
            self.update_archive(population, fitness)
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def update_archive(self, population, fitness):
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))
        self.archive.sort(key=lambda x: x[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] #Keep only the best

```

### Rank 4 (Overall AOCC Score: 5.0509e-02 |             AOCC Score on Unimodal instances: 1.5153e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedGaussianDE
# Description: Combines Differential Evolution with Gaussian mutation and an archive for enhanced exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedGaussianDE:
    """
    Combines Differential Evolution with Gaussian mutation and an archive for enhanced exploration in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds) # Initial Gaussian width
        self.sigma_decay = 0.99
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(population, i)
                trial = self._crossover(population[i], mutant)
                trial = self._gaussian_mutation(trial) #Gaussian mutation added
                trial = self._bound_solution(trial)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                
                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    offspring.append(population[i])

            population = np.array(offspring)
            self._update_archive(population, fitness_values) #Update archive
            self.sigma *= self.sigma_decay
            
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[best_index]
                self.best_solution_overall = population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _generate_mutant(self, population, i):
        a, b, c = self._select_different_individuals(i, self.population_size)
        mutant = population[a] + self.F * (population[b] - population[c])
        return mutant

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _gaussian_mutation(self, solution):
        solution += np.random.normal(0, self.sigma, self.dim)
        return solution

    def _bound_solution(self, solution):
        return np.clip(solution, self.lower_bounds, self.upper_bounds)

    def _select_different_individuals(self, i, pop_size):
        while True:
            a, b, c = random.sample(range(pop_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        combined = sorted(combined, key=lambda x: x[-1])
        
        if len(self.archive) < self.archive_size:
            self.archive.extend(combined[:self.archive_size-len(self.archive)])
        else:
            self.archive[:self.archive_size - len(combined)] = combined

```

### Rank 5 (Overall AOCC Score: 5.0505e-02 |             AOCC Score on Unimodal instances: 1.5152e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianDEwithArchive
# Description: Combines adaptive Gaussian mutation with differential evolution and an archive for enhanced exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class AdaptiveGaussianDEwithArchive:
    """Combines adaptive Gaussian mutation with differential evolution and an archive."""
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50  # Size of the archive
        self.archive = []
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))
        self.fitness_values = np.full(self.population_size, np.inf)


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.fitness_values = np.full(self.population_size, np.inf)
        self.evaluate_population(objective_function)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self.select_different_individuals(i)
                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])
                trial = self.crossover(self.population[i], mutant)
                trial = self.gaussian_mutation(trial) #Add Gaussian Mutation
                trial = self.bound_solution(trial)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    self.fitness_values[i] = trial_fitness
                else:
                    new_population.append(self.population[i]) #Keep the old solution

            self.population = np.array(new_population)
            self.update_archive()
            self.sigma *= self.sigma_decay #Adapt Gaussian Mutation

            best_index = np.argmin(self.fitness_values)
            if self.fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = self.fitness_values[best_index]
                self.best_solution_overall = self.population[best_index]


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def evaluate_population(self, objective_function):
        self.fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

    def select_different_individuals(self, i):
        while True:
            a, b, c = random.sample(range(self.population_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c

    def crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u

    def bound_solution(self, solution):
        solution = np.clip(solution, self.lower_bounds, self.upper_bounds)
        return solution

    def gaussian_mutation(self, solution):
        solution += np.random.normal(0, self.sigma, size=solution.shape)
        return solution

    def update_archive(self):
        # Add new solutions to archive, keeping only best
        for i in range(self.population_size):
            self.archive.append((self.population[i], self.fitness_values[i]))
        self.archive.sort(key=lambda item: item[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] # Keep only top solutions

```

### Rank 6 (Overall AOCC Score: 4.9120e-02 |             AOCC Score on Unimodal instances: 1.4736e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedGaussianMutationDE
# Description: Combines Differential Evolution, Gaussian mutation, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedGaussianMutationDE:
    """
    Combines Differential Evolution, Gaussian mutation, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Mutation with Archive Augmentation
                a, b, c = self._select_different(i, population)
                mutant = self._differential_mutation(population[a], population[b], population[c])

                # Adaptive Gaussian perturbation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    self._update_archive(trial, trial_fitness) #add to archive
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(fitness[:len(new_population)]))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.mutation_scale *= self.mutation_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        #Select from population and archive
        candidates = list(range(len(population))) + [i for i in range(len(self.archive))]
        a, b, c = random.sample(candidates, 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(candidates, 3)
        
        if a >= len(population):
            a_val = self.archive[a - len(population)][0]
        else:
            a_val = population[a]
        if b >= len(population):
            b_val = self.archive[b - len(population)][0]
        else:
            b_val = population[b]
        if c >= len(population):
            c_val = self.archive[c - len(population)][0]
        else:
            c_val = population[c]

        return a_val, b_val, c_val


    def _differential_mutation(self, a, b, c):
        return a + self.mutation_scale * (b - c)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

```

### Rank 7 (Overall AOCC Score: 4.9002e-02 |             AOCC Score on Unimodal instances: 1.4700e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedGaussianMutationDE
# Description: Differential Evolution with adaptive Gaussian mutation and an archive for enhanced exploration in multimodal landscapes.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedGaussianMutationDE:
    """
    Combines Differential Evolution with adaptive Gaussian mutation and an archive to enhance exploration and exploitation in multimodal landscapes.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50  # Size of the archive
        self.archive = []
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99
        self.population = None
        self.fitness_values = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)
        
        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation with Archive Integration
                a, b, c = self._select_different(i, self.population, self.archive)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])

                # Adaptive Gaussian Mutation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                # Selection and Archive Update
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay
            self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population, archive):
        candidates = np.concatenate((population, np.array(archive)))
        a, b, c = random.sample(range(len(candidates)), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(len(candidates)), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_solution, worst_fitness = max(self.archive, key=lambda item: item[1])
            if fitness < worst_fitness:
                self.archive.remove((worst_solution, worst_fitness))
                self.archive.append((solution, fitness))
```

### Rank 8 (Overall AOCC Score: 4.8919e-02 |             AOCC Score on Unimodal instances: 1.4676e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedGaussianMutationDE
# Description: Combines Differential Evolution, Gaussian mutation, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedGaussianMutationDE:
    """
    Combines Differential Evolution, Gaussian mutation, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99
        self.archive_diversity_threshold = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = self._initialize_population()
        self.fitness_values = self._evaluate_population(objective_function)

        self.best_solution_overall, self.best_fitness_overall = self._find_best(self.population, self.fitness_values)

        while self.eval_count < self.budget:
            new_population = []
            new_fitness_values = []

            for i in range(self.population_size):
                # Differential Mutation with Archive Guidance
                a, b, c = self._select_different(i)
                mutant = self.population[a] + self.mutation_scale * (self.population[b] - self.population[c])
                
                #add archive element with some prob
                if random.random()<0.2 and len(self.archive)>0:
                  archive_index = random.randint(0, len(self.archive)-1)
                  mutant += self.mutation_scale * (self.archive[archive_index] - self.population[i])

                #Adaptive Gaussian perturbation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                #Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, self.population[i])

                #Selection
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1
                if trial_fitness < self.fitness_values[i]:
                    new_population.append(trial)
                    new_fitness_values.append(trial_fitness)
                    self._update_archive(trial, trial_fitness) #add to archive
                else:
                    new_population.append(self.population[i])
                    new_fitness_values.append(self.fitness_values[i])

                self.best_solution_overall, self.best_fitness_overall = self._find_best(np.array(new_population), np.array(new_fitness_values))

            self.population = np.array(new_population)
            self.fitness_values = np.array(new_fitness_values)
            self.mutation_scale *= self.mutation_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function):
        fitness = objective_function(self.population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index):
        a, b, c = random.sample(range(self.population_size), 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(range(self.population_size), 3)
        return a, b, c

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

        #maintain diversity
        if len(self.archive)>1:
          self._maintain_archive_diversity()


    def _maintain_archive_diversity(self):
      archive_solutions = np.array([sol for sol,_ in self.archive])
      distances = np.linalg.norm(archive_solutions[:,None,:] - archive_solutions[None,:,:], axis=2)
      
      for i in range(len(distances)):
        if np.sum(distances[i]<self.archive_diversity_threshold)>1:
          #remove the worst solution
          worst_index = np.argmax([f for _,f in self.archive])
          self.archive.pop(worst_index)
          break #only remove one in each iteration
          

```

### Rank 9 (Overall AOCC Score: 4.8904e-02 |             AOCC Score on Unimodal instances: 1.4671e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to escape local optima in multimodal landscapes.
# Code:
class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (adaptive)
        self.gamma_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._cauchy_mutation(parents)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._update_population(population, fitness_values)
            self.gamma *= self.gamma_decay  # Adaptive Cauchy scale decay
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + cauchy.rvs(loc=0, scale=self.gamma, size=parents.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, solutions, fitness_values):
        combined = np.column_stack((solutions, fitness_values))
        self.archive.extend(combined)
        self.archive.sort(key=lambda x: x[-1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size]


    def _update_population(self, population, fitness_values):
        combined_pop = np.vstack((population, self._sample_archive()))
        combined_fit = np.concatenate((fitness_values, self._get_archive_fitness()))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _sample_archive(self):
        num_samples = self.population_size // 2
        if len(self.archive) > 0 :
            return np.array([x[:-1] for x in np.random.choice(self.archive, num_samples, replace=False)])
        else:
            return np.empty((0, self.dim))

    def _get_archive_fitness(self):
        if len(self.archive) > 0:
            return np.array([x[-1] for x in self.archive])
        else:
            return np.array([])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 10 (Overall AOCC Score: 4.8767e-02 |             AOCC Score on Unimodal instances: 1.4630e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 726.4727378432084, sigma_decay: float = 0.861395124804767, initial_sigma_multiplier: float = 0.5542077618767173):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = initial_sigma_multiplier * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 11 (Overall AOCC Score: 4.8702e-02 |             AOCC Score on Unimodal instances: 1.4611e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchySamplingWithArchive
# Description: An evolutionary algorithm using adaptive Cauchy sampling and an archive to escape local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchySamplingWithArchive
# Description: An evolutionary algorithm using adaptive Cauchy sampling and an archive to escape local optima in multimodal landscapes.
# Code:
class AdaptiveCauchySamplingWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.exploration_rate = 0.2

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        for _ in range(int(self.budget / self.population_size)):
            
            #Selection (Tournament Selection)
            parents = self._tournament_selection(population, fitness_values)

            #Recombination (Cauchy Mutation)
            offspring = self._cauchy_recombination(parents)

            #Archive Management
            self._update_archive(offspring, objective_function)

            #Adaptive Exploration
            self._adaptive_exploration(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            #Update best solution
            self._update_best(offspring, offspring_fitness)

            self.gamma *= self.gamma_decay


        if self.best_solution_overall is None and self.dim > 0:  # Fallback
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.gamma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, objective_function):
        offspring_fitness = objective_function(offspring)
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]


    def _adaptive_exploration(self, offspring):
        num_explore = int(self.exploration_rate * len(offspring))
        for i in range(num_explore):
            if len(self.archive) > 0:
                random_solution = np.random.choice(len(self.archive))[0]
                offspring[i] = self.archive[random_solution][0] + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:16:15 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveCauchySamplingWithArchive vs (worst) AdaptiveGaussianSamplingEA, we see that the Cauchy distribution, used in the best algorithm, is more robust to outliers and allows for larger jumps in the search space, which is beneficial for exploration in high-dimensional spaces.  AdaptiveGaussianSamplingEA, on the other hand, relies on Gaussian mutation which, while efficient for exploitation near the optimum, might struggle with exploration in complex multimodal landscapes. The archive in AdaptiveCauchySamplingWithArchive further enhances exploration and prevents premature convergence.

(second best) ArchiveGuidedAdaptiveGaussianDE vs (second worst) ArchiveGuidedGaussianMutationDE:  ArchiveGuidedAdaptiveGaussianDE uses adaptive Gaussian mutation and a more sophisticated archive update strategy. This allows for both fine-grained exploitation and efficient exploration by maintaining a diverse archive.  ArchiveGuidedGaussianMutationDE has a simpler archive update which may fail to maintain diversity effectively, especially in high-dimensional spaces. Its strategy is less sophisticated in balancing exploration and exploitation.

Comparing (1st) AdaptiveCauchySamplingWithArchive vs (2nd) ArchiveGuidedAdaptiveGaussianDE, we see that while both use archives, AdaptiveCauchySamplingWithArchive's Cauchy mutation provides a more powerful exploration mechanism than ArchiveGuidedAdaptiveGaussianDE's Gaussian mutation combined with Differential Evolution. Cauchy's heavy tails better suit exploration in complex and high-dimensional search spaces.

(3rd) ArchiveGuidedGaussianDE vs (4th) ArchiveGuidedGaussianDE:  These two algorithms are nearly identical, exhibiting only minor differences in implementation details such as population initialization and archive management. Minor variations in their implementations account for the slight performance difference, with the better algorithm having a slightly more robust archive update strategy.

Comparing (second worst) AdaptiveGaussianSamplingEA vs (worst) AdaptiveCauchySamplingWithArchive (the second one in the list), we see that the latter is poorly optimized and has the same issues as the former but with the additional detriment of a poorer archive implementation that does not effectively maintain diversity.

Overall: The top-performing algorithms consistently leverage adaptive mutation strategies (Cauchy or Gaussian with adaptive parameters) coupled with archives to effectively balance exploration and exploitation in high-dimensional spaces.  The use of archives prevents premature convergence and promotes diversity, and Cauchy mutation seems to be slightly better for exploration in this problem setting.  Simpler strategies or less sophisticated archive management result in substantially worse performance.


**Experience:**

Adaptive mutation and archive management are crucial for effective high-dimensional optimization.  Cauchy distributions appear particularly well-suited for exploration in complex search spaces compared to Gaussian, especially with the appropriate archive strategies for maintaining solution diversity.

2025-06-23 22:16:16 INFO Full response text: * **Keywords:**  Cauchy distribution, high-dimensional optimization, archive management, adaptive mutation, solution diversity.

* **Advice:** Focus on the specific advantages of Cauchy distributions over Gaussians in high-dimensional spaces.  Quantify the impact of different archive strategies on maintaining diversity.  Develop rigorous experiments comparing Cauchy-based approaches to alternatives.

* **Avoid:**  Generic statements about exploration/exploitation,  population initialization, and adaptive mechanisms.  Avoid comparisons to simple algorithms or claims of general superiority without strong evidence.  Don't overemphasize the "multimodal" aspect.

* **Explanation:** The current reflection is too general.  To design better heuristics, we must identify and precisely articulate the unique strengths of the Cauchy distribution within the specific context of archive-based high-dimensional optimization, focusing on measurable improvements in diversity and solution quality.  This requires detailed experimental validation.

2025-06-23 22:16:16 INFO Generating offspring via Crossover...
2025-06-23 22:22:41 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
ArchiveGuidedGaussianMutationDE
import numpy as np
import random

class ArchiveGuidedGaussianMutationDE:
    """
    Combines Differential Evolution, Gaussian mutation, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.mutation_scale = 0.8
        self.mutation_scale_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Mutation with Archive Augmentation
                a, b, c = self._select_different(i, population)
                mutant = self._differential_mutation(population[a], population[b], population[c])

                # Adaptive Gaussian perturbation
                mutant += np.random.normal(0, self.mutation_scale / 2, self.dim)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    self._update_archive(trial, trial_fitness) #add to archive
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(fitness[:len(new_population)]))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.mutation_scale *= self.mutation_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        #Select from population and archive
        candidates = list(range(len(population))) + [i for i in range(len(self.archive))]
        a, b, c = random.sample(candidates, 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(candidates, 3)
        
        if a >= len(population):
            a_val = self.archive[a - len(population)][0]
        else:
            a_val = population[a]
        if b >= len(population):
            b_val = self.archive[b - len(population)][0]
        else:
            b_val = population[b]
        if c >= len(population):
            c_val = self.archive[c - len(population)][0]
        else:
            c_val = population[c]

        return a_val, b_val, c_val


    def _differential_mutation(self, a, b, c):
        return a + self.mutation_scale * (b - c)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)


### Worse code
AdaptiveCauchySamplingWithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchySamplingWithArchive
# Description: An evolutionary algorithm using adaptive Cauchy sampling and an archive to escape local optima in multimodal landscapes.
# Code:
class AdaptiveCauchySamplingWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.mutation_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Cauchy mutation)
            offspring = self._cauchy_recombination(parents)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self._update_archive(offspring, offspring_fitness)

            # Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)

            # Adapt Cauchy scale parameter
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.gamma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]


### Analyze & experience
- Comparing (best) AdaptiveCauchySamplingWithArchive vs (worst) AdaptiveGaussianSamplingEA, we see that the Cauchy distribution, used in the best algorithm, is more robust to outliers and allows for larger jumps in the search space, which is beneficial for exploration in high-dimensional spaces.  AdaptiveGaussianSamplingEA, on the other hand, relies on Gaussian mutation which, while efficient for exploitation near the optimum, might struggle with exploration in complex multimodal landscapes. The archive in AdaptiveCauchySamplingWithArchive further enhances exploration and prevents premature convergence.

(second best) ArchiveGuidedAdaptiveGaussianDE vs (second worst) ArchiveGuidedGaussianMutationDE:  ArchiveGuidedAdaptiveGaussianDE uses adaptive Gaussian mutation and a more sophisticated archive update strategy. This allows for both fine-grained exploitation and efficient exploration by maintaining a diverse archive.  ArchiveGuidedGaussianMutationDE has a simpler archive update which may fail to maintain diversity effectively, especially in high-dimensional spaces. Its strategy is less sophisticated in balancing exploration and exploitation.

Comparing (1st) AdaptiveCauchySamplingWithArchive vs (2nd) ArchiveGuidedAdaptiveGaussianDE, we see that while both use archives, AdaptiveCauchySamplingWithArchive's Cauchy mutation provides a more powerful exploration mechanism than ArchiveGuidedAdaptiveGaussianDE's Gaussian mutation combined with Differential Evolution. Cauchy's heavy tails better suit exploration in complex and high-dimensional search spaces.

(3rd) ArchiveGuidedGaussianDE vs (4th) ArchiveGuidedGaussianDE:  These two algorithms are nearly identical, exhibiting only minor differences in implementation details such as population initialization and archive management. Minor variations in their implementations account for the slight performance difference, with the better algorithm having a slightly more robust archive update strategy.

Comparing (second worst) AdaptiveGaussianSamplingEA vs (worst) AdaptiveCauchySamplingWithArchive (the second one in the list), we see that the latter is poorly optimized and has the same issues as the former but with the additional detriment of a poorer archive implementation that does not effectively maintain diversity.

Overall: The top-performing algorithms consistently leverage adaptive mutation strategies (Cauchy or Gaussian with adaptive parameters) coupled with archives to effectively balance exploration and exploitation in high-dimensional spaces.  The use of archives prevents premature convergence and promotes diversity, and Cauchy mutation seems to be slightly better for exploration in this problem setting.  Simpler strategies or less sophisticated archive management result in substantially worse performance.
- * **Keywords:**  Cauchy distribution, high-dimensional optimization, archive management, adaptive mutation, solution diversity.

* **Advice:** Focus on the specific advantages of Cauchy distributions over Gaussians in high-dimensional spaces.  Quantify the impact of different archive strategies on maintaining diversity.  Develop rigorous experiments comparing Cauchy-based approaches to alternatives.

* **Avoid:**  Generic statements about exploration/exploitation,  population initialization, and adaptive mechanisms.  Avoid comparisons to simple algorithms or claims of general superiority without strong evidence.  Don't overemphasize the "multimodal" aspect.

* **Explanation:** The current reflection is too general.  To design better heuristics, we must identify and precisely articulate the unique strengths of the Cauchy distribution within the specific context of archive-based high-dimensional optimization, focusing on measurable improvements in diversity and solution quality.  This requires detailed experimental validation.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:22:41 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Cauchy distribution, high-dimensional optimization, archive management, adaptive mutation, solution diversity.

* **Advice:** Focus on the specific advantages of Cauchy distributions over Gaussians in high-dimensional spaces.  Quantify the impact of different archive strategies on maintaining diversity.  Develop rigorous experiments comparing Cauchy-based approaches to alternatives.

* **Avoid:**  Generic statements about exploration/exploitation,  population initialization, and adaptive mechanisms.  Avoid comparisons to simple algorithms or claims of general superiority without strong evidence.  Don't overemphasize the "multimodal" aspect.

* **Explanation:** The current reflection is too general.  To design better heuristics, we must identify and precisely articulate the unique strengths of the Cauchy distribution within the specific context of archive-based high-dimensional optimization, focusing on measurable improvements in diversity and solution quality.  This requires detailed experimental validation.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 22:24:26 INFO Perform Harmony Search...
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -5000
2025-06-23 22:24:36 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO AOCC mean: 0.0000
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -5000
2025-06-23 22:24:36 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO AOCC mean: 0.0000
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -5000
2025-06-23 22:24:36 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO AOCC mean: 0.0000
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -5000
2025-06-23 22:24:36 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO AOCC mean: 0.0000
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -5000
2025-06-23 22:24:36 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO AOCC mean: 0.0000
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -5000
2025-06-23 22:24:36 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:36 INFO AOCC mean: 0.0000
2025-06-23 22:24:36 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:36 ERROR Can not run the algorithm
2025-06-23 22:24:36 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:36 INFO FeHistory: []
2025-06-23 22:24:36 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -5000
2025-06-23 22:24:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO AOCC mean: 0.0000
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -5000
2025-06-23 22:24:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO AOCC mean: 0.0000
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -5000
2025-06-23 22:24:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO AOCC mean: 0.0000
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:24:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:24:37 ERROR Can not run the algorithm
2025-06-23 22:24:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:24:37 INFO FeHistory: []
2025-06-23 22:24:37 INFO Expected Optimum FE: -5000
2025-06-23 22:24:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:24:37 INFO AOCC mean: 0.0000
2025-06-23 22:24:37 INFO Generation 2, best so far: 0.24747886597801494
2025-06-23 22:24:37 INFO Population length is: 12
2025-06-23 22:24:37 INFO --- Performing Long-Term Reflection at Generation 3 ---
2025-06-23 22:24:37 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.3158e-02 |             AOCC Score on Unimodal instances: 1.5947e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedCauchyDE
# Description: Differential Evolution with adaptive Cauchy mutation and archive for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: ArchiveGuidedCauchyDE
# Description: Differential Evolution with adaptive Cauchy mutation and archive for multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    """
    Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.  
    Employs Cauchy's heavy tails for enhanced exploration in high-dimensional spaces.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness[:len(new_population)])
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < 0.5, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)
```

### Rank 2 (Overall AOCC Score: 5.3125e-02 |             AOCC Score on Unimodal instances: 1.5937e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to maintain solution diversity for high-dimensional multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: An evolutionary algorithm using adaptive Cauchy mutation and an archive to maintain solution diversity for high-dimensional multimodal optimization.
# Code:

class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (adaptive)
        self.gamma_decay = 0.95

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (intermediate recombination)
            offspring = self._intermediate_recombination(parents)

            # Mutation (adaptive Cauchy mutation)
            offspring = self._cauchy_mutation(offspring)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            # Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _intermediate_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            child1 = (parent1 + parent2) / 2
            child2 = (parent1 + parent2) / 2
            offspring.extend([child1, child2])
        return np.array(offspring)

    def _cauchy_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        mutated_offspring = offspring + mutation
        return np.clip(mutated_offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 3 (Overall AOCC Score: 5.2993e-02 |             AOCC Score on Unimodal instances: 1.5898e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchive
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95 #Decay rate for Cauchy scale parameter
        self.F = 0.5 #Differential Evolution scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)

            population, fitness = self._select_next_generation(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay #Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            
            #Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _select_next_generation(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
```

### Rank 4 (Overall AOCC Score: 5.1228e-02 |             AOCC Score on Unimodal instances: 1.5368e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveCauchyEA
# Description: Combines Cauchy mutation for robust exploration with an archive for diversity preservation in high-dimensional multimodal optimization.
# Code:
```python
import numpy as np

class ArchiveGuidedAdaptiveCauchyEA:
    """
    Combines Cauchy mutation for robust exploration with an archive for diversity preservation in high-dimensional multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (initially large for exploration)
        self.gamma_decay = 0.95 #Decay rate of gamma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._cauchy_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + self._cauchy_sample(self.gamma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + self._cauchy_sample(self.gamma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _cauchy_sample(self, scale, dim):
        return scale * np.tan(np.pi * (np.random.rand(dim) - 0.5))

    def _adaptive_mutation(self, offspring):
        return np.clip(offspring + self._cauchy_sample(self.gamma, self.dim), self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            self._add_to_archive(population[i], fitness_values[i])

    def _add_to_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 5 (Overall AOCC Score: 5.1143e-02 |             AOCC Score on Unimodal instances: 1.5343e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyArchiveEA
# Description: Combines Cauchy mutation with an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyArchiveEA
# Description: Combines Cauchy mutation with an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyArchiveEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.mutation_rate = 0.1


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Cauchy mutation)
            offspring = self._cauchy_recombination(parents)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self._update_archive(offspring, offspring_fitness)

            # Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)

            # Adapt Cauchy scale parameter
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.gamma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _cauchy_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            child2 = (parent1 + parent2) / 2 + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 6 (Overall AOCC Score: 5.0813e-02 |             AOCC Score on Unimodal instances: 1.5244e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEWithArchive
# Description: Combines Cauchy mutation with Differential Evolution and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy, norm

# Name: AdaptiveCauchyDEWithArchive
# Description: Combines Cauchy mutation with Differential Evolution and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            trial = self._crossover(population[i], mutant)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_parents(self, i, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 7 (Overall AOCC Score: 5.0704e-02 |             AOCC Score on Unimodal instances: 1.5211e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy
import random

# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 100
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.99
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                mutant = self._generate_mutant(population, i)
                trial = self._crossover(population[i], mutant)
                trial = self._cauchy_mutation(trial)  # Cauchy mutation
                trial = self._bound_solution(trial)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    offspring.append(population[i])

            population = np.array(offspring)
            self._update_archive(population, fitness_values)
            self.gamma *= self.gamma_decay

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[best_index]
                self.best_solution_overall = population[best_index]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))

    def _generate_mutant(self, population, i):
        a, b, c = self._select_different_individuals(i, self.population_size)
        mutant = population[a] + self.F * (population[b] - population[c])
        return mutant

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() <= self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _cauchy_mutation(self, solution):
        solution += cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
        return solution

    def _bound_solution(self, solution):
        return np.clip(solution, self.lower_bounds, self.upper_bounds)

    def _select_different_individuals(self, i, pop_size):
        while True:
            a, b, c = random.sample(range(pop_size), 3)
            if a != i and b != i and c != i and a != b and b != c and a != c:
                return a, b, c

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        combined = sorted(combined, key=lambda x: x[-1])

        if len(self.archive) < self.archive_size:
            self.archive.extend(combined[:self.archive_size - len(self.archive)])
        else:
            self.archive = combined[:self.archive_size] #Efficiently replace the whole archive
```

### Rank 8 (Overall AOCC Score: 5.0375e-02 |             AOCC Score on Unimodal instances: 1.5112e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution with Cauchy mutation and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedCauchyDE:
    """
    Combines Differential Evolution with Cauchy mutation and an archive to enhance exploration and exploitation in multimodal optimization problems. The archive stores promising solutions, promoting diversity and preventing premature convergence.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100, population_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []
        self.population_size = population_size

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate
        self.gamma = 1.0 #Cauchy scale parameter


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(population)
        self.eval_count += len(fitness)

        self.best_solution_overall = population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)
        
        self.update_archive(population, fitness)

        while self.eval_count < self.budget:
            # Differential Evolution with Cauchy Mutation
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
                
                #Cauchy Mutation
                mutant += np.random.standard_cauchy(self.dim) * self.gamma
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))
                self.eval_count += 1
                if trial_fitness[0] < fitness[i]:
                    offspring[i] = trial
                    fitness[i] = trial_fitness[0]
                else:
                    offspring[i] = population[i]

            population = offspring
            
            self.update_archive(population, fitness)
            best_solution = population[np.argmin(fitness)]
            best_fitness = np.min(fitness)

            if best_fitness < self.best_fitness_overall:
                self.best_fitness_overall = best_fitness
                self.best_solution_overall = best_solution

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def update_archive(self, population, fitness):
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))
        self.archive.sort(key=lambda x: x[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] #Keep only the best

```

### Rank 9 (Overall AOCC Score: 4.9987e-02 |             AOCC Score on Unimodal instances: 1.4996e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

class ArchiveGuidedAdaptiveCauchyDE:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and an archive for efficient multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim  # common heuristic
        self.archive_size = 100
        self.archive = []
        self.population = None
        self.F_scale = 0.5  # initial scaling factor
        self.gamma = 1.0 #initial Cauchy scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            #Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

            #Adapt Cauchy scale parameter based on progress. Reduce gamma if close to optimum.
            self.gamma = max(0.1, self.gamma * (1 - 0.1 * (self.best_fitness_overall < 1.0)))


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        #Adaptive scaling factor
        self.F_scale = 0.5 + 0.3*np.random.rand() #scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            mutant = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            
            #Cauchy Mutation
            cauchy_noise = np.random.standard_cauchy(self.dim) * self.gamma * (self.upper_bounds - self.lower_bounds)
            offspring[i] = mutant + cauchy_noise
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds) #Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                #Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

```

### Rank 10 (Overall AOCC Score: 4.9090e-02 |             AOCC Score on Unimodal instances: 1.4727e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedAdaptiveCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: ArchiveGuidedAdaptiveCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
class ArchiveGuidedAdaptiveCauchyDE:
    """
    Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], archive_size=100, population_size=100):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.archive_size = archive_size
        self.archive = []
        self.population_size = population_size

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.gamma = 1.0 #Initial Cauchy scale parameter
        self.gamma_decay = 0.99 #Decay rate for gamma

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                # Differential Mutation with Archive Augmentation
                a, b, c = self._select_different(i, population)
                mutant = self._differential_mutation(population[a], population[b], population[c])

                # Adaptive Cauchy perturbation
                mutant += self._cauchy_mutation(self.gamma)
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover (Binomial)
                trial = np.where(np.random.rand(self.dim) < 0.5, mutant, population[i])
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    self._update_archive(trial, trial_fitness)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), np.array(fitness[:len(new_population)]))
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        candidates = list(range(len(population))) + [i for i in range(len(self.archive))]
        a, b, c = random.sample(candidates, 3)
        while a == index or b == index or c == index or a == b or a == c or b == c:
            a, b, c = random.sample(candidates, 3)

        if a >= len(population):
            a_val = self.archive[a - len(population)][0]
        else:
            a_val = population[a]
        if b >= len(population):
            b_val = self.archive[b - len(population)][0]
        else:
            b_val = population[b]
        if c >= len(population):
            c_val = self.archive[c - len(population)][0]
        else:
            c_val = population[c]

        return a_val, b_val, c_val

    def _differential_mutation(self, a, b, c):
        return a + 0.8 * (b - c) #fixed mutation scale

    def _cauchy_mutation(self, gamma):
        return gamma * np.random.standard_cauchy(self.dim)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

```

### Rank 11 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 930.4585901799651, sigma_decay: float = 0.9228822057099063, acceptance_threshold: float = 3.893649626556104e-06):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width


    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:24:43 INFO Full response text: **Analysis:**

Comparing (best) `ArchiveGuidedCauchyDE` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the top performer uses Cauchy mutation, known for its heavy tails, which facilitates better exploration in high-dimensional spaces compared to the Gaussian distribution used in the worst performer.  `ArchiveGuidedCauchyDE` also incorporates a DE strategy for exploitation and an archive to maintain diversity.  The worst algorithm lacks these advanced components.

(second best) `AdaptiveCauchyArchiveEA` vs (second worst) `ArchiveGuidedAdaptiveCauchyDE`: The second-best algorithm uses tournament selection and intermediate recombination, while the second-worst uses a simpler selection method and relies solely on Cauchy mutation without DE. The addition of an archive in both helps, but the superior recombination and selection strategy in `AdaptiveCauchyArchiveEA` provide an advantage.

Comparing (1st) `ArchiveGuidedCauchyDE` vs (2nd) `AdaptiveCauchyArchiveEA`, we see that both use archives and adaptive mutation, but `ArchiveGuidedCauchyDE` leverages DE's strengths in exploitation.  `AdaptiveCauchyArchiveEA` employs tournament selection, which might be less effective than DE in complex landscapes.

(3rd) `AdaptiveCauchyDEwithArchive` vs (4th) `ArchiveGuidedAdaptiveCauchyEA`: Both use DE and an archive, but the third-ranked algorithm employs a more sophisticated adaptive Cauchy mutation, while the fourth uses a simpler adaptive scheme.  The population sizing heuristic (10x dimensionality) in the third-ranked algorithm might contribute to its better performance.

Comparing (second worst) `ArchiveGuidedAdaptiveCauchyDE` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the second-worst algorithm utilizes DE, an archive, and adaptive Cauchy mutation for a more robust approach.  The worst-performing algorithm, however, relies on simple Gaussian sampling and lacks the sophisticated exploration and exploitation mechanisms of the better-performing algorithms.

Overall:  The best-performing algorithms consistently incorporate Differential Evolution (DE), adaptive Cauchy mutation (for heavy-tailed exploration), and an archive (for diversity preservation).  Adaptive strategies for mutation scale and population size heuristics also seem beneficial. Simpler algorithms like the one using only Gaussian sampling tend to perform significantly worse.


**Experience:**

Effective high-dimensional optimization necessitates a balanced approach combining global exploration (Cauchy mutation) with efficient local exploitation (DE).  An archive is crucial to maintain diversity and escape local optima.  Adaptive mechanisms for mutation and population size enhance robustness.

2025-06-23 22:24:45 INFO Full response text: **Keywords:**  High-dimensional optimization, exploration-exploitation balance, archive management, adaptive mechanisms, mutation strategy, heuristic design.

**Advice:** Focus on quantifiable metrics for evaluating exploration/exploitation balance (e.g.,  coverage of search space, convergence rate, diversity metrics).  Systematically compare different mutation strategies (Cauchy vs. Gaussian, etc.) and archive designs under controlled conditions. Design heuristics that dynamically adjust based on these metrics, avoiding pre-defined parameter settings.  Explore novel archive structures beyond simple storage (e.g.,  graph-based, clustering-based).

**Avoid:** Vague statements like "critical," "crucial," and  "effective."  Avoid focusing on general principles without concrete operationalizations.  Don't prematurely dismiss simpler methods without rigorous comparison.  Avoid claims of universal superiority for specific techniques.

**Explanation:** The goal is to move from broad observations to specific, testable hypotheses about heuristic design.  This requires a shift from qualitative assessments to quantitative analysis and a more rigorous experimental approach to compare different design choices.  The $999K should fund this rigorous research and experimentation.

2025-06-23 22:24:45 INFO Generating offspring via Crossover...
2025-06-23 22:28:36 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveCauchyDEWithArchive
import numpy as np
from scipy.stats import cauchy, norm

# Name: AdaptiveCauchyDEWithArchive
# Description: Combines Cauchy mutation with Differential Evolution and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.F = 0.8 # Differential Evolution scaling factor
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            trial = self._crossover(population[i], mutant)
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_parents(self, i, pop_size):
        indices = np.random.choice(pop_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(pop_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            fitness = offspring_fitness[i]
            self.archive.append((sol, fitness))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:self.archive_size]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

### Worse code
AdaptiveCauchyDEwithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95 #Decay rate for Cauchy scale parameter
        self.F = 0.5 #Differential Evolution scaling factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)

            population, fitness = self._select_next_generation(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay #Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            
            #Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _select_next_generation(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

### Analyze & experience
- Comparing (best) `ArchiveGuidedCauchyDE` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the top performer uses Cauchy mutation, known for its heavy tails, which facilitates better exploration in high-dimensional spaces compared to the Gaussian distribution used in the worst performer.  `ArchiveGuidedCauchyDE` also incorporates a DE strategy for exploitation and an archive to maintain diversity.  The worst algorithm lacks these advanced components.

(second best) `AdaptiveCauchyArchiveEA` vs (second worst) `ArchiveGuidedAdaptiveCauchyDE`: The second-best algorithm uses tournament selection and intermediate recombination, while the second-worst uses a simpler selection method and relies solely on Cauchy mutation without DE. The addition of an archive in both helps, but the superior recombination and selection strategy in `AdaptiveCauchyArchiveEA` provide an advantage.

Comparing (1st) `ArchiveGuidedCauchyDE` vs (2nd) `AdaptiveCauchyArchiveEA`, we see that both use archives and adaptive mutation, but `ArchiveGuidedCauchyDE` leverages DE's strengths in exploitation.  `AdaptiveCauchyArchiveEA` employs tournament selection, which might be less effective than DE in complex landscapes.

(3rd) `AdaptiveCauchyDEwithArchive` vs (4th) `ArchiveGuidedAdaptiveCauchyEA`: Both use DE and an archive, but the third-ranked algorithm employs a more sophisticated adaptive Cauchy mutation, while the fourth uses a simpler adaptive scheme.  The population sizing heuristic (10x dimensionality) in the third-ranked algorithm might contribute to its better performance.

Comparing (second worst) `ArchiveGuidedAdaptiveCauchyDE` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the second-worst algorithm utilizes DE, an archive, and adaptive Cauchy mutation for a more robust approach.  The worst-performing algorithm, however, relies on simple Gaussian sampling and lacks the sophisticated exploration and exploitation mechanisms of the better-performing algorithms.

Overall:  The best-performing algorithms consistently incorporate Differential Evolution (DE), adaptive Cauchy mutation (for heavy-tailed exploration), and an archive (for diversity preservation).  Adaptive strategies for mutation scale and population size heuristics also seem beneficial. Simpler algorithms like the one using only Gaussian sampling tend to perform significantly worse.
- **Keywords:**  High-dimensional optimization, exploration-exploitation balance, archive management, adaptive mechanisms, mutation strategy, heuristic design.

**Advice:** Focus on quantifiable metrics for evaluating exploration/exploitation balance (e.g.,  coverage of search space, convergence rate, diversity metrics).  Systematically compare different mutation strategies (Cauchy vs. Gaussian, etc.) and archive designs under controlled conditions. Design heuristics that dynamically adjust based on these metrics, avoiding pre-defined parameter settings.  Explore novel archive structures beyond simple storage (e.g.,  graph-based, clustering-based).

**Avoid:** Vague statements like "critical," "crucial," and  "effective."  Avoid focusing on general principles without concrete operationalizations.  Don't prematurely dismiss simpler methods without rigorous comparison.  Avoid claims of universal superiority for specific techniques.

**Explanation:** The goal is to move from broad observations to specific, testable hypotheses about heuristic design.  This requires a shift from qualitative assessments to quantitative analysis and a more rigorous experimental approach to compare different design choices.  The $999K should fund this rigorous research and experimentation.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:28:36 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  High-dimensional optimization, exploration-exploitation balance, archive management, adaptive mechanisms, mutation strategy, heuristic design.

**Advice:** Focus on quantifiable metrics for evaluating exploration/exploitation balance (e.g.,  coverage of search space, convergence rate, diversity metrics).  Systematically compare different mutation strategies (Cauchy vs. Gaussian, etc.) and archive designs under controlled conditions. Design heuristics that dynamically adjust based on these metrics, avoiding pre-defined parameter settings.  Explore novel archive structures beyond simple storage (e.g.,  graph-based, clustering-based).

**Avoid:** Vague statements like "critical," "crucial," and  "effective."  Avoid focusing on general principles without concrete operationalizations.  Don't prematurely dismiss simpler methods without rigorous comparison.  Avoid claims of universal superiority for specific techniques.

**Explanation:** The goal is to move from broad observations to specific, testable hypotheses about heuristic design.  This requires a shift from qualitative assessments to quantitative analysis and a more rigorous experimental approach to compare different design choices.  The $999K should fund this rigorous research and experimentation.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 22:30:23 INFO Perform Harmony Search...
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:30:33 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:30:33 ERROR Can not run the algorithm
2025-06-23 22:30:33 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:30:33 INFO FeHistory: []
2025-06-23 22:30:33 INFO Expected Optimum FE: -5000
2025-06-23 22:30:33 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:30:33 INFO AOCC mean: 0.0000
2025-06-23 22:30:33 INFO Generation 3, best so far: 0.24747886597801494
2025-06-23 22:30:33 INFO Population length is: 12
2025-06-23 22:30:33 INFO --- Performing Long-Term Reflection at Generation 4 ---
2025-06-23 22:30:33 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.4234e-02 |             AOCC Score on Unimodal instances: 1.6270e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Combines Differential Evolution, adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Combines Differential Evolution, adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive),
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])

            # Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
```

### Rank 2 (Overall AOCC Score: 5.3392e-02 |             AOCC Score on Unimodal instances: 1.6018e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithTournamentSelection
# Description: Differential Evolution with adaptive Cauchy mutation and tournament selection for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelection
# Description: Differential Evolution with adaptive Cauchy mutation and tournament selection for multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5 #tournament size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
```

### Rank 3 (Overall AOCC Score: 5.3248e-02 |             AOCC Score on Unimodal instances: 1.5974e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithTournamentSelection
# Description: Combines Differential Evolution with adaptive Cauchy mutation and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelection
# Description: Combines Differential Evolution with adaptive Cauchy mutation and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95 #Decay rate for Cauchy scale parameter
        self.F = 0.5 #Differential Evolution scaling factor
        self.tournament_size = 5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)


        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay #Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            
            #Cauchy Mutation
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

```

### Rank 4 (Overall AOCC Score: 5.3034e-02 |             AOCC Score on Unimodal instances: 1.5910e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, and an archive for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                best_solution, best_fitness = self._find_best(np.array(new_population), fitness[:len(new_population)])
                if best_fitness < self.best_fitness_overall:
                    self.best_solution_overall = best_solution
                    self.best_fitness_overall = best_fitness

            population = np.array(new_population)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)
```

### Rank 5 (Overall AOCC Score: 5.0985e-02 |             AOCC Score on Unimodal instances: 1.5295e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential Evolution with adaptive mutation and an archive to maintain diversity and escape local optima.
# Code:
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential Evolution with adaptive mutation and an archive to maintain diversity and escape local optima.
# Code:
class AdaptiveDifferentialEvolutionWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.adaptation_rate = 0.1 #Rate at which F and CR adapt


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._adapt_parameters(population, fitness_values)
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutate(a, b, c)
            child = self._crossover(population[i], mutant)
            offspring.append(child)
        return np.array(offspring)
    
    def _select_parents(self, i, population):
      indices = np.random.choice(self.population_size, 3, replace=False)
      while i in indices:
        indices = np.random.choice(self.population_size, 3, replace=False)
      return population[indices[0]], population[indices[1]], population[indices[2]]
    

    def _mutate(self, a, b, c):
        return np.clip(a + self.F * (b - c), self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        mask = np.random.rand(self.dim) < self.CR
        return np.where(mask, mutant, parent)

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.hstack((population, fitness_values.reshape(-1, 1)))
        self.archive.extend(combined)
        self.archive.sort(key=lambda x: x[-1])
        self.archive = self.archive[:self.archive_size]


    def _adapt_parameters(self, population, fitness_values):
        #Simple adaptation based on diversity and convergence.
        diversity = np.mean(pdist(population))
        convergence = np.std(fitness_values)
        
        if diversity < np.mean(self.upper_bounds - self.lower_bounds) / 4 : #Low Diversity, Increase exploration.
          self.F = min(1, self.F + self.adaptation_rate)
          self.CR = max(0, self.CR - self.adaptation_rate/2)

        if convergence < 0.1 * np.mean(fitness_values): #Rapid Convergence, Increase Exploitation
          self.F = max(0, self.F - self.adaptation_rate/2)
          self.CR = min(1, self.CR + self.adaptation_rate)

        self.F = np.clip(self.F, 0, 1)
        self.CR = np.clip(self.CR, 0, 1)

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 6 (Overall AOCC Score: 5.0895e-02 |             AOCC Score on Unimodal instances: 1.5268e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and an archive for escaping local optima.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and an archive for escaping local optima.
# Code:
class AdaptiveCauchyDEwithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50  # Size of the archive to store diverse solutions
        self.archive = []
        self.F = 0.8  # Differential weight (scale factor)
        self.CR = 0.9  # Crossover rate
        self.scale = 1.0 # Initial Cauchy scale


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            
            self._adapt_scale(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutate(a, b, c)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring


    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _mutate(self, a, b, c):
        mutant = a + self.F * (b - c)
        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        child = np.where(crosspoints, mutant, parent)
        return child

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        # simple archive update, replace worst with best if better
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness_values[i]))
            else:
                worst_idx = np.argmax([f for _, f in self.archive])
                if fitness_values[i] < self.archive[worst_idx][1]:
                    self.archive[worst_idx] = (population[i], fitness_values[i])
                    
    def _adapt_scale(self, population, fitness_values):
        # Adapt Cauchy scale based on population diversity
        diversity = np.std(population)
        if diversity < 0.1 * np.ptp(self.upper_bounds - self.lower_bounds): # ptp is peak-to-peak
            self.scale *= 1.1  # Increase scale for low diversity
        else:
            self.scale *= 0.9  # Reduce scale for high diversity
        self.scale = max(0.01, min(self.scale, 10.0)) # Keep scale within reasonable bounds

```

### Rank 7 (Overall AOCC Score: 5.0215e-02 |             AOCC Score on Unimodal instances: 1.5065e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: ArchiveGuidedCauchyDE
# Description:  Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim # Heuristic population sizing
        self.archive_size = 2 * self.population_size
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter (adaptive)
        self.gamma_decay = 0.95
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._cauchy_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_different_individuals(i,len(population))
            mutant = population[a] + self.F * (population[b] - population[c])
            trial = self._crossover(population[i], mutant)
            offspring[i] = trial
        return offspring

    def _select_different_individuals(self, i, pop_size):
        candidates = list(range(pop_size))
        candidates.remove(i)
        np.random.shuffle(candidates)
        return candidates[0], candidates[1], candidates[2]
    
    def _crossover(self,x,v):
        jrand = np.random.randint(self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _cauchy_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        mutated_offspring = offspring + mutation
        return np.clip(mutated_offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 8 (Overall AOCC Score: 5.0124e-02 |             AOCC Score on Unimodal instances: 1.5037e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: ArchiveGuidedCauchyDE
# Description: Combines Differential Evolution with adaptive Cauchy mutation and an archive for robust multimodal optimization.
# Code:
class ArchiveGuidedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic population sizing
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy scale parameter
        self.gamma_decay = 0.95
        self.F = 0.8  # DE scaling factor
        self.CR = 0.9  # DE crossover rate


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring = self._cauchy_mutation(offspring) # Apply Cauchy mutation after DE
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            self._update_archive(offspring, offspring_fitness)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Choose 3 distinct vectors (excluding the current one)
            indices = np.random.choice(self.population_size, 3, replace=False)
            while i in indices:
                indices = np.random.choice(self.population_size, 3, replace=False)
            a, b, c = population[indices]
            mutant = a + self.F * (b - c)
            
            # Binomial crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(crossover_mask, mutant, population[i])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring

    def _cauchy_mutation(self, offspring):
        mutation = cauchy.rvs(loc=0, scale=self.gamma, size=offspring.shape)
        mutated_offspring = offspring + mutation
        return np.clip(mutated_offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 9 (Overall AOCC Score: 5.0003e-02 |             AOCC Score on Unimodal instances: 1.5001e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential Evolution with adaptive mutation and an archive to maintain diversity and escape local optima.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential Evolution with adaptive mutation and an archive to maintain diversity and escape local optima.
# Code:
class AdaptiveDifferentialEvolutionWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_random_vectors(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _select_random_vectors(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _crossover(self, x, v):
        jrand = np.random.randint(self.dim)
        y = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                y[j] = v[j]
        return y

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_archive(self, population, fitness_values):
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness_values[i]))
            else:
                worst_index = np.argmax([x[1] for x in self.archive])
                if fitness_values[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (population[i], fitness_values[i])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adapt_parameters(self, population, fitness_values):
      #Simple adaptation.  More sophisticated methods could be implemented here.
      std_dev = np.std(fitness_values)
      if std_dev < 0.1: #Increase exploration if solutions are too similar
          self.F = min(self.F + 0.1, 1.0)
      else:
          self.F = max(self.F-0.05, 0.5) # Reduce exploration if diverse enough
```

### Rank 10 (Overall AOCC Score: 4.9102e-02 |             AOCC Score on Unimodal instances: 1.4730e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential evolution with adaptive mutation and an archive to escape local optima.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithArchive
# Description: Differential evolution with adaptive mutation and an archive to escape local optima.
# Code:
class AdaptiveDifferentialEvolutionWithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.F = 0.5  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.F_scale = 1.1 # Scaling factor for F

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(population, fitness_values)
            self._update_best(population, fitness_values)
            self._adapt_parameters(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutation(a, b, c)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring

    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _mutation(self, a, b, c):
        mutant = a + self.F * (b - c)
        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        child = np.where(crosspoints, mutant, parent)
        return child

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]

    def _update_archive(self, population, fitness_values):
        combined = np.concatenate((self.archive, population)) if self.archive else population
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness_values)) if self.archive else fitness_values
        sorted_indices = np.argsort(combined_fitness)
        self.archive = [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]
    

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self, population, fitness_values):
        #Simple Adaptive F based on average fitness improvement
        if len(self.archive) > 0:
            avg_archive_fitness = np.mean([x[1] for x in self.archive])
            avg_pop_fitness = np.mean(fitness_values)
            improvement = avg_archive_fitness - avg_pop_fitness
            self.F = max(0.1, min(1.0, self.F + 0.01*improvement))  # Keep F within reasonable bounds
            self.F = min(self.F * self.F_scale,1.0) #Cap the value of F for better exploration, otherwise the algorithm might over-exploit
            

```

### Rank 11 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 117.06113239804215, sigma_decay: float = 0.954238236554928, acceptance_threshold: float = 7.2134214273590346e-06):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width


    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:30:38 INFO Full response text: **Analysis:**

Comparing `AdaptiveCauchyDEwithArchiveAndTournament` (best) vs `AdaptiveDifferentialEvolutionWithArchive` (worst), we see that the best uses Cauchy mutation, which is more robust to noise in high dimensions, and tournament selection which is more efficient than the simple selection used by the worst. The best also employs an archive to maintain diversity.  `AdaptiveCauchyDEwithTournamentSelection` (second best) vs `AdaptiveCauchyDEwithArchive` (second worst) shows that adding an archive improves performance slightly, but the tournament selection is a more significant improvement. Comparing `AdaptiveCauchyDEwithArchiveAndTournament` (1st) vs `AdaptiveCauchyDEwithTournamentSelection` (2nd), we see that the archive adds a small performance benefit.  `AdaptiveCauchyDEwithTournamentSelection` (3rd) vs `AdaptiveCauchyDEwithArchive` (4th) again highlights the minor, but consistent advantage of tournament selection over only an archive. Comparing `AdaptiveDifferentialEvolutionWithArchive` (second worst) vs `AdaptiveDifferentialEvolutionWithArchive` (worst), both are similar DE algorithms with archives; minor differences in parameter settings result in slight performance variations. Overall: The consistent superior performance of algorithms incorporating both Cauchy mutation and tournament selection, with or without an archive,  suggests these features are key to success in the GNBG benchmark.  The adaptive gamma parameter and tournament selection are particularly noteworthy in the top three algorithms.

**Experience:**

Prioritizing efficient selection mechanisms (like tournament selection) and robust mutation strategies (like adaptive Cauchy) significantly improves performance in high-dimensional multimodal optimization.  Archive-based methods offer incremental improvement, particularly when combined with other advanced techniques.

2025-06-23 22:30:41 INFO Full response text: **Keywords:** Tournament selection, Adaptive Cauchy mutation, Archive enhancement, High-dimensional multimodal optimization.

**Advice:** Focus on improving the efficiency of selection and mutation *without* explicitly addressing population initialization or adaptive parameter tuning (as these are mentioned in "Ineffective self-reflection"). Explore novel archive management techniques to complement tournament selection and adaptive Cauchy mutation.  Consider hybrid approaches only if they demonstrably improve *specific* aspects of the selection and mutation mechanisms.

**Avoid:**  General statements about exploration/exploitation balance, adaptive mechanisms (beyond mutation), and the overall importance of archives.  Do not directly address population size or initialization strategies.  Avoid comparisons to simpler algorithms on unimodal problems.

**Explanation:** The "Ineffective self-reflection" section highlights common, often-stated best practices. To develop better heuristics, we must move beyond these generalities and focus on specific, measurable improvements to the selection and mutation mechanisms within the context of high-dimensional multimodal problems. The key is refining existing effective components rather than adding complexity for complexity's sake.  The $999K will be best spent on rigorous empirical evaluation of novel enhancements to tournament selection and adaptive Cauchy mutation, within the framework of enhanced archive management.

2025-06-23 22:30:41 INFO Generating offspring via Crossover...
2025-06-23 22:34:08 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveCauchyDEwithArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchive
# Description: Differential Evolution with adaptive Cauchy mutation and an archive for escaping local optima.
# Code:
class AdaptiveCauchyDEwithArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50  # Size of the archive to store diverse solutions
        self.archive = []
        self.F = 0.8  # Differential weight (scale factor)
        self.CR = 0.9  # Crossover rate
        self.scale = 1.0 # Initial Cauchy scale


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)
        self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            
            self._adapt_scale(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = self._mutate(a, b, c)
            offspring[i] = self._crossover(population[i], mutant)
        return offspring


    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _mutate(self, a, b, c):
        mutant = a + self.F * (b - c)
        return np.clip(mutant, self.lower_bounds, self.upper_bounds)

    def _crossover(self, parent, mutant):
        crosspoints = np.random.rand(self.dim) < self.CR
        child = np.where(crosspoints, mutant, parent)
        return child

    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _update_archive(self, population, fitness_values):
        # simple archive update, replace worst with best if better
        for i in range(len(population)):
            if len(self.archive) < self.archive_size:
                self.archive.append((population[i], fitness_values[i]))
            else:
                worst_idx = np.argmax([f for _, f in self.archive])
                if fitness_values[i] < self.archive[worst_idx][1]:
                    self.archive[worst_idx] = (population[i], fitness_values[i])
                    
    def _adapt_scale(self, population, fitness_values):
        # Adapt Cauchy scale based on population diversity
        diversity = np.std(population)
        if diversity < 0.1 * np.ptp(self.upper_bounds - self.lower_bounds): # ptp is peak-to-peak
            self.scale *= 1.1  # Increase scale for low diversity
        else:
            self.scale *= 0.9  # Reduce scale for high diversity
        self.scale = max(0.01, min(self.scale, 10.0)) # Keep scale within reasonable bounds


### Worse code
AdaptiveCauchyDEwithTournamentSelection
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelection
# Description: Differential Evolution with adaptive Cauchy mutation and tournament selection for multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelection:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5 #tournament size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

### Analyze & experience
- Comparing `AdaptiveCauchyDEwithArchiveAndTournament` (best) vs `AdaptiveDifferentialEvolutionWithArchive` (worst), we see that the best uses Cauchy mutation, which is more robust to noise in high dimensions, and tournament selection which is more efficient than the simple selection used by the worst. The best also employs an archive to maintain diversity.  `AdaptiveCauchyDEwithTournamentSelection` (second best) vs `AdaptiveCauchyDEwithArchive` (second worst) shows that adding an archive improves performance slightly, but the tournament selection is a more significant improvement. Comparing `AdaptiveCauchyDEwithArchiveAndTournament` (1st) vs `AdaptiveCauchyDEwithTournamentSelection` (2nd), we see that the archive adds a small performance benefit.  `AdaptiveCauchyDEwithTournamentSelection` (3rd) vs `AdaptiveCauchyDEwithArchive` (4th) again highlights the minor, but consistent advantage of tournament selection over only an archive. Comparing `AdaptiveDifferentialEvolutionWithArchive` (second worst) vs `AdaptiveDifferentialEvolutionWithArchive` (worst), both are similar DE algorithms with archives; minor differences in parameter settings result in slight performance variations. Overall: The consistent superior performance of algorithms incorporating both Cauchy mutation and tournament selection, with or without an archive,  suggests these features are key to success in the GNBG benchmark.  The adaptive gamma parameter and tournament selection are particularly noteworthy in the top three algorithms.
- **Keywords:** Tournament selection, Adaptive Cauchy mutation, Archive enhancement, High-dimensional multimodal optimization.

**Advice:** Focus on improving the efficiency of selection and mutation *without* explicitly addressing population initialization or adaptive parameter tuning (as these are mentioned in "Ineffective self-reflection"). Explore novel archive management techniques to complement tournament selection and adaptive Cauchy mutation.  Consider hybrid approaches only if they demonstrably improve *specific* aspects of the selection and mutation mechanisms.

**Avoid:**  General statements about exploration/exploitation balance, adaptive mechanisms (beyond mutation), and the overall importance of archives.  Do not directly address population size or initialization strategies.  Avoid comparisons to simpler algorithms on unimodal problems.

**Explanation:** The "Ineffective self-reflection" section highlights common, often-stated best practices. To develop better heuristics, we must move beyond these generalities and focus on specific, measurable improvements to the selection and mutation mechanisms within the context of high-dimensional multimodal problems. The key is refining existing effective components rather than adding complexity for complexity's sake.  The $999K will be best spent on rigorous empirical evaluation of novel enhancements to tournament selection and adaptive Cauchy mutation, within the framework of enhanced archive management.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:34:08 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:** Tournament selection, Adaptive Cauchy mutation, Archive enhancement, High-dimensional multimodal optimization.

**Advice:** Focus on improving the efficiency of selection and mutation *without* explicitly addressing population initialization or adaptive parameter tuning (as these are mentioned in "Ineffective self-reflection"). Explore novel archive management techniques to complement tournament selection and adaptive Cauchy mutation.  Consider hybrid approaches only if they demonstrably improve *specific* aspects of the selection and mutation mechanisms.

**Avoid:**  General statements about exploration/exploitation balance, adaptive mechanisms (beyond mutation), and the overall importance of archives.  Do not directly address population size or initialization strategies.  Avoid comparisons to simpler algorithms on unimodal problems.

**Explanation:** The "Ineffective self-reflection" section highlights common, often-stated best practices. To develop better heuristics, we must move beyond these generalities and focus on specific, measurable improvements to the selection and mutation mechanisms within the context of high-dimensional multimodal problems. The key is refining existing effective components rather than adding complexity for complexity's sake.  The $999K will be best spent on rigorous empirical evaluation of novel enhancements to tournament selection and adaptive Cauchy mutation, within the framework of enhanced archive management.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 22:35:40 INFO Perform Harmony Search...
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:35:50 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:35:50 ERROR Can not run the algorithm
2025-06-23 22:35:50 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:35:50 INFO FeHistory: []
2025-06-23 22:35:50 INFO Expected Optimum FE: -5000
2025-06-23 22:35:50 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:35:50 INFO AOCC mean: 0.0000
2025-06-23 22:35:50 INFO Generation 4, best so far: 0.24747886597801494
2025-06-23 22:35:50 INFO Population length is: 12
2025-06-23 22:35:50 INFO --- Performing Long-Term Reflection at Generation 5 ---
2025-06-23 22:35:50 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.4547e-02 |             AOCC Score on Unimodal instances: 1.6364e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithTournamentSelectionAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive to maintain diversity for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentSelectionAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive to maintain diversity for multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentSelectionAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 10 * self.dim  # Heuristic: 10 times dimensionality
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.95  # Decay rate for Cauchy scale parameter
        self.F = 0.5  # Differential Evolution scaling factor
        self.tournament_size = 5 #tournament size
        self.archive_size = 100 #Archive size
        self.archive = []


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = objective_function(population)
        self.eval_count += self.population_size
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay  # Adapt Cauchy scale parameter
            self._update_archive(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'final_gamma': self.gamma
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._get_unique_indices(i, self.population_size)
            mutant = population[r1] + self.F * (population[r2] - population[r3])
            cauchy_noise = cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            trial = mutant + cauchy_noise
            offspring[i] = np.clip(trial, self.lower_bounds, self.upper_bounds)
        return offspring

    def _get_unique_indices(self, exclude_index, max_index):
        indices = np.random.choice(max_index, 3, replace=False)
        while exclude_index in indices:
            indices = np.random.choice(max_index, 3, replace=False)
        return indices

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

    def _update_archive(self, population, fitness):
        #add to archive, maintaining diversity
        for i in range(len(population)):
            self.archive.append((population[i], fitness[i]))
        
        #Maintain archive size
        self.archive.sort(key=lambda item:item[1])
        self.archive = self.archive[:self.archive_size]
```

### Rank 2 (Overall AOCC Score: 5.3461e-02 |             AOCC Score on Unimodal instances: 1.6038e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveEnhancedCauchyEA
# Description: Employs adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description: Employs adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy distribution scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Tournament Selection
            parents = self._tournament_selection(population, fitness_values)

            # Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            # Evaluate offspring
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Archive Management
            self._update_archive(offspring, offspring_fitness)

            #Selection for next generation (Elitism + Random Selection from archive and offspring)
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)
            

            # Update best solution
            self._update_best(offspring, offspring_fitness)

        if self.best_solution_overall is None and self.dim > 0: # Fallback
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + np.random.standard_cauchy(size=parents.shape) * self.gamma
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            self.archive.append((sol, offspring_fitness[i]))
        self.archive.sort(key=lambda x: x[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size]


    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        #Elitism: Keep the best solutions from the previous generation.
        next_gen = population[np.argsort(fitness_values)[:self.population_size//2]]
        next_fit = fitness_values[np.argsort(fitness_values)[:self.population_size//2]]
        #Combine with offspring and archive
        
        combined_pop = np.vstack((next_gen, offspring, np.array([x[0] for x in self.archive])))
        combined_fit = np.concatenate((next_fit, offspring_fitness, np.array([x[1] for x in self.archive])))

        #Select the best population_size
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit



    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 3 (Overall AOCC Score: 5.3277e-02 |             AOCC Score on Unimodal instances: 1.5983e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithTournamentAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Heuristic population size
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

```

### Rank 4 (Overall AOCC Score: 5.3113e-02 |             AOCC Score on Unimodal instances: 1.5934e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            #Tournament Selection for next generation
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]

```

### Rank 5 (Overall AOCC Score: 4.9206e-02 |             AOCC Score on Unimodal instances: 1.4762e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchiveAndTournamentSelection
# Description: Combines Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np

class AdaptiveCauchyDEwithArchiveAndTournamentSelection:
    """
    Combines Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Initial Cauchy scale parameter
        self.gamma_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)
        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            self._update_best(offspring, offspring_fitness)
            self.archive = self._update_archive(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))
            population, fitness_values = self._select_next_generation(self.archive)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            parents = self._tournament_selection(population, fitness_values, 5)
            mutant = self._cauchy_mutation(parents)
            offspring.append(mutant)
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _cauchy_mutation(self, parents):
        # Cauchy mutation with adaptive gamma
        base = parents[0]
        difference = parents[1] - parents[2]
        mutant = base + self.gamma * np.random.standard_cauchy(self.dim) * difference
        return mutant

    def _tournament_selection(self, population, fitness_values, tournament_size):
        tournament = np.random.choice(len(population), tournament_size, replace=False)
        winner_index = tournament[np.argmin(fitness_values[tournament])]
        return population[winner_index]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        sorted_combined = combined[np.argsort(combined[:, -1])]
        return sorted_combined[:min(len(sorted_combined), self.archive_size), :-1]

    def _select_next_generation(self, archive):
        if len(archive) < self.population_size:
            return archive, objective_function(archive) #Should not happen
        return archive[:self.population_size], objective_function(archive[:self.population_size])

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 6 (Overall AOCC Score: 4.9156e-02 |             AOCC Score on Unimodal instances: 1.4747e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            fitness = self._evaluate_population(objective_function, population) #Re-evaluate after tournament
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, ind1, ind2, fit1, fit2):
        tournament = np.random.choice(np.array([ind1, ind2]), size=self.tournament_size, replace=True)
        tournament_fitness = np.array([fit1 if t is ind1 else fit2 for t in tournament])
        return tournament[np.argmin(tournament_fitness)]
```

### Rank 7 (Overall AOCC Score: 4.9053e-02 |             AOCC Score on Unimodal instances: 1.4716e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveEnhancedCauchyEA
# Description: Employs adaptive Cauchy mutation and archive-enhanced tournament selection for efficient multimodal optimization.
# Code:
```python
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description:  Employs adaptive Cauchy mutation and archive-enhanced tournament selection for efficient multimodal optimization.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0 #Cauchy distribution scale parameter

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Archive Management
            self._update_archive(population, fitness_values)

            # Enhanced Tournament Selection
            parents = self._enhanced_tournament_selection(population, fitness_values)

            # Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Selection for next generation (Elitist)
            population, fitness_values = self._elitist_selection(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _update_archive(self, population, fitness_values):
        combined = np.concatenate((np.array(self.archive), population))
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness_values))
        
        sorted_indices = np.argsort(combined_fitness)
        
        self.archive = [(combined[i],combined_fitness[i]) for i in sorted_indices[:self.archive_size]]

    def _enhanced_tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        #Add Archive members to tournament selection
        archive_tournament = np.random.choice(len(self.archive), tournament_size, replace = False)
        archive_winner = np.array([x[0] for x in self.archive])[archive_tournament[np.argmin([x[1] for x in self.archive][archive_tournament])]]
        selected_parents.append(archive_winner)
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = []
        for parent in parents:
            offspring.append(np.clip(parent + np.random.standard_cauchy(self.dim) * self.gamma, self.lower_bounds, self.upper_bounds))
        return np.array(offspring)

    def _elitist_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 8 (Overall AOCC Score: 4.9027e-02 |             AOCC Score on Unimodal instances: 1.4708e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population, fitness):
        offspring = []
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population)
            mutant = self._cauchy_mutation(a, b, c)
            trial = self._crossover(population[i], mutant)
            offspring.append(trial)
            self._update_archive(trial, objective_function(trial.reshape(1,-1))[0]) #Added for archive update
        return np.array(offspring)

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

```

### Rank 9 (Overall AOCC Score: 4.8883e-02 |             AOCC Score on Unimodal instances: 1.4665e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], 
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            self.gamma *= self.gamma_decay
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, x, v, fx, fv):
        tournament = np.random.choice(np.array([x, v]), self.tournament_size, replace=True)
        tournament_fitness = objective_function(tournament)
        return tournament[np.argmin(tournament_fitness)]


def objective_function(x): #Example objective function (replace with actual GNBG functions)
    return np.sum(x**2, axis=1)

```

### Rank 10 (Overall AOCC Score: 4.8862e-02 |             AOCC Score on Unimodal instances: 1.4659e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveEnhancedCauchyEA
# Description: An evolutionary algorithm employing adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np

# Name: ArchiveEnhancedCauchyEA
# Description: An evolutionary algorithm employing adaptive Cauchy mutation and an archive to escape local optima in high-dimensional multimodal landscapes.
# Code:
class ArchiveEnhancedCauchyEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 0.1 #Cauchy scale parameter


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            #Tournament Selection with Archive Enhancement
            parents = self._tournament_selection(population, fitness_values)

            #Cauchy Mutation
            offspring = self._cauchy_mutation(parents)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Archive Management
            self._manage_archive(offspring, offspring_fitness)

            #Update population
            population, fitness_values = self._update_population(population, fitness_values, offspring, offspring_fitness)

            #Update Best
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []
        
        #Incorporate archive into tournament selection
        tournament_pool = np.vstack((population, np.array(self.archive)))
        tournament_fit = np.concatenate((fitness_values, [x[1] for x in self.archive]))

        for _ in range(num_parents):
            tournament = np.random.choice(len(tournament_pool), tournament_size, replace=False)
            winner_index = tournament[np.argmin(tournament_fit[tournament])]
            selected_parents.append(tournament_pool[winner_index])
        return np.array(selected_parents)

    def _cauchy_mutation(self, parents):
        offspring = parents + np.random.standard_cauchy(size=parents.shape) * self.gamma
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _manage_archive(self, offspring, offspring_fitness):
        for i, (solution, fitness) in enumerate(zip(offspring, offspring_fitness)):
            if len(self.archive) < self.archive_size:
                self.archive.append((solution, fitness))
            else:
                worst_index = np.argmax([x[1] for x in self.archive])
                if fitness < self.archive[worst_index][1]:
                    self.archive[worst_index] = (solution, fitness)


    def _update_population(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 11 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 670.4162204483325, sigma_decay: float = 0.93985967832758, acceptance_threshold: float = 0.009264207877634148):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width


    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:35:55 INFO Full response text: **Analysis:**

Comparing (best) `AdaptiveCauchyDEwithTournamentSelectionAndArchive` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the best utilizes Differential Evolution (DE) for efficient exploration and exploitation, adaptive Cauchy mutation for handling multimodal landscapes, tournament selection for robust selection pressure, and an archive for maintaining diversity.  The worst uses Gaussian sampling, a simpler approach lacking DE's sophisticated search mechanism and archive-based diversity retention.  It also lacks a well-defined archive management strategy.

(second best) `ArchiveEnhancedCauchyEA` vs (second worst) `AdaptiveCauchyDEwithArchiveAndTournament`: The second-best uses adaptive Cauchy mutation and an archive, showcasing the importance of these components. However, it has a simpler selection mechanism than the top performer. The second-worst again uses DE with Cauchy mutation and an archive, demonstrating the importance of DE framework and archive, but the implementation has less sophisticated selection and archive management compared to top performers.

Comparing (1st) vs (2nd), we see that the inclusion of DE significantly enhances performance.  (3rd) `AdaptiveCauchyDEwithTournamentAndArchive` vs (4th) `AdaptiveCauchyDEwithArchiveAndTournament`: Both use DE, adaptive Cauchy, and an archive, but the difference lies in tournament selection implementation and slightly different offspring generation. Rank 3 incorporates tournament selection within the main loop while Rank 4 uses tournament selection only for the final population selection.

Comparing (second worst) `AdaptiveCauchyDEwithArchiveAndTournament` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the presence of DE, Cauchy mutation, and an archive significantly improves performance over a purely Gaussian-based approach. Overall: The top performers consistently leverage DE, adaptive Cauchy mutation, tournament selection, and an archive, highlighting the crucial role of these elements in solving high-dimensional multimodal problems efficiently.  The simpler algorithms lack crucial exploration and exploitation balance, leading to significantly worse performance.

**Experience:**

The crucial factors for successful high-dimensional multimodal optimization are a robust exploration strategy (like DE), an effective mutation operator (like adaptive Cauchy), a selective pressure mechanism (tournament selection), and a mechanism to preserve diversity (an archive).  Carefully designed interactions between these components are key to overall success.

2025-06-23 22:35:57 INFO Full response text: **Keywords:**  High-dimensional multimodal optimization, exploration-exploitation balance, diversity preservation, heuristic design.

**Advice:** Focus on novel interactions between exploration (e.g., adaptive Cauchy mutation), exploitation (e.g., DE variants), selection (e.g., tournament selection with novel tie-breaking), and diversity mechanisms (e.g.,  novel archive designs or population management strategies that go beyond simple size adaptation).  Consider theoretical analysis to guide design choices.

**Avoid:**  Generic statements about exploration/exploitation, archives, and adaptive mechanisms. Avoid repeating established best practices without significant innovation. Don't solely focus on  Cauchy distributions or DE; explore alternatives and their synergistic combinations.  Avoid claims of universal superiority for any single technique.

**Explanation:** The goal is to move beyond simply combining known good components. The key to better heuristics lies in understanding *how* these components interact and identifying novel, potentially synergistic interactions that haven't been explored.  This requires a deeper theoretical understanding and potentially novel algorithmic structures.  The $999K prize implies a significant advance, not incremental improvement.

2025-06-23 22:35:57 INFO Generating offspring via Crossover...
2025-06-23 22:39:38 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveCauchyDEwithArchiveAndTournament
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization in high dimensions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            #Tournament Selection for next generation
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]


### Worse code
AdaptiveCauchyDEwithTournamentAndArchive
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchive
# Description: Differential Evolution with adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchive:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, tournament selection, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Heuristic population size
        self.archive_size = 100
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall


### Analyze & experience
- Comparing (best) `AdaptiveCauchyDEwithTournamentSelectionAndArchive` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the best utilizes Differential Evolution (DE) for efficient exploration and exploitation, adaptive Cauchy mutation for handling multimodal landscapes, tournament selection for robust selection pressure, and an archive for maintaining diversity.  The worst uses Gaussian sampling, a simpler approach lacking DE's sophisticated search mechanism and archive-based diversity retention.  It also lacks a well-defined archive management strategy.

(second best) `ArchiveEnhancedCauchyEA` vs (second worst) `AdaptiveCauchyDEwithArchiveAndTournament`: The second-best uses adaptive Cauchy mutation and an archive, showcasing the importance of these components. However, it has a simpler selection mechanism than the top performer. The second-worst again uses DE with Cauchy mutation and an archive, demonstrating the importance of DE framework and archive, but the implementation has less sophisticated selection and archive management compared to top performers.

Comparing (1st) vs (2nd), we see that the inclusion of DE significantly enhances performance.  (3rd) `AdaptiveCauchyDEwithTournamentAndArchive` vs (4th) `AdaptiveCauchyDEwithArchiveAndTournament`: Both use DE, adaptive Cauchy, and an archive, but the difference lies in tournament selection implementation and slightly different offspring generation. Rank 3 incorporates tournament selection within the main loop while Rank 4 uses tournament selection only for the final population selection.

Comparing (second worst) `AdaptiveCauchyDEwithArchiveAndTournament` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the presence of DE, Cauchy mutation, and an archive significantly improves performance over a purely Gaussian-based approach. Overall: The top performers consistently leverage DE, adaptive Cauchy mutation, tournament selection, and an archive, highlighting the crucial role of these elements in solving high-dimensional multimodal problems efficiently.  The simpler algorithms lack crucial exploration and exploitation balance, leading to significantly worse performance.
- **Keywords:**  High-dimensional multimodal optimization, exploration-exploitation balance, diversity preservation, heuristic design.

**Advice:** Focus on novel interactions between exploration (e.g., adaptive Cauchy mutation), exploitation (e.g., DE variants), selection (e.g., tournament selection with novel tie-breaking), and diversity mechanisms (e.g.,  novel archive designs or population management strategies that go beyond simple size adaptation).  Consider theoretical analysis to guide design choices.

**Avoid:**  Generic statements about exploration/exploitation, archives, and adaptive mechanisms. Avoid repeating established best practices without significant innovation. Don't solely focus on  Cauchy distributions or DE; explore alternatives and their synergistic combinations.  Avoid claims of universal superiority for any single technique.

**Explanation:** The goal is to move beyond simply combining known good components. The key to better heuristics lies in understanding *how* these components interact and identifying novel, potentially synergistic interactions that haven't been explored.  This requires a deeper theoretical understanding and potentially novel algorithmic structures.  The $999K prize implies a significant advance, not incremental improvement.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:39:38 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  High-dimensional multimodal optimization, exploration-exploitation balance, diversity preservation, heuristic design.

**Advice:** Focus on novel interactions between exploration (e.g., adaptive Cauchy mutation), exploitation (e.g., DE variants), selection (e.g., tournament selection with novel tie-breaking), and diversity mechanisms (e.g.,  novel archive designs or population management strategies that go beyond simple size adaptation).  Consider theoretical analysis to guide design choices.

**Avoid:**  Generic statements about exploration/exploitation, archives, and adaptive mechanisms. Avoid repeating established best practices without significant innovation. Don't solely focus on  Cauchy distributions or DE; explore alternatives and their synergistic combinations.  Avoid claims of universal superiority for any single technique.

**Explanation:** The goal is to move beyond simply combining known good components. The key to better heuristics lies in understanding *how* these components interact and identifying novel, potentially synergistic interactions that haven't been explored.  This requires a deeper theoretical understanding and potentially novel algorithmic structures.  The $999K prize implies a significant advance, not incremental improvement.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 22:41:27 INFO Perform Harmony Search...
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:41:37 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:41:37 ERROR Can not run the algorithm
2025-06-23 22:41:37 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:41:37 INFO FeHistory: []
2025-06-23 22:41:37 INFO Expected Optimum FE: -5000
2025-06-23 22:41:37 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:41:37 INFO AOCC mean: 0.0000
2025-06-23 22:41:37 INFO Generation 5, best so far: 0.24747886597801494
2025-06-23 22:41:37 INFO Population length is: 12
2025-06-23 22:41:37 INFO --- Performing Long-Term Reflection at Generation 6 ---
2025-06-23 22:41:37 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.2719e-02 |             AOCC Score on Unimodal instances: 1.5816e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithTournamentAndArchiveEnhancements
# Description: Combines DE, adaptive Cauchy mutation, tournament selection, and an enhanced archive for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchiveEnhancements
# Description: Combines DE, adaptive Cauchy mutation, tournament selection, and an enhanced archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchiveEnhancements:
    """
    Differential Evolution with adaptive Cauchy mutation, tournament selection, and an enhanced archive for multimodal optimization.  Improves upon previous designs by incorporating a more sophisticated archive management strategy and a dynamic population size adjustment.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Initial population size, can be adjusted dynamically
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size_adjustment_factor = 1.1  #Factor to adjust population size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay
            
            #Dynamic Population Size Adjustment
            if self.eval_count % (self.population_size * 2) == 0: # Adjust every 2 generations
                if self.best_fitness_overall < 1e-2:  #Check if converging well
                    self.population_size = int(self.population_size / self.population_size_adjustment_factor)  #Reduce if converging
                else:
                    self.population_size = int(self.population_size * self.population_size_adjustment_factor) #Increase otherwise


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Enhanced archive management: remove the furthest solution from the best
                distances = np.linalg.norm(np.array([x for x, _ in self.archive]) - self.best_solution_overall, axis=1)
                worst_index = np.argmax(distances)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall
```

### Rank 2 (Overall AOCC Score: 5.0736e-02 |             AOCC Score on Unimodal instances: 1.5221e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm enhanced with adaptive Cauchy mutation and a diversity-preserving selection mechanism for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm enhanced with adaptive Cauchy mutation and a diversity-preserving selection mechanism for efficient multimodal optimization.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma_cauchy = 0.1 #Initial Cauchy scale parameter
        self.sigma_decay = 0.99


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size
            
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            self.sigma_cauchy *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = self._select_parents(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds) #Bound the mutant

            #Cauchy Mutation
            cauchy_mutation = cauchy.rvs(loc=0, scale=self.sigma_cauchy, size=self.dim)
            mutant += cauchy_mutation

            #Crossover
            j_rand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    offspring[i, j] = mutant[j]

        return offspring


    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 3 (Overall AOCC Score: 5.0613e-02 |             AOCC Score on Unimodal instances: 1.5184e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithArchiveAndTournamentSelection
# Description: Differential Evolution with adaptive Gaussian mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import norm

class AdaptiveDEwithArchiveAndTournamentSelection:
    """
    Combines Differential Evolution (DE), adaptive Gaussian mutation, an archive, and tournament selection for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._gaussian_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _gaussian_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + norm.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]

```

### Rank 4 (Overall AOCC Score: 5.0572e-02 |             AOCC Score on Unimodal instances: 1.5172e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveLevyFlightWithDifferentialEvolution
# Description: Combines adaptive Levy flights for global exploration with differential evolution for local exploitation and utilizes a niching strategy to maintain diversity.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveLevyFlightWithDifferentialEvolution
# Description: Combines adaptive Levy flights for global exploration with differential evolution for local exploitation and utilizes a niching strategy to maintain diversity.
# Code:
class AdaptiveLevyFlightWithDifferentialEvolution:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.levy_alpha = 1.5  # Levy flight exponent
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._niching_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Levy Flight Exploration
            levy_step = self._levy_flight(self.levy_alpha, self.dim)
            new_solution = population[i] + 0.1*levy_step * (self.upper_bounds - self.lower_bounds)  #scale levy step
            new_solution = np.clip(new_solution, self.lower_bounds, self.upper_bounds)

            # Differential Evolution Exploitation
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, new_solution)
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _levy_flight(self, alpha, dim):
        # Generates a Levy flight step using Mantegna's algorithm.
        u = np.random.normal(0, 1, dim)
        v = np.random.normal(0, 1, dim)
        step = u / (np.abs(v)**(1/alpha))
        return step

    def _niching_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        selected_population = []
        selected_fitness = []
        
        while len(selected_population) < self.population_size:
            best_index = np.argmin(combined_fitness)
            best_solution = combined_population[best_index]
            best_fitness = combined_fitness[best_index]
            
            selected_population.append(best_solution)
            selected_fitness.append(best_fitness)
            
            combined_population = np.delete(combined_population, best_index, axis=0)
            combined_fitness = np.delete(combined_fitness, best_index)

        return np.array(selected_population), np.array(selected_fitness)


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

```

### Rank 5 (Overall AOCC Score: 5.0500e-02 |             AOCC Score on Unimodal instances: 1.5150e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A Differential Evolution variant using adaptive Cauchy mutation for efficient exploration in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A Differential Evolution variant using adaptive Cauchy mutation for efficient exploration in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.initial_cauchy_scale = 0.1
        self.cauchy_scale = self.initial_cauchy_scale


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_indices(i)
                mutant = population[a] + self.F * (population[b] - population[c])
                trial = self._crossover(population[i], mutant)
                
                #Adaptive Cauchy Mutation
                trial = trial + cauchy.rvs(loc=0, scale=self.cauchy_scale, size=self.dim)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    offspring.append(population[i])

            population = np.array(offspring)
            self._update_best(population, fitness_values)
            self._adapt_cauchy_scale(population,fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _select_indices(self, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return indices

    def _crossover(self, x, v):
        jrand = np.random.randint(0, self.dim)
        trial = np.copy(x)
        for j in range(self.dim):
            if np.random.rand() < self.CR or j == jrand:
                trial[j] = v[j]
        return trial

    def _update_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        if fitness_values[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness_values[best_index]
            self.best_solution_overall = population[best_index]

    def _adapt_cauchy_scale(self, population, fitness_values):
      #Reduce Cauchy scale if the algorithm converges
      if np.std(fitness_values) < 0.1 * (self.best_fitness_overall):
          self.cauchy_scale *= 0.9
      else: #increase if stuck
          self.cauchy_scale *= 1.1
      self.cauchy_scale = max(self.cauchy_scale, self.initial_cauchy_scale * 0.1) #Avoid extremely small scale
      self.cauchy_scale = min(self.cauchy_scale, self.initial_cauchy_scale * 10) #Avoid extremely large scale

```

### Rank 6 (Overall AOCC Score: 5.0452e-02 |             AOCC Score on Unimodal instances: 1.5135e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm enhanced with adaptive Cauchy mutation and a diversity-preserving selection strategy for efficient multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm enhanced with adaptive Cauchy mutation and a diversity-preserving selection strategy for efficient multimodal optimization.
# Code:

class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.scale_factor = 0.2 # For initial Cauchy scale
        self.cauchy_scale_decay = 0.99

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        cauchy_scale = self.scale_factor * (self.upper_bounds - self.lower_bounds)

        while self.eval_count < self.budget:
            offspring = np.copy(population)
            for i in range(self.population_size):
                # Differential Evolution mutation
                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)
                mutant = population[a] + self.F * (population[b] - population[c])

                # Adaptive Cauchy mutation
                mutant += cauchy.rvs(loc=0, scale=cauchy_scale, size=self.dim)

                #Clipping
                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

                # Crossover
                jrand = np.random.randint(0, self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == jrand:
                        offspring[i, j] = mutant[j]

            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection (combined population, diversity-preserving)
            combined_population = np.vstack((population, offspring))
            combined_fitness = np.concatenate((fitness_values, offspring_fitness))
            
            sorted_indices = np.argsort(combined_fitness)
            population = combined_population[sorted_indices[:self.population_size]]
            fitness_values = combined_fitness[sorted_indices[:self.population_size]]


            # Update best solution
            self._update_best(offspring, offspring_fitness)
            cauchy_scale *= self.cauchy_scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 7 (Overall AOCC Score: 4.9113e-02 |             AOCC Score on Unimodal instances: 1.4734e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithLevyFlights
# Description: A differential evolution algorithm enhanced with Levy flights for robust exploration and adaptive parameter control for exploitation in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np

# Name: AdaptiveDifferentialEvolutionWithLevyFlights
# Description: A differential evolution algorithm enhanced with Levy flights for robust exploration and adaptive parameter control for exploitation in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithLevyFlights:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9 # Crossover rate

        self.levy_alpha = 1.5 #Levy flight exponent

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_different_vectors(population, i)
                mutant = a + self.F * (b - c)
                trial = self._crossover(population[i], mutant, self.CR)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                # Levy Flight Mutation for Exploration
                levy_step = self._levy_flight(self.levy_alpha, self.dim)
                trial = trial + 0.1 * levy_step * (self.upper_bounds-self.lower_bounds)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)


                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    new_population.append(population[i])

                self._update_best(trial, trial_fitness)

            population = np.array(new_population)
            self.F = max(0.1, self.F * 0.99) #Adaptive F decay
            self.CR = min(1, self.CR + 0.001)  #Adaptive CR increase


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _select_different_vectors(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]


    def _crossover(self, x, v, CR):
        u = np.copy(x)
        jrand = np.random.randint(self.dim)
        for j in range(self.dim):
            if np.random.rand() < CR or j == jrand:
                u[j] = v[j]
        return u

    def _levy_flight(self, alpha, dim):
        beta = 3 / 2
        sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1/alpha)
        sigma_v = 1
        u = np.random.normal(0, sigma_u, dim)
        v = np.random.normal(0, sigma_v, dim)
        step = u / (np.abs(v)**(1/beta))
        return step


    def _update_best(self, solution, fitness):
        if fitness < self.best_fitness_overall:
            self.best_fitness_overall = fitness
            self.best_solution_overall = solution

```

### Rank 8 (Overall AOCC Score: 4.9099e-02 |             AOCC Score on Unimodal instances: 1.4730e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveCauchyDEwithEnhancedArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, enhanced archive management, and tournament selection for robust multimodal optimization.
# Code:
```python
# Name: AdaptiveCauchyDEwithEnhancedArchiveAndTournament
# Description: Differential Evolution with adaptive Cauchy mutation, enhanced archive management, and tournament selection for robust multimodal optimization.
# Code:
import numpy as np
from scipy.stats import cauchy

class AdaptiveCauchyDEwithEnhancedArchiveAndTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an enhanced archive, and tournament selection for robust multimodal optimization in high dimensions.  The archive uses a dynamically adjusted capacity and prioritizes diverse solutions.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, initial_archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = initial_archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.archive_growth_rate = 0.1 # Adjust archive size dynamically


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            fitness = self._evaluate_population(objective_function, population)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.gamma *= self.gamma_decay
            self._adjust_archive_size() #Dynamic archive size adjustment

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            #Prioritize diversity and solutions near the best solution
            distances = np.linalg.norm(np.array([s for s,_ in self.archive]) - solution, axis=1)
            worst_index = np.argmax(distances)  #Remove the furthest
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)


    def _tournament_selection(self, ind1, ind2, fit1, fit2):
        tournament = np.random.choice(np.array([ind1, ind2]), size=self.tournament_size, replace=True)
        tournament_fitness = np.array([fit1 if t is ind1 else fit2 for t in tournament])
        return tournament[np.argmin(tournament_fitness)]

    def _adjust_archive_size(self):
        if len(self.archive) > 0:
          self.archive_size = int(self.archive_size * (1 + self.archive_growth_rate))
          self.archive_size = min(self.archive_size, self.population_size * 2) # Limit archive growth


```

### Rank 9 (Overall AOCC Score: 4.8903e-02 |             AOCC Score on Unimodal instances: 1.4671e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: ArchiveEnhancedCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
```python
# Name: ArchiveEnhancedCauchyDE
# Description: Combines Differential Evolution, adaptive Cauchy mutation, and an archive for robust multimodal optimization.
# Code:
import numpy as np

class ArchiveEnhancedCauchyDE:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200
        self.archive = []
        self.gamma = 1.0  # Cauchy distribution scale parameter
        self.F = 0.8 #Differential Evolution scaling factor
        self.CR = 0.9 #Differential Evolution crossover rate

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Archive Management
            self._update_archive(population, fitness_values)

            # Differential Evolution with Cauchy Mutation
            offspring = self._cauchy_de(population, fitness_values)

            # Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Elitist Selection
            population, fitness_values = self._elitist_selection(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _update_archive(self, population, fitness_values):
        combined = np.concatenate((np.array([x[0] for x in self.archive]), population))
        combined_fitness = np.concatenate((np.array([x[1] for x in self.archive]), fitness_values))
        sorted_indices = np.argsort(combined_fitness)
        self.archive = [(combined[i], combined_fitness[i]) for i in sorted_indices[:self.archive_size]]

    def _cauchy_de(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            #Select three distinct vectors
            a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)
            while a == i or b == i or c == i:
                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)

            mutant = population[a] + self.F * (population[b] - population[c])

            #Cauchy mutation
            mutant += np.random.standard_cauchy(self.dim) * self.gamma

            #Crossover
            trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
            offspring.append(np.clip(trial, self.lower_bounds, self.upper_bounds))
        return np.array(offspring)

    def _elitist_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 10 (Overall AOCC Score: 4.8818e-02 |             AOCC Score on Unimodal instances: 1.4645e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithTournamentAndArchiveSelection
# Description: Differential Evolution with adaptive Gaussian mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
```python
# Name: AdaptiveDEwithTournamentAndArchiveSelection
# Description: Differential Evolution with adaptive Gaussian mutation, tournament selection, and an archive for robust multimodal optimization.
# Code:
import numpy as np
from scipy.stats import norm

class AdaptiveDEwithTournamentAndArchiveSelection:
    """
    Combines Differential Evolution (DE), adaptive Gaussian mutation, tournament selection, and an archive for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, sigma_init=10.0, sigma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.sigma = sigma_init
        self.sigma_decay = sigma_decay
        self.cr = cr
        self.tournament_size = tournament_size
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._gaussian_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                winner = self._tournament_selection(population[i], trial, fitness[i], trial_fitness)
                new_population.append(winner)
                if winner is trial:
                    self._update_archive(trial, trial_fitness)

            population = np.array(new_population)
            fitness = self._evaluate_population(objective_function, population)
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _gaussian_mutation(self, a, b, c):
        return a + self.sigma * (b - c) + norm.rvs(loc=0, scale=self.sigma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, ind1, ind2, fit1, fit2):
        tournament = np.random.choice(np.array([ind1, ind2]), size=self.tournament_size, replace=True)
        tournament_fitness = np.array([fit1 if t is ind1 else fit2 for t in tournament])
        return tournament[np.argmin(tournament_fitness)]
```

### Rank 11 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 322.66958311203854, sigma_decay: float = 0.9411053028409444, acceptance_threshold: float = 7.565043419324692e-06):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay #Decay rate of sigma
        self.acceptance_threshold = acceptance_threshold


    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:41:42 INFO Full response text: **Analysis:**

Comparing (best) `AdaptiveCauchyDEwithTournamentAndArchiveEnhancements` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the best utilizes Differential Evolution (DE), a powerful population-based optimization technique, along with adaptive Cauchy mutation for robust exploration and an archive for maintaining diversity.  The worst uses Gaussian sampling with relatively basic operators, lacking the sophisticated mutation and selection strategies of the top performers.  (second best) `AdaptiveDifferentialEvolutionWithCauchyMutation` vs (second worst) `AdaptiveDEwithTournamentAndArchiveSelection` shows a similar trend:  Adaptive Cauchy mutation, used in the second best, proves more effective than the adaptive Gaussian mutation in the second worst. Comparing (1st) vs (2nd), we see that the inclusion of tournament selection and enhanced archive management in the best significantly improves performance over the simpler diversity-preserving selection and lack of archive in the second best. (3rd) `AdaptiveDEwithArchiveAndTournamentSelection` vs (4th) `AdaptiveLevyFlightWithDifferentialEvolution` highlights the importance of well-integrated components.  The third-best balances adaptive Gaussian mutation, archive, and tournament selection more effectively than the fourth-best's combination of Levy flights and DE.  Comparing (second worst) `AdaptiveDEwithTournamentAndArchiveSelection` vs (worst) `AdaptiveGaussianSamplingEA`, we observe that incorporating DE and a structured selection mechanism (tournament) vastly outperforms the simple Gaussian sampling approach. Overall: The top-performing algorithms consistently leverage DE, adaptive mutations (Cauchy proving superior to Gaussian), and advanced selection and archive management strategies.  These elements are critical for handling the complexities of the GNBG benchmark functions.

**Experience:**

Effective population-based algorithms for high-dimensional problems require sophisticated mutation operators, archiving strategies for maintaining diversity, and robust selection schemes that effectively balance exploration and exploitation.  Adaptive parameter control is also crucial for optimal performance.

2025-06-23 22:41:44 INFO Full response text: **Keywords:**  Heuristic design, high-dimensional optimization, population-based algorithms, mutation operators, selection, archiving, adaptation.

**Advice:** Focus on novel combinations of existing operators and strategies.  Explore less-explored areas like dynamically adjusting the balance between exploration and exploitation based on problem characteristics (e.g., using problem-specific fitness landscape analysis to inform parameter adaptation). Investigate the use of machine learning to guide heuristic adaptation and selection.  Evaluate performance rigorously using statistical analysis across diverse benchmark problems.

**Avoid:**  Repetitive phrasing emphasizing already-known components (e.g., "archive is crucial").  Generic statements about exploration/exploitation without concrete mechanisms.  Over-reliance on a single "best" operator (e.g., Cauchy mutation) without comparative analysis.  Lack of quantitative evaluation and comparison to existing state-of-the-art methods.

**Explanation:** The ineffective self-reflection examples fall into the trap of simply restating known good practices without offering novel insights or directions for improvement.  The proposed advice pushes towards more creative heuristic design, rigorous evaluation, and the integration of advanced techniques like machine learning to surpass the limitations of current methods.  This approach is more likely to yield impactful, publishable results and justify the significant investment.

2025-06-23 22:41:44 INFO Generating offspring via Crossover...
2025-06-23 22:45:23 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveCauchyDEwithTournamentAndArchiveEnhancements
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveCauchyDEwithTournamentAndArchiveEnhancements
# Description: Combines DE, adaptive Cauchy mutation, tournament selection, and an enhanced archive for robust multimodal optimization.
# Code:
class AdaptiveCauchyDEwithTournamentAndArchiveEnhancements:
    """
    Differential Evolution with adaptive Cauchy mutation, tournament selection, and an enhanced archive for multimodal optimization.  Improves upon previous designs by incorporating a more sophisticated archive management strategy and a dynamic population size adjustment.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 10 * self.dim  # Initial population size, can be adjusted dynamically
        self.archive_size = 200  # Increased archive size for better diversity
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9
        self.F = 0.5
        self.tournament_size = 5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size_adjustment_factor = 1.1  #Factor to adjust population size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population)
            offspring_fitness = self._evaluate_population(objective_function, offspring)
            self._update_archive(offspring, offspring_fitness)
            population, fitness = self._tournament_selection(population, fitness, offspring, offspring_fitness)
            self.best_solution_overall, self.best_fitness_overall = self._update_best(population, fitness)
            self.gamma *= self.gamma_decay
            
            #Dynamic Population Size Adjustment
            if self.eval_count % (self.population_size * 2) == 0: # Adjust every 2 generations
                if self.best_fitness_overall < 1e-2:  #Check if converging well
                    self.population_size = int(self.population_size / self.population_size_adjustment_factor)  #Reduce if converging
                else:
                    self.population_size = int(self.population_size * self.population_size_adjustment_factor) #Increase otherwise


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _generate_offspring(self, population):
        offspring = np.zeros((self.population_size, self.dim))
        for i in range(self.population_size):
            r1, r2, r3 = self._select_different(i, population)
            mutant = r1 + self.F * (r2 - r3) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)
            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]


    def _update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Enhanced archive management: remove the furthest solution from the best
                distances = np.linalg.norm(np.array([x for x, _ in self.archive]) - self.best_solution_overall, axis=1)
                worst_index = np.argmax(distances)
                if offspring_fitness[i] < self.archive[worst_index][1]:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def _tournament_selection(self, population, fitness, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness, offspring_fitness))
        next_gen = np.zeros((self.population_size, self.dim))
        next_fit = np.zeros(self.population_size)
        for i in range(self.population_size):
            tournament = np.random.choice(len(combined_pop), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(combined_fit[tournament])]
            next_gen[i] = combined_pop[winner_index]
            next_fit[i] = combined_fit[winner_index]
        return next_gen, next_fit

    def _update_best(self, population, fitness):
        best_index = np.argmin(fitness)
        if fitness[best_index] < self.best_fitness_overall:
            self.best_fitness_overall = fitness[best_index]
            self.best_solution_overall = population[best_index]
        return self.best_solution_overall, self.best_fitness_overall

### Worse code
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

### Analyze & experience
- Comparing (best) `AdaptiveCauchyDEwithTournamentAndArchiveEnhancements` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the best utilizes Differential Evolution (DE), a powerful population-based optimization technique, along with adaptive Cauchy mutation for robust exploration and an archive for maintaining diversity.  The worst uses Gaussian sampling with relatively basic operators, lacking the sophisticated mutation and selection strategies of the top performers.  (second best) `AdaptiveDifferentialEvolutionWithCauchyMutation` vs (second worst) `AdaptiveDEwithTournamentAndArchiveSelection` shows a similar trend:  Adaptive Cauchy mutation, used in the second best, proves more effective than the adaptive Gaussian mutation in the second worst. Comparing (1st) vs (2nd), we see that the inclusion of tournament selection and enhanced archive management in the best significantly improves performance over the simpler diversity-preserving selection and lack of archive in the second best. (3rd) `AdaptiveDEwithArchiveAndTournamentSelection` vs (4th) `AdaptiveLevyFlightWithDifferentialEvolution` highlights the importance of well-integrated components.  The third-best balances adaptive Gaussian mutation, archive, and tournament selection more effectively than the fourth-best's combination of Levy flights and DE.  Comparing (second worst) `AdaptiveDEwithTournamentAndArchiveSelection` vs (worst) `AdaptiveGaussianSamplingEA`, we observe that incorporating DE and a structured selection mechanism (tournament) vastly outperforms the simple Gaussian sampling approach. Overall: The top-performing algorithms consistently leverage DE, adaptive mutations (Cauchy proving superior to Gaussian), and advanced selection and archive management strategies.  These elements are critical for handling the complexities of the GNBG benchmark functions.
- **Keywords:**  Heuristic design, high-dimensional optimization, population-based algorithms, mutation operators, selection, archiving, adaptation.

**Advice:** Focus on novel combinations of existing operators and strategies.  Explore less-explored areas like dynamically adjusting the balance between exploration and exploitation based on problem characteristics (e.g., using problem-specific fitness landscape analysis to inform parameter adaptation). Investigate the use of machine learning to guide heuristic adaptation and selection.  Evaluate performance rigorously using statistical analysis across diverse benchmark problems.

**Avoid:**  Repetitive phrasing emphasizing already-known components (e.g., "archive is crucial").  Generic statements about exploration/exploitation without concrete mechanisms.  Over-reliance on a single "best" operator (e.g., Cauchy mutation) without comparative analysis.  Lack of quantitative evaluation and comparison to existing state-of-the-art methods.

**Explanation:** The ineffective self-reflection examples fall into the trap of simply restating known good practices without offering novel insights or directions for improvement.  The proposed advice pushes towards more creative heuristic design, rigorous evaluation, and the integration of advanced techniques like machine learning to surpass the limitations of current methods.  This approach is more likely to yield impactful, publishable results and justify the significant investment.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:45:23 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:**  Heuristic design, high-dimensional optimization, population-based algorithms, mutation operators, selection, archiving, adaptation.

**Advice:** Focus on novel combinations of existing operators and strategies.  Explore less-explored areas like dynamically adjusting the balance between exploration and exploitation based on problem characteristics (e.g., using problem-specific fitness landscape analysis to inform parameter adaptation). Investigate the use of machine learning to guide heuristic adaptation and selection.  Evaluate performance rigorously using statistical analysis across diverse benchmark problems.

**Avoid:**  Repetitive phrasing emphasizing already-known components (e.g., "archive is crucial").  Generic statements about exploration/exploitation without concrete mechanisms.  Over-reliance on a single "best" operator (e.g., Cauchy mutation) without comparative analysis.  Lack of quantitative evaluation and comparison to existing state-of-the-art methods.

**Explanation:** The ineffective self-reflection examples fall into the trap of simply restating known good practices without offering novel insights or directions for improvement.  The proposed advice pushes towards more creative heuristic design, rigorous evaluation, and the integration of advanced techniques like machine learning to surpass the limitations of current methods.  This approach is more likely to yield impactful, publishable results and justify the significant investment.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 22:48:50 INFO Perform Harmony Search...
2025-06-23 22:48:59 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:48:59 ERROR Can not run the algorithm
2025-06-23 22:48:59 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:48:59 INFO FeHistory: []
2025-06-23 22:48:59 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:49:00 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:49:00 ERROR Can not run the algorithm
2025-06-23 22:49:00 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:49:00 INFO FeHistory: []
2025-06-23 22:49:00 INFO Expected Optimum FE: -5000
2025-06-23 22:49:00 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:49:00 INFO AOCC mean: 0.0000
2025-06-23 22:49:00 INFO Generation 6, best so far: 0.24747886597801494
2025-06-23 22:49:00 INFO Population length is: 12
2025-06-23 22:49:00 INFO --- Performing Long-Term Reflection at Generation 7 ---
2025-06-23 22:49:00 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.3598e-02 |             AOCC Score on Unimodal instances: 1.6079e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Combines DE, adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Combines DE, adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = 5

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
```

### Rank 2 (Overall AOCC Score: 5.3555e-02 |             AOCC Score on Unimodal instances: 1.6067e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDECauchyArchiveTournament
# Description: Combines Differential Evolution with Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

class AdaptiveDECauchyArchiveTournament:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation, an archive, and tournament selection.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
```

### Rank 3 (Overall AOCC Score: 5.3494e-02 |             AOCC Score on Unimodal instances: 1.6048e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A differential evolution algorithm enhanced with adaptive mutation and clustering to escape local optima in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A differential evolution algorithm enhanced with adaptive mutation and clustering to escape local optima in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.archive = []  # Archive of good solutions
        self.cluster_threshold = 0.1 #parameter for clustering

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            self._adaptive_parameter_tuning(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            #Differential Mutation
            a, b, c = self._select_differents(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            cross_points = np.random.rand(self.dim) < self.CR
            offspring[i] = np.where(cross_points, mutant, population[i])
            #Cauchy Mutation for exploration
            offspring[i] += cauchy.rvs(loc=0, scale=0.1, size=self.dim)
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)
        return offspring


    def _select_differents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]


    def _selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        return combined_pop[sorted_indices[:self.population_size]], combined_fit[sorted_indices[:self.population_size]]


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]


    def _update_archive(self, offspring, offspring_fitness):
        for i, solution in enumerate(offspring):
          self.archive.append((solution, offspring_fitness[i]))
        self.archive = sorted(self.archive, key=lambda x: x[1])[:int(self.population_size * 0.2)]

    def _adaptive_parameter_tuning(self, population, fitness_values):
        #Adjust F and CR based on convergence and diversity
        mean_fitness = np.mean(fitness_values)
        std_fitness = np.std(fitness_values)
        if std_fitness < 0.1 * (self.upper_bounds[0] - self.lower_bounds[0]): # Low diversity
            self.F *= 1.1 # increase exploration
            self.CR *= 0.9 # reduce exploitation
        else:
            self.F *= 0.9
            self.CR *= 1.1



```

### Rank 4 (Overall AOCC Score: 5.2931e-02 |             AOCC Score on Unimodal instances: 1.5879e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDECauchyWithArchiveTournament
# Description: Combines DE, adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDECauchyWithArchiveTournament
# Description: Combines DE, adaptive Cauchy mutation, archive, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDECauchyWithArchiveTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, an archive, and tournament selection for robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
```

### Rank 5 (Overall AOCC Score: 5.0741e-02 |             AOCC Score on Unimodal instances: 1.5222e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithCauchyMutationAndNiching
# Description: Combines adaptive Differential Evolution with Cauchy mutation and a niching strategy for multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEwithCauchyMutationAndNiching
# Description:Combines adaptive Differential Evolution with Cauchy mutation and a niching strategy for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyMutationAndNiching:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._niching_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= 0.99 #Adapt Cauchy scale


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_step = self._cauchy_mutation(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _cauchy_mutation(self, dim):
        return np.random.standard_cauchy(dim)

    def _niching_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        selected_population = []
        selected_fitness = []
        
        while len(selected_population) < self.population_size:
            best_index = np.argmin(combined_fitness)
            best_solution = combined_population[best_index]
            best_fitness = combined_fitness[best_index]
            
            #Niching: check for distance to existing solutions
            is_niche_occupied = False
            for sol in selected_population:
                if np.linalg.norm(best_solution - sol) < self.niche_radius:
                    is_niche_occupied = True
                    break

            if not is_niche_occupied:
                selected_population.append(best_solution)
                selected_fitness.append(best_fitness)
            
            combined_population = np.delete(combined_population, best_index, axis=0)
            combined_fitness = np.delete(combined_fitness, best_index)

        return np.array(selected_population), np.array(selected_fitness)


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]
```

### Rank 6 (Overall AOCC Score: 4.9293e-02 |             AOCC Score on Unimodal instances: 1.4788e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalEA
# Description: An evolutionary algorithm using adaptive mutation, niching, and a multi-stage exploration strategy for multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveMultimodalEA
# Description: An evolutionary algorithm using adaptive mutation, niching, and a multi-stage exploration strategy for multimodal landscapes.
# Code:
class AdaptiveMultimodalEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.niche_radius = 0.5*(np.max(self.upper_bounds) - np.min(self.lower_bounds)) #Initial niche radius. Adapts later
        self.archive = [] # Archive of good solutions to promote diversity
        self.exploration_stage = 1 # 1: Global exploration, 2: Local refinement


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._environmental_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adaptive_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            parent = population[i]
            if self.exploration_stage == 1:  #Global exploration
                offspring.append(parent + np.random.normal(0, self.sigma, self.dim))
            else: #Local Refinement: Cauchy mutation for wider exploration
                 offspring.append(parent + cauchy.rvs(loc=0, scale=self.sigma, size=self.dim))

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _environmental_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        #Niching: only select solutions sufficiently far from existing solutions in archive
        selected_pop = []
        selected_fit = []
        for i in range(len(combined_pop)):
            is_unique = True
            for sol in self.archive:
                if np.linalg.norm(combined_pop[i] - sol) < self.niche_radius:
                    is_unique = False
                    break
            if is_unique:
                selected_pop.append(combined_pop[i])
                selected_fit.append(combined_fit[i])

        #Tournament selection among unique solutions
        sorted_indices = np.argsort(selected_fit)
        next_gen = np.array(selected_pop)[sorted_indices[:self.population_size]]
        next_fit = np.array(selected_fit)[sorted_indices[:self.population_size]]
        self.archive.extend(next_gen)
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adaptive_parameters(self):
        self.sigma *= self.sigma_decay
        #Adapt exploration stage based on progress.
        if self.eval_count > self.budget*0.7 and self.exploration_stage ==1:
             self.exploration_stage = 2
             self.niche_radius *= 0.5 #Reduce niche radius for finer local search


```

### Rank 7 (Overall AOCC Score: 4.9123e-02 |             AOCC Score on Unimodal instances: 1.4737e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A Differential Evolution variant incorporating clustering to escape local optima and adaptive mutation strategies.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A Differential Evolution variant incorporating clustering to escape local optima and adaptive mutation strategies.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.archive = [] #To store good solutions
        self.cluster_threshold = 0.5 #Parameter to adjust cluster size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Clustering
            clusters = self._cluster_population(np.vstack((population, offspring)), np.concatenate((fitness_values, offspring_fitness)))

            #Adaptive Mutation based on cluster diversity
            population, fitness_values = self._adaptive_mutation(clusters)


            # Update best solution
            self._update_best(offspring, offspring_fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            if objective_function(trial.reshape(1,-1))[0] < fitness_values[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring

    def _select_different(self, i, size):
        candidates = list(range(size))
        candidates.remove(i)
        a,b,c = random.sample(candidates, 3)
        return a,b,c

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _cluster_population(self, population, fitness_values):
        #Simple clustering based on Euclidean distance.  Could be replaced with more sophisticated methods.
        clusters = []
        for i in range(len(population)):
            assigned = False
            for j, cluster in enumerate(clusters):
                centroid = np.mean(cluster[0], axis=0)
                distance = np.linalg.norm(population[i] - centroid)
                if distance < self.cluster_threshold:
                    clusters[j][0] = np.vstack((clusters[j][0], population[i]))
                    clusters[j][1] = np.concatenate((clusters[j][1], [fitness_values[i]]))
                    assigned = True
                    break
            if not assigned:
                clusters.append([np.array([population[i]]), np.array([fitness_values[i]])])
        return clusters


    def _adaptive_mutation(self, clusters):
        new_population = []
        new_fitness = []
        for cluster in clusters:
            if len(cluster[0]) > 1:  # Only mutate clusters with more than one solution
              #Calculate cluster diversity.  Higher variance implies more exploration needed.
                diversity = np.var(cluster[0], axis=0).mean()
                mutation_scale = 0.1 + 0.5 * diversity #Adjust mutation based on cluster diversity

                #Apply mutation to cluster
                mutated_cluster = cluster[0] + np.random.normal(0, mutation_scale, size=cluster[0].shape)
                mutated_cluster = np.clip(mutated_cluster, self.lower_bounds, self.upper_bounds)
                new_population.extend(list(mutated_cluster))

                #Evaluate the mutated cluster
                new_fitness.extend(list(objective_function(mutated_cluster)))
            else:
                new_population.extend(list(cluster[0]))
                new_fitness.extend(list(cluster[1]))


        #Select best from the combined population
        combined_pop = np.array(new_population)
        combined_fit = np.array(new_fitness)
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 8 (Overall AOCC Score: 4.9112e-02 |             AOCC Score on Unimodal instances: 1.4733e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithLevyFlightsAndArchive
# Description: Differential Evolution with Levy flights and an archive for enhanced exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithLevyFlightsAndArchive
# Description: Differential Evolution with Levy flights and an archive for enhanced exploration and exploitation in multimodal landscapes.
# Code:
class AdaptiveDEwithLevyFlightsAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.archive = []  # To store good solutions
        self.archive_size = 100
        self.levy_alpha = 1.5 #Levy flight exponent


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_parents(population, i)
                mutant = a + self.F * (b - c)
                trial = self._crossover(population[i], mutant, self.CR)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                # Levy Flight Mutation for Exploration
                levy_step = self._levy_flight(self.levy_alpha, self.dim)
                trial = trial + 0.1 * levy_step * (self.upper_bounds - self.lower_bounds)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1,-1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

                self._update_best(trial, trial_fitness)

            population = np.array(new_population)
            self.F = max(0.1, self.F * 0.99) #Adaptive F decay
            self.CR = min(1, self.CR + 0.001)  #Adaptive CR increase


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _select_parents(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]


    def _crossover(self, x, v, CR):
        u = np.copy(x)
        jrand = np.random.randint(self.dim)
        for j in range(self.dim):
            if np.random.rand() < CR or j == jrand:
                u[j] = v[j]
        return u

    def _levy_flight(self, alpha, dim):
        beta = 3 / 2
        sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1/alpha)
        sigma_v = 1
        u = np.random.normal(0, sigma_u, dim)
        v = np.random.normal(0, sigma_v, dim)
        step = u / (np.abs(v)**(1/beta))
        return step


    def _update_best(self, solution, fitness):
        if fitness < self.best_fitness_overall:
            self.best_fitness_overall = fitness
            self.best_solution_overall = solution

    def _update_archive(self, solution, fitness):
        self.archive.append((solution, fitness))
        self.archive.sort(key=lambda item: item[1])  # Sort by fitness
        self.archive = self.archive[:self.archive_size] #Keep only top archive_size

```

### Rank 9 (Overall AOCC Score: 4.8973e-02 |             AOCC Score on Unimodal instances: 1.4692e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCauchyAndLevyFlights
# Description: Combines Differential Evolution, adaptive Cauchy and Levy flight mutations for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyAndLevyFlights
# Description: Combines Differential Evolution, adaptive Cauchy and Levy flight mutations for robust multimodal optimization.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyAndLevyFlights:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Crossover rate
        self.sigma_cauchy = 0.1 #Initial Cauchy scale parameter
        self.sigma_decay = 0.99
        self.levy_alpha = 1.5 #Levy flight exponent
        self.levy_scale = 0.1

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            self.sigma_cauchy *= self.sigma_decay
            self.F = max(0.1, self.F * 0.99) #Adaptive F decay
            self.CR = min(1, self.CR + 0.001)  #Adaptive CR increase

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = np.copy(population)
        for i in range(self.population_size):
            a, b, c = self._select_parents(i, population)
            mutant = a + self.F * (b - c)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_mutation = cauchy.rvs(loc=0, scale=self.sigma_cauchy, size=self.dim)
            mutant += cauchy_mutation

            #Levy Flight Mutation
            levy_step = self._levy_flight(self.levy_alpha, self.dim)
            mutant += self.levy_scale * levy_step * (self.upper_bounds - self.lower_bounds)
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Crossover
            j_rand = np.random.randint(0, self.dim)
            for j in range(self.dim):
                if np.random.rand() < self.CR or j == j_rand:
                    offspring[i, j] = mutant[j]

        return offspring

    def _select_parents(self, i, population):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _levy_flight(self, alpha, dim):
        beta = 3 / 2
        sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1/alpha)
        sigma_v = 1
        u = np.random.normal(0, sigma_u, dim)
        v = np.random.normal(0, sigma_v, dim)
        step = u / (np.abs(v)**(1/beta))
        return step
```

### Rank 10 (Overall AOCC Score: 4.8866e-02 |             AOCC Score on Unimodal instances: 1.4660e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveMultimodalOptimizer
# Description: An evolutionary algorithm combining adaptive Gaussian and Cauchy mutations with dynamic population sizing and niching for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveMultimodalOptimizer
# Description: An evolutionary algorithm combining adaptive Gaussian and Cauchy mutations with dynamic population sizing and niching for multimodal optimization.
# Code:
class AdaptiveMultimodalOptimizer:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.cauchy_scale = 0.1 * (self.upper_bounds - self.lower_bounds)  # Cauchy mutation scale
        self.niche_radius = 0.5 * np.mean(self.upper_bounds - self.lower_bounds) # initial niche radius
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1
        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._update_population(population, fitness_values, offspring, offspring_fitness)
            self._update_archive(offspring, offspring_fitness)
            self._adapt_parameters(population, fitness_values)

        if self.best_solution_overall is None and self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _generate_offspring(self, population, fitness_values):
        parents = self._tournament_selection(population, fitness_values)
        offspring = self._gaussian_recombination(parents)
        offspring = self._mutate(offspring)
        return offspring

    def _mutate(self, offspring):
        mutation_choice = np.random.rand(len(offspring)) < 0.5 #Half Gaussian, half Cauchy
        offspring[mutation_choice] += np.random.normal(0, self.sigma, size=(np.sum(mutation_choice), self.dim))
        offspring[~mutation_choice] += cauchy.rvs(loc=0, scale=self.cauchy_scale, size=(np.sum(~mutation_choice), self.dim))
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.array(offspring)


    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size
        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)

    def _update_population(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_archive(self, offspring, offspring_fitness):
        for i, sol in enumerate(offspring):
            is_new = True
            for j, archived_sol in enumerate(self.archive):
                if np.linalg.norm(sol - archived_sol[0]) < self.niche_radius:
                    is_new = False
                    if offspring_fitness[i] < archived_sol[1]:
                        self.archive[j] = (sol, offspring_fitness[i])
                    break
            if is_new:
                self.archive.append((sol, offspring_fitness[i]))

    def _adapt_parameters(self, population, fitness_values):
        self.sigma *= self.sigma_decay
        # Adjust niche radius based on population spread
        spread = np.max(np.linalg.norm(population - np.mean(population, axis=0), axis=1))
        self.niche_radius = 0.5 * spread
        # Dynamic population sizing (simple example):
        average_fitness = np.mean(fitness_values)
        if average_fitness < self.best_fitness_overall * 0.8: #increase pop if doing good
            self.population_size = min(self.population_size * 1.1, 500) # limit to 500
        else: #decrease pop if doing bad
            self.population_size = max(int(self.population_size * 0.9), 50) # limit to 50

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 11 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size: int = 781.3691417856942, sigma_decay: float = 0.9883683836686223, acceptance_threshold: float = 9.125665385392451e-07):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = population_size
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold


    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:49:04 INFO Full response text: **Analysis:**

Comparing (best) `AdaptiveDEwithCauchyArchiveTournament` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the best utilizes an archive and tournament selection to maintain diversity and efficiently select promising solutions, while the worst relies on simple Gaussian sampling and lacks mechanisms to escape local optima.  `(second best)` `AdaptiveDECauchyArchiveTournament` and `(second worst)` `AdaptiveMultimodalOptimizer` show similar differences in sophisticated selection vs simpler approaches.  Comparing (1st) vs (2nd), we see almost identical performance, suggesting that minor variations in implementation don't significantly impact results for these unimodal functions.  `(3rd)` `AdaptiveDifferentialEvolutionWithClustering` and `(4th)` `AdaptiveDECauchyWithArchiveTournament` also show minor differences, with clustering being slightly less effective than archive-based approaches. Comparing (second worst) vs (worst), we see that `AdaptiveMultimodalOptimizer` attempts to incorporate niching and dynamic population sizing, which provide some improvement over the basic Gaussian sampling of `AdaptiveGaussianSamplingEA`, but still lacks the effectiveness of archive-based strategies. Overall:  The top-performing algorithms consistently employ archives, adaptive mutation strategies (like Cauchy), and tournament selection to balance exploration and exploitation, achieving robust performance across unimodal problems.  Algorithms lacking these features struggle with multimodal problems, achieving near-zero AOCC scores in the multi-modal groups.

**Experience:**

To design better heuristics, focus on incorporating adaptive mechanisms, leveraging archive-based techniques for diversity preservation and efficient selection strategies. Combining different mutation operators (e.g., Cauchy and Levy flights) can also improve exploration in complex high-dimensional spaces.  Careful parameter tuning is crucial for optimal performance.

2025-06-23 22:49:06 INFO Full response text: **Keywords:** Adaptive heuristics, diversity preservation, efficient selection, mutation operator combination, parameter tuning.

**Advice:**  Focus on novel combinations of existing techniques rather than simply reiterating known best practices. Explore less common mutation operators and selection methods.  Develop rigorous methods for adaptive parameter tuning based on performance feedback, not intuition.  Emphasize measurable improvements in exploration and exploitation trade-offs.

**Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, and multimodal problems.  Avoid unsubstantiated claims of superiority for specific operators (e.g., "Cauchy is best").  Refrain from simply listing known components of effective algorithms without proposing novel integrations.

**Explanation:** The provided "Ineffective self-reflection" examples suffer from vagueness and repetition.  To design better heuristics, we must move beyond generic advice and focus on concrete, testable improvements in specific algorithm components and their interactions.  Novelty and rigorous evaluation are key to justifying the claimed improvement.

2025-06-23 22:49:06 INFO Generating offspring via Crossover...
2025-06-23 22:52:13 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveMultimodalEA
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveMultimodalEA
# Description: An evolutionary algorithm using adaptive mutation, niching, and a multi-stage exploration strategy for multimodal landscapes.
# Code:
class AdaptiveMultimodalEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)
        self.sigma_decay = 0.99
        self.niche_radius = 0.5*(np.max(self.upper_bounds) - np.min(self.lower_bounds)) #Initial niche radius. Adapts later
        self.archive = [] # Archive of good solutions to promote diversity
        self.exploration_stage = 1 # 1: Global exploration, 2: Local refinement


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._environmental_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adaptive_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            parent = population[i]
            if self.exploration_stage == 1:  #Global exploration
                offspring.append(parent + np.random.normal(0, self.sigma, self.dim))
            else: #Local Refinement: Cauchy mutation for wider exploration
                 offspring.append(parent + cauchy.rvs(loc=0, scale=self.sigma, size=self.dim))

        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _environmental_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        #Niching: only select solutions sufficiently far from existing solutions in archive
        selected_pop = []
        selected_fit = []
        for i in range(len(combined_pop)):
            is_unique = True
            for sol in self.archive:
                if np.linalg.norm(combined_pop[i] - sol) < self.niche_radius:
                    is_unique = False
                    break
            if is_unique:
                selected_pop.append(combined_pop[i])
                selected_fit.append(combined_fit[i])

        #Tournament selection among unique solutions
        sorted_indices = np.argsort(selected_fit)
        next_gen = np.array(selected_pop)[sorted_indices[:self.population_size]]
        next_fit = np.array(selected_fit)[sorted_indices[:self.population_size]]
        self.archive.extend(next_gen)
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _adaptive_parameters(self):
        self.sigma *= self.sigma_decay
        #Adapt exploration stage based on progress.
        if self.eval_count > self.budget*0.7 and self.exploration_stage ==1:
             self.exploration_stage = 2
             self.niche_radius *= 0.5 #Reduce niche radius for finer local search



### Worse code
AdaptiveDEwithCauchyMutationAndNiching
import numpy as np
import random

# Name: AdaptiveDEwithCauchyMutationAndNiching
# Description:Combines adaptive Differential Evolution with Cauchy mutation and a niching strategy for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyMutationAndNiching:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._niching_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self.gamma *= 0.99 #Adapt Cauchy scale


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_step = self._cauchy_mutation(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _cauchy_mutation(self, dim):
        return np.random.standard_cauchy(dim)

    def _niching_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        selected_population = []
        selected_fitness = []
        
        while len(selected_population) < self.population_size:
            best_index = np.argmin(combined_fitness)
            best_solution = combined_population[best_index]
            best_fitness = combined_fitness[best_index]
            
            #Niching: check for distance to existing solutions
            is_niche_occupied = False
            for sol in selected_population:
                if np.linalg.norm(best_solution - sol) < self.niche_radius:
                    is_niche_occupied = True
                    break

            if not is_niche_occupied:
                selected_population.append(best_solution)
                selected_fitness.append(best_fitness)
            
            combined_population = np.delete(combined_population, best_index, axis=0)
            combined_fitness = np.delete(combined_fitness, best_index)

        return np.array(selected_population), np.array(selected_fitness)


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

### Analyze & experience
- Comparing (best) `AdaptiveDEwithCauchyArchiveTournament` vs (worst) `AdaptiveGaussianSamplingEA`, we see that the best utilizes an archive and tournament selection to maintain diversity and efficiently select promising solutions, while the worst relies on simple Gaussian sampling and lacks mechanisms to escape local optima.  `(second best)` `AdaptiveDECauchyArchiveTournament` and `(second worst)` `AdaptiveMultimodalOptimizer` show similar differences in sophisticated selection vs simpler approaches.  Comparing (1st) vs (2nd), we see almost identical performance, suggesting that minor variations in implementation don't significantly impact results for these unimodal functions.  `(3rd)` `AdaptiveDifferentialEvolutionWithClustering` and `(4th)` `AdaptiveDECauchyWithArchiveTournament` also show minor differences, with clustering being slightly less effective than archive-based approaches. Comparing (second worst) vs (worst), we see that `AdaptiveMultimodalOptimizer` attempts to incorporate niching and dynamic population sizing, which provide some improvement over the basic Gaussian sampling of `AdaptiveGaussianSamplingEA`, but still lacks the effectiveness of archive-based strategies. Overall:  The top-performing algorithms consistently employ archives, adaptive mutation strategies (like Cauchy), and tournament selection to balance exploration and exploitation, achieving robust performance across unimodal problems.  Algorithms lacking these features struggle with multimodal problems, achieving near-zero AOCC scores in the multi-modal groups.
- **Keywords:** Adaptive heuristics, diversity preservation, efficient selection, mutation operator combination, parameter tuning.

**Advice:**  Focus on novel combinations of existing techniques rather than simply reiterating known best practices. Explore less common mutation operators and selection methods.  Develop rigorous methods for adaptive parameter tuning based on performance feedback, not intuition.  Emphasize measurable improvements in exploration and exploitation trade-offs.

**Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, and multimodal problems.  Avoid unsubstantiated claims of superiority for specific operators (e.g., "Cauchy is best").  Refrain from simply listing known components of effective algorithms without proposing novel integrations.

**Explanation:** The provided "Ineffective self-reflection" examples suffer from vagueness and repetition.  To design better heuristics, we must move beyond generic advice and focus on concrete, testable improvements in specific algorithm components and their interactions.  Novelty and rigorous evaluation are key to justifying the claimed improvement.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:52:13 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- **Keywords:** Adaptive heuristics, diversity preservation, efficient selection, mutation operator combination, parameter tuning.

**Advice:**  Focus on novel combinations of existing techniques rather than simply reiterating known best practices. Explore less common mutation operators and selection methods.  Develop rigorous methods for adaptive parameter tuning based on performance feedback, not intuition.  Emphasize measurable improvements in exploration and exploitation trade-offs.

**Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, and multimodal problems.  Avoid unsubstantiated claims of superiority for specific operators (e.g., "Cauchy is best").  Refrain from simply listing known components of effective algorithms without proposing novel integrations.

**Explanation:** The provided "Ineffective self-reflection" examples suffer from vagueness and repetition.  To design better heuristics, we must move beyond generic advice and focus on concrete, testable improvements in specific algorithm components and their interactions.  Novelty and rigorous evaluation are key to justifying the claimed improvement.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 22:54:00 INFO Perform Harmony Search...
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -5000
2025-06-23 22:54:09 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO AOCC mean: 0.0000
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -5000
2025-06-23 22:54:09 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO AOCC mean: 0.0000
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -5000
2025-06-23 22:54:09 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO AOCC mean: 0.0000
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:09 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:09 ERROR Can not run the algorithm
2025-06-23 22:54:09 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:09 INFO FeHistory: []
2025-06-23 22:54:09 INFO Expected Optimum FE: -5000
2025-06-23 22:54:09 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:09 INFO AOCC mean: 0.0000
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -5000
2025-06-23 22:54:10 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO AOCC mean: 0.0000
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -5000
2025-06-23 22:54:10 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO AOCC mean: 0.0000
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -5000
2025-06-23 22:54:10 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO AOCC mean: 0.0000
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -5000
2025-06-23 22:54:10 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO AOCC mean: 0.0000
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -5000
2025-06-23 22:54:10 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO AOCC mean: 0.0000
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 22:54:10 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 22:54:10 ERROR Can not run the algorithm
2025-06-23 22:54:10 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 22:54:10 INFO FeHistory: []
2025-06-23 22:54:10 INFO Expected Optimum FE: -5000
2025-06-23 22:54:10 INFO Unimodal AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 22:54:10 INFO AOCC mean: 0.0000
2025-06-23 22:54:10 INFO Generation 7, best so far: 0.24747886597801494
2025-06-23 22:54:10 INFO Population length is: 12
2025-06-23 22:54:10 INFO --- Performing Long-Term Reflection at Generation 8 ---
2025-06-23 22:54:10 INFO Reflection Prompt: ### Problem Description
Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    
### List heuristics
Below is a list of design heuristics ranked from best to worst based on their average AOCC score, where higher is better, across a subset of the GNBG benchmark. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score: 5.0873e-02 |             AOCC Score on Unimodal instances: 1.5262e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm with adaptive mutation strength and Cauchy mutation for escaping local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm with adaptive mutation strength and Cauchy mutation for escaping local optima in multimodal landscapes.

class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9 # Crossover rate
        self.gamma = 0.95 #Cauchy scale factor decay


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf') if self.dim > 0 else 0

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        cauchy_scale = 0.1 * (self.upper_bounds - self.lower_bounds) # Initial Cauchy scale

        while self.eval_count < self.budget:
            offspring = np.zeros_like(population)
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_different(population, i)
                mutant = a + self.F * (b - c)
                
                #Cauchy Mutation
                mutant += cauchy.rvs(loc=0, scale=cauchy_scale, size=self.dim)

                #Crossover
                jrand = np.random.randint(self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == jrand:
                        offspring[i,j] = mutant[j]
                    else:
                        offspring[i,j] = population[i,j]
                
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)


            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            self._update_best(offspring, offspring_fitness)
            cauchy_scale *= self.gamma #Decay Cauchy scale

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _select_different(self, population, i):
        indices = np.random.choice(self.population_size, 3, replace=False)
        while i in indices:
            indices = np.random.choice(self.population_size, 3, replace=False)
        return population[indices[0]], population[indices[1]], population[indices[2]]

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

```

### Rank 2 (Overall AOCC Score: 5.0715e-02 |             AOCC Score on Unimodal instances: 1.5214e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm with adaptive mutation scale and Cauchy mutation for escaping local optima in multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: A differential evolution algorithm with adaptive mutation scale and Cauchy mutation for escaping local optima in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.scale_factor = 1.0 #Initial Cauchy scale factor
        self.scale_decay = 0.95 #Decay rate for scale factor


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                #Differential Evolution
                a, b, c = self._select_differents(population, i)
                mutant = a + self.F * (b - c)
                trial = self._crossover(population[i], mutant)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)
                #Cauchy mutation for exploration
                trial += cauchy.rvs(loc=0, scale=self.scale_factor, size=self.dim)
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    fitness_values[i] = trial_fitness
                else:
                    new_population.append(population[i])

                self._update_best(trial, trial_fitness)

            population = np.array(new_population)
            self.scale_factor *= self.scale_decay


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _select_differents(self, population, i):
        candidates = list(range(self.population_size))
        candidates.remove(i)
        a, b, c = np.random.choice(candidates, 3, replace=False)
        return population[a], population[b], population[c]

    def _crossover(self, x, v):
        u = np.copy(x)
        indices = np.random.rand(self.dim) < self.CR
        u[indices] = v[indices]
        return u

    def _update_best(self, solution, fitness):
        if fitness < self.best_fitness_overall:
            self.best_fitness_overall = fitness
            self.best_solution_overall = solution
```

### Rank 3 (Overall AOCC Score: 5.0517e-02 |             AOCC Score on Unimodal instances: 1.5155e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A differential evolution algorithm incorporating adaptive mutation strength and population clustering for enhanced exploration and exploitation in multimodal landscapes.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDifferentialEvolutionWithClustering
# Description: A differential evolution algorithm incorporating adaptive mutation strength and population clustering for enhanced exploration and exploitation in multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithClustering:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.k = 5 # Number of clusters for k-means

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            #Clustering
            centroids = self._kmeans_clustering(population, self.k)
            
            offspring = []
            offspring_fitness = []
            for i in range(self.population_size):
                #Adaptive Mutation using Centroid information.
                closest_centroid_index = self._closest_centroid(population[i], centroids)
                centroid = centroids[closest_centroid_index]
                
                #Differential Evolution Mutation
                a, b, c = self._select_differents(population, i) #Avoid self
                mutant = population[a] + self.F * (population[b] - population[c])

                #Binomial Crossover
                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])
                trial = np.clip(trial, self.lower_bounds, self.upper_bounds)

                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness_values[i]:
                    offspring.append(trial)
                    offspring_fitness.append(trial_fitness)
                else:
                    offspring.append(population[i])
                    offspring_fitness.append(fitness_values[i])
            population = np.array(offspring)
            fitness_values = np.array(offspring_fitness)

            #Update Best
            self._update_best(population, fitness_values)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _kmeans_clustering(self, population, k):
        # Simple k-means++ initialization
        centroids = random.sample(list(population), k)
        
        while True:
            clusters = [[] for _ in range(k)]
            for point in population:
                distances = np.linalg.norm(point - np.array(centroids), axis=1)
                closest_centroid_index = np.argmin(distances)
                clusters[closest_centroid_index].append(point)
            
            new_centroids = np.array([np.mean(cluster, axis=0) if cluster else centroid for cluster, centroid in zip(clusters, centroids)])
            if np.allclose(centroids, new_centroids):
                break
            centroids = new_centroids
        return centroids

    def _closest_centroid(self, point, centroids):
        distances = np.linalg.norm(point - np.array(centroids), axis=1)
        return np.argmin(distances)

    def _select_differents(self, population, current_index):
        indices = list(range(len(population)))
        indices.remove(current_index)
        return random.sample(indices, 3)


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```

### Rank 4 (Overall AOCC Score: 4.9551e-02 |             AOCC Score on Unimodal instances: 1.4865e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithCauchyClusteringTournament
# Description: Combines DE, adaptive Cauchy mutation, clustering, and tournament selection for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyClusteringTournament
# Description: Combines DE, adaptive Cauchy mutation, clustering, and tournament selection for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyClusteringTournament:
    """
    Combines Differential Evolution (DE), adaptive Cauchy mutation, 
    k-means clustering for diversity, and tournament selection for 
    robust multimodal optimization.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, cluster_k=5, gamma_init=1.0, gamma_decay=0.95, cr=0.9, tournament_size=5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.cluster_k = cluster_k
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.tournament_size = tournament_size

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._tournament_selection(population, fitness)
            population = self._maintain_diversity(population, fitness) #Clustering for diversity
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _tournament_selection(self, population, fitness_values):
        num_selected = self.population_size
        selected_indices = []
        for _ in range(num_selected):
            tournament = np.random.choice(len(population), self.tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_indices.append(winner_index)
        return population[selected_indices]
    
    def _maintain_diversity(self, population, fitness_values):
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=self.cluster_k, random_state=0)
        kmeans.fit(population)
        labels = kmeans.labels_

        #Ensure at least one member from each cluster
        cluster_members = [[] for _ in range(self.cluster_k)]
        for i, label in enumerate(labels):
            cluster_members[label].append((population[i], fitness_values[i]))

        new_population = []
        for cluster in cluster_members:
            if cluster: #handle empty cluster
                best_individual = min(cluster, key=lambda x: x[1])[0]
                new_population.append(best_individual)
        #Fill remaining spots randomly
        while len(new_population) < self.population_size:
            new_population.append(np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim))

        return np.array(new_population)

```

### Rank 5 (Overall AOCC Score: 4.9260e-02 |             AOCC Score on Unimodal instances: 1.4778e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithCauchyAndClustering
# Description: Combines DE, adaptive Cauchy mutation, and clustering for robust multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDEwithCauchyAndClustering
# Description: Combines DE, adaptive Cauchy mutation, and clustering for robust multimodal optimization.
# Code:
class AdaptiveDEwithCauchyAndClustering:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation and clustering 
    to handle multimodal landscapes effectively.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, cluster_threshold=0.5, gamma_init=1.0, gamma_decay=0.95, cr=0.9):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.cluster_threshold = cluster_threshold
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population, fitness = self._clustering(population, fitness) # Apply clustering
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _clustering(self, population, fitness_values):
        # Simple distance-based clustering (can be replaced with more sophisticated methods)
        
        #This is a placeholder; a real clustering algorithm should be implemented here.  This example just removes some solutions.
        
        if len(population) > self.population_size //2:
            indices_to_keep = np.argsort(fitness_values)[:self.population_size //2]
            return population[indices_to_keep], fitness_values[indices_to_keep]
        else:
            return population, fitness_values
```

### Rank 6 (Overall AOCC Score: 4.9149e-02 |             AOCC Score on Unimodal instances: 1.4745e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Adaptive Differential Evolution with Cauchy mutation, archive, and tournament selection for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy
import random

# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Adaptive Differential Evolution with Cauchy mutation, archive, and tournament selection for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.archive = [] # Archive of good solutions
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._archive_tournament_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_step = np.random.standard_cauchy(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _archive_tournament_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        #Tournament Selection with Archive
        tournament_size = 5
        next_gen = []
        next_fit = []
        for i in range(self.population_size):
            tournament_indices = np.random.choice(len(combined_population), tournament_size, replace=False)
            winner_index = tournament_indices[np.argmin(combined_fitness[tournament_indices])]
            winner = combined_population[winner_index]
            winner_fit = combined_fitness[winner_index]

            # Check Archive for Niching
            is_unique = True
            for sol in self.archive:
                if np.linalg.norm(winner - sol) < self.niche_radius:
                    is_unique = False
                    break

            if is_unique :
                next_gen.append(winner)
                next_fit.append(winner_fit)
                self.archive.append(winner) # Add to archive

        return np.array(next_gen), np.array(next_fit)



    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self):
        self.gamma *= 0.99 # Adapt Cauchy scale
        self.niche_radius *= 0.99 #Gradually reduce niche radius for finer local search

```

### Rank 7 (Overall AOCC Score: 4.9032e-02 |             AOCC Score on Unimodal instances: 1.4710e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: Differential evolution with adaptive scaling and Cauchy mutation for escaping local optima in high-dimensional multimodal landscapes.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDifferentialEvolutionWithCauchyMutation
# Description: Differential evolution with adaptive scaling and Cauchy mutation for escaping local optima in high-dimensional multimodal landscapes.
# Code:
class AdaptiveDifferentialEvolutionWithCauchyMutation:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.scale_factor = 1.0 # Initial scaling factor for mutation
        self.scale_decay = 0.98 # Decay rate for scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]
        self.eval_count += 1

        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = np.copy(population)
            for i in range(self.population_size):
                #Differential Evolution Mutation
                a, b, c = self._select_different(population, i)
                mutant = a + self.F * (b - c)
                
                #Cauchy Mutation for Exploration
                cauchy_mutation = cauchy.rvs(loc=0, scale=self.scale_factor, size=self.dim)
                mutant += cauchy_mutation

                #Crossover
                j_rand = np.random.randint(self.dim)
                for j in range(self.dim):
                    if np.random.rand() < self.CR or j == j_rand:
                        offspring[i, j] = mutant[j]

                #Bound handling
                offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            # Selection
            population = np.where(offspring_fitness < fitness_values[:,None], offspring, population)
            fitness_values = np.where(offspring_fitness < fitness_values, offspring_fitness, fitness_values)


            # Update best solution
            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_fitness_overall = fitness_values[best_index]
                self.best_solution_overall = population[best_index]

            self.scale_factor *= self.scale_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _select_different(self, population, i):
        a, b, c = np.random.choice(range(self.population_size), size=3, replace=False)
        while a == i:
            a = np.random.randint(self.population_size)
        while b == i or b == a:
            b = np.random.randint(self.population_size)
        while c == i or c == a or c == b:
            c = np.random.randint(self.population_size)
        return population[a], population[b], population[c]

```

### Rank 8 (Overall AOCC Score: 4.9000e-02 |             AOCC Score on Unimodal instances: 1.4700e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEWithClusteringAndArchive
# Description: Combines Differential Evolution, clustering, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random

# Name: AdaptiveDEWithClusteringAndArchive
# Description: Combines Differential Evolution, clustering, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDEWithClusteringAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential weight
        self.CR = 0.9  # Crossover rate
        self.archive = []  # To store good solutions
        self.cluster_threshold = 0.5  # Parameter to adjust cluster size
        self.archive_size = 100 #Maximum archive size


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += self.population_size

            #Combine population and offspring
            combined_pop = np.vstack((population, offspring))
            combined_fit = np.concatenate((fitness_values, offspring_fitness))

            #Update Archive
            self._update_archive(combined_pop, combined_fit)

            #Clustering
            clusters = self._cluster_population(combined_pop, combined_fit)

            #Select next generation using archive and clustering information.
            population, fitness_values = self._select_next_generation(clusters)

            # Update best solution
            self._update_best(combined_pop, combined_fit)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, self.population_size)
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)
            trial = self._crossover(population[i], mutant)
            if objective_function(trial.reshape(1,-1))[0] < fitness_values[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring

    def _select_different(self, i, size):
        candidates = list(range(size))
        candidates.remove(i)
        a,b,c = random.sample(candidates, 3)
        return a,b,c

    def _crossover(self, x, v):
        u = np.copy(x)
        jrand = random.randint(0, self.dim - 1)
        for j in range(self.dim):
            if random.random() < self.CR or j == jrand:
                u[j] = v[j]
        return u

    def _cluster_population(self, population, fitness_values):
        #Simple clustering based on Euclidean distance.  Could be replaced with more sophisticated methods.
        clusters = []
        for i in range(len(population)):
            assigned = False
            for j, cluster in enumerate(clusters):
                centroid = np.mean(cluster[0], axis=0)
                distance = np.linalg.norm(population[i] - centroid)
                if distance < self.cluster_threshold:
                    clusters[j][0] = np.vstack((clusters[j][0], population[i]))
                    clusters[j][1] = np.concatenate((clusters[j][1], [fitness_values[i]]))
                    assigned = True
                    break
            if not assigned:
                clusters.append([np.array([population[i]]), np.array([fitness_values[i]])])
        return clusters

    def _update_archive(self, population, fitness_values):
        sorted_indices = np.argsort(fitness_values)
        top_solutions = population[sorted_indices[:self.archive_size]]
        top_fitness = fitness_values[sorted_indices[:self.archive_size]]
        self.archive = list(zip(top_solutions, top_fitness))

    def _select_next_generation(self, clusters):
        next_gen = []
        next_fit = []
        #Prioritize solutions from diverse clusters
        for cluster in clusters:
            num_to_select = int(len(cluster[0]) * 0.8)  #Select 80% from each cluster

            if len(cluster[0]) > 0:
                sorted_indices = np.argsort(cluster[1])
                selected_solutions = cluster[0][sorted_indices[:num_to_select]]
                selected_fitness = cluster[1][sorted_indices[:num_to_select]]
                next_gen.extend(selected_solutions)
                next_fit.extend(selected_fitness)

        #add from archive to maintain diversity
        archive_solutions, archive_fitness = zip(*self.archive)
        next_gen.extend(archive_solutions)
        next_fit.extend(archive_fitness)

        #Truncate the population to the desired size
        next_gen = np.array(next_gen)
        next_fit = np.array(next_fit)
        if len(next_gen) > self.population_size:
            sorted_indices = np.argsort(next_fit)
            next_gen = next_gen[sorted_indices[:self.population_size]]
            next_fit = next_fit[sorted_indices[:self.population_size]]


        return next_gen, next_fit


    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]
```

### Rank 9 (Overall AOCC Score: 4.8986e-02 |             AOCC Score on Unimodal instances: 1.4696e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDECauchyArchiveClustering
# Description: Combines DE with adaptive Cauchy mutation, an archive, and clustering for multimodal optimization.
# Code:
```python
import numpy as np
from scipy.stats import cauchy

# Name: AdaptiveDECauchyArchiveClustering
# Description: Combines DE with adaptive Cauchy mutation, an archive, and clustering for multimodal optimization.
# Code:
class AdaptiveDECauchyArchiveClustering:
    """
    Combines Differential Evolution (DE) with adaptive Cauchy mutation, an archive, and clustering to handle multimodal landscapes.  
    The algorithm uses clustering to identify and exploit multiple optima.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size=100, archive_size=50, gamma_init=1.0, gamma_decay=0.95, cr=0.9, cluster_threshold=0.5):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.archive_size = archive_size
        self.archive = []
        self.gamma = gamma_init
        self.gamma_decay = gamma_decay
        self.cr = cr  # Crossover rate for DE
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.cluster_threshold = cluster_threshold # Threshold for clustering

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            new_population = []
            for i in range(self.population_size):
                a, b, c = self._select_different(i, population)
                mutant = self._cauchy_mutation(a, b, c)
                trial = self._crossover(population[i], mutant)
                trial_fitness = objective_function(trial.reshape(1, -1))[0]
                self.eval_count += 1

                if trial_fitness < fitness[i]:
                    new_population.append(trial)
                    fitness[i] = trial_fitness
                    self._update_archive(trial, trial_fitness)
                else:
                    new_population.append(population[i])

            population = np.array(new_population)
            population = self._cluster_selection(population, fitness) #Clustering-based selection
            fitness = self._evaluate_population(objective_function, population)
            self.gamma *= self.gamma_decay
            best_solution, best_fitness = self._find_best(population, fitness)
            if best_fitness < self.best_fitness_overall:
                self.best_solution_overall = best_solution
                self.best_fitness_overall = best_fitness

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += self.population_size
        return fitness

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _cluster_selection(self, population, fitness_values):
        # Simple clustering based on Euclidean distance
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=min(len(population), 5), random_state=0).fit(population) #Adjust number of clusters as needed

        cluster_centers = kmeans.cluster_centers_
        cluster_fitnesses = []
        for center in cluster_centers:
            distances = np.linalg.norm(population - center, axis=1)
            indices_close = np.where(distances < self.cluster_threshold)[0]
            if len(indices_close)>0:
                best_index_in_cluster = indices_close[np.argmin(fitness_values[indices_close])]
                cluster_fitnesses.append((best_index_in_cluster, fitness_values[best_index_in_cluster]))
            else:
                # Handle empty cluster by selecting a random individual.
                cluster_fitnesses.append((np.random.randint(len(population)),fitness_values[np.random.randint(len(population))]))



        selected_indices = [index for index, _ in sorted(cluster_fitnesses, key=lambda item: item[1])]
        
        return population[selected_indices]
```

### Rank 10 (Overall AOCC Score: 4.8875e-02 |             AOCC Score on Unimodal instances: 1.4662e-01 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveDEWithClusteringAndArchive
# Description: Combines DE, adaptive Cauchy mutation, clustering, and an archive for robust multimodal optimization.
# Code:
```python
import numpy as np
import random
from scipy.stats import cauchy

# Name: AdaptiveDEWithClusteringAndArchive
# Description: Combines DE, adaptive Cauchy mutation, clustering, and an archive for robust multimodal optimization.
# Code:
class AdaptiveDEWithClusteringAndArchive:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = 100
        self.archive_size = 50
        self.archive = []
        self.gamma = 1.0
        self.gamma_decay = 0.95
        self.cr = 0.9  # Crossover rate for DE
        self.cluster_threshold = 0.5
        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        population = self._initialize_population()
        fitness = self._evaluate_population(objective_function, population)
        self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        while self.eval_count < self.budget:
            offspring = self._differential_evolution(population, fitness)
            offspring_fitness = self._evaluate_population(objective_function, offspring)

            combined_population = np.vstack((population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))

            clusters = self._cluster_population(combined_population, combined_fitness)
            population, fitness = self._adaptive_mutation(clusters)

            self._update_archive(population, fitness)
            self.gamma *= self.gamma_decay
            self.best_solution_overall, self.best_fitness_overall = self._find_best(population, fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        return np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))

    def _evaluate_population(self, objective_function, population):
        fitness = objective_function(population)
        self.eval_count += len(population)
        return fitness

    def _differential_evolution(self, population, fitness_values):
        offspring = np.zeros_like(population)
        for i in range(self.population_size):
            a, b, c = self._select_different(i, population)
            mutant = self._cauchy_mutation(a, b, c)
            trial = self._crossover(population[i], mutant)
            if objective_function(trial.reshape(1,-1))[0] < fitness_values[i]:
                offspring[i] = trial
            else:
                offspring[i] = population[i]
        return offspring

    def _select_different(self, index, population):
        a, b, c = np.random.choice(len(population), 3, replace=False)
        while a == index or b == index or c == index:
            a, b, c = np.random.choice(len(population), 3, replace=False)
        return population[a], population[b], population[c]

    def _cauchy_mutation(self, a, b, c):
        return a + self.gamma * (b - c) + cauchy.rvs(loc=0, scale=self.gamma, size=self.dim)

    def _crossover(self, x, v):
        return np.where(np.random.rand(self.dim) < self.cr, v, x)

    def _find_best(self, population, fitness_values):
        best_index = np.argmin(fitness_values)
        return population[best_index], fitness_values[best_index]

    def _update_archive(self, population, fitness):
        for sol, fit in zip(population, fitness):
          self._update_archive_single(sol, fit)

    def _update_archive_single(self, solution, fitness):
        if len(self.archive) < self.archive_size:
            self.archive.append((solution, fitness))
        else:
            worst_index = np.argmax([f for _, f in self.archive])
            if fitness < self.archive[worst_index][1]:
                self.archive[worst_index] = (solution, fitness)

    def _cluster_population(self, population, fitness_values):
        clusters = []
        for i in range(len(population)):
            assigned = False
            for j, cluster in enumerate(clusters):
                centroid = np.mean(cluster[0], axis=0)
                distance = np.linalg.norm(population[i] - centroid)
                if distance < self.cluster_threshold:
                    clusters[j][0] = np.vstack((clusters[j][0], population[i]))
                    clusters[j][1] = np.concatenate((clusters[j][1], [fitness_values[i]]))
                    assigned = True
                    break
            if not assigned:
                clusters.append([np.array([population[i]]), np.array([fitness_values[i]])])
        return clusters

    def _adaptive_mutation(self, clusters):
        new_population = []
        new_fitness = []
        for cluster in clusters:
            if len(cluster[0]) > 1:
                diversity = np.var(cluster[0], axis=0).mean()
                mutation_scale = 0.1 + 0.5 * diversity
                mutated_cluster = cluster[0] + np.random.normal(0, mutation_scale, size=cluster[0].shape)
                mutated_cluster = np.clip(mutated_cluster, self.lower_bounds, self.upper_bounds)
                new_population.extend(list(mutated_cluster))
                new_fitness.extend(list(self._evaluate_population(objective_function, mutated_cluster)))
            else:
                new_population.extend(list(cluster[0]))
                new_fitness.extend(list(cluster[1]))

        return np.array(new_population)[:self.population_size], np.array(new_fitness)[:self.population_size]
```

### Rank 11 (Overall AOCC Score: 0.0000e+00 |             AOCC Score on Unimodal instances: 0.0000e+00 |             AOCC Score on Multimodal instances with a single component: 0.0000e+00 |             AOCC Score on Multimodal instances with multiple components: 0.0000e+00)
# Name: AdaptiveGaussianSamplingEA
# Description: 
# Code:
```python
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float], population_size: int = 586.2849455876094, sigma_decay: float = 0.9707429035887052, acceptance_threshold: float = 6.955285920334002e-08):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)
        self.population_size = population_size
        self.sigma_decay = sigma_decay
        self.acceptance_threshold = acceptance_threshold

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width


    def optimize(self, objective_function: callable) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values, tournament_size: int = 5):
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))

        sorted_indices = np.argsort(combined_fit)

        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit


    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]
```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 22:54:16 INFO Full response text: **Analysis:**

Comparing (best) AdaptiveDifferentialEvolutionWithCauchyMutation vs (worst) AdaptiveGaussianSamplingEA, we see that the best utilizes Differential Evolution (DE) which is a powerful optimization technique known for its efficiency in exploring the search space. DE's use of vector differences helps in finding promising directions more effectively than random Gaussian sampling used by the worst. The best also incorporates adaptive mutation strength and Cauchy mutation which provides robustness in escaping local optima, a crucial aspect in multimodal problems, which AdaptiveGaussianSamplingEA lacks.

(second best) AdaptiveDifferentialEvolutionWithCauchyMutation vs (second worst) AdaptiveDEwithCauchyAndClustering shows the importance of fine-tuned parameters and adaptive mechanisms. The second-best algorithm includes a decay rate for the Cauchy mutation scale, allowing it to balance exploration and exploitation as the optimization progresses. The second worst's clustering is simplistic, lacking the adaptive adjustments of the second best's Cauchy mutation.

Comparing (1st) AdaptiveDifferentialEvolutionWithCauchyMutation vs (2nd) AdaptiveDifferentialEvolutionWithCauchyMutation (different implementations), we see that even small differences in implementation can affect performance. The first version seems more sophisticated in update mechanism and has a more systematic approach for managing the Cauchy scale decay.

(3rd) AdaptiveDifferentialEvolutionWithClustering vs (4th) AdaptiveDEwithCauchyClusteringTournament highlights the benefit of sophisticated selection mechanisms. The 4th ranks algorithm incorporates a tournament selection which introduces more competition and diversity into the search.  While clustering is present in both, the tournament selection in the 4th seems to provide a more robust exploration and avoids premature convergence.


Comparing (second worst) AdaptiveDEwithCauchyAndClustering vs (worst) AdaptiveGaussianSamplingEA, we see that even a simple DE algorithm with adaptive Cauchy mutation significantly outperforms a simple Gaussian sampling EA.  The DE structure promotes efficient exploration and exploitation, while the Cauchy mutation facilitates escaping local optima, something the Gaussian Sampling EA doesn't effectively handle.  Adaptive parameter adjustments also play a role.

Overall: The best-performing algorithms consistently use Differential Evolution with adaptive mutation strategies (Cauchy mutation being especially effective) and incorporate mechanisms to maintain diversity (clustering, archives, and tournament selection).  Adaptive parameter adjustments and careful selection mechanisms are vital.


**Experience:**

The analysis reveals that combining Differential Evolution with adaptive mutation (Cauchy in particular) and diversity maintenance strategies (clustering, archives, tournament selection) yields superior performance. Adaptive parameter control, particularly for mutation strength, is crucial for balancing exploration and exploitation.  Sophisticated selection mechanisms enhance performance further.

2025-06-23 22:54:18 INFO Full response text: * **Keywords:**  Differential Evolution (DE), Adaptive Cauchy Mutation, Diversity Maintenance (Clustering, Archives, Tournament Selection), Adaptive Parameter Control.

* **Advice:** Focus on novel combinations of existing techniques. Investigate the interaction effects between adaptive mutation, selection, and diversity preservation methods. Explore less-studied aspects of existing methods (e.g., the specific parameters within Cauchy mutation,  novel clustering approaches). Develop rigorous experimental designs to quantify the individual contribution of each component.


* **Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, or multimodal problems.  Repeating established knowledge about DE, Cauchy mutation, or archives. Overly broad claims about parameter tuning.


* **Explanation:** The ineffective reflections are redundant and lack specific, actionable insights. The redefined reflection focuses on identifying unexplored areas within the successful combination of DE, adaptive Cauchy mutation, and diversity maintenance.  The advice pushes for deeper investigation of component interactions and less-explored aspects of these components, thereby generating truly novel heuristics, justifying the investment.

2025-06-23 22:54:18 INFO Generating offspring via Crossover...
2025-06-23 23:07:38 INFO Crossover Prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

### Better code
AdaptiveDEwithCauchyArchiveTournament
import numpy as np
from scipy.stats import cauchy
import random

# Name: AdaptiveDEwithCauchyArchiveTournament
# Description: Adaptive Differential Evolution with Cauchy mutation, archive, and tournament selection for multimodal optimization.
# Code:
class AdaptiveDEwithCauchyArchiveTournament:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.F = 0.8  # Differential evolution scaling factor
        self.CR = 0.9  # Differential evolution crossover rate
        self.gamma = 1.0 #Cauchy mutation scale, adaptive
        self.archive = [] # Archive of good solutions
        self.niche_radius = 0.1 * np.linalg.norm(self.upper_bounds - self.lower_bounds) # Adaptive niching radius


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = float('inf')
        
        population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(population)
        self.eval_count += self.population_size
        
        self._update_best(population, fitness_values)

        while self.eval_count < self.budget:
            offspring = self._generate_offspring(population, fitness_values)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            population, fitness_values = self._archive_tournament_selection(population, fitness_values, offspring, offspring_fitness)
            self._update_best(offspring, offspring_fitness)
            self._adapt_parameters()


        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _generate_offspring(self, population, fitness_values):
        offspring = []
        for i in range(self.population_size):
            # Differential Evolution
            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)
            
            mutant = population[a] + self.F * (population[b] - population[c])
            mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)

            #Cauchy Mutation
            cauchy_step = np.random.standard_cauchy(self.dim)
            mutant = mutant + self.gamma * cauchy_step

            #Crossover
            crossover_mask = np.random.rand(self.dim) < self.CR
            trial_vector = np.where(crossover_mask, mutant, population[i])
            trial_vector = np.clip(trial_vector, self.lower_bounds, self.upper_bounds)

            offspring.append(trial_vector)
            
        return np.array(offspring)


    def _archive_tournament_selection(self, population, fitness_values, offspring, offspring_fitness):
        combined_population = np.vstack((population, offspring))
        combined_fitness = np.concatenate((fitness_values, offspring_fitness))

        #Tournament Selection with Archive
        tournament_size = 5
        next_gen = []
        next_fit = []
        for i in range(self.population_size):
            tournament_indices = np.random.choice(len(combined_population), tournament_size, replace=False)
            winner_index = tournament_indices[np.argmin(combined_fitness[tournament_indices])]
            winner = combined_population[winner_index]
            winner_fit = combined_fitness[winner_index]

            # Check Archive for Niching
            is_unique = True
            for sol in self.archive:
                if np.linalg.norm(winner - sol) < self.niche_radius:
                    is_unique = False
                    break

            if is_unique :
                next_gen.append(winner)
                next_fit.append(winner_fit)
                self.archive.append(winner) # Add to archive

        return np.array(next_gen), np.array(next_fit)



    def _update_best(self, population, fitness_values):
        for i, fitness in enumerate(fitness_values):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = population[i]

    def _adapt_parameters(self):
        self.gamma *= 0.99 # Adapt Cauchy scale
        self.niche_radius *= 0.99 #Gradually reduce niche radius for finer local search


### Worse code
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

### Analyze & experience
- Comparing (best) AdaptiveDifferentialEvolutionWithCauchyMutation vs (worst) AdaptiveGaussianSamplingEA, we see that the best utilizes Differential Evolution (DE) which is a powerful optimization technique known for its efficiency in exploring the search space. DE's use of vector differences helps in finding promising directions more effectively than random Gaussian sampling used by the worst. The best also incorporates adaptive mutation strength and Cauchy mutation which provides robustness in escaping local optima, a crucial aspect in multimodal problems, which AdaptiveGaussianSamplingEA lacks.

(second best) AdaptiveDifferentialEvolutionWithCauchyMutation vs (second worst) AdaptiveDEwithCauchyAndClustering shows the importance of fine-tuned parameters and adaptive mechanisms. The second-best algorithm includes a decay rate for the Cauchy mutation scale, allowing it to balance exploration and exploitation as the optimization progresses. The second worst's clustering is simplistic, lacking the adaptive adjustments of the second best's Cauchy mutation.

Comparing (1st) AdaptiveDifferentialEvolutionWithCauchyMutation vs (2nd) AdaptiveDifferentialEvolutionWithCauchyMutation (different implementations), we see that even small differences in implementation can affect performance. The first version seems more sophisticated in update mechanism and has a more systematic approach for managing the Cauchy scale decay.

(3rd) AdaptiveDifferentialEvolutionWithClustering vs (4th) AdaptiveDEwithCauchyClusteringTournament highlights the benefit of sophisticated selection mechanisms. The 4th ranks algorithm incorporates a tournament selection which introduces more competition and diversity into the search.  While clustering is present in both, the tournament selection in the 4th seems to provide a more robust exploration and avoids premature convergence.


Comparing (second worst) AdaptiveDEwithCauchyAndClustering vs (worst) AdaptiveGaussianSamplingEA, we see that even a simple DE algorithm with adaptive Cauchy mutation significantly outperforms a simple Gaussian sampling EA.  The DE structure promotes efficient exploration and exploitation, while the Cauchy mutation facilitates escaping local optima, something the Gaussian Sampling EA doesn't effectively handle.  Adaptive parameter adjustments also play a role.

Overall: The best-performing algorithms consistently use Differential Evolution with adaptive mutation strategies (Cauchy mutation being especially effective) and incorporate mechanisms to maintain diversity (clustering, archives, and tournament selection).  Adaptive parameter adjustments and careful selection mechanisms are vital.
- * **Keywords:**  Differential Evolution (DE), Adaptive Cauchy Mutation, Diversity Maintenance (Clustering, Archives, Tournament Selection), Adaptive Parameter Control.

* **Advice:** Focus on novel combinations of existing techniques. Investigate the interaction effects between adaptive mutation, selection, and diversity preservation methods. Explore less-studied aspects of existing methods (e.g., the specific parameters within Cauchy mutation,  novel clustering approaches). Develop rigorous experimental designs to quantify the individual contribution of each component.


* **Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, or multimodal problems.  Repeating established knowledge about DE, Cauchy mutation, or archives. Overly broad claims about parameter tuning.


* **Explanation:** The ineffective reflections are redundant and lack specific, actionable insights. The redefined reflection focuses on identifying unexplored areas within the successful combination of DE, adaptive Cauchy mutation, and diversity maintenance.  The advice pushes for deeper investigation of component interactions and less-explored aspects of these components, thereby generating truly novel heuristics, justifying the investment.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-23 23:07:38 INFO Mutation prompt: Your objective is to design a novel and sophisticated population function in Python, solving 24 GNBG benchmark functions, particularly:

Unimodal Group (f1-f6): Problems with a single optimum, but often with ill-conditioned (narrow, rotated) landscapes that test an algorithm's exploitation and convergence efficiency.

Multimodal Single-Component Group (f7-f15): Problems with a single main basin of attraction that is filled with numerous, often deep and rugged, local optima. This tests an algorithm's ability to escape local traps.

Multimodal Multi-Component Group (f16-f24): The most difficult problems, featuring multiple, separate, and often deceptive basins of attraction. This rigorously tests an algorithm's global exploration capability.

This function is for an Evolutionary Algorithm that will solve the GNBG benchmark. The key challenge is creating a good population for a high-dimensional search space (30D) with wide bounds (typically [-100, 100]).

    

Current heuristics:
AdaptiveGaussianSamplingEA
import numpy as np
class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Gaussian width
        self.sigma_decay = 0.99 #Decay rate of sigma


    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        while self.eval_count < self.budget:
            # Selection (tournament selection)
            parents = self._tournament_selection(population, fitness_values)

            # Recombination (Gaussian perturbation)
            offspring = self._gaussian_recombination(parents)

            # Mutation (adjust sigma adaptively)
            offspring = self._adaptive_mutation(offspring)

            #Evaluation
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)
            
            #Selection for next generation
            population, fitness_values = self._select_next_generation(population, fitness_values, offspring, offspring_fitness)

            # Update best solution
            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info


    def _initialize_population(self):
        #Adaptive Gaussian Sampling
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        population = np.clip(population, self.lower_bounds, self.upper_bounds)
        return population

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size //2 #Binary Recombination

        selected_parents = []
        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])
        return np.array(selected_parents)


    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i+1]
            child1 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = (parent1 + parent2) / 2 + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)


    def _adaptive_mutation(self, offspring):
        #Simple Mutation, sigma is already updated
        offspring += np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(offspring, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        
        sorted_indices = np.argsort(combined_fit)
        
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit
    

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- * **Keywords:**  Differential Evolution (DE), Adaptive Cauchy Mutation, Diversity Maintenance (Clustering, Archives, Tournament Selection), Adaptive Parameter Control.

* **Advice:** Focus on novel combinations of existing techniques. Investigate the interaction effects between adaptive mutation, selection, and diversity preservation methods. Explore less-studied aspects of existing methods (e.g., the specific parameters within Cauchy mutation,  novel clustering approaches). Develop rigorous experimental designs to quantify the individual contribution of each component.


* **Avoid:**  Generic statements about exploration/exploitation, high-dimensionality, or multimodal problems.  Repeating established knowledge about DE, Cauchy mutation, or archives. Overly broad claims about parameter tuning.


* **Explanation:** The ineffective reflections are redundant and lack specific, actionable insights. The redefined reflection focuses on identifying unexplored areas within the successful combination of DE, adaptive Cauchy mutation, and diversity maintenance.  The advice pushes for deeper investigation of component interactions and less-explored aspects of these components, thereby generating truly novel heuristics, justifying the investment.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
2025-06-23 23:10:15 INFO Perform Harmony Search...
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f6 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -186.864053
  Lambda (Curvature): [0.05]
  Mu (Asymmetry/Depth): [0 0]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 6 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -186.86405320391498
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f13 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -216.727696
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [1 1]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 13 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -216.7276963542314
2025-06-23 23:10:26 INFO --- GNBG Problem Parameters for f18 ---
  Dimension: 30, MaxEvals: 1000000
  Search Bounds: [-100, 100]
  Number of Components: 5
  Known Optimum Value: -5000.000000
  Lambda (Curvature): [1 1 1 1 1]
  Mu (Asymmetry/Depth): [0.22159228 0.42314776 0.4901829  0.25862884 0.37043014 0.37440768
 0.26098797 0.491006   0.27569772 0.45404864]
----------------------------------------
2025-06-23 23:10:26 ERROR Can not run the algorithm
2025-06-23 23:10:26 INFO Run function 18 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-23 23:10:26 INFO FeHistory: []
2025-06-23 23:10:26 INFO Expected Optimum FE: -5000
2025-06-23 23:10:26 INFO Unimodal AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Multimodal (multiple components) AOCC mean: 0.0000
2025-06-23 23:10:26 INFO AOCC mean: 0.0000
2025-06-23 23:10:26 INFO Generation 8, best so far: 0.24747886597801494
