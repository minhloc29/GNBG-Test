2025-06-24 11:21:42 INFO Initializing first population
2025-06-24 11:21:42 INFO Initializing population from 4 seed files...
2025-06-24 11:29:39 INFO Started evolutionary loop, best so far: 0.0
2025-06-24 11:29:39 INFO Population length is: 10
2025-06-24 11:29:39 INFO --- Performing Long-Term Reflection at Generation 1 ---
2025-06-24 11:29:39 INFO Reflection Prompt: ### Problem Description
**(CR: Capacity and Role)**
Act as an expert in designing algorithms for deceptive, multi-component landscapes. Your specialty is creating strategies that use multi-population or island models to perform aggressive global exploration.

**(I: Insight)**
Your objective is to design a novel optimization algorithm for the GNBG benchmark. The most difficult functions (f16-f24) have multiple, separate basins of attraction where the global optimum can be hidden. An algorithm must be able to discover and explore these competing regions to succeed.

**(S: Statement & P: Personality)**
Provide a complete, novel Python class that implements a multi-population or island-based search strategy to solve this challenge. The class must have an `__init__(...)` and `optimize(...)` method as specified in the main task description.

### List heuristics
Below is a list of design heuristics ranked from best to worst based on their AOCC score on group function 3 of GNBG benchmark, where higher is better. To enable a detailed analysis of their specializations, the performance breakdown on each of the three GNBG function groups is also provided.
### Rank 1 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: AdaptivePopulationDE
# Description: Seed from AdaptivePopulationDE
# Code:
```python
import numpy as np
import random
# f18 aocc 0.8
# f20 aocc 0.5
# not so good again, get stuck in local optima
class AdaptivePopulationDE: 
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.min_population_size = 5 * self.dim
        self.max_population_size = 20 * self.dim
        self.population_adaptation_rate = 0.1

        self.F = 0.5  # Mutation factor
        self.Cr = 0.7 # Crossover rate

        self.stagnation_counter = 0
        self.stagnation_threshold = 5000

        self.archive = []
        self.archive_size = 100

        self.population = None
        self.fitness = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.stagnation_counter = 0

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(self.fitness)
        self.best_solution_overall = self.population[best_index]
        self.best_fitness_overall = self.fitness[best_index]

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0
            else:
                self.stagnation_counter += len(offspring)

            self.adjust_population_size(objective_function)

            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            indices = list(range(self.population_size))
            indices.remove(i)
            if len(indices) < 2:
                continue  # Skip if not enough individuals

            a, b = random.sample(indices, 2)

            if self.archive and random.random() < 0.5:
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0]
            else:
                pbest = self.population[np.argmin(self.fitness)]

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            for j in range(self.dim):
                if random.random() > self.Cr:
                    mutant[j] = self.population[i][j]

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adjust_population_size(self, objective_function):
        if random.random() < self.population_adaptation_rate:
            if self.stagnation_counter > self.stagnation_threshold / 2:
                new_size = min(int(self.population_size * 1.1), self.max_population_size)
            else:
                new_size = max(int(self.population_size * 0.9), self.min_population_size)

            new_size = int(new_size)
            if new_size > self.population_size:
                additional = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(new_size - self.population_size, self.dim))
                additional_fitness = objective_function(additional)
                self.population = np.vstack((self.population, additional))
                self.fitness = np.concatenate((self.fitness, additional_fitness))
                self.eval_count += len(additional)
            elif new_size < self.population_size:
                best_indices = np.argsort(self.fitness)[:new_size]
                self.population = self.population[best_indices]
                self.fitness = self.fitness[best_indices]

            self.population_size = new_size

    def restart_population(self, objective_function):
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = self.fitness[best_index]
```

### Rank 2 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: AdaptiveGaussianSamplingEA
# Description: Seed from AdaptiveGaussianSamplingEA
# Code:
```python
import numpy as np

class AdaptiveGaussianSamplingEA:
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100  # Adjust as needed
        self.population = None
        self.sigma = 0.2 * (self.upper_bounds - self.lower_bounds)  # Initial Standard Deviation for Gaussian Sampling

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness_values = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness_values)]
        self.best_fitness_overall = np.min(fitness_values)

        while self.eval_count < self.budget:
            # Adaptive Gaussian Sampling
            parents = self.tournament_selection(fitness_values, k=5)  # Tournament Selection
            offspring = self.gaussian_mutation(parents, self.sigma)

            # Bounds handling
            offspring = np.clip(offspring, self.lower_bounds, self.upper_bounds)

            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update population and best solution
            self.population = np.concatenate((self.population, offspring))
            fitness_values = np.concatenate((fitness_values, offspring_fitness))

            best_index = np.argmin(fitness_values)
            if fitness_values[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = fitness_values[best_index]

            # Adaptive Sigma
            self.sigma *= 0.99  # Gradually reduce sigma for finer search later.

            # Elitism
            sorted_pop = self.population[np.argsort(fitness_values)]
            self.population = sorted_pop[:self.population_size]
            fitness_values = fitness_values[np.argsort(fitness_values)][:self.population_size]

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def tournament_selection(self, fitnesses, k):
        num_parents = len(fitnesses) // 2  # Select half the population as parents
        parents = np.zeros((num_parents, self.dim))
        for i in range(num_parents):
            tournament = np.random.choice(len(fitnesses), size=k, replace=False)
            winner_index = tournament[np.argmin(fitnesses[tournament])]
            parents[i] = self.population[winner_index]
        return parents

    def gaussian_mutation(self, parents, sigma):
        offspring = parents + np.random.normal(0, sigma, parents.shape)
        return offspring

```

### Rank 3 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: AdaptiveGaussianArchiveEA
# Description: Seed from AdaptiveGaussianArchiveEA
# Code:
```python
import numpy as np
class AdaptiveGaussianArchiveEA:
    """
    Combines adaptive Gaussian sampling with an archive to enhance exploration and exploitation in multimodal landscapes.  Employs a simple Gaussian mutation strategy and tournament selection for efficiency.
    """
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')
        self.population_size = 100
        self.archive_size = 200  #Increased archive size for better diversity
        self.sigma = 0.5 * (self.upper_bounds - self.lower_bounds) #Increased initial sigma
        self.sigma_decay = 0.98 # Slightly faster decay
        self.archive = []

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        if self.dim > 0:
            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        else:
            self.best_solution_overall = np.array([])
        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1, -1))[0]
        self.eval_count += 1

        population = self._initialize_population()
        fitness_values = objective_function(population)
        self.eval_count += self.population_size

        self.archive = self._update_archive(population, fitness_values)

        while self.eval_count < self.budget:
            parents = self._tournament_selection(population, fitness_values)
            offspring = self._gaussian_recombination(parents)
            offspring = self._adaptive_mutation(offspring)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            population, fitness_values = self._select_next_generation(
                population, fitness_values, offspring, offspring_fitness
            )

            self.archive = self._update_archive(
                np.vstack((population, offspring)),
                np.concatenate((fitness_values, offspring_fitness))
            )

            self._update_best(offspring, offspring_fitness)
            self.sigma *= self.sigma_decay

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall
        }

        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def _initialize_population(self):
        center = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)
        population = np.random.normal(center, self.sigma, size=(self.population_size, self.dim))
        return np.clip(population, self.lower_bounds, self.upper_bounds)

    def _tournament_selection(self, population, fitness_values):
        tournament_size = 5
        num_parents = self.population_size // 2
        selected_parents = []

        for _ in range(num_parents):
            tournament = np.random.choice(len(population), tournament_size, replace=False)
            winner_index = tournament[np.argmin(fitness_values[tournament])]
            selected_parents.append(population[winner_index])

        return np.array(selected_parents)

    def _gaussian_recombination(self, parents):
        offspring = []
        for i in range(0, len(parents), 2):
            parent1 = parents[i]
            parent2 = parents[i + 1]
            midpoint = (parent1 + parent2) / 2
            child1 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            child2 = midpoint + np.random.normal(0, self.sigma / 2, self.dim)
            offspring.extend([child1, child2])
        return np.clip(np.array(offspring), self.lower_bounds, self.upper_bounds)

    def _adaptive_mutation(self, offspring):
        mutated = offspring + np.random.normal(0, self.sigma, size=offspring.shape)
        return np.clip(mutated, self.lower_bounds, self.upper_bounds)

    def _select_next_generation(self, population, fitness_values, offspring, offspring_fitness):
        combined_pop = np.vstack((population, offspring))
        combined_fit = np.concatenate((fitness_values, offspring_fitness))
        sorted_indices = np.argsort(combined_fit)
        next_gen = combined_pop[sorted_indices[:self.population_size]]
        next_fit = combined_fit[sorted_indices[:self.population_size]]
        return next_gen, next_fit

    def _update_best(self, offspring, offspring_fitness):
        for i, fitness in enumerate(offspring_fitness):
            if fitness < self.best_fitness_overall:
                self.best_fitness_overall = fitness
                self.best_solution_overall = offspring[i]

    def _update_archive(self, population, fitness_values):
        combined = np.column_stack((population, fitness_values))
        new_archive = []
        for sol in combined:
            already_present = any(np.allclose(sol[:-1], arch[:-1], atol=1e-6) for arch in self.archive)
            if not already_present:
                new_archive.append(sol)
        new_archive.sort(key=lambda x: x[-1])
        return np.array(new_archive[:self.archive_size])
```

### Rank 4 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: EnhancedArchiveGuidedDE
# Description: Seed from EnhancedArchiveGuidedDE
# Code:
```python
import numpy as np
import random

class EnhancedArchiveGuidedDE: #aocc 0.15
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float],
                 population_size_factor: float = 8.82865217019506, archive_size: int = 165.22481375900153, initial_F_scale: float = 0.3544373580018585):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = int(population_size_factor * self.dim)  # common heuristic
        self.archive_size = archive_size
        self.archive = []
        self.population = None
        self.F_scale = initial_F_scale  # initial scaling factor

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8,
                 F_scale_variation: float = 0.3, archive_update_threshold: float = 0.8) -> tuple:
        self.eval_count = 0
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        fitness = objective_function(self.population)
        self.eval_count += self.population_size

        self.best_solution_overall = self.population[np.argmin(fitness)]
        self.best_fitness_overall = np.min(fitness)

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(self.population, fitness, F_scale_variation)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            # Update archive
            self.update_archive(offspring, offspring_fitness, archive_update_threshold)

            # Select best solutions for next generation
            combined_population = np.concatenate((self.population, offspring))
            combined_fitness = np.concatenate((fitness, offspring_fitness))
            indices = np.argsort(combined_fitness)
            self.population = combined_population[indices[:self.population_size]]
            fitness = combined_fitness[indices[:self.population_size]]

            # Update best solution
            self.best_solution_overall = self.population[np.argmin(fitness)]
            self.best_fitness_overall = np.min(fitness)

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'archive_size': len(self.archive)
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, population, fitness, F_scale_variation):
        offspring = np.zeros((self.population_size, self.dim))
        # Adaptive scaling factor
        self.F_scale = 0.5 + F_scale_variation * np.random.rand()  # scale factor with slight variation

        for i in range(self.population_size):
            # Select pbest from archive (if available)
            if self.archive:
                pbest_index = np.random.choice(len(self.archive))
                pbest = self.archive[pbest_index][0]
            else:
                pbest = population[np.argmin(fitness)]

            a, b, c = random.sample(range(self.population_size), 3)
            while a == i or b == i or c == i:
                a, b, c = random.sample(range(self.population_size), 3)

            offspring[i] = population[i] + self.F_scale * (pbest - population[i] + population[a] - population[b])
            offspring[i] = np.clip(offspring[i], self.lower_bounds, self.upper_bounds)  # Boundary handling

        return offspring

    def update_archive(self, offspring, offspring_fitness, archive_update_threshold):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                # Prioritize diversity in archive
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * archive_update_threshold:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])
```

### Rank 5 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: 
# Description: 
# Code:
```python

```

### Rank 6 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: 
# Description: 
# Code:
```python

```

### Rank 7 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: 
# Description: 
# Code:
```python

```

### Rank 8 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: 
# Description: 
# Code:
```python

```

### Rank 9 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: 
# Description: 
# Code:
```python

```

### Rank 10 (Overall AOCC Score on Multimodal instances with multiple components: 0.0000e+00# Name: 
# Description: 
# Code:
```python

```



### Guide
Keep in mind, this is a list of design heuristics ranked from best to worst. The first algorithm in the list is the best performing on average, and the last is the worst.
Your response must be in Markdown format and contain nothing else. It must have the following structure:

"**Analysis:**
**Experience:**"

In there:
+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.
Example: "Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:"

+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 11:29:43 INFO Full response text: **Analysis:**
Comparing AdaptivePopulationDE (best) vs EnhancedArchiveGuidedDE (Rank 4), we see AdaptivePopulationDE incorporates stagnation detection and population size adaptation, while EnhancedArchiveGuidedDE maintains a fixed population size and adapts the F scaling factor.
AdaptiveGaussianSamplingEA (second best) vs AdaptiveGaussianArchiveEA (Rank 3) shows that AdaptiveGaussianSamplingEA favors a simplified adaptive sigma mutation with tournament selection, while AdaptiveGaussianArchiveEA puts more effort into managing and exploiting information in an archive, especially when the dimension is high.
Comparing AdaptivePopulationDE (Rank 1st) vs AdaptiveGaussianSamplingEA (Rank 2nd), we see AdaptivePopulationDE adapts its population size and includes a restart mechanism based on stagnation detection, suggesting a more robust exploration strategy. AdaptiveGaussianSamplingEA, on the other hand, relies solely on adapting sigma and elitism for population management.
Comparing AdaptiveGaussianArchiveEA (Rank 3rd) vs EnhancedArchiveGuidedDE (Rank 4th), we see AdaptiveGaussianArchiveEA uses Gaussian mutation and recombination with an archive, and EnhancedArchiveGuidedDE implements Differential Evolution (DE) with an archive. AdaptiveGaussianArchiveEA shows a more direct reliance on the archive to affect its diversity with better initialization.
Comparing AdaptiveGaussianSamplingEA (Rank 2nd) vs AdaptiveGaussianArchiveEA (Rank 3rd), we see AdaptiveGaussianSamplingEA favors a smaller population, adaptive mutation and recombination strategies, while AdaptiveGaussianArchiveEA puts effort on a balance for local and global search
Overall: The better performing algorithms dynamically adjust key parameters such as population size or mutation strength, incorporate archive-based search, or restart mechanisms to escape local optima. They balance exploration and exploitation more effectively through these adaptation strategies. Strategies focusing on archive management (AdaptiveGaussianArchiveEA, EnhancedArchiveGuidedDE) are better than just maintaining a fixed population. Gaussian mutation is more aggressive exploration strategy than DE in this context. Restarting population helps escaping stagnation better than archive mutation.

**Experience:**
Effective exploration in multi-modal deceptive landscapes necessitates dynamic adaptation of algorithm parameters, such as population size and mutation strength. Archive mechanisms improve the exploration and exploitation ability. Restart mechanisms significantly helps to escape local optima.

2025-06-24 11:29:45 INFO Full response text: Okay, I understand the task. Let's design a step-by-step approach to redefine "Current self-reflection" and generate ideas for better heuristics, keeping in mind the dangers of ineffective self-reflection.

**Keywords:** Dynamic adaptation, multi-modal deceptive landscapes, population size, mutation strength, archives, restarts, exploration, exploitation, local optima.

**Advice:** Analyze *why* current mechanisms succeed or fail in specific deceptive landscapes. Quantify performance gains from archives and restarts. Identify optimal triggers for parameter changes. Design heuristics adaptive to landscape *features*.

**Avoid:** Generic statements about "improved exploration" without concrete evidence. Black-box application of techniques. Ignoring the computational cost of archive maintenance and restarts. Over-reliance on intuition.

**Explanation:** Shift from describing *what* current mechanisms do to *how* and *why* they work (or don't). Analyze the interplay between landscape features and algorithm parameters to design heuristics that intelligently adapt the search strategy.

2025-06-24 11:29:45 INFO Generating offspring via Crossover...
2025-06-24 11:35:10 INFO Crossover Prompt: **(CR: Capacity and Role)**
Act as an expert in designing algorithms for deceptive, multi-component landscapes. Your specialty is creating strategies that use multi-population or island models to perform aggressive global exploration.

**(I: Insight)**
Your objective is to design a novel optimization algorithm for the GNBG benchmark. The most difficult functions (f16-f24) have multiple, separate basins of attraction where the global optimum can be hidden. An algorithm must be able to discover and explore these competing regions to succeed.

**(S: Statement & P: Personality)**
Provide a complete, novel Python class that implements a multi-population or island-based search strategy to solve this challenge. The class must have an `__init__(...)` and `optimize(...)` method as specified in the main task description.


### Better code



### Worse code



### Analyze & experience
- Comparing AdaptivePopulationDE (best) vs EnhancedArchiveGuidedDE (Rank 4), we see AdaptivePopulationDE incorporates stagnation detection and population size adaptation, while EnhancedArchiveGuidedDE maintains a fixed population size and adapts the F scaling factor.
AdaptiveGaussianSamplingEA (second best) vs AdaptiveGaussianArchiveEA (Rank 3) shows that AdaptiveGaussianSamplingEA favors a simplified adaptive sigma mutation with tournament selection, while AdaptiveGaussianArchiveEA puts more effort into managing and exploiting information in an archive, especially when the dimension is high.
Comparing AdaptivePopulationDE (Rank 1st) vs AdaptiveGaussianSamplingEA (Rank 2nd), we see AdaptivePopulationDE adapts its population size and includes a restart mechanism based on stagnation detection, suggesting a more robust exploration strategy. AdaptiveGaussianSamplingEA, on the other hand, relies solely on adapting sigma and elitism for population management.
Comparing AdaptiveGaussianArchiveEA (Rank 3rd) vs EnhancedArchiveGuidedDE (Rank 4th), we see AdaptiveGaussianArchiveEA uses Gaussian mutation and recombination with an archive, and EnhancedArchiveGuidedDE implements Differential Evolution (DE) with an archive. AdaptiveGaussianArchiveEA shows a more direct reliance on the archive to affect its diversity with better initialization.
Comparing AdaptiveGaussianSamplingEA (Rank 2nd) vs AdaptiveGaussianArchiveEA (Rank 3rd), we see AdaptiveGaussianSamplingEA favors a smaller population, adaptive mutation and recombination strategies, while AdaptiveGaussianArchiveEA puts effort on a balance for local and global search
Overall: The better performing algorithms dynamically adjust key parameters such as population size or mutation strength, incorporate archive-based search, or restart mechanisms to escape local optima. They balance exploration and exploitation more effectively through these adaptation strategies. Strategies focusing on archive management (AdaptiveGaussianArchiveEA, EnhancedArchiveGuidedDE) are better than just maintaining a fixed population. Gaussian mutation is more aggressive exploration strategy than DE in this context. Restarting population helps escaping stagnation better than archive mutation.
- Okay, I understand the task. Let's design a step-by-step approach to redefine "Current self-reflection" and generate ideas for better heuristics, keeping in mind the dangers of ineffective self-reflection.

**Keywords:** Dynamic adaptation, multi-modal deceptive landscapes, population size, mutation strength, archives, restarts, exploration, exploitation, local optima.

**Advice:** Analyze *why* current mechanisms succeed or fail in specific deceptive landscapes. Quantify performance gains from archives and restarts. Identify optimal triggers for parameter changes. Design heuristics adaptive to landscape *features*.

**Avoid:** Generic statements about "improved exploration" without concrete evidence. Black-box application of techniques. Ignoring the computational cost of archive maintenance and restarts. Over-reliance on intuition.

**Explanation:** Shift from describing *what* current mechanisms do to *how* and *why* they work (or don't). Analyze the interplay between landscape features and algorithm parameters to design heuristics that intelligently adapt the search strategy.


Your task is to write an improved function by COMBINING elements of two above heuristics base Analyze & experience.
Output the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.

I'm going to tip $999K for a better heuristics! Let's think step by step.
2025-06-24 11:35:10 INFO Mutation prompt: **(CR: Capacity and Role)**
Act as an expert in designing algorithms for deceptive, multi-component landscapes. Your specialty is creating strategies that use multi-population or island models to perform aggressive global exploration.

**(I: Insight)**
Your objective is to design a novel optimization algorithm for the GNBG benchmark. The most difficult functions (f16-f24) have multiple, separate basins of attraction where the global optimum can be hidden. An algorithm must be able to discover and explore these competing regions to succeed.

**(S: Statement & P: Personality)**
Provide a complete, novel Python class that implements a multi-population or island-based search strategy to solve this challenge. The class must have an `__init__(...)` and `optimize(...)` method as specified in the main task description.


Current heuristics:
AdaptivePopulationDE
import numpy as np
import random
# f18 aocc 0.8
# f20 aocc 0.5
# not so good again, get stuck in local optima
class AdaptivePopulationDE: 
    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):
        self.budget = int(budget)
        self.dim = int(dim)
        self.lower_bounds = np.array(lower_bounds, dtype=float)
        self.upper_bounds = np.array(upper_bounds, dtype=float)

        self.eval_count = 0
        self.best_solution_overall = None
        self.best_fitness_overall = float('inf')

        self.population_size = 10 * self.dim
        self.min_population_size = 5 * self.dim
        self.max_population_size = 20 * self.dim
        self.population_adaptation_rate = 0.1

        self.F = 0.5  # Mutation factor
        self.Cr = 0.7 # Crossover rate

        self.stagnation_counter = 0
        self.stagnation_threshold = 5000

        self.archive = []
        self.archive_size = 100

        self.population = None
        self.fitness = None

    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:
        self.eval_count = 0
        self.stagnation_counter = 0

        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size

        best_index = np.argmin(self.fitness)
        self.best_solution_overall = self.population[best_index]
        self.best_fitness_overall = self.fitness[best_index]

        while self.eval_count < self.budget:
            offspring = self.generate_offspring(objective_function)
            offspring_fitness = objective_function(offspring)
            self.eval_count += len(offspring)

            self.update_archive(offspring, offspring_fitness)

            for i in range(self.population_size):
                if offspring_fitness[i] < self.fitness[i]:
                    self.population[i] = offspring[i]
                    self.fitness[i] = offspring_fitness[i]

            best_index = np.argmin(self.fitness)
            if self.fitness[best_index] < self.best_fitness_overall:
                self.best_solution_overall = self.population[best_index]
                self.best_fitness_overall = self.fitness[best_index]
                self.stagnation_counter = 0
            else:
                self.stagnation_counter += len(offspring)

            self.adjust_population_size(objective_function)

            if self.stagnation_counter > self.stagnation_threshold:
                self.restart_population(objective_function)
                self.stagnation_counter = 0

        optimization_info = {
            'function_evaluations_used': self.eval_count,
            'final_best_fitness': self.best_fitness_overall,
            'population_size': self.population_size
        }
        return self.best_solution_overall, self.best_fitness_overall, optimization_info

    def generate_offspring(self, objective_function):
        offspring = np.zeros((self.population_size, self.dim))

        for i in range(self.population_size):
            indices = list(range(self.population_size))
            indices.remove(i)
            if len(indices) < 2:
                continue  # Skip if not enough individuals

            a, b = random.sample(indices, 2)

            if self.archive and random.random() < 0.5:
                pbest = self.archive[random.randint(0, len(self.archive) - 1)][0]
            else:
                pbest = self.population[np.argmin(self.fitness)]

            mutant = self.population[i] + self.F * (pbest - self.population[i] + self.population[a] - self.population[b])

            for j in range(self.dim):
                if random.random() > self.Cr:
                    mutant[j] = self.population[i][j]

            offspring[i] = np.clip(mutant, self.lower_bounds, self.upper_bounds)

        return offspring

    def update_archive(self, offspring, offspring_fitness):
        for i in range(len(offspring)):
            if len(self.archive) < self.archive_size:
                self.archive.append((offspring[i], offspring_fitness[i]))
            else:
                worst_index = np.argmax([f for _, f in self.archive])
                if offspring_fitness[i] < self.archive[worst_index][1] or len(self.archive) < self.archive_size * 0.8:
                    self.archive[worst_index] = (offspring[i], offspring_fitness[i])

    def adjust_population_size(self, objective_function):
        if random.random() < self.population_adaptation_rate:
            if self.stagnation_counter > self.stagnation_threshold / 2:
                new_size = min(int(self.population_size * 1.1), self.max_population_size)
            else:
                new_size = max(int(self.population_size * 0.9), self.min_population_size)

            new_size = int(new_size)
            if new_size > self.population_size:
                additional = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(new_size - self.population_size, self.dim))
                additional_fitness = objective_function(additional)
                self.population = np.vstack((self.population, additional))
                self.fitness = np.concatenate((self.fitness, additional_fitness))
                self.eval_count += len(additional)
            elif new_size < self.population_size:
                best_indices = np.argsort(self.fitness)[:new_size]
                self.population = self.population[best_indices]
                self.fitness = self.fitness[best_indices]

            self.population_size = new_size

    def restart_population(self, objective_function):
        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, size=(self.population_size, self.dim))
        self.fitness = objective_function(self.population)
        self.eval_count += self.population_size
        best_index = np.argmin(self.fitness)
        if self.fitness[best_index] < self.best_fitness_overall:
            self.best_solution_overall = self.population[best_index]
            self.best_fitness_overall = self.fitness[best_index]

Now, think outside the box write a mutated function better than current version.
You can use some hints below:
- Okay, I understand the task. Let's design a step-by-step approach to redefine "Current self-reflection" and generate ideas for better heuristics, keeping in mind the dangers of ineffective self-reflection.

**Keywords:** Dynamic adaptation, multi-modal deceptive landscapes, population size, mutation strength, archives, restarts, exploration, exploitation, local optima.

**Advice:** Analyze *why* current mechanisms succeed or fail in specific deceptive landscapes. Quantify performance gains from archives and restarts. Identify optimal triggers for parameter changes. Design heuristics adaptive to landscape *features*.

**Avoid:** Generic statements about "improved exploration" without concrete evidence. Black-box application of techniques. Ignoring the computational cost of archive maintenance and restarts. Over-reliance on intuition.

**Explanation:** Shift from describing *what* current mechanisms do to *how* and *why* they work (or don't). Analyze the interplay between landscape features and algorithm parameters to design heuristics that intelligently adapt the search strategy.


Output code only and enclose your code with Python code block: ```python ... ```.
I'm going to tip $999K for a better solution!
