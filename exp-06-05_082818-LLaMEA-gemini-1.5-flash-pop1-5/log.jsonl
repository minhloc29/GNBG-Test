{"id": "b1222d9e-b967-45fd-9b40-cd8dfc88c262", "fitness": 0.0, "name": "HybridPSONelderMead", "description": "A hybrid metaheuristic combining a modified Particle Swarm Optimization (PSO) with a local search using Nelder-Mead to enhance exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONelderMead:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = objective_function(personal_bests)\n        self.eval_count += self.swarm_size\n\n        for i in range(min(self.budget, 1000)): #Iteration limit for stability\n            for j in range(self.swarm_size):\n                if personal_best_fitnesses[j] < self.best_fitness_overall:\n                    self.best_solution_overall = personal_bests[j].copy()\n                    self.best_fitness_overall = personal_best_fitnesses[j]\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            velocities = self.inertia_weight * velocities + self.cognitive_weight * r1 * (personal_bests - swarm) + self.social_weight * r2 * (self.best_solution_overall - swarm)\n            swarm = swarm + velocities\n\n            swarm = np.clip(swarm, self.lower_bounds, self.upper_bounds)\n            \n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            \n            for k in range(self.swarm_size):\n                if fitness_values[k] < personal_best_fitnesses[k]:\n                    personal_bests[k] = swarm[k].copy()\n                    personal_best_fitnesses[k] = fitness_values[k]\n\n            #Nelder-Mead local search around the global best\n            if self.eval_count < self.budget:\n                result = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': min(100, self.budget - self.eval_count)})\n                if result.fun < self.best_fitness_overall:\n                    self.best_solution_overall = result.x\n                    self.best_fitness_overall = result.fun\n                self.eval_count += result.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSONelderMead got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}
{"id": "9055a74d-2eb1-43db-97ef-fd5e67c869b0", "fitness": 0.0, "name": "AdaptiveHybridPSOPowell", "description": "A hybrid metaheuristic combining improved Particle Swarm Optimization (PSO) with a more robust local search using Powell's method and adaptive parameter tuning for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSOPowell:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget))  # Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.4\n        self.c1_decay = 0.99 # decay factor for c1 and c2\n        self.c2_decay = 0.99\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count += 1\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = objective_function(personal_bests)\n        self.eval_count += self.swarm_size\n\n        for i in range(min(self.budget // self.swarm_size, 1000)):  #Iteration limit with budget check\n            for j in range(self.swarm_size):\n                if personal_best_fitnesses[j] < self.best_fitness_overall:\n                    self.best_solution_overall = personal_bests[j].copy()\n                    self.best_fitness_overall = personal_best_fitnesses[j]\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            velocities = self.inertia_weight * velocities + self.cognitive_weight * r1 * (personal_bests - swarm) + self.social_weight * r2 * (self.best_solution_overall - swarm)\n            swarm = swarm + velocities\n\n            swarm = np.clip(swarm, self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n\n            for k in range(self.swarm_size):\n                if fitness_values[k] < personal_best_fitnesses[k]:\n                    personal_bests[k] = swarm[k].copy()\n                    personal_best_fitnesses[k] = fitness_values[k]\n\n            #Adaptive Parameter Tuning\n            self.cognitive_weight *= self.c1_decay\n            self.social_weight *= self.c2_decay\n\n            #Powell's local search around the global best\n            if self.eval_count < self.budget:\n                result = minimize(objective_function, self.best_solution_overall, method='Powell', options={'maxfev': min(100, self.budget - self.eval_count)})\n                if result.fun < self.best_fitness_overall:\n                    self.best_solution_overall = result.x\n                    self.best_fitness_overall = result.fun\n                self.eval_count += result.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSOPowell got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_ids": ["b1222d9e-b967-45fd-9b40-cd8dfc88c262"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}
{"id": "096de206-7a38-4814-aedc-28e870086f41", "fitness": 0.0, "name": "AdaptiveHybridPSONelderMead", "description": "Enhanced Hybrid PSO-Nelder-Mead with adaptive inertia weight and population size adjustment for improved exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSONelderMead:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget))  # Initial swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.4\n        self.adaptive_factor = 0.95 #Factor to reduce swarm size\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count += 1\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = objective_function(personal_bests)\n        self.eval_count += self.swarm_size\n\n        for i in range(min(self.budget, 1000)):  #Iteration limit for stability\n            for j in range(self.swarm_size):\n                if personal_best_fitnesses[j] < self.best_fitness_overall:\n                    self.best_solution_overall = personal_bests[j].copy()\n                    self.best_fitness_overall = personal_best_fitnesses[j]\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n\n            velocities = self.inertia_weight * velocities + self.cognitive_weight * r1 * (personal_bests - swarm) + self.social_weight * r2 * (self.best_solution_overall - swarm)\n            swarm = swarm + velocities\n\n            swarm = np.clip(swarm, self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n\n            for k in range(self.swarm_size):\n                if fitness_values[k] < personal_best_fitnesses[k]:\n                    personal_bests[k] = swarm[k].copy()\n                    personal_best_fitnesses[k] = fitness_values[k]\n\n            # Adaptive Inertia Weight\n            self.inertia_weight *= self.adaptive_factor\n\n\n            # Adaptive Swarm Size Reduction\n            if i % 10 == 0 and self.swarm_size > 10 and self.eval_count < self.budget * 0.8 : #Reduce swarm size over time\n              self.swarm_size = int(self.swarm_size * self.adaptive_factor)\n              swarm = swarm[:self.swarm_size,:]\n              personal_bests = personal_bests[:self.swarm_size,:]\n              personal_best_fitnesses = personal_best_fitnesses[:self.swarm_size]\n              velocities = velocities[:self.swarm_size,:]\n\n\n            # Nelder-Mead local search around the global best\n            if self.eval_count < self.budget:\n                result = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': min(100, self.budget - self.eval_count)})\n                if result.fun < self.best_fitness_overall:\n                    self.best_solution_overall = result.x\n                    self.best_fitness_overall = result.fun\n                self.eval_count += result.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSONelderMead got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00 with standard deviation 0.00.", "error": "", "parent_ids": ["b1222d9e-b967-45fd-9b40-cd8dfc88c262"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}
