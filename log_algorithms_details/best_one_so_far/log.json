{"id": "a69aa84f-6c29-4b61-8977-dd258de17795", "fitness": 0.025512274071639366, "name": "AdaptiveDE", "description": "A hybrid algorithm combining Differential Evolution with a novel adaptive mutation strategy based on the estimated gradient and population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness = None\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n            self.fitness = objective_function(self.population)\n            self.eval_count += self.population_size\n        else:\n            self.population = np.array([])\n            self.fitness = np.array([])\n        self.best_solution_overall = self.population[np.argmin(self.fitness)]\n        self.best_fitness_overall = np.min(self.fitness)\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.population_size):\n                # Select parents\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                \n                # Adaptive Mutation\n                diff = self.population[a] - self.population[b]\n                gradient_estimate = np.zeros(self.dim)\n                \n                # Simple gradient estimate based on neighboring solutions\n                if i>0:\n                    gradient_estimate = (self.population[i] - self.population[i-1])/(self.fitness[i] - self.fitness[i-1]) if self.fitness[i] != self.fitness[i-1] else np.zeros(self.dim)\n\n                mutated = self.population[i] + self.F * (self.population[c] + gradient_estimate)\n                mutated = np.clip(mutated, self.lower_bounds, self.upper_bounds)\n                \n                # Crossover\n                j_rand = np.random.randint(0, self.dim)\n                trial = np.copy(self.population[i])\n                trial[np.random.rand(self.dim) < self.CR] = mutated[np.random.rand(self.dim) < self.CR]\n                trial[j_rand] = mutated[j_rand]\n\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count += 1\n                if trial_fitness < self.fitness[i]:\n                    new_population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_fitness_overall = trial_fitness\n                        self.best_solution_overall = trial\n                else:\n                    new_population[i] = self.population[i]\n\n            self.population = new_population\n\n        if self.best_solution_overall is None and self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0765368222149181]}}
{"id": "7888ff0c-6607-4185-97a3-6cc796654ee0", "fitness": 0.02597573715694813, "name": "AdaptiveCovarianceDE", "description": "A hybrid algorithm combining Differential Evolution with a novel adaptive mutation based on the population's covariance matrix and a local search strategy.", "code": "import numpy as np\n\nclass AdaptiveCovarianceDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness_values = None\n        self.covariance_matrix = None\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        \n        #Initialization\n        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        self.fitness_values = objective_function(self.population)\n        self.eval_count += self.population_size\n        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]\n        self.best_fitness_overall = np.min(self.fitness_values)\n        self.covariance_matrix = np.cov(self.population, rowvar=False)\n\n        #Main Loop\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n                while a == i or b == i or c == i:  #Ensure different individuals\n                    a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                \n                #Adaptive Mutation using Covariance Matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += 0.2 * mutation_vector #scaling factor\n\n                #Clipping\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n\n                #Selection\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count +=1\n                if trial_fitness < self.fitness_values[i]:\n                    self.population[i] = trial\n                    self.fitness_values[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_solution_overall = trial\n                        self.best_fitness_overall = trial_fitness\n                        \n            self.covariance_matrix = np.cov(self.population, rowvar=False) #Update Covariance Matrix\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveCovarianceDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07792721147084439]}}
{"id": "eab1581a-7dda-41d8-b26c-e06035b4673c", "fitness": 0.02655497912363272, "name": "AdaptiveDE", "description": "A hybrid algorithm combining Differential Evolution with a novel adaptive mutation strategy based on a learned covariance matrix and a population diversity preservation mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += self.F * mutation_vector\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = offspring[i].copy()\n                        self.best_fitness_overall = fitness_values[i]\n\n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                mean = np.mean(selected_solutions, axis=0)\n                cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07966493737089816]}}
{"id": "4342ffd6-ca06-44e4-ba9e-ad9169877dfb", "fitness": 0.025894306562796347, "name": "AdaptiveGaussianDE", "description": "A hybrid algorithm combining Differential Evolution with a novel adaptive mutation strategy based on a Gaussian Mixture Model to efficiently explore and exploit the search space.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 5), covariance_type='full') # Adjust number of components as needed\n                gm.fit(np.array(self.archive))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append(population[j])\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07768291968838904]}}
{"id": "3212fea8-aabe-46b6-945e-eaeff1d335c4", "fitness": 0.026050468383671973, "name": "AdaptiveDE", "description": "A hybrid algorithm combining Differential Evolution with a novel adaptive mutation strategy based on population diversity and a local search phase.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n\n\n            #Local Search\n            if self.eval_count < self.budget *0.8: #Reduce the local search calls as it approaches the budget.\n              local_search_point = self.best_solution_overall + np.random.normal(0,0.1,self.dim) #Add some noise\n              local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n              local_fitness = objective_function(np.array([local_search_point]))[0]\n              self.eval_count += 1\n              if local_fitness < self.best_fitness_overall:\n                  self.best_fitness_overall = local_fitness\n                  self.best_solution_overall = local_search_point.copy()\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07815140515101592]}}
{"id": "27e7b428-0e81-4068-8c62-e16386d7ac77", "fitness": 0.025728453996679848, "name": "AdaptiveDE_Refined", "description": "Adaptive Differential Evolution with refined gradient-based mutation and population diversity preservation.", "code": "import numpy as np\n\nclass AdaptiveDE_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness = None\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n            self.fitness = objective_function(self.population)\n            self.eval_count += self.population_size\n        else:\n            self.population = np.array([])\n            self.fitness = np.array([])\n        self.best_solution_overall = self.population[np.argmin(self.fitness)]\n        self.best_fitness_overall = np.min(self.fitness)\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.population_size):\n                # Select parents\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                \n                # Adaptive Mutation\n                diff = self.population[a] - self.population[b]\n                gradient_estimate = np.zeros(self.dim)\n                \n                # Refined gradient estimate using a weighted average of neighbors\n                if i > 0 and i < self.population_size -1:\n                    gradient_estimate = 0.5 * (self.population[i+1] - self.population[i-1]) / (self.fitness[i+1] - self.fitness[i-1]) if self.fitness[i+1] != self.fitness[i-1] else np.zeros(self.dim)\n\n                mutated = self.population[i] + self.F * (self.population[c] + gradient_estimate)\n                mutated = np.clip(mutated, self.lower_bounds, self.upper_bounds)\n                \n                # Crossover\n                j_rand = np.random.randint(0, self.dim)\n                trial = np.copy(self.population[i])\n                trial[np.random.rand(self.dim) < self.CR] = mutated[np.random.rand(self.dim) < self.CR]\n                trial[j_rand] = mutated[j_rand]\n\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count += 1\n                if trial_fitness < self.fitness[i]:\n                    new_population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_fitness_overall = trial_fitness\n                        self.best_solution_overall = trial\n                else:\n                    new_population[i] = self.population[i]\n\n            self.population = new_population\n\n        if self.best_solution_overall is None and self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["a69aa84f-6c29-4b61-8977-dd258de17795"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07718536199003954]}}
{"id": "d9d0d0c8-9aab-459e-ab4e-5649801d8dac", "fitness": 0.025509286514208612, "name": "AdaptiveCovarianceDE", "description": "AdaptiveCovarianceDE enhanced with a diversity-preserving mechanism by adding a small amount of random noise to the best solution periodically.", "code": "import numpy as np\n\nclass AdaptiveCovarianceDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness_values = None\n        self.covariance_matrix = None\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        \n        #Initialization\n        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        self.fitness_values = objective_function(self.population)\n        self.eval_count += self.population_size\n        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]\n        self.best_fitness_overall = np.min(self.fitness_values)\n        self.covariance_matrix = np.cov(self.population, rowvar=False)\n\n        #Main Loop\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n                while a == i or b == i or c == i:  #Ensure different individuals\n                    a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                \n                #Adaptive Mutation using Covariance Matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += 0.2 * mutation_vector #scaling factor\n\n                #Clipping\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n\n                #Selection\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count +=1\n                if trial_fitness < self.fitness_values[i]:\n                    self.population[i] = trial\n                    self.fitness_values[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_solution_overall = trial\n                        self.best_fitness_overall = trial_fitness\n                        \n            self.covariance_matrix = np.cov(self.population, rowvar=False) #Update Covariance Matrix\n            if self.eval_count % (self.budget // 10) == 0: #add noise every 10% of budget\n                noise = 0.01 * np.random.randn(self.dim)\n                self.best_solution_overall = np.clip(self.best_solution_overall + noise, self.lower_bounds, self.upper_bounds)\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveCovarianceDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["7888ff0c-6607-4185-97a3-6cc796654ee0"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07652785954262584]}}
{"id": "62b3258b-a58f-4c3e-a787-a6dd2d252b37", "fitness": 0.026290898876592583, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n        self.stagnation_counter = 0 # Added for stagnation detection\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n                        self.stagnation_counter = 0 #Reset stagnation counter\n                else:\n                    self.stagnation_counter +=1 #Increment stagnation counter\n\n\n            #Local Search - triggered by stagnation\n            if self.stagnation_counter > self.population_size * 2 : # Trigger local search after a period of stagnation\n              local_search_point = self.best_solution_overall + np.random.normal(0,0.1,self.dim) #Add some noise\n              local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n              local_fitness = objective_function(np.array([local_search_point]))[0]\n              self.eval_count += 1\n              if local_fitness < self.best_fitness_overall:\n                  self.best_fitness_overall = local_fitness\n                  self.best_solution_overall = local_search_point.copy()\n                  self.stagnation_counter = 0 #Reset counter after successful local search\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3212fea8-aabe-46b6-945e-eaeff1d335c4"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07887269662977775]}}
{"id": "b71b0ccf-484c-4309-8a7b-6d7f4e755809", "fitness": 0.02490522242269803, "name": "AdaptiveGaussianDE_Improved", "description": "Adaptive Gaussian Mixture DE with enhanced archive management and adaptive crossover rate.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE_Improved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.CR_adaptation_rate = 0.01\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 5), covariance_type='full') # Adjust number of components as needed\n                gm.fit(np.array(self.archive))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adaptive CR\n            self.CR += self.CR_adaptation_rate * (np.mean(offspring_fitness) - np.mean(fitness_values))\n            self.CR = np.clip(self.CR, 0.1, 0.99)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveGaussianDE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["4342ffd6-ca06-44e4-ba9e-ad9169877dfb"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07471566726809409]}}
{"id": "091d1106-c24f-4ac5-bccd-be52961d02e5", "fitness": 0.02483120997857399, "name": "AdaptiveCovarianceDE", "description": "AdaptiveCovarianceDE enhanced with a diversity-preserving mechanism using a crowding distance and a refined covariance matrix update.", "code": "import numpy as np\n\nclass AdaptiveCovarianceDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness_values = None\n        self.covariance_matrix = None\n        self.crowding_distances = None\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        \n        #Initialization\n        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        self.fitness_values = objective_function(self.population)\n        self.eval_count += self.population_size\n        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]\n        self.best_fitness_overall = np.min(self.fitness_values)\n        self.covariance_matrix = np.cov(self.population, rowvar=False)\n        self.crowding_distances = self.calculate_crowding_distance(self.population)\n\n        #Main Loop\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n                while a == i or b == i or c == i:  #Ensure different individuals\n                    a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                \n                #Adaptive Mutation using Covariance Matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += 0.2 * mutation_vector #scaling factor\n\n                #Clipping\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n\n                #Selection\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count +=1\n                if trial_fitness < self.fitness_values[i]:\n                    self.population[i] = trial\n                    self.fitness_values[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_solution_overall = trial\n                        self.best_fitness_overall = trial_fitness\n                        \n            self.covariance_matrix = self.update_covariance_matrix(self.population) #Update Covariance Matrix\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n\n    def calculate_crowding_distance(self, population):\n        #Simple crowding distance calculation (can be improved)\n        num_individuals = population.shape[0]\n        num_objectives = 1 #assuming single objective optimization\n        distances = np.zeros(num_individuals)\n        for i in range(num_objectives):\n            sorted_indices = np.argsort(self.fitness_values)\n            distances[sorted_indices[0]] = float('inf')\n            distances[sorted_indices[-1]] = float('inf')\n            for j in range(1,num_individuals-1):\n                distances[sorted_indices[j]] += (self.fitness_values[sorted_indices[j+1]]-self.fitness_values[sorted_indices[j-1]])\n        return distances\n\n\n    def update_covariance_matrix(self, population):\n        #Weighted Covariance Matrix Update to emphasize diversity\n        weights = self.crowding_distances / np.sum(self.crowding_distances)\n        return np.cov(population, aweights=weights, rowvar=False)\n", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveCovarianceDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["7888ff0c-6607-4185-97a3-6cc796654ee0"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07449362993572196]}}
{"id": "d453d602-c8b8-4294-963b-5619c191aa34", "fitness": 0.025198113051616133, "name": "AdaptiveDE_Refined", "description": "Adaptive Differential Evolution with refined gradient-based mutation and population diversity preservation.", "code": "import numpy as np\n\nclass AdaptiveDE_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness = None\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n            self.fitness = objective_function(self.population)\n            self.eval_count += self.population_size\n        else:\n            self.population = np.array([])\n            self.fitness = np.array([])\n        self.best_solution_overall = self.population[np.argmin(self.fitness)]\n        self.best_fitness_overall = np.min(self.fitness)\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.population_size):\n                # Select parents\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                \n                # Adaptive Mutation\n                diff = self.population[a] - self.population[b]\n                gradient_estimate = np.zeros(self.dim)\n                \n                # Refined gradient estimate with diversity consideration\n                if i > 0:\n                    #Use a weighted average of the gradient to reduce noise and improve stability.\n                    gradient_estimate = 0.5 * (self.population[i] - self.population[i-1]) / (self.fitness[i] - self.fitness[i-1] + 1e-10) if self.fitness[i] != self.fitness[i-1] else np.zeros(self.dim)\n\n                mutated = self.population[i] + self.F * (self.population[c] + gradient_estimate)\n                mutated = np.clip(mutated, self.lower_bounds, self.upper_bounds)\n                \n                # Crossover\n                j_rand = np.random.randint(0, self.dim)\n                trial = np.copy(self.population[i])\n                trial[np.random.rand(self.dim) < self.CR] = mutated[np.random.rand(self.dim) < self.CR]\n                trial[j_rand] = mutated[j_rand]\n\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count += 1\n                if trial_fitness < self.fitness[i]:\n                    new_population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_fitness_overall = trial_fitness\n                        self.best_solution_overall = trial\n                else:\n                    new_population[i] = self.population[i]\n\n            self.population = new_population\n\n        if self.best_solution_overall is None and self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["a69aa84f-6c29-4b61-8977-dd258de17795"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0755943391548484]}}
{"id": "bdc2ccd2-8d99-400b-8e84-e99d4f462719", "fitness": 0.024636536161643987, "name": "AdaptiveDE_Refined", "description": "Adaptive Differential Evolution with refined gradient-based mutation and population diversity preservation.", "code": "import numpy as np\n\nclass AdaptiveDE_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness = None\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n            self.fitness = objective_function(self.population)\n            self.eval_count += self.population_size\n        else:\n            self.population = np.array([])\n            self.fitness = np.array([])\n        self.best_solution_overall = self.population[np.argmin(self.fitness)]\n        self.best_fitness_overall = np.min(self.fitness)\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros_like(self.population)\n            for i in range(self.population_size):\n                # Select parents\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                \n                # Adaptive Mutation\n                diff = self.population[a] - self.population[b]\n                gradient_estimate = np.zeros(self.dim)\n                \n                # Refined gradient estimate with smoothing and scaling\n                if i > 0:\n                    #smoothing over 5 neighbours\n                    if i >= 5:\n                        gradient_estimate = np.mean(self.population[i-5:i+1] - self.population[i-6:i], axis=0) / np.mean(self.fitness[i-5:i+1] - self.fitness[i-6:i]) if np.mean(self.fitness[i-5:i+1] - self.fitness[i-6:i]) !=0 else np.zeros(self.dim)\n                    else:\n                        gradient_estimate = np.mean(self.population[:i+1] - self.population[:i]) / np.mean(self.fitness[:i+1] - self.fitness[:i]) if np.mean(self.fitness[:i+1] - self.fitness[:i]) != 0 else np.zeros(self.dim)\n\n                mutated = self.population[i] + self.F * (self.population[c] + 0.1 * gradient_estimate) # Scaling factor added\n                mutated = np.clip(mutated, self.lower_bounds, self.upper_bounds)\n                \n                # Crossover\n                j_rand = np.random.randint(0, self.dim)\n                trial = np.copy(self.population[i])\n                trial[np.random.rand(self.dim) < self.CR] = mutated[np.random.rand(self.dim) < self.CR]\n                trial[j_rand] = mutated[j_rand]\n\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count += 1\n                if trial_fitness < self.fitness[i]:\n                    new_population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_fitness_overall = trial_fitness\n                        self.best_solution_overall = trial\n                else:\n                    new_population[i] = self.population[i]\n\n            self.population = new_population\n\n        if self.best_solution_overall is None and self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["a69aa84f-6c29-4b61-8977-dd258de17795"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07390960848493196]}}
{"id": "21481b62-2bb4-41a2-b4d1-b3d5a699c329", "fitness": 0.025080385979073624, "name": "AdaptiveCovarianceDE", "description": "Adaptive Covariance DE with enhanced local search via a shrinking exploration radius around the best solution.", "code": "import numpy as np\n\nclass AdaptiveCovarianceDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.fitness_values = None\n        self.covariance_matrix = None\n        self.radius = 0.5 # Initial exploration radius\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        \n        #Initialization\n        self.population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        self.fitness_values = objective_function(self.population)\n        self.eval_count += self.population_size\n        self.best_solution_overall = self.population[np.argmin(self.fitness_values)]\n        self.best_fitness_overall = np.min(self.fitness_values)\n        self.covariance_matrix = np.cov(self.population, rowvar=False)\n\n        #Main Loop\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n                while a == i or b == i or c == i:  #Ensure different individuals\n                    a, b, c = np.random.choice(np.arange(self.population_size), 3, replace=False)\n\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                \n                #Adaptive Mutation using Covariance Matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += 0.2 * mutation_vector #scaling factor\n\n                #Clipping\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n\n                #Selection\n                trial_fitness = objective_function(trial.reshape(1, -1))[0]\n                self.eval_count +=1\n                if trial_fitness < self.fitness_values[i]:\n                    self.population[i] = trial\n                    self.fitness_values[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_solution_overall = trial\n                        self.best_fitness_overall = trial_fitness\n                        \n            self.covariance_matrix = np.cov(self.population, rowvar=False) #Update Covariance Matrix\n            self.radius *= 0.9 # Shrink radius for local search\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveCovarianceDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["7888ff0c-6607-4185-97a3-6cc796654ee0"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07524115793722087]}}
{"id": "aac57dcf-4dd2-4e21-b7b4-cc47f0227d83", "fitness": 0.025422559517755985, "name": "AdaptiveDE", "description": "AdaptiveDE with improved covariance matrix adaptation using a weighted average of the best solutions' covariance and the population's covariance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += self.F * mutation_vector\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = offspring[i].copy()\n                        self.best_fitness_overall = fitness_values[i]\n\n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                #WEIGHTED AVERAGE\n                pop_cov = np.cov(population, rowvar=False)\n                best_cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = 0.7 * best_cov + 0.3 * pop_cov\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["eab1581a-7dda-41d8-b26c-e06035b4673c"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07626767855326795]}}
{"id": "3bdd94fe-7082-421a-b11c-0c4ae0b63d7a", "fitness": 0.031314119785903906, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management and adaptive F and CR.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 5), covariance_type='full') # Adjust number of components as needed\n                gm.fit(np.array([sol for sol, _ in self.archive])) #Fit only on solutions, not fitness values\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["4342ffd6-ca06-44e4-ba9e-ad9169877dfb"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09394235935771172]}}
{"id": "9fcaae9d-f570-4abf-b3b6-c0e8a44e1b41", "fitness": 0.026348404497849167, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling and improved local search exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n\n\n            #Local Search  Improved exploration radius\n            if self.eval_count < self.budget *0.8:\n              local_search_point = self.best_solution_overall + np.random.normal(0,0.2,self.dim) #Increased exploration radius\n              local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n              local_fitness = objective_function(np.array([local_search_point]))[0]\n              self.eval_count += 1\n              if local_fitness < self.best_fitness_overall:\n                  self.best_fitness_overall = local_fitness\n                  self.best_solution_overall = local_search_point.copy()\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3212fea8-aabe-46b6-945e-eaeff1d335c4"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0790452134935475]}}
{"id": "42883201-7787-4d67-b457-e3226bf4383b", "fitness": 0.02490887960183237, "name": "AdaptiveDEImproved", "description": "Adaptive Differential Evolution with enhanced archive management and adaptive F and CR based on solution diversity.", "code": "import numpy as np\n\nclass AdaptiveDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 100\n        self.diversity_threshold = 0.1\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += self.F * mutation_vector\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = offspring[i].copy()\n                        self.best_fitness_overall = fitness_values[i]\n\n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n\n            # Adaptive F and CR based on diversity\n            diversity = np.std(population)\n            self.F = 0.5 + 0.5 * (diversity / self.diversity_threshold) #increase F if low diversity\n            self.CR = 0.1 + 0.8 * (1- diversity / self.diversity_threshold) #increase CR if low diversity\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                mean = np.mean(selected_solutions, axis=0)\n                cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDEImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["eab1581a-7dda-41d8-b26c-e06035b4673c"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07472663880549711]}}
{"id": "4e5336e5-4231-47e5-b8c4-d928f9221b5a", "fitness": 0.025315780294950085, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling and improved local search exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n\n\n            #Local Search\n            if self.eval_count < self.budget *0.9: #Increased local search budget\n              local_search_point = self.best_solution_overall + np.random.normal(0,0.2,self.dim) #Increased exploration\n              local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n              local_fitness = objective_function(np.array([local_search_point]))[0]\n              self.eval_count += 1\n              if local_fitness < self.best_fitness_overall:\n                  self.best_fitness_overall = local_fitness\n                  self.best_solution_overall = local_search_point.copy()\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3212fea8-aabe-46b6-945e-eaeff1d335c4"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07594734088485025]}}
{"id": "91b43b5b-1bec-45f4-92e0-ab23ade533e0", "fitness": 0.025342130007211885, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 100\n        self.stagnation_counter = 0 # Added for stagnation detection\n        self.stagnation_threshold = 10 # Number of generations without improvement before triggering local search\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        last_improvement = self.best_fitness_overall\n\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += self.F * mutation_vector\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = offspring[i].copy()\n                        last_improvement = self.best_fitness_overall\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                    \n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n                \n            if self.best_fitness_overall == last_improvement:\n                 self.stagnation_counter +=1\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                mean = np.mean(selected_solutions, axis=0)\n                cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["eab1581a-7dda-41d8-b26c-e06035b4673c"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07602639002163565]}}
{"id": "d481ddb4-5fd8-43e5-8645-0ca8aba943bd", "fitness": 0.02551969675089306, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling, improved local search radius.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n        self.stagnation_counter = 0 # Added for stagnation detection\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n                        self.stagnation_counter = 0 #Reset stagnation counter\n                else:\n                    self.stagnation_counter +=1 #Increment stagnation counter\n\n\n            #Local Search - triggered by stagnation\n            if self.stagnation_counter > self.population_size * 2 : # Trigger local search after a period of stagnation\n              local_search_point = self.best_solution_overall + np.random.normal(0,0.2,self.dim) #Increased local search radius\n              local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n              local_fitness = objective_function(np.array([local_search_point]))[0]\n              self.eval_count += 1\n              if local_fitness < self.best_fitness_overall:\n                  self.best_fitness_overall = local_fitness\n                  self.best_solution_overall = local_search_point.copy()\n                  self.stagnation_counter = 0 #Reset counter after successful local search\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["62b3258b-a58f-4c3e-a787-a6dd2d252b37"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07655909025267918]}}
{"id": "b16e2e3d-e7ff-4605-8724-9f6b2431f4ce", "fitness": 0.025320735369482456, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling and improved local search exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n\n\n            #Local Search  Improved exploration radius\n            if self.eval_count < self.budget *0.8:\n              local_search_point = self.best_solution_overall + np.random.normal(0,0.2,self.dim) #Increased exploration radius\n              local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n              local_fitness = objective_function(np.array([local_search_point]))[0]\n              self.eval_count += 1\n              if local_fitness < self.best_fitness_overall:\n                  self.best_fitness_overall = local_fitness\n                  self.best_solution_overall = local_search_point.copy()\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3212fea8-aabe-46b6-945e-eaeff1d335c4"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07596220610844737]}}
{"id": "dbf936e9-c117-4667-8984-b6048ca88d60", "fitness": 0.025613151942226683, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling, and improved local search radius.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n        self.stagnation_counter = 0 # Added for stagnation detection\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n                        self.stagnation_counter = 0 #Reset stagnation counter\n                else:\n                    self.stagnation_counter +=1 #Increment stagnation counter\n\n\n            #Local Search - triggered by stagnation\n            if self.stagnation_counter > self.population_size * 2 : # Trigger local search after a period of stagnation\n              local_search_point = self.best_solution_overall + np.random.normal(0,0.05,self.dim) #Improved local search radius\n              local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n              local_fitness = objective_function(np.array([local_search_point]))[0]\n              self.eval_count += 1\n              if local_fitness < self.best_fitness_overall:\n                  self.best_fitness_overall = local_fitness\n                  self.best_solution_overall = local_search_point.copy()\n                  self.stagnation_counter = 0 #Reset counter after successful local search\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["62b3258b-a58f-4c3e-a787-a6dd2d252b37"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07683945582668004]}}
{"id": "0a5721fa-58cf-41e8-a5ce-7a719ac85a98", "fitness": 0.026719695944091102, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 100\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 10\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        previous_best = self.best_fitness_overall\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += (self.F * (1 + 0.1 * np.random.rand()) * mutation_vector) #Diversity based scaling\n\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = offspring[i].copy()\n                        self.best_fitness_overall = fitness_values[i]\n                        self.stagnation_counter = 0 #reset stagnation counter\n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n                \n            if self.best_fitness_overall == previous_best:\n                self.stagnation_counter +=1\n            else:\n                previous_best = self.best_fitness_overall\n                \n            #local search triggered by stagnation\n            if self.stagnation_counter >= self.stagnation_threshold:\n                # Implement local search here (e.g., Nelder-Mead)\n                pass # placeholder for local search\n\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                mean = np.mean(selected_solutions, axis=0)\n                cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["eab1581a-7dda-41d8-b26c-e06035b4673c"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.08015908783227331]}}
{"id": "2a95c4d8-bf6e-410f-9f48-82a4def8c682", "fitness": 0.025393895847125782, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 100\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 10\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        last_best_fitness = self.best_fitness_overall\n\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix and diversity scaling\n                diversity = np.std(population, axis=0)\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix) * diversity\n                mutant += self.F * mutation_vector\n\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = offspring[i].copy()\n                        self.best_fitness_overall = fitness_values[i]\n                        self.stagnation_counter = 0\n                    else:\n                        self.stagnation_counter +=1\n\n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                mean = np.mean(selected_solutions, axis=0)\n                cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov\n\n            # Local Search Triggered by Stagnation\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Implement a local search here (e.g., hill climbing)\n                pass # Placeholder for local search\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["eab1581a-7dda-41d8-b26c-e06035b4673c"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07618168754137734]}}
{"id": "a500227c-576e-462c-926d-41399eea125f", "fitness": 0.03195953190338576, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation to better capture the solution landscape.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["3bdd94fe-7082-421a-b11c-0c4ae0b63d7a"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09587859571015728]}}
{"id": "906b58ad-2abf-448a-8a9e-c3521928a0de", "fitness": 0.025803133184532975, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation and diversity-based mutation scaling, improved local search exploration, and dynamic population size adjustment.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # Mutation factor\n        self.CR = 0.9 # Crossover rate\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(np.array([self.best_solution_overall]))[0]\n        self.eval_count += 1\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness_overall:\n                self.best_fitness_overall = fitness_values[i]\n                self.best_solution_overall = population[i, :].copy()\n\n\n        while self.eval_count < self.budget:\n            #Adaptive Mutation Strategy based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + np.exp(-diversity)) # Reduce F for high diversity, increase for low\n\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                #Differential Evolution Mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n\n                #Clamp mutant vector\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                \n                #Crossover\n                jrand = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        offspring[i, j] = mutant[j]\n                    else:\n                        offspring[i, j] = population[i, j]\n\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n            #Selection\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_fitness_overall = fitness_values[i]\n                        self.best_solution_overall = population[i, :].copy()\n\n\n            #Local Search  Improved exploration radius and dynamic population size adjustment\n            if self.eval_count < self.budget *0.8:\n                self.population_size = int(10 * self.dim * (1 + np.exp(-self.eval_count/self.budget))) #Dynamic population size\n                local_search_point = self.best_solution_overall + np.random.normal(0,0.2,self.dim) #Increased exploration radius\n                local_search_point = np.clip(local_search_point, self.lower_bounds, self.upper_bounds)\n                local_fitness = objective_function(np.array([local_search_point]))[0]\n                self.eval_count += 1\n                if local_fitness < self.best_fitness_overall:\n                    self.best_fitness_overall = local_fitness\n                    self.best_solution_overall = local_search_point.copy()\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["9fcaae9d-f570-4abf-b3b6-c0e8a44e1b41"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07740939955359892]}}
{"id": "1b20f52c-9bcc-4b17-99ca-4138729c874f", "fitness": 0.025729734795379322, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation, diversity-based mutation scaling, and improved archive management for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 200 # Increased archive size for better exploration\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 10\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        previous_best = self.best_fitness_overall\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += (self.F * (1 + 0.1 * np.random.rand()) * mutation_vector) #Diversity based scaling\n\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = offspring[i].copy()\n                        self.best_fitness_overall = fitness_values[i]\n                        self.stagnation_counter = 0 #reset stagnation counter\n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n                \n            if self.best_fitness_overall == previous_best:\n                self.stagnation_counter +=1\n            else:\n                previous_best = self.best_fitness_overall\n                \n            #local search triggered by stagnation\n            if self.stagnation_counter >= self.stagnation_threshold:\n                # Implement local search here (e.g., Nelder-Mead)\n                pass # placeholder for local search\n\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                mean = np.mean(selected_solutions, axis=0)\n                cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["0a5721fa-58cf-41e8-a5ce-7a719ac85a98"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07718920438613797]}}
{"id": "5d65342a-7ac2-4309-80ee-6bded96bcd06", "fitness": 0.025262613020265227, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with enhanced local search triggered by stagnation, diversity-based mutation scaling, and improved archive management for better exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim # Rule of thumb\n        self.F = 0.8 # DE scaling factor\n        self.CR = 0.9 # DE crossover rate\n        self.covariance_matrix = np.eye(self.dim) # Initial covariance matrix\n        self.learning_rate = 0.1 # Learning rate for covariance matrix adaptation\n        self.archive = [] # Archive of good solutions\n        self.archive_size = 200 # Increased archive size for better exploration\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 10\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        best_index = np.argmin(fitness_values)\n        self.best_solution_overall = population[best_index].copy()\n        self.best_fitness_overall = fitness_values[best_index]\n\n        previous_best = self.best_fitness_overall\n        for _ in range(self.budget // self.population_size):\n            offspring = []\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n\n                # Adaptive mutation using covariance matrix\n                mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n                mutant += (self.F * (1 + 0.1 * np.random.rand()) * mutation_vector) #Diversity based scaling\n\n\n                # Clip to bounds\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                offspring.append(trial)\n\n            offspring = np.array(offspring)\n            offspring_fitness = objective_function(offspring)\n            self.eval_count += self.population_size\n\n\n            for i in range(self.population_size):\n                if offspring_fitness[i] < fitness_values[i]:\n                    population[i] = offspring[i]\n                    fitness_values[i] = offspring_fitness[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = offspring[i].copy()\n                        self.best_fitness_overall = fitness_values[i]\n                        self.stagnation_counter = 0 #reset stagnation counter\n                    self.archive.append((offspring[i], offspring_fitness[i]))\n                    self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size]\n                \n            if self.best_fitness_overall == previous_best:\n                self.stagnation_counter +=1\n            else:\n                previous_best = self.best_fitness_overall\n                \n            #local search triggered by stagnation\n            if self.stagnation_counter >= self.stagnation_threshold:\n                # Implement local search here (e.g., Nelder-Mead)\n                pass # placeholder for local search\n\n\n            # Covariance matrix adaptation\n            selected_solutions = np.array([sol for sol, fit in self.archive])\n            if selected_solutions.shape[0] > 0:\n                mean = np.mean(selected_solutions, axis=0)\n                cov = np.cov(selected_solutions, rowvar=False)\n                self.covariance_matrix = (1 - self.learning_rate) * self.covariance_matrix + self.learning_rate * cov\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["0a5721fa-58cf-41e8-a5ce-7a719ac85a98"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07578783906079568]}}
{"id": "fc420483-33e1-4e29-a4e4-b30790fbfafa", "fitness": 0.031241331219179467, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) #Initial covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Covariance Matrix Adaptation\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                # Update Covariance Matrix (simple example -  consider more sophisticated updates)\n                mean = np.mean(np.array([sol for sol, _ in self.archive]),axis=0)\n                diffs = np.array([sol - mean for sol,_ in self.archive])\n                self.C = np.cov(diffs, rowvar=False) + 0.1 * np.eye(self.dim) #Regularization\n\n                # Sample from multivariate normal\n                new_mutations = np.random.multivariate_normal(mean, self.C, self.population_size)\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3bdd94fe-7082-421a-b11c-0c4ae0b63d7a"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0937239936575384]}}
{"id": "1787c9dd-cf5e-4f32-bac6-71b97fcc5c26", "fitness": 0.03144866822481946, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix for better capturing the solution landscape.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.covariance_matrix = np.eye(self.dim) # Initialize covariance matrix\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and covariance matrix\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model  using covariance matrix\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 5), covariance_type='full') # Adjust number of components as needed\n                gm.fit(np.array([sol for sol, _ in self.archive])) #Fit only on solutions, not fitness values\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + np.dot(new_mutations,self.covariance_matrix)* 0.2, self.lower_bounds, self.upper_bounds) # blend with covariance\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3bdd94fe-7082-421a-b11c-0c4ae0b63d7a"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09434600467445838]}}
{"id": "e8acc75e-ae25-413b-8f7f-e0f9d6fa93ef", "fitness": 0.03128761091605996, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a more robust covariance estimation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full',  reg_covar=1e-6) # Added reg_covar for robustness\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["a500227c-576e-462c-926d-41399eea125f"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09386283274817987]}}
{"id": "11080892-f14f-4054-a985-dc812cf110cb", "fitness": 0.031376092661839716, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation to better capture the solution landscape, improving GMM component selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 5), covariance_type='full',random_state=42) # Adjust number of components as needed and added random_state for reproducibility.\n                gm.fit(np.array([sol for sol, _ in self.archive])) #Fit only on solutions, not fitness values\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3bdd94fe-7082-421a-b11c-0c4ae0b63d7a"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09412827798551915]}}
{"id": "e2029dff-6121-4f78-893d-ca8accc1fc22", "fitness": 0.03096495876978536, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation and improved diversity preservation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.diversity_threshold = 0.1 #Added diversity threshold\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full')\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management and Diversity Preservation\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n            # Adaptive F and CR (simplified for brevity)\n            if i % 10 == 0 and i > 0:\n                self.F = max(0.1, self.F + 0.1 * np.random.randn())\n                self.CR = max(0.1, min(1.0, self.CR + 0.1 * np.random.randn()))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["a500227c-576e-462c-926d-41399eea125f"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09289487630935608]}}
{"id": "14f70475-0a11-4bcf-b37b-d48ddb55584d", "fitness": 0.03258297154509717, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["a500227c-576e-462c-926d-41399eea125f"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09774891463529152]}}
{"id": "5a0eaced-9263-49d7-a199-3639472e9210", "fitness": 0.03125730516627492, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and refined Gaussian Mixture Model for mutation using BIC for optimal component selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\nfrom sklearn.mixture import GaussianMixture\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model with BIC for optimal component selection\n                best_bic = np.inf\n                best_n_components = 1\n                for n_components in range(1, min(len(self.archive), 10)): # Adjust upper bound as needed\n                    gm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=0)\n                    gm.fit(np.array([sol for sol, _ in self.archive]))\n                    bic = gm.bic(np.array([sol for sol, _ in self.archive]))\n                    if bic < best_bic:\n                        best_bic = bic\n                        best_n_components = n_components\n                gm = GaussianMixture(n_components=best_n_components, covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3bdd94fe-7082-421a-b11c-0c4ae0b63d7a"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09377191549882474]}}
{"id": "8cb14c45-6ffa-418c-8b58-0ca9305f748a", "fitness": 0.025577903651576302, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration, incorporating a dynamic population size adjustment.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Dynamic Population Size Adjustment\n            self.population_size = int(10 * self.dim * (1 + np.exp(-i/self.budget))) # Adjusts population over time\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["14f70475-0a11-4bcf-b37b-d48ddb55584d"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0767337109547289]}}
{"id": "db36525e-091b-434d-9bca-034bb2d212d3", "fitness": 0.025714484964424227, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and covariance matrix adaptation for better landscape capture and exploration, incorporating a dynamic population size adjustment.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Dynamic Population Size Adjustment\n            self.population_size = int(10 * self.dim + 5 * np.log(i+1)) #Increased population size gradually\n            population = np.concatenate((population, np.random.uniform(self.lower_bounds, self.upper_bounds,(self.population_size - len(population),self.dim))))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["14f70475-0a11-4bcf-b37b-d48ddb55584d"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07714345489327268]}}
{"id": "bc052637-3a8b-41a0-a914-664de720cf2a", "fitness": 0.03147547623795634, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix for better capturing the solution landscape, improving GMM component selection and adding a local search.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 5), covariance_type='full', random_state=42) # Adjust number of components as needed, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive])) #Fit only on solutions, not fitness values\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["3bdd94fe-7082-421a-b11c-0c4ae0b63d7a"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09442642871386901]}}
{"id": "eae39388-40fc-4e8c-bef6-e44fc1bc0874", "fitness": 0.03255766668581623, "name": "HybridAdaptiveDE", "description": "Hybrid Differential Evolution with adaptive Gaussian Mixture Model mutation and covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.covariance_matrix = np.eye(self.dim) # Initialize covariance matrix\n        self.gmm_components = 5 # Number of GMM components\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and covariance matrix\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model  using covariance matrix\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), self.gmm_components), covariance_type='full', random_state=42) # added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive])) #Fit only on solutions, not fitness values\n                # Sample from GMM for mutation and blend with DE offspring\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + 0.3 * (new_mutations - np.mean(new_mutations, axis=0)), self.lower_bounds, self.upper_bounds) # blend with covariance\n\n                # Update covariance matrix\n                self.covariance_matrix = np.cov(np.array([sol for sol, _ in self.archive]).T)\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm HybridAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["1787c9dd-cf5e-4f32-bac6-71b97fcc5c26"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0976730000574487]}}
{"id": "8c0ea6ca-83bd-488a-9320-610e9bb464d0", "fitness": 0.031518934239900154, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation to better capture the solution landscape, improving GMM component selection and adding a local search step.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 5), covariance_type='full',random_state=42) # Adjust number of components as needed and added random_state for reproducibility.\n                gm.fit(np.array([sol for sol, _ in self.archive])) #Fit only on solutions, not fitness values\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds) # blend\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n            #Local Search (added)\n            if self.eval_count < self.budget:\n                local_search_solution = self.local_search(self.best_solution_overall, objective_function)\n                if local_search_solution[1] < self.best_fitness_overall:\n                    self.best_solution_overall = local_search_solution[0]\n                    self.best_fitness_overall = local_search_solution[1]\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n\n    def local_search(self, x, objective_function):\n        # Simple local search (hill climbing)\n        step_size = 0.1\n        for i in range(10): #Limit iterations to avoid excessive evaluations\n            for j in range(self.dim):\n                x_plus = x.copy()\n                x_plus[j] += step_size\n                x_minus = x.copy()\n                x_minus[j] -= step_size\n                x_plus = np.clip(x_plus, self.lower_bounds, self.upper_bounds)\n                x_minus = np.clip(x_minus, self.lower_bounds, self.upper_bounds)\n                f_plus = objective_function(x_plus.reshape(1,-1))[0]\n                f_minus = objective_function(x_minus.reshape(1,-1))[0]\n                self.eval_count += 2\n                if f_plus < self.best_fitness_overall:\n                    x = x_plus\n                    self.best_fitness_overall = f_plus\n                elif f_minus < self.best_fitness_overall:\n                    x = x_minus\n                    self.best_fitness_overall = f_minus\n                if self.eval_count >= self.budget:\n                    break\n            if self.eval_count >= self.budget:\n                break\n        return x, self.best_fitness_overall\n", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["11080892-f14f-4054-a985-dc812cf110cb"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09455680271970046]}}
{"id": "687654f2-0f50-43e0-bfcb-d4295b498236", "fitness": 0.031076349236629098, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation to better capture the solution landscape, improving GMM component selection and adding a local search step.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 20), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["a500227c-576e-462c-926d-41399eea125f"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0932290477098873]}}
{"id": "72b224ed-e723-4120-877e-d5697487eb3c", "fitness": 0.17752983888815335, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.14.", "error": "", "parent_ids": ["14f70475-0a11-4bcf-b37b-d48ddb55584d"], "operator": null, "metadata": {"aucs": [0.0, 0.20029746897795433, 0.3322920476865058]}}
{"id": "8be3d2eb-86be-4066-aa34-a62cbc2d6ec2", "fitness": 0.03289285913754066, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration, incorporating a Levy flight mutation for enhanced exploration in later stages.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here.  Only change in this response.\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step*(1-(i/(self.budget-self.population_size))), self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["14f70475-0a11-4bcf-b37b-d48ddb55584d"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.098678577412622]}}
{"id": "5efff939-93c2-4262-b357-2c15f55805a3", "fitness": 0.031408939401023954, "name": "HybridAdaptiveDE", "description": "Hybrid Differential Evolution with Adaptive Gaussian Mixture Model mutation and enhanced archive-based diversity preservation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.diversity_threshold = 0.1 #parameter to control diversity\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full')\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n\n            #Enhanced Archive Management with Diversity Check\n            for j in range(self.population_size):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((population[j], fitness_values[j]))\n                else:\n                    if fitness_values[j] < np.max([f for _, f in self.archive]):\n                        worst_index = np.argmax([f for _, f in self.archive])\n                        #Diversity Check: Replace only if diversity is maintained\n                        if self.check_diversity(population[j], self.archive, self.diversity_threshold):\n                            self.archive.pop(worst_index)\n                            self.archive.append((population[j], fitness_values[j]))\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n    \n    def check_diversity(self, new_solution, archive, threshold):\n        distances = np.array([np.linalg.norm(new_solution - sol) for sol, _ in archive])\n        return np.all(distances > threshold)\n", "configspace": "", "generation": 4, "feedback": "The algorithm HybridAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["a500227c-576e-462c-926d-41399eea125f"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09422681820307185]}}
{"id": "503f7e27-f465-4e0d-b4a5-28aa4ce7ba6a", "fitness": 0.0314439659220113, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix for better capturing the solution landscape, improving GMM component selection and adding a local search phase.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n\n            #Local Search (added)\n            for j in range(self.population_size):\n                if fitness_values[j] < self.best_fitness_overall *1.1: #condition to check if it's worth running local search\n                  self.local_search(objective_function, population[j])\n\n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n\n    def local_search(self, objective_function, solution):\n        step_size = 0.1\n        for i in range(10):  # Limited local search iterations\n            for j in range(self.dim):\n                temp_sol = solution.copy()\n                temp_sol[j] += np.random.uniform(-step_size, step_size)\n                temp_sol = np.clip(temp_sol, self.lower_bounds, self.upper_bounds)\n                temp_fitness = objective_function(temp_sol.reshape(1,-1))[0]\n                self.eval_count += 1\n                if temp_fitness < self.best_fitness_overall:\n                    self.best_fitness_overall = temp_fitness\n                    self.best_solution_overall = temp_sol\n                if temp_fitness < objective_function(solution.reshape(1,-1))[0]:\n                    solution = temp_sol", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["a500227c-576e-462c-926d-41399eea125f"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09433189776603389]}}
{"id": "00382b1b-5b8a-4beb-a86a-8d3714d2d5e0", "fitness": -Infinity, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, incorporating a Levy flight mutation for enhanced exploration in later stages and refined archive management.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.levy_alpha = 1.5 # Levy flight parameter\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) \n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations_cma = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight\n                levy_steps = levy_stable.rvs(self.levy_alpha, 0, scale=0.1, size=(self.population_size, self.dim))\n                new_mutations = np.clip(crossed + new_mutations_cma * 0.2 + levy_steps, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management - improved elitism\n            for j in range(self.population_size):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((population[j], fitness_values[j]))\n                else:\n                    if fitness_values[j] < np.max([f for _, f in self.archive]):\n                        worst_index = np.argmax([f for _, f in self.archive])\n                        self.archive.pop(worst_index)\n                        self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 66, 168, '                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\\n', 66, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 66, 168, '                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\\n', 66, 184))", "parent_ids": ["72b224ed-e723-4120-877e-d5697487eb3c"], "operator": null, "metadata": {}}
{"id": "6892c0dc-d335-4acb-9125-1486deb2986b", "fitness": 0.025623823641279103, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and refined GMM mutation using covariance matrix adaptation for better landscape capture and improved exploration, incorporating a Levy flight mutation for enhanced exploration in later stages and dynamic population size adjustment.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step, self.lower_bounds, self.upper_bounds) # added levy flight\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.population_size = int(10 * self.dim * (1 + np.exp(-0.1 * i))) #dynamic population size\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["14f70475-0a11-4bcf-b37b-d48ddb55584d"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07687147092383731]}}
{"id": "7d287bb7-3b8c-438e-8ceb-a7ec7b21b38a", "fitness": 0.02555737315512867, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration, incorporating a Levy flight mutation for enhanced exploration in later stages, and a dynamic population size adjustment.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step*(1-(i/(self.budget-self.population_size))), self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Dynamic population size adjustment (added)\n            self.population_size = int(10 * self.dim * (1 + 0.1 * (self.budget - self.eval_count) / self.budget))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["8be3d2eb-86be-4066-aa34-a62cbc2d6ec2"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07667211946538602]}}
{"id": "bbc224fd-8de6-4d66-aed2-0a748d4be6de", "fitness": 0.025797826742180344, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration, incorporating a Levy flight mutation for enhanced exploration in later stages, and refined archive management to prioritize diverse solutions.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step*(1-(i/(self.budget-self.population_size))), self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management  ---Only changed line---\n            self.archive = sorted(self.archive, key=lambda item: item[1])[:self.archive_size] #Prioritize best solutions\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["8be3d2eb-86be-4066-aa34-a62cbc2d6ec2"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07739348022654104]}}
{"id": "a6288c54-c722-4f59-ac51-4e3dd5d6c6e5", "fitness": 0.031911771200852194, "name": "HybridAdaptiveDE_Improved", "description": "Hybrid Differential Evolution enhanced with adaptive Gaussian Mixture Model mutation, covariance matrix adaptation, and a diversity-preserving archive.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass HybridAdaptiveDE_Improved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.covariance_matrix = np.eye(self.dim) # Initialize covariance matrix\n        self.gmm_components = 5 # Number of GMM components\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and covariance matrix\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model  using covariance matrix\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), self.gmm_components), covariance_type='full', random_state=42) # added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive])) #Fit only on solutions, not fitness values\n                # Sample from GMM for mutation and blend with DE offspring\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                crossed = np.clip(crossed + 0.3 * (new_mutations - np.mean(new_mutations, axis=0)), self.lower_bounds, self.upper_bounds) # blend with covariance\n\n                # Update covariance matrix\n                self.covariance_matrix = np.cov(np.array([sol for sol, _ in self.archive]).T) + 0.1 * np.eye(self.dim) #Regularization\n\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm HybridAdaptiveDE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["eae39388-40fc-4e8c-bef6-e44fc1bc0874"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09573531360255659]}}
{"id": "1a4d407e-1e50-444b-94f9-c00d62e0b091", "fitness": 0.03286715707588238, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, incorporating Levy flights for enhanced exploration in later generations.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.alpha = 1.5 # Levy flight parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full')\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                # Incorporate Levy Flights for enhanced exploration in later generations.\n                levy_step = levy_stable.rvs(self.alpha, 0, scale=0.1, size=(self.population_size, self.dim)) # Adjust scale as needed\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step * (1 - i / self.budget), self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["14f70475-0a11-4bcf-b37b-d48ddb55584d"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09860147122764713]}}
{"id": "a28058cd-393a-419b-a05b-8b75d0af92e5", "fitness": 0.20604728233542047, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    # Modification 1: Use a learning rate for covariance matrix update\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.18.", "error": "", "parent_ids": ["72b224ed-e723-4120-877e-d5697487eb3c"], "operator": null, "metadata": {"aucs": [0.0014360273660971089, 0.43860678977270323, 0.178099029867461]}}
{"id": "55b6c56a-9c69-4d2f-91e7-2a8cbbc4cf7e", "fitness": 0.05460836155464663, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration, incorporating a Levy flight mutation for enhanced exploration in later stages, and refined parameter adaptation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_damp = 0.99 #damping factor for F\n        self.CR_damp = 0.995 #damping factor for CR\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step*(1-(i/(self.budget-self.population_size))), self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n            #Adapt F and CR\n            self.F *= self.F_damp\n            self.CR *= self.CR_damp\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.06.", "error": "", "parent_ids": ["8be3d2eb-86be-4066-aa34-a62cbc2d6ec2"], "operator": null, "metadata": {"aucs": [0.029032210180721697, 0.0, 0.1347928744832182]}}
{"id": "9958b9b2-00ed-475f-9e25-e5065c604dab", "fitness": 0.03235270121954067, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration, incorporating a Levy flight mutation for enhanced exploration in later stages and improved archive management.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_stable.rvs(1.5, 0, scale=0.1, size=(self.population_size,self.dim)), self.lower_bounds, self.upper_bounds) #Added Levy flight\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["14f70475-0a11-4bcf-b37b-d48ddb55584d"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09705810365862201]}}
{"id": "e30a338a-264a-4b4f-a0ec-aa3c0114cb94", "fitness": 0.29781053015128994, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) #More robust update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.33.", "error": "", "parent_ids": ["72b224ed-e723-4120-877e-d5697487eb3c"], "operator": null, "metadata": {"aucs": [0.7524007917907823, 0.0, 0.1410307986630874]}}
{"id": "658b59a4-14f9-437a-83e3-a9c52dd5be52", "fitness": -Infinity, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and improved GMM initialization.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=42) #Improved GMM initialization with random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 63, 168, '                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\\n', 63, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 63, 168, '                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\\n', 63, 184))", "parent_ids": ["72b224ed-e723-4120-877e-d5697487eb3c"], "operator": null, "metadata": {}}
{"id": "82c47cb7-f191-4245-9afb-62cceeffea2d", "fitness": 0.032417785771632644, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, and a refined Gaussian Mixture Model for mutation using a covariance matrix adaptation for better landscape capture and improved exploration, incorporating a Levy flight mutation for enhanced exploration in later stages, and refined parameter adaptation, with improved covariance matrix update frequency.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step*(1-(i/(self.budget-self.population_size))), self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA) - **Modified line to update more frequently**\n                if i % 5 == 0 and len(self.archive) > 0: # Update every 5 iterations\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["8be3d2eb-86be-4066-aa34-a62cbc2d6ec2"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09725335731489794]}}
    {"id": "008164de-960f-4f09-be0f-a8926c07fb9a", "fitness": 0.6399042786130745, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined parameter adaptation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size) #Added sigma for step size control\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) #More robust update\n                    self.sigma *= 0.99 #Adapt sigma for better convergence\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.25.", "error": "", "parent_ids": ["e30a338a-264a-4b4f-a0ec-aa3c0114cb94"], "operator": null, "metadata": {"aucs": [0.8407803288501235, 0.7880362898740088, 0.2908962171150913]}}
{"id": "6e53811f-1066-40b1-9ad5-22600b2a159c", "fitness": 0.17816117246831123, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and increased GMM components for better landscape capture.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 20), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) #More robust update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.14.", "error": "", "parent_ids": ["e30a338a-264a-4b4f-a0ec-aa3c0114cb94"], "operator": null, "metadata": {"aucs": [0.20327428623109603, 0.0, 0.33120923117383766]}}
{"id": "11e358ef-c4ea-4ff7-a1c4-ace6c1eca478", "fitness": 0.0607635524559734, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined Levy flight mutation strategy.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_damp = 0.99 #damping factor for F\n        self.CR_damp = 0.995 #damping factor for CR\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1 * (1 - i/(self.budget - self.population_size)), size=(self.population_size, self.dim)) #Refined Levy flight\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step, self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n            #Adapt F and CR\n            self.F *= self.F_damp\n            self.CR *= self.CR_damp\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.05.", "error": "", "parent_ids": ["55b6c56a-9c69-4d2f-91e7-2a8cbbc4cf7e"], "operator": null, "metadata": {"aucs": [0.031728703721642944, 0.01709790956944306, 0.1334640440768342]}}
{"id": "f61387e7-f1f8-4b9c-a4f0-f97e7794ae55", "fitness": 0.4554669650726553, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = max(10 * self.dim, 50)  # Refined population size: minimum 50\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.22.", "error": "", "parent_ids": ["e30a338a-264a-4b4f-a0ec-aa3c0114cb94"], "operator": null, "metadata": {"aucs": [0.44560222941716654, 0.7332386279754856, 0.18756003782531386]}}
{"id": "f7a9daa3-9f02-4764-9cd4-2bcf9e74fc40", "fitness": 0.05826631309529065, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined Levy flight.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_damp = 0.99 #damping factor for F\n        self.CR_damp = 0.995 #damping factor for CR\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step*(1-(i/(self.budget-self.population_size))), self.lower_bounds, self.upper_bounds) # refined Levy flight scaling\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n            #Adapt F and CR\n            self.F *= self.F_damp\n            self.CR *= self.CR_damp\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.06.", "error": "", "parent_ids": ["55b6c56a-9c69-4d2f-91e7-2a8cbbc4cf7e"], "operator": null, "metadata": {"aucs": [0.03922778798918672, 0.0, 0.13557115129668523]}}
{"id": "d3b806c7-3cb7-48b3-a122-b7bcfc9ba0ee", "fitness": 0.056330158522913114, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and increased GMM components.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_damp = 0.99 #damping factor for F\n        self.CR_damp = 0.995 #damping factor for CR\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 20), covariance_type='full') #Increased n_components for better landscape capture\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                #Levy Flight Mutation added here\n                levy_step = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=(self.population_size, self.dim))\n                crossed = np.clip(crossed + new_mutations * 0.2 + levy_step*(1-(i/(self.budget-self.population_size))), self.lower_bounds, self.upper_bounds)\n\n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.8 * self.C + 0.2 * np.outer(best_archive_sol,best_archive_sol)\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n\n            #Adapt F and CR\n            self.F *= self.F_damp\n            self.CR *= self.CR_damp\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.06.", "error": "", "parent_ids": ["55b6c56a-9c69-4d2f-91e7-2a8cbbc4cf7e"], "operator": null, "metadata": {"aucs": [0.03448729470757272, 0.0, 0.1345031808611666]}}
{"id": "01fdce5f-37a2-459c-8af5-36e20387b078", "fitness": 0.32644667105706004, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    # Modification 1: Use a learning rate for covariance matrix update\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Modification: Prioritize solutions closer to the best solution overall.\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]) or np.linalg.norm(population[j]-self.best_solution_overall)<np.linalg.norm(np.array([sol for sol, _ in self.archive])[np.argmax([f for _, f in self.archive])]-self.best_solution_overall):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.10.", "error": "", "parent_ids": ["a28058cd-393a-419b-a05b-8b75d0af92e5"], "operator": null, "metadata": {"aucs": [0.2678549319597697, 0.472066974997862, 0.23941810621354842]}}
{"id": "79fe57e1-491e-49c4-b082-49599ec3d704", "fitness": 0.30428656620293876, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection strategy.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    # Modification 1: Use a learning rate for covariance matrix update\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  # Refined archive selection:  Select the worst solution based on a weighted fitness and distance from the best solution.\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 0.1 * distances #Added a small penalty for distant solutions\n                  index_to_remove = np.argmax(weighted_fitness)\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.10.", "error": "", "parent_ids": ["a28058cd-393a-419b-a05b-8b75d0af92e5"], "operator": null, "metadata": {"aucs": [0.20180546609248284, 0.43128386073604896, 0.27977037178028447]}}
{"id": "4128b85b-1ef6-4688-91e0-976221127838", "fitness": -Infinity, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined parameter adaptation, and improved archive selection based on fitness percentile.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size) #Added sigma for step size control\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\n                    self.sigma *= 0.99 #Adapt sigma for better convergence\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  #Improved archive selection: replace worst 10% instead of single worst\n                  archive_fitness = np.array([f for _, f in self.archive])\n                  threshold = np.percentile(archive_fitness, 90) #Select top 90%\n                  indices_to_remove = np.where(archive_fitness > threshold)[0]\n                  for index in indices_to_remove:\n                      self.archive[index] = (population[j], fitness_values[j])\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184))", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {}}
{"id": "dae6b620-24eb-4dd2-99ed-a08e4cf4fd2a", "fitness": -Infinity, "name": "AdaptiveGaussianDEImproved", "description": "Hybrid Differential Evolution with Adaptive Gaussian Mixture Model mutation and enhanced archive management for robust exploration and exploitation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n        self.gmm_components = min(10, self.dim) #Adaptive number of GMM components\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=self.gmm_components, covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 65, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 65, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 65, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 65, 184))", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {}}
{"id": "4baf7892-578b-41dc-94e6-d319dc86583b", "fitness": -Infinity, "name": "AdaptiveGaussianDEImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing, with improved Gaussian Mixture Model component selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size, refined sizing\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive)//2 +1, 10), covariance_type='full', random_state=0) #Improved GMM component selection\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size) #Added sigma for step size control\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\n                    self.sigma *= 0.99 #Adapt sigma for better convergence\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184))", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {}}
{"id": "b5d53a74-7020-4389-b977-cc0add318204", "fitness": -Infinity, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism, improved GMM fitting and archive prioritization.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 20), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility and increased n_components\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    # Modification 1: Use a learning rate for covariance matrix update\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Modification: Prioritize solutions closer to the best solution overall.  Improved prioritization logic.\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]) or np.linalg.norm(population[j]-self.best_solution_overall) < 0.8*np.linalg.norm(np.array([sol for sol, _ in self.archive])[np.argmax([f for _, f in self.archive])]-self.best_solution_overall): #Prioritize solutions closer to the best\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 65, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\\n', 65, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 65, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) # Centered CMA update\\n', 65, 210))", "parent_ids": ["01fdce5f-37a2-459c-8af5-36e20387b078"], "operator": null, "metadata": {}}
{"id": "1116ba44-59ce-4bf1-9bb6-3d58de29b632", "fitness": 0.5531983771517648, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.55 with standard deviation 0.29.", "error": "", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {"aucs": [0.6648282939157935, 0.8354902825927373, 0.1592765549467636]}}
{"id": "5077d250-4fd0-40db-87de-2178fc037436", "fitness": 0.21616160207367133, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism with enhanced diversity preservation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.diversity_threshold = 0.1 #Added for diversity preservation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    # Modification 1: Use a learning rate for covariance matrix update\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Modification: Prioritize solutions closer to the best solution overall and maintain diversity.\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  #Diversity preservation: Calculate distances and only replace if significantly different\n                  distances = np.linalg.norm(population[j] - np.array([sol for sol, _ in self.archive]), axis=1)\n                  if fitness_values[j] < np.max([f for _, f in self.archive]) or np.min(distances) > self.diversity_threshold * np.linalg.norm(self.upper_bounds - self.lower_bounds): #Added diversity check\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.19.", "error": "", "parent_ids": ["01fdce5f-37a2-459c-8af5-36e20387b078"], "operator": null, "metadata": {"aucs": [0.4753610286621599, 0.04388202654518108, 0.12924175101367302]}}
{"id": "c614cdab-0802-4078-b35f-5a1d0508f26b", "fitness": 0.502446334547767, "name": "AdaptiveGaussianDEImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection strategy with improved distance weighting and archive size adaptation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 0.5 * distances #Increased distance weight\n                  index_to_remove = np.argmax(weighted_fitness)\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveGaussianDEImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.50 with standard deviation 0.28.", "error": "", "parent_ids": ["79fe57e1-491e-49c4-b082-49599ec3d704"], "operator": null, "metadata": {"aucs": [0.6551439532553339, 0.7416780727414015, 0.11051697764656546]}}
{"id": "a350538c-4255-4d9a-96b3-cd57cd6a620e", "fitness": 0.1543853077958189, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing, incorporating a Levy flight mutation operator for enhanced exploration.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = max(10 * self.dim, 50)  # Refined population size: minimum 50\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n                #Levy Flight Mutation\n                levy = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=self.dim)\n                mutated[j] += levy\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_ids": ["f61387e7-f1f8-4b9c-a4f0-f97e7794ae55"], "operator": null, "metadata": {"aucs": [0.1331819684242083, 0.1955238400605215, 0.1344501149027269]}}
{"id": "414c693d-2323-4981-ba7a-a7f28418131c", "fitness": 0.45831402865120224, "name": "AdaptiveGaussianDE_Improved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism with prioritized diversity.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE_Improved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) \n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Prioritize diversity and proximity to best solution\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.array([np.linalg.norm(population[j] - sol) for sol, _ in self.archive])\n                  worst_index = np.argmax([f for _, f in self.archive])\n                  if fitness_values[j] < self.archive[worst_index][1] or distances[worst_index] < np.min(distances): #Prioritize diversity if fitness is comparable\n                      self.archive.pop(worst_index)\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveGaussianDE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.14.", "error": "", "parent_ids": ["01fdce5f-37a2-459c-8af5-36e20387b078"], "operator": null, "metadata": {"aucs": [0.5154883009500781, 0.5942333868371833, 0.2652203981663454]}}
{"id": "2b9c8a3f-4f9b-4d8c-8c18-be2ff16b0fd0", "fitness": 0.14643508466251945, "name": "AdaptiveGaussianDE", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism with elitism and diversity preservation.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    # Modification 1: Use a learning rate for covariance matrix update\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0)) # Centered CMA update\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Modification: Prioritize solutions closer to the best solution overall and maintain diversity.\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  #Modification 2:  Add diversity check using Euclidean distance.\n                  distances = np.array([np.linalg.norm(population[j] - sol) for sol, _ in self.archive])\n                  if fitness_values[j] < np.max([f for _, f in self.archive]) or np.min(distances) > 0.5 * np.mean(distances): #Added diversity check.  Replace 0.5 with a tunable parameter if needed\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveGaussianDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.07.", "error": "", "parent_ids": ["01fdce5f-37a2-459c-8af5-36e20387b078"], "operator": null, "metadata": {"aucs": [0.08357927631473522, 0.10793290120076598, 0.24779307647205712]}}
{"id": "e5fb61b3-68c6-44a5-8e15-6132edbbe092", "fitness": -Infinity, "name": "AdaptiveGaussianDEImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, incorporating a Levy flight mutation for enhanced exploration.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n        self.levy_alpha = 1.5 # Parameter for Levy flight\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n                #Levy flight component\n                levy_step = levy_stable.rvs(self.levy_alpha, 0, scale=0.01, size=self.dim) # Adjust scale as needed\n                mutated[j] += levy_step\n\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 63, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 63, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 63, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 63, 184))", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {}}
{"id": "7022d492-e0a3-43c2-a61b-6ba537abdde4", "fitness": -Infinity, "name": "AdaptiveGaussianDEImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined parameter adaptation with improved Gaussian Mixture Model component selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size) #Added sigma for step size control\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\n                    self.sigma *= 0.99 #Adapt sigma for better convergence\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184))", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {}}
{"id": "7cb7f22c-9804-4d47-8457-18c99038149a", "fitness": -Infinity, "name": "AdaptiveGaussianDE_Improved_Elitism", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism with prioritized diversity and elitism.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE_Improved_Elitism:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) \n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Prioritize diversity and proximity to best solution and elitism\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.array([np.linalg.norm(population[j] - sol) for sol, _ in self.archive])\n                  worst_index = np.argmax([f for _, f in self.archive])\n                  if fitness_values[j] < self.archive[worst_index][1] or distances[worst_index] < np.min(distances) or fitness_values[j] < self.best_fitness_overall: #Prioritize diversity if fitness is comparable or if better than overall best\n                      self.archive.pop(worst_index)\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210))", "parent_ids": ["414c693d-2323-4981-ba7a-a7f28418131c"], "operator": null, "metadata": {}}
{"id": "8dff23d4-7510-4a75-8fb4-ccffc003a189", "fitness": -Infinity, "name": "AdaptiveGaussianDE_Improved_v2", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution, and incorporating a dynamic archive size adjustment.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE_Improved_v2:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) \n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Prioritize diversity and proximity to best solution\n            self.archive_size = int(100 + 50 * np.log(1 + i/self.budget)) # Dynamic archive size\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.array([np.linalg.norm(population[j] - sol) for sol, _ in self.archive])\n                  worst_index = np.argmax([f for _, f in self.archive])\n                  if fitness_values[j] < self.archive[worst_index][1] or distances[worst_index] < np.min(distances): #Prioritize diversity if fitness is comparable\n                      self.archive.pop(worst_index)\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210))", "parent_ids": ["414c693d-2323-4981-ba7a-a7f28418131c"], "operator": null, "metadata": {}}
{"id": "8144b5dd-64ca-4000-aa6d-eb32582579b4", "fitness": -Infinity, "name": "AdaptiveGaussianDEImproved_v2", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved_v2:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 0.5 * distances + 0.1*np.random.rand(len(self.archive)) #Added noise for diversity\n                  index_to_remove = np.argmax(weighted_fitness)\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210))", "parent_ids": ["c614cdab-0802-4078-b35f-5a1d0508f26b"], "operator": null, "metadata": {}}
{"id": "fc08dc0a-5b26-438e-960d-cb5dc9893c8e", "fitness": 0.026018251847465177, "name": "AdaptiveGaussianDEImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, and improved archive selection prioritizing diversity and fitness.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = max(10 * self.dim, 50)  # Refined population size: minimum 50\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            #Improved Archive Selection: Prioritize diversity and fitness\n            sorted_archive = sorted(self.archive, key=lambda item: item[1])  \n            if len(self.archive) >= self.archive_size:\n                # Remove the worst solutions while maintaining diversity (simple approach)\n                to_remove = sorted_archive[:self.archive_size // 2]\n                self.archive = [item for item in self.archive if item not in to_remove]\n\n            for j in range(self.population_size):\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((population[j], fitness_values[j]))\n\n\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveGaussianDEImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["f61387e7-f1f8-4b9c-a4f0-f97e7794ae55"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07805475554239553]}}
{"id": "183f07c3-98a5-4722-9ac7-94fa833e7395", "fitness": 0.21242186138030253, "name": "AdaptiveGaussianDEImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, and improved archive selection prioritizing diversity and fitness.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    #Improved Archive Selection: Prioritize diversity and fitness\n                    archive_array = np.array([sol for sol, _ in self.archive])\n                    archive_fitness = np.array([f for _, f in self.archive])\n                    distances = np.linalg.norm(archive_array - np.mean(archive_array, axis=0), axis=1)\n                    diversity_weights = 1.0 / (distances + 1e-9) #Avoid division by zero\n                    weighted_fitness = archive_fitness * diversity_weights\n                    best_archive_index = np.argmin(weighted_fitness)\n                    best_archive_sol = archive_array[best_archive_index]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean(archive_array, axis=0),best_archive_sol - np.mean(archive_array, axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveGaussianDEImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.22.", "error": "", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {"aucs": [0.5196994445920124, 0.00983431552227996, 0.10773182402661521]}}
{"id": "7c7a5ed5-5539-48f1-a39f-7dc325349376", "fitness": 0.5349058694925428, "name": "AdaptiveGaussianDEImprovedRefined", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 1.5 * distances #Increased distance weight and proximity weight\n                  index_to_remove = np.argmax(weighted_fitness) #remove worst solution considering both fitness and diversity\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveGaussianDEImprovedRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.53 with standard deviation 0.23.", "error": "", "parent_ids": ["c614cdab-0802-4078-b35f-5a1d0508f26b"], "operator": null, "metadata": {"aucs": [0.600475438417799, 0.7820089290993039, 0.22223324096052563]}}
{"id": "19a28c46-2f2a-4690-873a-bdb97109db48", "fitness": 0.24516840273152443, "name": "AdaptiveGaussianDEImproved_Refined", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity based on distance and fitness.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - population[j], axis=1) #Changed this line to prioritize diversity around the newly added solution.\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 0.5 * distances #Increased distance weight\n                  index_to_remove = np.argmax(weighted_fitness)\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveGaussianDEImproved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.10.", "error": "", "parent_ids": ["c614cdab-0802-4078-b35f-5a1d0508f26b"], "operator": null, "metadata": {"aucs": [0.271586328103521, 0.34707673715514786, 0.11684214293590446]}}
{"id": "3301851e-6e33-4f66-aa5d-a5b6202ff28a", "fitness": 0.15701788877838974, "name": "AdaptiveGaussianDEImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing, incorporating a Levy flight mutation for enhanced exploration.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDEImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = max(10 * self.dim, 50)  # Refined population size: minimum 50\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n                #Levy Flight\n                levy = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.1, size=self.dim)\n                mutated[j] += levy\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveGaussianDEImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.04.", "error": "", "parent_ids": ["f61387e7-f1f8-4b9c-a4f0-f97e7794ae55"], "operator": null, "metadata": {"aucs": [0.2140572822326918, 0.1369900927332763, 0.12000629136920109]}}
{"id": "f84254fa-c593-4422-b88b-2e371f8dd5e5", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedLevy", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, incorporating a Levy flight mutation for enhanced exploration.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal, levy_stable\n\nclass AdaptiveGaussianDEImprovedLevy:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n                #Levy Flight\n                levy = levy_stable.rvs(alpha=1.5, beta=0, loc=0, scale=0.01, size=self.dim)\n                mutated[j] += levy\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 61, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 61, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 61, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 61, 184))", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {}}
{"id": "f2804113-5d7d-4e6b-bf85-54f2c93da2ac", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedPopulation", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality and improved GMM component selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedPopulation:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = max(10 * self.dim, 50)  # Adaptive population size, minimum 50\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), max(self.dim, 10)), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility and improved component selection based on dim\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size) #Added sigma for step size control\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\n                    self.sigma *= 0.99 #Adapt sigma for better convergence\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184))", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {}}
{"id": "51c323ad-65e9-42ce-a6ba-bf7db817bfbb", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedDynamic", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing dynamically adjusted based on exploration/exploitation balance.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedDynamic:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.initial_population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n        self.exploration_factor = 1.2 #factor for population size increase during exploration\n        self.exploitation_factor = 0.8 #factor for population size decrease during exploitation\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += population_size\n\n        for i in range(self.budget - population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((population_size, self.dim))\n            for j in range(population_size):\n                a, b, c = np.random.choice(np.arange(population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((population_size, self.dim))\n            for j in range(population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += population_size\n            for j in range(population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            #Dynamic Population Size Adjustment\n            if i < self.budget // 3:  # Exploration phase\n                population_size = int(population_size * self.exploration_factor)\n            elif i > 2 * self.budget // 3: # Exploitation phase\n                population_size = int(population_size * self.exploitation_factor)\n            population_size = max(10, min(population_size, 1000)) # keep it within reasonable bounds\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 66, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 66, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 66, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 66, 184))", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {}}
{"id": "0c5b50e3-446d-432d-98c8-d0115ea08942", "fitness": 0.024568771504131438, "name": "AdaptiveGaussianDEImprovedSelection", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, and improved archive selection by prioritizing solutions closer to the best solution.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedSelection:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            #Improved archive selection\n            distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n            indices_to_remove = np.argsort(distances)[-min(len(self.archive) - self.archive_size,0):]\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(indices_to_remove[0]) #Prioritize removing furthest\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveGaussianDEImprovedSelection got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07370631451239432]}}
{"id": "2d060162-2335-4dfc-807e-b9b7527cc136", "fitness": 0.6021984136242475, "name": "AdaptiveGaussianDEImprovedLocalSearch", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, incorporating a local search phase for intensified exploitation around promising solutions.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedLocalSearch:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n        self.local_search_iterations = 10 #New parameter\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        #Local search intensification\n                        current_solution = self.best_solution_overall.copy()\n                        for k in range(self.local_search_iterations):\n                            neighbor = current_solution + np.random.normal(0, 0.1, self.dim)\n                            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)\n                            neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]\n                            self.eval_count += 1\n                            if neighbor_fitness < self.best_fitness_overall:\n                                self.best_fitness_overall = neighbor_fitness\n                                self.best_solution_overall = neighbor.copy()\n                                current_solution = neighbor.copy()\n\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveGaussianDEImprovedLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60 with standard deviation 0.32.", "error": "", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {"aucs": [0.8886575565343325, 0.7638053580550349, 0.1541323262833752]}}
{"id": "d0e09b17-7c4a-4fd3-86b2-e0cf558f60dc", "fitness": 0.298127751649964, "name": "AdaptiveGaussianDEImproved2", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality and an improved archive selection mechanism.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImproved2:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = max(10 * self.dim, 50)  # Improved adaptive population size\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive])) #Improved archive selection\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveGaussianDEImproved2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.11.", "error": "", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {"aucs": [0.39055983101945113, 0.366047951202673, 0.13777547272776774]}}
{"id": "7ba69b3e-a979-48f0-95c4-23f5e5446731", "fitness": 0.4803460745327603, "name": "AdaptiveGaussianDEImprovedRefinedImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution, with improved covariance matrix learning rate.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefinedImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.5  # Improved learning rate\n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 1.5 * distances #Increased distance weight and proximity weight\n                  index_to_remove = np.argmax(weighted_fitness) #remove worst solution considering both fitness and diversity\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveGaussianDEImprovedRefinedImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.22.", "error": "", "parent_ids": ["7c7a5ed5-5539-48f1-a39f-7dc325349376"], "operator": null, "metadata": {"aucs": [0.7837903313282286, 0.3598028419631211, 0.2974450503069311]}}
{"id": "3d2e7882-ae47-4b5c-9b18-a5d965c37696", "fitness": 0.2780459164098876, "name": "AdaptiveGaussianDEImprovedRefinedImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution, with improved diversity weighting.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefinedImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 2.0 * distances #Improved diversity weighting factor\n                  index_to_remove = np.argmax(weighted_fitness) \n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveGaussianDEImprovedRefinedImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.07.", "error": "", "parent_ids": ["7c7a5ed5-5539-48f1-a39f-7dc325349376"], "operator": null, "metadata": {"aucs": [0.332438316837446, 0.32909401233027674, 0.1726054200619399]}}
{"id": "04561f02-a58f-49bc-b6a7-000233851346", "fitness": 0.03312395147578521, "name": "AdaptiveGaussianDE_ImprovedRefined", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution, with improved GMM component selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDE_ImprovedRefined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) \n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation, selecting components based on weights\n                component_weights = gm.weights_\n                selected_component = np.random.choice(len(component_weights), p=component_weights)\n                new_mutations = np.random.multivariate_normal(gm.means_[selected_component], gm.covariances_[selected_component], self.population_size)\n                #CMA adaptation - reduced influence\n                new_mutations = new_mutations * 0.1 + np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size) * 0.1\n                crossed = np.clip(crossed + new_mutations, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            #Prioritize diversity and proximity to best solution\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.array([np.linalg.norm(population[j] - sol) for sol, _ in self.archive])\n                  worst_index = np.argmax([f for _, f in self.archive])\n                  if fitness_values[j] < self.archive[worst_index][1] or distances[worst_index] < np.min(distances): #Prioritize diversity if fitness is comparable\n                      self.archive.pop(worst_index)\n                      self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveGaussianDE_ImprovedRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["414c693d-2323-4981-ba7a-a7f28418131c"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.09937185442735562]}}
{"id": "9619dd11-fda7-442a-8cfa-9e3b7ddd5818", "fitness": 0.2979464485681725, "name": "AdaptiveGaussianDEImprovedRefined", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism with prioritized diversity and adaptive archive size based on convergence rate.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.convergence_rate = 0.0\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 0.5 * distances #Increased distance weight\n                  index_to_remove = np.argmax(weighted_fitness)\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            #Adaptive Archive Size based on convergence rate\n            if i > 0 and self.best_fitness_overall < 0.99 * self.best_fitness_overall:\n                self.convergence_rate = self.convergence_rate + 0.1\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) * (1 + self.convergence_rate) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveGaussianDEImprovedRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.04.", "error": "", "parent_ids": ["c614cdab-0802-4078-b35f-5a1d0508f26b"], "operator": null, "metadata": {"aucs": [0.31807881171018965, 0.3327672516013242, 0.24299328239300355]}}
{"id": "ce34e8e8-b5f5-4968-8257-ad226cca04c6", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedRefinedEnhanced", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution, and improved GMM component number selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefinedEnhanced:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), int(10 + np.sqrt(self.dim))), covariance_type='full', random_state=0) #Improved GMM component selection\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 1.5 * distances #Increased distance weight and proximity weight\n                  index_to_remove = np.argmax(weighted_fitness) #remove worst solution considering both fitness and diversity\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210))", "parent_ids": ["7c7a5ed5-5539-48f1-a39f-7dc325349376"], "operator": null, "metadata": {}}
{"id": "48a469c4-d9a5-4b0e-b4fc-8a23190a3bef", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedRefinedImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution, and improved GMM component number selection.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefinedImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), int(10 + np.sqrt(self.dim))), covariance_type='full', random_state=0) #Improved GMM component selection\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 1.5 * distances #Increased distance weight and proximity weight\n                  index_to_remove = np.argmax(weighted_fitness) #remove worst solution considering both fitness and diversity\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210))", "parent_ids": ["7c7a5ed5-5539-48f1-a39f-7dc325349376"], "operator": null, "metadata": {}}
{"id": "052b80a1-d65b-4225-a007-2ec9eb1fba68", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedRefinedImproved", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection mechanism prioritizing diversity and proximity to the best solution, and improved covariance matrix update frequency.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefinedImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if i % 5 == 0 and len(self.archive) > 0: # Update less frequently\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 1.5 * distances #Increased distance weight and proximity weight\n                  index_to_remove = np.argmax(weighted_fitness) #remove worst solution considering both fitness and diversity\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 64, 210))", "parent_ids": ["7c7a5ed5-5539-48f1-a39f-7dc325349376"], "operator": null, "metadata": {}}
{"id": "38d13341-6f69-4fb8-a769-75dcafcdc92d", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedDiversity", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update, refined parameter adaptation, and improved archive selection prioritizing diversity.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedDiversity:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n        self.sigma = 0.5 # initial step size for CMA\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0) #Increased n_components for better landscape capture, added random_state for reproducibility\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size) #Added sigma for step size control\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\n                    self.sigma *= 0.99 #Adapt sigma for better convergence\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management  <---  CHANGE IS HERE\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  #Prioritize diversity in archive selection\n                  distances = np.array([np.linalg.norm(population[j] - sol) for sol, _ in self.archive])\n                  idx_to_replace = np.argmax(distances) #replace the furthest solution\n                  if fitness_values[j] < self.archive[idx_to_replace][1]:\n                      self.archive[idx_to_replace] = (population[j], fitness_values[j])\n            #Adapt F and CR\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 64, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0)) #More robust update\\n', 64, 184))", "parent_ids": ["008164de-960f-4f09-be0f-a8926c07fb9a"], "operator": null, "metadata": {}}
{"id": "0ac67618-6b91-451e-a69d-65e0d7642963", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedClustered", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and a refined archive selection strategy with improved distance weighting and archive size adaptation, incorporating a clustering-based diversity mechanism.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveGaussianDEImprovedClustered:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  \n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management and Diversity Enhancement\n            archive_array = np.array([sol for sol, _ in self.archive])\n            if len(archive_array) > 0:\n                kmeans = KMeans(n_clusters=min(len(archive_array), 5), random_state=0).fit(archive_array)\n                cluster_centers = kmeans.cluster_centers_\n                cluster_labels = kmeans.labels_\n\n                for j in range(self.population_size):\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append((population[j], fitness_values[j]))\n                    else:\n                        distances = np.linalg.norm(archive_array - population[j], axis=1)\n                        weighted_fitness = np.array([f for _, f in self.archive]) + 0.5 * distances #Increased distance weight\n                        index_to_remove = np.argmax(weighted_fitness)\n                        self.archive.pop(index_to_remove)\n                        self.archive.append((population[j], fitness_values[j]))\n\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 65, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 65, 210)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 65, 194, '                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 65, 210))", "parent_ids": ["c614cdab-0802-4078-b35f-5a1d0508f26b"], "operator": null, "metadata": {}}
{"id": "70e82734-7331-4e1e-9c50-49bfa6134160", "fitness": -Infinity, "name": "AdaptiveGaussianDEImprovedLocalSearchDynamicPop", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, local search, and a novel dynamic population size adjustment based on convergence rate.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedLocalSearchDynamicPop:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n        self.local_search_iterations = 10 #New parameter\n        self.convergence_rate_threshold = 0.01 #New parameter for dynamic population size\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        #Local search intensification\n                        current_solution = self.best_solution_overall.copy()\n                        for k in range(self.local_search_iterations):\n                            neighbor = current_solution + np.random.normal(0, 0.1, self.dim)\n                            neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)\n                            neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]\n                            self.eval_count += 1\n                            if neighbor_fitness < self.best_fitness_overall:\n                                self.best_fitness_overall = neighbor_fitness\n                                self.best_solution_overall = neighbor.copy()\n                                current_solution = neighbor.copy()\n\n            #Dynamic population size adjustment\n            if i > 0 and (self.best_fitness_overall - previous_best_fitness) / previous_best_fitness < self.convergence_rate_threshold:\n                self.population_size = max(10, int(self.population_size * 0.9))  # Reduce population size\n            previous_best_fitness = self.best_fitness_overall\n\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "An exception occurred: SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 59, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 59, 184)).", "error": "SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('<string>', 59, 168, '                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_in self.archive], axis=0))\\n', 59, 184))", "parent_ids": ["2d060162-2335-4dfc-807e-b9b7527cc136"], "operator": null, "metadata": {}}
{"id": "7bda86ca-9139-4918-a57b-f6c356290543", "fitness": 0.02623288898626382, "name": "AdaptiveGaussianDEImprovedRefined", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and covariance matrix adaptation, using a robust covariance update, refined archive selection prioritizing diversity and proximity, and dynamic population sizing.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 10 * self.dim  # Adaptive population size\n        self.F = 0.8 # scaling factor for DE\n        self.CR = 0.9 # crossover rate for DE\n        self.archive = [] # archive of good solutions\n        self.archive_size = 100 #Initial archive size\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.F_adapt_rate = 0.05 #rate of F adaptation\n        self.CR_adapt_rate = 0.02 #rate of CR adaptation\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            # Differential Evolution mutation and crossover\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            #Adaptive Mutation using Gaussian Mixture Model and CMA\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n              # Fit a Gaussian Mixture Model\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                # Sample from GMM for mutation\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                #CMA adaptation\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                #Update Covariance Matrix (simplified CMA)\n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    learning_rate = 0.3  #Increased learning rate for faster adaptation\n                    self.C = (1 - learning_rate) * self.C + learning_rate * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n\n            # Selection\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            # Archive Management\n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  distances = np.linalg.norm(np.array([sol for sol, _ in self.archive]) - self.best_solution_overall, axis=1)\n                  weighted_fitness = np.array([f for _, f in self.archive]) + 2 * distances #Increased distance weight for stronger diversity\n                  index_to_remove = np.argmax(weighted_fitness)\n                  self.archive.pop(index_to_remove)\n                  self.archive.append((population[j], fitness_values[j]))\n            #Adapt F and CR and adjust archive size dynamically\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            self.archive_size = int(100 + 50 * np.exp(-i/self.budget)) #Dynamic Archive Size\n            self.population_size = int(10 * self.dim * (1 + i/self.budget)) #Dynamic population size\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveGaussianDEImprovedRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["c614cdab-0802-4078-b35f-5a1d0508f26b"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07869866695879146]}}
{"id": "b769f2c6-2a74-4cbd-abff-ae09ac4c4c57", "fitness": 0.28265913578294916, "name": "AdaptiveGaussianDEImprovedRefined", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and covariance matrix adaptation, using a more robust covariance matrix update, refined population sizing, and improved archive selection prioritizing diversity and proximity to the best solution.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedRefined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.995 #Improved convergence speed\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveGaussianDEImprovedRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.13.", "error": "", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {"aucs": [0.1021584962213062, 0.3599656924958205, 0.3858532186317209]}}
{"id": "9e45def9-a229-497f-a3e7-ae91efcf8f27", "fitness": 0.607815503232129, "name": "AdaptiveGaussianDEImprovedLocalSearch", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, incorporating a local search around the best solution.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedLocalSearch:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n\n            # Local search around best solution\n            if i % 10 == 0: #added local search every 10 iterations\n                current_best = self.best_solution_overall.copy()\n                for k in range(10): #perform 10 iterations\n                  neighbor = current_best + np.random.uniform(-0.1, 0.1, self.dim)\n                  neighbor = np.clip(neighbor, self.lower_bounds, self.upper_bounds)\n                  neighbor_fitness = objective_function(neighbor.reshape(1,-1))[0]\n                  self.eval_count += 1\n                  if neighbor_fitness < self.best_fitness_overall:\n                      self.best_fitness_overall = neighbor_fitness\n                      self.best_solution_overall = neighbor.copy()\n                      current_best = neighbor.copy()\n\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveGaussianDEImprovedLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61 with standard deviation 0.27.", "error": "", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {"aucs": [0.8123366538414427, 0.7886656090326752, 0.2224442468222689]}}
{"id": "78c9acdb-492d-4062-a0d1-a6473358ce4c", "fitness": 0.41939918301438667, "name": "AdaptiveGaussianDEImprovedLocalSearch", "description": "Adaptive Gaussian Mixture Differential Evolution with enhanced archive management, adaptive F and CR, refined GMM, and a covariance matrix adaptation for improved exploration and exploitation, using a more robust covariance matrix update and refined population sizing based on problem dimensionality, incorporating a local search around the best solution.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass AdaptiveGaussianDEImprovedLocalSearch:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 5 * self.dim + 50 # Refined population sizing\n        self.F = 0.8\n        self.CR = 0.9\n        self.archive = []\n        self.archive_size = 100\n        self.C = np.eye(self.dim)\n        self.F_adapt_rate = 0.05\n        self.CR_adapt_rate = 0.02\n        self.sigma = 0.5\n\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        fitness_values = objective_function(population)\n        self.eval_count += self.population_size\n\n        for i in range(self.budget - self.population_size):\n            mutated = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                while a == j or b == j or c == j:\n                    a, b, c = np.random.choice(np.arange(self.population_size), size=3, replace=False)\n                mutated[j] = population[a] + self.F * (population[b] - population[c])\n\n            crossed = np.zeros((self.population_size, self.dim))\n            for j in range(self.population_size):\n                rand = np.random.rand(self.dim)\n                crossed[j] = np.where(rand < self.CR, mutated[j], population[j])\n\n            if len(self.archive) > self.dim and len(self.archive) > 0:\n                from sklearn.mixture import GaussianMixture\n                gm = GaussianMixture(n_components=min(len(self.archive), 10), covariance_type='full', random_state=0)\n                gm.fit(np.array([sol for sol, _ in self.archive]))\n                new_mutations = gm.sample(self.population_size)[0]\n                new_mutations = np.clip(new_mutations, self.lower_bounds, self.upper_bounds)\n                new_mutations = np.random.multivariate_normal(np.zeros(self.dim), self.C * (self.sigma**2), self.population_size)\n                crossed = np.clip(crossed + new_mutations * 0.2, self.lower_bounds, self.upper_bounds)\n                \n                if len(self.archive) > 0:\n                    best_archive_sol = np.array([sol for sol, _ in self.archive])[np.argmin([f for _, f in self.archive])]\n                    self.C = 0.9 * self.C + 0.1 * np.outer(best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0),best_archive_sol - np.mean([sol for sol,_ in self.archive], axis=0))\n                    self.sigma *= 0.99\n\n            offspring_fitness = objective_function(crossed)\n            self.eval_count += self.population_size\n            for j in range(self.population_size):\n                if offspring_fitness[j] < fitness_values[j]:\n                    fitness_values[j] = offspring_fitness[j]\n                    population[j] = crossed[j]\n                    if offspring_fitness[j] < self.best_fitness_overall:\n                        self.best_fitness_overall = offspring_fitness[j]\n                        self.best_solution_overall = crossed[j]\n                        \n            for j in range(self.population_size):\n              if len(self.archive) < self.archive_size:\n                  self.archive.append((population[j], fitness_values[j]))\n              else:\n                  if fitness_values[j] < np.max([f for _, f in self.archive]):\n                      self.archive.pop(np.argmax([f for _, f in self.archive]))\n                      self.archive.append((population[j], fitness_values[j]))\n            self.F = self.F * (1 + self.F_adapt_rate * np.random.randn())\n            self.CR = self.CR * (1 + self.CR_adapt_rate * np.random.randn())\n            self.F = np.clip(self.F, 0.1, 1)\n            self.CR = np.clip(self.CR, 0.1, 1)\n            # Local search around best solution\n            if i % 10 == 0: #Perform local search every 10 iterations\n                self.local_search(objective_function)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n\n    def local_search(self, objective_function):\n        current_solution = self.best_solution_overall.copy()\n        for _ in range(5 * self.dim): #Simple local search with a fixed number of iterations proportional to dim\n            for i in range(self.dim):\n                temp_solution = current_solution.copy()\n                temp_solution[i] += np.random.uniform(-0.1, 0.1) * (self.upper_bounds[i] - self.lower_bounds[i])\n                temp_solution = np.clip(temp_solution, self.lower_bounds, self.upper_bounds)\n                fitness = objective_function(temp_solution.reshape(1, -1))[0]\n                self.eval_count += 1\n                if fitness < self.best_fitness_overall:\n                    self.best_fitness_overall = fitness\n                    self.best_solution_overall = temp_solution.copy()\n                    current_solution = temp_solution.copy()\n\n", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveGaussianDEImprovedLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.20.", "error": "", "parent_ids": ["1116ba44-59ce-4bf1-9bb6-3d58de29b632"], "operator": null, "metadata": {"aucs": [0.49567421021568414, 0.6160442982137928, 0.14647904061368316]}}
