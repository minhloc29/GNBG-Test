2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:09 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:15 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:15 ERROR Can not run the algorithm
2025-06-15 08:58:15 INFO Run function 8 complete. FEHistory len: 0, AOCC: 0.0000
2025-06-15 08:58:15 INFO FeHistory: []
2025-06-15 08:58:15 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:15 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:15 INFO AOCC mean: 0.0000
2025-06-15 08:58:16 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:16 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:16 ERROR Can not run the algorithm
2025-06-15 08:58:16 INFO Run function 8 complete. FEHistory len: 1, AOCC: 0.0000
2025-06-15 08:58:16 INFO FeHistory: [213300.34512062]
2025-06-15 08:58:16 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:16 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:16 INFO AOCC mean: 0.0000
2025-06-15 08:58:16 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:17 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:18 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:18 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:18 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:18 ERROR Can not run the algorithm
2025-06-15 08:58:19 INFO Run function 8 complete. FEHistory len: 11, AOCC: 0.0000
2025-06-15 08:58:19 INFO FeHistory: [182833.91033531 228016.61566378 205412.08910543 143886.67275847
 172555.7841373  215790.21552906 145412.32237148 124757.77429607
 292974.72274936 208915.7418029  172478.82542892]
2025-06-15 08:58:19 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:19 INFO AOCC mean: 0.0000
2025-06-15 08:58:19 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:19 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:19 ERROR Can not run the algorithm
2025-06-15 08:58:19 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:19 ERROR Can not run the algorithm
2025-06-15 08:58:19 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:19 INFO Run function 8 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-15 08:58:19 INFO FeHistory: [238252.09530621 145343.65592471 167354.6388629  218126.89978968
 256780.5334083  197201.05371363 197711.04905809 234169.9053342
 201514.62985025 161263.83918804 167397.60273177 148215.01039525
 137781.99610643 167782.9821688  176603.75029282 280619.52786994
 154254.2898226  180350.44293142 219499.15559378 225432.67745122
 116165.87671342 197491.01795435 127916.74680772 147995.55565134
  83452.35501661 233403.6206456  187711.8881613  149751.43363044
 142391.9838459  161493.18202503 208370.00308527 220670.39625345
 147130.00965226 201341.2799974  151940.78894913 266620.83985203
 224780.28375265 229559.17282654 201843.3624755  176167.74353403
 179736.2457283  178387.64989053 240749.0811311  151140.36406081
 243590.50426212 154353.84674065 218496.01254855 147229.54032893
 212144.21723338 240555.79890187 177922.71446588 112933.55996367
 186161.22433113 159278.98452181 191200.05670749 164854.90881489
 122162.23121554 181708.95620953 149099.50559679 232333.12302298
 185743.51793896 149772.8126893  155161.30679712 206879.09193303
 259312.18239803 212540.07796389 272384.65800984 185517.47602971
 191809.25229187 211318.30209058 117132.44021285 192478.72787483
 147057.47104109 194320.58120919 112979.53071936 194803.35003302
 207104.9087338  196589.60143883 220741.26618191 216073.53804639
 226840.89265673 115972.97311502 227395.33356724 150988.67092523
 222529.60473332 155568.14180874 177488.12216138 168406.16031859
 274573.15620416 213675.98383009 222610.87929777 221934.36026078
 150342.63782816 209679.28513946 145250.36059691 129235.79887087
 192444.96458507 220116.53529517 202444.35445131 191743.97412739
 238134.69770378 151996.5471278  140053.02138902 266879.11847399
 175696.27446876 308187.47756139 146320.50469152 267014.73037655
 184687.83039738 163907.78291136 169055.41147812 164086.77725675
 215625.79190346 157464.86604978 174001.91895924 158689.94931969
 181973.00336465 227998.61125139 113236.61777675 248545.30412881
 170137.00315782 170028.08797056 228507.53117054 176561.94611881
 220945.08999889 157798.25017101 127181.30965271  98308.60440308
 176853.44726097 193943.56440949 234721.40179807  99936.4901396
 223604.72430312 152869.3942455  202210.06693737 148641.25111134
 164945.99705485 176516.69764186 223327.66103179 162315.7648191
 204976.34533644 188956.36912429 157891.56117156 156955.41808782
 129668.84062934 262345.93684875 213853.2042603  114180.96200459
 207814.36486729 186496.1584055  239714.29191315 215393.22245353
 234590.01765366 169301.15461556 264861.40023865 214085.2022951
 238659.31445601 195006.25727037 144524.05415714 222011.43403951
 189451.29176808 168315.24946256 180111.99608464 267344.92636733
 174905.7745828  227746.83915409 278160.56119641 259676.68596206
 144373.66972578 181510.73065243 175821.83011617 120331.55795724
 231262.41522166 248853.80336961 116688.81692571 163464.54358775
 188643.93207028 160440.95153724 138509.37255754 198169.19849416
 238045.23826316  99625.73102554 153978.89270311 183478.63116025
 209485.54680323 194353.4423788  183482.30110752 132349.10564237
 198179.16000053 237517.27896602 172416.90898995 208064.6393943
 180879.34396829 215260.37011866 200512.86475407 254147.42119201
 154845.66214129 241732.20259429 315306.06297848 185577.72412085
 212828.39072053 228157.19734551 126062.0899328  151889.05397233
 239497.23380744 163539.9697487  207669.78229928 176574.36616697
 124314.19136339 224034.83731742 199443.95841539 194809.60057537
 188689.85474351 330542.04490164 152195.40644036 132198.41973142
 211227.18217038 231451.62095463 262097.82154047 180576.88466426
 256120.03966339 129715.32808814 145136.60109533 208002.23234048
 185671.87516573 199349.9720757  209212.47111366  93518.004495
 183143.45963847 166936.79732128 186831.9596302  253659.58423483
 136581.87643337 242938.47624987 118021.5326531  112478.26908837
 250900.21950797 152086.96196889 208557.88967223 141021.95834972
 230224.96018211 366082.02283123 247730.85270688 143283.39425091
 221107.23967285 130326.27502854 224407.43624018 273593.8658475
 220821.16137918 244977.41616459 178848.81878932 160699.46436002
 296707.07755454 148812.9595155  164724.76958766 137019.64572731
 171769.87995317 179619.60475945 319063.17936186 160327.97700949
 186169.16886411 143690.50016544 219135.47825815 184927.83474873
 260643.59888614 150159.70495546 241824.11610897 179846.44332613
 131915.76024027 145565.85494018 196087.74040955 179190.60622159
 132523.93732274 144973.00569636 236669.7112401  143479.40002168
 201535.80735967 228234.27865337 170683.5743028  281746.53759473
 257405.39325681 177886.43249021 203272.79150992 235016.33263227
 163866.65833025 186508.68222411 171030.94908276 245912.63130754
 144811.04745478 274781.61131892 251801.9505051  141892.85919617
 140667.46196706 157004.52127915 150340.20186817 317257.94208104
 200378.42942464 184074.96424922 152988.0577947  134993.69094035]
2025-06-15 08:58:19 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:19 INFO AOCC mean: 0.0000
2025-06-15 08:58:19 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:19 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:19 INFO Run function 8 complete. FEHistory len: 20, AOCC: 0.0000
2025-06-15 08:58:19 INFO FeHistory: [186018.47681071 178160.58044543 186195.8348571  162458.70766198
 148525.46397895 175551.20031687  84465.59459256 170347.12060884
 202537.04856789 199676.17124953 149065.86086749 163216.43176716
 186493.93405844 183054.27658341 177253.54663171 150135.51031502
 161692.51109102 287548.27474776 142991.69707763 197318.75368124]
2025-06-15 08:58:19 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:19 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:19 INFO AOCC mean: 0.0000
2025-06-15 08:58:19 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:22 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:22 INFO FeHistory: [158517.03804911 213601.45235981 199224.85560697 ... 321622.12654757
 375343.46470034 390119.48717451]
2025-06-15 08:58:22 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:22 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:22 INFO AOCC mean: 0.0000
2025-06-15 08:58:22 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:23 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:23 INFO FeHistory: [176839.04450932 212985.13206488 223250.29585354 ...  32310.9417315
  32255.40293639  32169.4617048 ]
2025-06-15 08:58:23 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:23 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:23 INFO AOCC mean: 0.0000
2025-06-15 08:58:23 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:23 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:24 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:25 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:25 INFO FeHistory: [222931.22941335 233372.65512358 237445.34354872 ... 424496.55234361
 378130.83146212 371203.80370724]
2025-06-15 08:58:25 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:25 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:25 INFO AOCC mean: 0.0000
2025-06-15 08:58:25 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:25 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:25 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 34
}
]
.
2025-06-15 08:58:25 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:25 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0014
2025-06-15 08:58:25 INFO FeHistory: [176988.14369784 179327.0761207  177938.73985886 ...   -556.30282497
   -575.72930621   -455.2209018 ]
2025-06-15 08:58:25 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:25 INFO Multimodal (single component) AOCC mean: 0.0014
2025-06-15 08:58:25 INFO AOCC mean: 0.0014
2025-06-15 08:58:25 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:25 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 34
}
]
.
2025-06-15 08:58:25 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:26 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 33
}
]
.
2025-06-15 08:58:26 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:26 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 33
}
]
.
2025-06-15 08:58:26 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:27 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:27 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 32
}
]
.
2025-06-15 08:58:27 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:27 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 32
}
]
.
2025-06-15 08:58:27 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:28 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 31
}
]
.
2025-06-15 08:58:28 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:28 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:28 INFO FeHistory: [168616.08297567 189334.58334297 160238.09568061 ... 219613.96226313
 235774.49096451 250870.42758345]
2025-06-15 08:58:28 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:28 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:28 INFO AOCC mean: 0.0000
2025-06-15 08:58:28 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:29 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:29 INFO FeHistory: [248857.22636656 187406.75387351 150914.24824223 ...  10853.5484707
  10852.60977314  10854.5927519 ]
2025-06-15 08:58:29 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:29 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:29 INFO AOCC mean: 0.0000
2025-06-15 08:58:29 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:58:29 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:58:29 INFO Using LLM instance #0 (Model: gemini-1.5-flash)
2025-06-15 08:58:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:58:29 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:29 ERROR Can not run the algorithm
2025-06-15 08:58:29 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:29 INFO Run function 8 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-15 08:58:29 INFO FeHistory: [164328.891763   134326.14445806 146969.32859113 141192.09821045
 111062.04280463  97213.92644276 130067.05608002 264279.46119374
 194609.70238057  93534.74416487 188423.0698091  265172.40275235
 158780.80996163 169480.39245978 158556.5618566  206081.70334584
 120451.16000016 171465.40085824 141336.63581187 121500.57159838
 196363.47148067 238315.76233922 193538.35576214 158874.6355916
 156230.80642768 125696.04592514 186636.67699011 206135.39629359
 193723.59824564 181514.25111725 211980.13890265 220136.95452784
 203409.33292453 158844.51512281 219220.29826392 161439.97606683
 200205.9573865  190717.11874123 218942.4451621  186214.42417368
 251128.91234636  79096.77691168 130125.88758816 192791.95065184
 240041.16378663 162959.97496949 220624.09240725 310699.15076711
 271667.26969021 253392.16496583  98605.76300983 135923.04418104
 201359.29950221 170844.95705888 165134.31992017 145374.38323853
 138391.18017556 141373.71462547 199234.71675193 228316.21349574
 176325.16740552 188405.2753142  250377.65192493 339833.93868641
 197526.37424135 172926.19155001 145933.32967967 179390.13246045
 181996.60727377 256720.65914088 176949.63730984 246669.38861216
 148369.00447366 171857.97666033 132796.25171595 170633.71034424
 167464.34937151 303200.22641457 149630.90518875 172604.09076919
 258343.15273    238114.47801459 213164.15205654 256660.88733979
 196408.85435518 196418.52248256 134643.40504797 227216.61515495
 217875.78537253 262840.8088618  186857.98831246 200123.34103885
 126645.99774953 261642.85978811 296208.51960708 163491.64942538
 277823.05918922 221778.80198151 181036.68668484 308729.74547582
 228176.28417384 110139.75150235 272151.39635089 215316.57086744
 218117.22544873 107069.14916468 152202.69498283 129787.947779
 160111.76872146 122159.88909176 189584.8841938  220572.5634817
 289958.94923274 177480.66442792 270550.56433134 176638.10393073
 253412.02722861 152351.9602913  186683.19964967 160999.58022576
 145452.41190296 154657.46799487 178687.54962338 214526.24367021
 210919.43921438 176996.2497704  248736.73090923 277485.75539982
 207009.54560465 191414.50343525 130527.05332913 121661.21244947
 169860.45459029 219196.9946572  209145.87753303 236636.3503531
 221326.08981501 143284.72435223 240423.52675332 243371.67223986
 161675.18648472 258669.03246803 125043.40222178 101668.81387713
 130534.46645769 196471.29812341 176120.07747396 219396.64077555
 146686.27579049 194890.4951029  193685.11675236 252021.5202718
 177891.17736157 201356.37029943 286318.38962447 176377.43211767
 145424.51903329 147946.28869384 222838.17963356 175067.56981386
 230614.25700716 180964.21243844 155262.91228129 155877.709911
 153046.23684964 122029.16381614 155771.92516992 180193.55034247
 223079.92130645 154054.02785802 253026.80286905 193920.19323073
 153615.62403363 154657.64199003 242502.0404398  194898.24785149
 201731.30270639 266751.65910122 213730.99365037 176081.63366787
 221228.98926981 301048.80344511 168146.05078367 201464.79607774
 150253.63076685 142203.92221125 127189.27434104 127507.5233889
 246126.02502447 247474.70569869 125905.89418271 159632.86536194
 172268.4692012  240503.0854887  183021.63442132 159017.83403508
 188449.31607397 247662.8331344  184922.04556016 193401.56520946
 167829.10960242 152185.69738117 186792.0033467  152513.51618592
 207299.48034361 159554.45022336 237908.24700707 132216.83678703
 238101.4017625  143324.289597   234315.09503401 202435.19350734
 221245.56224936 232852.46370353 223925.91451935 191624.18827167
 228678.69158636 142753.68826439 171656.95994542 175439.46249716
 306092.28137661 166455.48402501 168545.280258   178565.07212969
 219614.81774084 160039.13996792 165232.68422873 158089.44141958
 238059.68769535 164679.70942076 258680.67551601 230845.77717047
 151207.8170686  127313.1322737  230395.21970444 154003.69499935
 270372.02072247 165497.86230533 176783.47998076 169036.34003063
 149263.42733153 199950.06979795 103622.30106148 231100.96767471
 223993.23414625 146327.98640743 189798.22348501 154105.45361299
 142382.17418221 180583.25759615 286628.84214671 225082.4053475
 226079.79472023 199264.66854412 167955.36199499 271578.66210811
 205933.36652123 169884.26546674 145316.81909529 176896.74145916
 176434.3818315  134449.27673337 157569.81461781 158950.2805811
 207774.11382521 118561.21540603 143537.24733631 183840.23927403
 223824.22498005 129264.68582216 190612.57045541 155116.42609066
 117134.18802204 142025.92021999 184671.10570094 155504.37124903
 159068.85625929 166444.01723331 132735.37248244 166849.46631222
 135341.49718785 202251.87030242 194415.67808349 151814.13391403
 170679.31935676 165070.04612828 223122.65843703 141350.94430095
 136186.9362715  255340.42149462 223921.65381851 145843.76452802
 221037.17870995 159698.19130195 162139.83459053 160864.59704044
 148222.70945334 187517.9461692  211947.39467808 167656.83916921]
2025-06-15 08:58:29 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:29 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:29 INFO AOCC mean: 0.0000
2025-06-15 08:58:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:58:29 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_api_rotations.py", line 159, in initialize_single
    new_individual = chosen_llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 30
}
]
.
2025-06-15 08:58:31 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:34 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:58:34 ERROR Can not run the algorithm
2025-06-15 08:58:34 INFO Run function 8 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-15 08:58:34 INFO FeHistory: [157462.46295804 253157.38541632 177119.72829791 138806.61394046
 150409.37546793 210297.94222558 133675.0635497  246794.93955131
 251689.21007593 215172.37594926 158166.04207533 246068.42310779
 147939.64236617 300192.36909307 176425.50168387 297762.95331515
 104160.59010418 123435.83151051 260623.76714207 230771.84032743
 174428.43299785 230254.10105771 161768.99815914 180421.68526719
 154023.42722962 133429.67548877 197964.16061549 173376.96778257
 206668.99013675 178444.74278578 243884.68787042 292652.10797831
 244402.46452693 262527.86782177 295441.90999387 182247.09740794
 171960.7464735  165023.92721988 140562.25314566 232822.06799068
 162338.58467276 213966.18729655  85175.9953409  114333.68847836
 155233.51810048 233409.87622944 174063.72055915 313845.39570771
 132045.93395623 211324.44190748 167797.36510156  87249.19460321
 209941.47159885 237746.72423041 178152.12224731 225025.53195488
  93747.36969394 195542.53430623 171876.52628898 126414.5362358
 223673.05078683 186094.12952054 185417.79749289 172454.13442235
 210338.59340324 268323.7041199  236897.73744038 147496.65829733
 205290.09546236 229159.30210406 149951.12062489 194655.55564085
 238676.35404515 137066.5234512  234171.04274821 155268.58253437
 147351.75151048 196004.6815964  196282.25778246 241832.91631578
 184850.44731805 145478.58755834 291903.2255071  174998.34453404
 302386.28959469 169156.53406849 284853.45666169 289299.39122649
 137757.37587888 220346.54935961 186621.77375593 189241.94274869
 179859.80593457 100748.03740016 320284.82101787 131238.7972803
 140976.86114318 121149.4510634  156379.76950466 202882.10323337
 159839.48283446 277221.96614001 167490.99132216 262829.52908548
 166780.56047661 224263.11834453 169880.72831906 227650.34334525
 269425.48117818 185060.48623788 168077.63644721 191960.02720556
 118895.34342762  93820.13954124 204209.97901761 262913.47905877
 187248.32191455 187977.42970724 134502.65446527 117594.59661461
 180710.08622042 189257.71728035 243256.9290271  281813.47819737
 170200.52304285 249066.36031977 190142.54346445 198137.43471715
 300973.60300222 170847.40250941 159058.96702966 335727.19564827
 154795.27822333 263400.68212228 185434.28471911 109484.22862116
 200290.43376512 136988.79792782 169505.61860982 257315.01103361
 273214.98663617 109586.11549521 167912.06592789 171155.855062
 243651.48816193 236677.604885   190622.3720542  161185.30014289
 182716.14985901 109432.25284021 171710.14296033 193493.6264654
 176248.58005617 186329.94434437 166862.30678701 141246.279797
 113606.62804666  73362.49375697 123327.278508   310887.08341477
 242830.10056082 185147.12876055 157889.93906743 173157.00851946
 234837.99695837 173100.21061694 135062.53180307 245449.20433276
  79361.42063933  95415.41978189 159664.64387182 201664.5719998
 161823.83591304 255637.19967372 193480.94935785 183700.41899209
 135231.38694538 177905.59248726 261685.44509632 161355.17741453
 153877.75868328 249237.81031646 141454.82729368 156739.91720763
 209077.90785828 226268.72357903 239576.93456355 150499.53007306
 275367.72765597 252121.67489077 198912.59695132 216107.89695439
 218331.84671702 218179.86679002 169648.19872998 212475.21061961
 215319.80254639 196301.01537078 202540.17018197 153153.04141595
 176524.89761705 178641.46287705 136262.71936358 136524.26785761
 166463.89615588 192746.61468245 156851.86406376 155616.4964277
 198361.38859031 177911.27265397 192509.84933585 144835.9944936
 142351.53504459 172391.38878074 182142.05735152 196282.45376037
 202772.13851342 270730.54494987 173399.26962333 184457.50290728
  82224.42862956 179931.63419436 169829.81128479 192189.65788644
 117339.65655222  84712.74138929  99031.69542599 135836.98691012
  81034.98827409 239033.49937538 166373.87254254 176057.85647473
 203521.80358651 210167.08835379 168742.27522984 168361.01675022
 171715.23037618 213153.10498332 104985.91258646 162763.43724958
 179014.83426553  67773.06894052 169542.95105999 297974.56979514
 168494.65480175 172243.15099428 151366.15275286 273222.47803205
 207586.12776762 207413.25583998 135870.35389626 265016.6276051
 254377.34616432 208702.94254713 218460.43911226 193006.76610862
 176563.27034994 134406.40094269 246865.20086962 256703.12956735
 149447.47193057 149829.72000638 192831.64548481 187236.11850876
 244488.30751587 225977.07874994 161547.67820229 266700.81756903
 233822.86813888 197690.09460821 166236.14378559 182353.57827078
 227231.27727059 239859.15904859 247906.76402285 176210.92390559
 127076.58882208 220309.77257463 206912.01774402 191441.0059049
 166591.77172421 230320.69247588 261021.27575017 205163.64160924
 220791.99961634 158954.06858894 113710.36140136 173827.06743163
 151147.04219713 246994.32359299 140594.50875664 255450.52595838
 139669.01855204 180757.11127156 197873.57283468 121140.55053758
 210968.88947266 141545.9096349  214998.6920953   95616.69368812]
2025-06-15 08:58:34 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:34 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:34 INFO AOCC mean: 0.0000
2025-06-15 08:58:34 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:34 INFO FeHistory: [192494.78092285 164919.34101461 226525.78459786 ... 105281.79896864
 116467.17356855  72556.12806708]
2025-06-15 08:58:34 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:34 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:34 INFO AOCC mean: 0.0000
2025-06-15 08:58:35 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:35 INFO FeHistory: [127494.16736805 134110.32716553 180890.70935738 ...  21198.29749183
  21194.5125645   21148.29876929]
2025-06-15 08:58:35 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:35 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:35 INFO AOCC mean: 0.0000
2025-06-15 08:58:38 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:58:38 INFO FeHistory: [251707.4001082  146192.03288317 266740.66122085 ...  27201.30798743
  27049.56138106  26899.61057082]
2025-06-15 08:58:38 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:38 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:38 INFO AOCC mean: 0.0000
2025-06-15 08:58:48 INFO Run function 8 complete. FEHistory len: 25000, AOCC: 0.0000
2025-06-15 08:58:48 INFO FeHistory: [175811.57118938 176236.09667115 175882.2376478  ...  69218.73151799
  69272.29340493  69259.91485303]
2025-06-15 08:58:48 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:58:48 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:58:48 INFO AOCC mean: 0.0000
