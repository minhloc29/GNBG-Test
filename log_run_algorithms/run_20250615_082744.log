2025-06-15 08:27:52 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:52 ERROR Can not run the algorithm
2025-06-15 08:27:53 INFO Run function 8 complete. FEHistory len: 5, AOCC: 0.0000
2025-06-15 08:27:53 INFO FeHistory: [200666.55592175 201794.46591699 197683.61227361 203149.0748945
 196022.756094  ]
2025-06-15 08:27:53 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:27:53 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:27:53 INFO AOCC mean: 0.0000
2025-06-15 08:27:53 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:53 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:53 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:53 ERROR Can not run the algorithm
2025-06-15 08:27:53 INFO Run function 8 complete. FEHistory len: 302, AOCC: 0.0000
2025-06-15 08:27:53 INFO FeHistory: [164484.61181048 190288.98200776 166758.64518173 171877.80952685
  96685.11588644 173795.33313591 126337.20545223 262739.645631
 135096.19303372 204227.47509803 344517.30295199 226292.47984178
 165884.49565433 170910.55024624 314512.99841886 354830.06272404
 192573.20471371 145013.16908243 235728.52958555 227476.82403517
 117542.98615559 176550.43775657 102503.84516835  79998.95199643
 151910.78985569 141001.47715786 239419.05057131 284857.0602507
 159931.47841729 152371.29975982 263887.37620639 116493.10846275
 195343.42249228 263164.02345221 190269.63349383 237459.50371722
 177095.83376025 243367.15077537 164483.34575284 143800.95680044
 239367.65151953 191621.11457727 208117.3021948  195098.98598427
 230468.62149142 226191.37679543 194807.44911645 212472.3238854
 139886.27278428 202859.29041139 129560.34397309 189997.43804005
 244423.12429998 217994.04055234 227660.57815231 203864.44769801
 280774.29460511 137462.11047904 126316.32249747 189646.6644252
 115615.50177694 137266.84999556 190525.77606005 266808.6681754
 322000.9105896  125866.87185736 187141.65329905 187181.91501478
 137465.08370996 218455.7570159  201263.57973248 219236.69675006
 252265.11030278 202948.6334569  221311.61827322 177442.57973658
 173005.73092065 287187.66006239  99870.91813672 175360.95058825
 218085.43591469 155333.48282552 167011.07846451 161751.6438504
 104685.33474189 120898.24254843 136453.06610457 304072.23372144
 125520.40959251 216994.84631189 296706.50722147 216825.22576498
 170655.93013638 218469.23476178 145434.38772927 178561.3187919
 152233.01572036 159072.23122826 182252.22553019 193338.92109112
 163519.29376755 258070.9127186  229859.38479494 192431.13409693
 225626.10471914 217991.71654919 196139.23991949 244193.50576858
 146252.94042072 146675.89470158 160475.4771906  187439.37538454
 219315.65069579 250472.82254788 136883.13807753 151344.35959362
 121267.02797245 232191.68118421 135400.74824457 321613.12717819
 186500.73958325 177904.94590848 153948.11786896 131505.16837628
 231140.93166084 139812.49275991 332296.24187477 189148.44775657
 166408.57000274 179280.04803055 219707.37168915 168638.1650579
 259122.03401563 203560.92388237 193887.96831494 151827.8585714
 152805.83853666 219320.21843005 192945.98933396 144126.70528487
 152188.71364334 146125.8210458  214638.09542616 205064.87653267
 181549.24005074 186834.8891537  185479.2493054  141193.14083283
 156153.85756311 153471.42335398 158985.2615695  147300.92272009
 198121.97603171 149812.27080837 262642.34534918 176182.49651781
 162089.19015827 191742.52904895 171047.00820406 168471.08207775
 305012.6204272  114511.5285943  166946.13082226 171186.43123532
 182954.41195997 197094.23686227 131788.34614746 335273.9555431
 211838.37211788 152916.54820998 117339.15060377 302816.55863747
 180208.28308228 183735.32759033 149826.71635815 192956.67590028
 165977.09213107 188985.13209894 168406.65525601 163902.76031993
 204901.15068524 206069.17637285 203866.08238446 223899.24696721
 187198.6905017  157084.79765391 176970.90589296 137811.29776134
 117776.54036666 217873.97111447 205672.47825972 194263.41892699
 217971.94303045 184199.68138277 173288.55457762 191965.65099987
 199768.02673834 230344.21109394 146018.04385138 121412.08491343
 180700.72595597 105969.88104687 193432.40194831 163753.82203093
 132971.90651568 229928.22452438 247794.89498775 242550.93657232
 155502.4001185  142057.43936502 160857.52484496 122246.82711908
 218940.12638559 175237.30500879 182124.22570052 180953.38648619
 203112.4978799  211582.55288785 199578.6293139  245062.66972369
 186678.17122449 123976.59078236 138609.25132418 200459.49344181
 246604.79536697 170399.92841378 205944.66739874  87344.28476102
 127915.49152586 212002.5962973  113718.40605151 166698.25408475
 247583.48093714 181436.33901785 109899.39396358 150597.57894871
 219696.86113656 243182.73559763 156177.832809   182288.86150849
 285193.07500406 160076.73935861 132440.38229801 149641.40401614
 143864.8431612  243047.7402809  171287.06678771 131179.35930493
 108518.11801846 109309.04559804 125413.29137452 196207.7071074
 289466.92097759 136006.75681202 103951.20476137 249645.90082791
 171311.25757331 115286.13932806 134334.82226436 174348.79896937
 177120.55544637 235047.24866043 167932.71514538 240173.18312991
 243199.99076607 162065.21511585 214872.9111435  153964.93239659
 180505.101468   212047.04119664 259756.9069211  142283.90439765
 159390.97937165 134985.10619949 187976.64162734 190094.08320133
 197594.67291228 160983.3865207  223712.33863802 219437.4471323
 177020.3398338  141454.16824276 197870.44340603 194120.07323398
 154913.92812975 185612.03002803 276707.83779175 207360.49213555
 164864.12412611 184690.56911678 161082.32186734 161475.98271011
  89560.18727099 181494.94840447 256190.46709715 134288.82914863
 173954.75206184 204083.61754448 288808.62316687 242512.36068354
 211419.88192733 119231.05387079]
2025-06-15 08:27:53 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:27:53 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:27:53 INFO AOCC mean: 0.0000
2025-06-15 08:27:54 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:54 ERROR Can not run the algorithm
2025-06-15 08:27:54 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:54 INFO Run function 8 complete. FEHistory len: 20, AOCC: 0.0000
2025-06-15 08:27:54 INFO FeHistory: [200243.03781708 228120.333482   238048.2301773  235751.32253623
 193299.29738853 142394.1540519  136670.98420279 192798.13347563
 128666.55194739 176379.57035059 210746.25876499 218403.35500497
 172716.40494111 211119.75865497 253785.86389924 169807.91929883
 135977.946311   191597.15462627 171371.72282902 176911.51852178]
2025-06-15 08:27:54 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:27:54 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:27:54 INFO AOCC mean: 0.0000
2025-06-15 08:27:54 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:56 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:27:56 ERROR Can not run the algorithm
2025-06-15 08:27:56 INFO Run function 8 complete. FEHistory len: 300, AOCC: 0.0000
2025-06-15 08:27:56 INFO FeHistory: [200612.57483582 230163.34682573 149538.48386469 168635.63793715
 200918.05601562 138906.89349901  88963.81402981 135755.20904938
 254027.56767899 210308.24019093 158086.37993004 310387.49793965
 193355.39744255 145899.20399919 197913.08353933 147901.840254
 164871.64302554 155644.85116398 255514.45896723 224398.83697831
 273156.30387402 193639.02498641 197042.47353927 127680.49353928
 189254.52599186 203622.77778095 329812.23131841 218946.36265148
 194731.50140336 198309.91572076 132096.69163565 182501.55813168
 248926.73876381 169088.64457235 224006.56103679 178369.16196946
 182353.84498611 152522.44563285 239078.31643716 225935.93371193
 224109.79254278 153778.9685559  274822.00141868 258702.15504353
 184334.5738875  224127.54176449 210471.92096495 133063.21107028
 179893.55715802 169531.66009469 128455.62163698 289594.49638269
 175333.851614   139877.67502417 232669.55333762 233011.26747724
 190195.01009744 191425.33676129 198415.25673131 190780.49331038
 175166.85777809 223339.1838276  178381.16601223 231131.54438868
 197001.69747663 271490.55144024 210576.27284374 303968.16353043
 169333.64622659 172950.25863032 227659.06679347 131269.86432518
 173432.85854416 277396.20273159 105801.96981116 169172.07895973
 147082.05667794 179795.41085749 200653.92334509 149746.0909544
 204882.41849834 146632.25718646 207069.33597314 124080.89193365
 159473.34738557 152372.19615058 245539.26179754 212467.20694604
 135189.6616762  184068.22306237 179653.62430553 180319.08271864
 139788.50471212 190086.61075062 231865.33011066 287077.27763902
 229546.2335216  253953.97580075 179624.22384371 119975.35576855
 205697.72429113 187859.10468629 137039.27411036 178132.09802957
 133619.7410869  155439.09581026 114541.99810986 198057.72735878
 226869.83571985 142668.91944265 169549.71901513 124473.70072447
 231788.37099187 175866.31863083 229694.17816088 146320.18222144
 286614.69478706 220763.65732194 251041.14917533 269286.46954493
 220330.74745724 265629.90753678 233084.35363859 215189.36614199
 209581.72548603 194197.82407974 159044.55800856 215758.22775036
 165638.56550884 183714.06735959 200713.93112963 147694.34556589
 153086.71575629 154525.39849799 151712.10941098 221494.88201787
 162273.89900173 174339.45699273 148651.39731541 205748.6979801
 135642.9621877  212476.0517809  208579.33227266 153844.30696618
 138112.13464717 207975.79035404 178510.12055603 199311.98135559
 197262.87834452 202228.42740535 165102.04678082 185870.80808596
 171253.63293159 331516.66035017 230314.27061929 194489.58865877
 181218.26195936 223778.85831106 105257.77848424 167059.80247213
 242529.59657269 236611.04175833 186263.66012355 288386.18049892
 283821.43241318  99288.57375758 223845.58774817 242458.8241204
 178064.61997656 198079.95872494 149642.44499957 169503.0780147
 171658.20061573 230186.26625997 132641.83601149 141284.68782812
 168234.07367039 191053.03858045 258394.21760432 259929.49659413
 198273.37682977 183369.19029801 155252.56592849 148796.49707636
 222569.71119742 179837.48550746 187807.65702791 158526.7544462
 178221.10220634 161298.68442096 185236.96740459 215322.39572293
 221360.19314768 273460.38217322 168854.63964119 210763.39325469
 203834.89225157 113299.35275247 186137.87017473 211287.39534212
 189580.09221813 184008.45433044 185756.59415925 201390.87459388
 202793.88593497 189739.74784177 215275.83331977 184208.86756892
 216379.40879876 144298.51354928 109871.82344918 199945.78020357
 218120.52571668 171961.43197395 288168.75389536 155173.59159272
 173716.07270837 232970.72255209 212443.88167267 200299.44370067
 142828.93128252 238631.30696572 168979.32955974 172457.79422409
 257345.04308784 154879.47595398 162213.54104031 246704.73715716
  96146.48068171 194718.51712108 244524.78762507 125711.34259715
 109128.16877953 188598.14708432 169567.43864925 148998.71605839
 191872.01568765  92843.3282069  149596.00241278 206063.49731002
 224876.01408277 195260.644775   198709.12083974 169896.84942795
 186845.40549231 179819.13967947 163915.78324291 211195.01980529
 229789.53863317 274510.57891568 149144.18900598 191545.93914371
 136910.7267732  169832.46636403 197361.92746724 217121.14084278
 246241.29894528 204514.93295596 279450.50974963 195995.71820012
 209860.65630109 144215.1327226  123292.28971963 227021.03115283
 167850.210078   104586.68772611 241691.09099585 160396.71800117
 230344.1076529  191859.77840147 223925.83478672 144647.00008406
 213010.28651693 159021.24753649 279174.82729332 271581.30473709
 212149.58826629 232532.89488406  97836.11044118 202038.56644541
 148797.47912627 223714.00137232 251716.77645024 198562.55639491
 166978.88607395 145747.17755643 148330.99844365 165292.49520786
 204411.46533508 146184.36531563 233424.97460266 138866.57183997
 167666.55448997 191811.83997242 248439.28355589 208507.99264824
 249352.10427974 120535.65696083 233964.41463071 227398.45290348]
2025-06-15 08:27:56 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:27:56 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:27:56 INFO AOCC mean: 0.0000
2025-06-15 08:27:59 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:27:59 INFO FeHistory: [252390.2044066  106692.66985108 235898.23110113 ...   9842.91653482
  13937.84029934  12520.64975693]
2025-06-15 08:27:59 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:27:59 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:27:59 INFO AOCC mean: 0.0000
2025-06-15 08:27:59 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:28:00 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:28:01 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:28:06 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0026
2025-06-15 08:28:06 INFO FeHistory: [169805.45187041 251965.20628152 162126.20100244 ...   -610.56883243
   -581.33805191   -581.91668563]
2025-06-15 08:28:06 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:28:06 INFO Multimodal (single component) AOCC mean: 0.0026
2025-06-15 08:28:06 INFO AOCC mean: 0.0026
2025-06-15 08:28:06 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 53
}
]
.
2025-06-15 08:28:06 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:28:07 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 52
}
]
.
2025-06-15 08:28:07 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:28:07 INFO FeHistory: [163758.76197936 220103.2525281  118152.96953253 ... 102056.62980321
  99863.12515515  74417.25462036]
2025-06-15 08:28:07 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:28:07 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:28:07 INFO AOCC mean: 0.0000
2025-06-15 08:28:07 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 52
}
]
.
2025-06-15 08:28:07 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:28:07 INFO FeHistory: [245509.04428153  89289.0835532  143469.2044331  ...  32443.40842999
  32443.40757356  32443.40496603]
2025-06-15 08:28:07 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:28:07 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:28:07 INFO AOCC mean: 0.0000
2025-06-15 08:28:07 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 52
}
]
.
2025-06-15 08:28:07 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 52
}
]
.
2025-06-15 08:28:08 INFO --- GNBG Problem Parameters for f8 ---
  Dimension: 30, MaxEvals: 500000
  Search Bounds: [-100, 100]
  Number of Components: 1
  Known Optimum Value: -656.788998
  Lambda (Curvature): [1]
  Mu (Asymmetry/Depth): [0.2 0.2]
----------------------------------------
2025-06-15 08:28:08 ERROR Can not run the algorithm
2025-06-15 08:28:08 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 51
}
]
.
2025-06-15 08:28:08 INFO Run function 8 complete. FEHistory len: 11, AOCC: 0.0000
2025-06-15 08:28:08 INFO FeHistory: [253898.50237064 274045.48646904 279882.66727271 191714.79197351
 270931.72810342 224666.5848647  140145.92011874 117845.34324831
 161490.36550902 174615.31072779 257822.69507937]
2025-06-15 08:28:08 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:28:08 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:28:08 INFO AOCC mean: 0.0000
2025-06-15 08:28:08 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 51
}
]
.
2025-06-15 08:28:08 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 51
}
]
.
2025-06-15 08:28:08 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 51
}
]
.
2025-06-15 08:28:08 INFO An exception occured: Traceback (most recent call last):
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llamea_multi_prompts.py", line 150, in initialize_single
    new_individual = self.llm.sample_solution(session_messages, role_index=role_index)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 106, in sample_solution
    message = self.query(session_messages)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/Documents/Code/LLMdesignedEA-comp/llamea/llm.py", line 278, in query
    response = chat_session.send_message(last["content"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 578, in send_message
    response = self.model.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/generativeai/generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/macbook/miniconda3/envs/eoh/lib/python3.12/site-packages/google/api_core/grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-1.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 15
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 51
}
]
.
2025-06-15 08:28:09 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:28:09 INFO FeHistory: [253308.17489999 218305.75611715 218305.75607084 ... 460280.93628256
 460280.93629479 460280.93628439]
2025-06-15 08:28:09 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:28:09 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:28:09 INFO AOCC mean: 0.0000
2025-06-15 08:28:12 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:28:12 INFO FeHistory: [163281.55667175 175342.12565782 164651.81554346 ...  92661.34691102
  26038.95252926  59101.19531997]
2025-06-15 08:28:12 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:28:12 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:28:12 INFO AOCC mean: 0.0000
2025-06-15 08:28:46 INFO Run function 8 complete. FEHistory len: 50000, AOCC: 0.0000
2025-06-15 08:28:46 INFO FeHistory: [136375.27079354 180610.37424011 179745.57045852 ...  30914.73189784
  30914.740816    30914.75147487]
2025-06-15 08:28:46 INFO Expected Optimum FE: -656.7889979935655
2025-06-15 08:28:46 INFO Multimodal (single component) AOCC mean: 0.0000
2025-06-15 08:28:46 INFO AOCC mean: 0.0000
