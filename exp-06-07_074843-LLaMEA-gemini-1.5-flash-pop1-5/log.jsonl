{"id": "dada8287-0f11-4106-a99d-ada366c80775", "fitness": 0.02367251112920893, "name": "HybridPSO_NelderMead", "description": "A hybrid algorithm combining a modified particle swarm optimization with a local search using Nelder-Mead to refine promising solutions.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NelderMead:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n                        \n            # Local search with Nelder-Mead for the best solution\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': min(100,self.budget - self.eval_count)})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n            else:\n                break\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_NelderMead got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07101753338762679]}}
{"id": "29cb9318-23ce-4679-976e-01b8695ed479", "fitness": 0.022104705901444994, "name": "HybridPSO_NelderMead_Improved", "description": "Hybrid PSO with Nelder-Mead local search, improved swarm initialization for better exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NelderMead_Improved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        #Improved swarm initialization: Latin Hypercube Sampling for better initial diversity\n        swarm = self._lhs_initialization(self.swarm_size, self.dim, self.lower_bounds, self.upper_bounds)\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n                        \n            # Local search with Nelder-Mead for the best solution\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': min(100,self.budget - self.eval_count)})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n            else:\n                break\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n\n    def _lhs_initialization(self, n_samples, n_dim, lower_bounds, upper_bounds):\n        samples = np.zeros((n_samples, n_dim))\n        for i in range(n_dim):\n            values = np.random.permutation(np.linspace(0,1,n_samples))\n            samples[:,i] = lower_bounds[i] + values * (upper_bounds[i]-lower_bounds[i])\n        return samples", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_NelderMead_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["dada8287-0f11-4106-a99d-ada366c80775"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06631411770433498]}}
{"id": "3ccc5e27-fcb4-4ca1-bff5-064353d53455", "fitness": 0.023480722891470473, "name": "HybridPSO_NelderMead_Improved", "description": "A hybrid algorithm combining improved particle swarm optimization with a local search using Nelder-Mead to refine promising solutions, using adaptive inertia weight.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NelderMead_Improved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.inertia_weight = 0.4 + 0.3 * (1 - self.eval_count / self.budget) #Adaptive inertia weight\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n                        \n            # Local search with Nelder-Mead for the best solution\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': min(100,self.budget - self.eval_count)})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n            else:\n                break\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_NelderMead_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["dada8287-0f11-4106-a99d-ada366c80775"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07044216867441142]}}
{"id": "37a8ccf1-5141-4bea-886d-3ce36ed3d60e", "fitness": 0.023797502542440428, "name": "EnhancedHybridPSO_NelderMead", "description": "Enhanced Hybrid PSO-NelderMead with adaptive inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n                        \n            # Local search with Nelder-Mead for the best solution\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': min(100,self.budget - self.eval_count)})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n            else:\n                break\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_NelderMead got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["dada8287-0f11-4106-a99d-ada366c80775"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07139250762732129]}}
{"id": "f69bd7c9-9c35-47ee-bb08-3abbe6b47569", "fitness": 0.024139326661275856, "name": "EnhancedHybridPSO_NelderMead_Dynamic", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size adjustment based on exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n                        \n            # Local search with Nelder-Mead for the best solution\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': min(100,self.budget - self.eval_count)})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n            else:\n                break\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["37a8ccf1-5141-4bea-886d-3ce36ed3d60e"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07241797998382757]}}
{"id": "b75c690c-24f5-4649-8a5c-ac68e76c61f8", "fitness": 0.025137105491421115, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, and improved local search intensification.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.1 * self.budget), self.budget - self.eval_count) #Allocate 10% of budget to local search\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["f69bd7c9-9c35-47ee-bb08-3abbe6b47569"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07541131647426334]}}
{"id": "3d1d7c5a-4e63-42f7-aeb5-92886df335c0", "fitness": 0.02356358925301609, "name": "HybridDEPSO_DynamicAdaptive", "description": "Hybrid Differential Evolution and Particle Swarm Optimization with dynamic population size and adaptive mutation strategy.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEPSO_DynamicAdaptive:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.population_size = int(np.sqrt(self.budget)) #Heuristic population size\n        self.F = 0.8 # Mutation factor for DE\n        self.CR = 0.9 # Crossover rate for DE\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros_like(population)\n        personal_bests = population.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        while self.eval_count < self.budget:\n            #Dynamic population size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.population_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust population size dynamically\n\n            #Differential Evolution\n            for i in range(self.population_size):\n                a, b, c = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, self.lower_bounds, self.upper_bounds)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_fitness = objective_function(trial.reshape(1,-1))[0]\n                self.eval_count +=1\n                if trial_fitness < personal_best_fitnesses[i]:\n                    personal_bests[i] = trial\n                    personal_best_fitnesses[i] = trial_fitness\n                    if trial_fitness < self.best_fitness_overall:\n                        self.best_solution_overall = trial\n                        self.best_fitness_overall = trial_fitness\n\n            #Particle Swarm Optimization\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight and mutation factor\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                self.F = 0.5 + 0.3 * np.exp(-self.eval_count / self.budget) #Adaptive mutation\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - population[i]) + self.social_coeff * r2 * (self.best_solution_overall - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], self.lower_bounds, self.upper_bounds)\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDEPSO_DynamicAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07069076775904827]}}
{"id": "dae4e213-8037-43fc-bf91-e13826b029fa", "fitness": 0.023505937121452505, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search intensification, and refined exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.2 * self.budget), self.budget - self.eval_count) #Allocate 20% of budget to local search instead of 10%\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07051781136435752]}}
{"id": "3a2fed22-2507-44d3-ac30-12e865874ae2", "fitness": 0.02338614304229909, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and refined exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.6 + 0.4 * exploration_rate)) # Refined exploration-exploitation balance #This line is changed\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.1 * self.budget), self.budget - self.eval_count) #Allocate 10% of budget to local search\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07015842912689726]}}
{"id": "aa82bb0b-6525-46a2-8d49-f312409b576a", "fitness": 0.024123494218740705, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search intensification, and a refined exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.6 + 0.4 * exploration_rate)) # Refined exploration-exploitation balance\n            \n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.1 * self.budget), self.budget - self.eval_count) #Allocate 10% of budget to local search\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07237048265622212]}}
{"id": "c3b0f57e-1070-4435-9b3c-5ca2f9630fa6", "fitness": 0.024463583434741903, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and refined Nelder-Mead termination criteria.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.15 * self.budget), self.budget - self.eval_count) #Increased local search budget\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget, 'xatol':1e-10, 'fatol':1e-10}) #Added termination criteria\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0733907503042257]}}
{"id": "313ab33e-2e4a-4c01-96f1-771325c5bc52", "fitness": 0.022573607299986337, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and refined Nelder-Mead termination criteria.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.1 * self.budget), self.budget - self.eval_count) #Allocate 10% of budget to local search\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget, 'xatol':1e-10}) #Added xatol for refined termination\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06772082189995901]}}
{"id": "3e0c68db-d80f-488b-ba52-cb4157fc5be3", "fitness": 0.02353729892112234, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search intensification, and refined exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.2 * self.budget), self.budget - self.eval_count) #Increased local search budget\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07061189676336702]}}
{"id": "20fc334e-20c9-4c8a-a720-6443ba2304a3", "fitness": 0.023394214150144477, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and refined parameter tuning for better exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.2 * self.budget), self.budget - self.eval_count) #Allocate 20% of budget to local search\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07018264245043343]}}
{"id": "6769d997-ed9f-44ab-a60f-3d6f4050cbb3", "fitness": 0.023050491712684695, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search intensification, and refined exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.15 * self.budget), self.budget - self.eval_count) #Increased local search budget\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06915147513805409]}}
{"id": "4def8962-1c65-4c82-82f1-6d4ecde7513b", "fitness": 0.022278251264893443, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Elitism", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and elitism.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Elitism:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.2 * self.budget), self.budget - self.eval_count) #Increased local search budget\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Elitism got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06683475379468033]}}
{"id": "afa7e93a-7c2a-4943-b385-d7891219e574", "fitness": 0.022352771782732095, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and refined parameter tuning for better balance between exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.2 # Refined parameter\n        self.social_coeff = 1.2 # Refined parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.1 * self.budget), self.budget - self.eval_count) #Allocate 10% of budget to local search\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06705831534819628]}}
{"id": "4e7b975b-bbfd-40ba-8578-3c8b3ac2af6f", "fitness": 0.02305877459200333, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Cauchy", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and Cauchy mutation for exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import cauchy\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Cauchy:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n                #Cauchy Mutation\n                swarm[i] += cauchy.rvs(loc=0, scale=0.1, size=self.dim)\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.1 * self.budget), self.budget - self.eval_count) #Allocate 10% of budget to local search\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Cauchy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06917632377600999]}}
{"id": "28595f8e-231b-4fdf-bd28-704852186a54", "fitness": 0.024074120816676568, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search intensification, and refined exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.15 * self.budget), self.budget - self.eval_count) #Increased local search budget\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0722223624500297]}}
{"id": "1e102306-824f-48ff-86c7-6d045831fe8b", "fitness": 0.0237396775973245, "name": "EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined", "description": "Enhanced Hybrid PSO-NelderMead with dynamic swarm size, adaptive inertia weight, improved local search, and refined exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None \n        self.best_fitness_overall = float('inf')\n        self.swarm_size = int(np.sqrt(self.budget)) #Heuristic swarm size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        if self.dim > 0:\n            self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n            self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n            self.eval_count +=1\n        else:\n            self.best_solution_overall = np.array([])\n\n        swarm = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        personal_bests = swarm.copy()\n        personal_best_fitnesses = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, swarm)\n        self.eval_count += self.swarm_size\n\n        while self.eval_count < self.budget:\n            #Dynamic swarm size adjustment\n            exploration_rate = 1 - (self.eval_count / self.budget)\n            self.swarm_size = int(np.sqrt(self.budget) * (0.5 + 0.5 * exploration_rate)) # Adjust swarm size dynamically\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                #Adaptive inertia weight\n                self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n                velocities[i] = self.inertia_weight * velocities[i] + self.cognitive_coeff * r1 * (personal_bests[i] - swarm[i]) + self.social_coeff * r2 * (self.best_solution_overall - swarm[i])\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(swarm)\n            self.eval_count += self.swarm_size\n            for i in range(self.swarm_size):\n                if fitness_values[i] < personal_best_fitnesses[i]:\n                    personal_bests[i] = swarm[i]\n                    personal_best_fitnesses[i] = fitness_values[i]\n                    if fitness_values[i] < self.best_fitness_overall:\n                        self.best_solution_overall = swarm[i]\n                        self.best_fitness_overall = fitness_values[i]\n\n            #Improved Local search intensification\n            local_search_budget = min(int(0.15 * self.budget), self.budget - self.eval_count) #Increased local search budget by 50% for better exploitation.\n            if local_search_budget > 0:\n                res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxfev': local_search_budget})\n                if res.fun < self.best_fitness_overall:\n                    self.best_fitness_overall = res.fun\n                    self.best_solution_overall = res.x\n                    self.eval_count += res.nfev\n\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSO_NelderMead_Dynamic_Improved_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b75c690c-24f5-4649-8a5c-ac68e76c61f8"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0712190327919735]}}
